{
  "university_name": "Stanford University",
  "policies": [
    {
      "policy_title": "Report of the AI at Stanford Advisory Committee",
      "policy_url": "https://provost.stanford.edu/sites/g/files/sbiybj29391/files/media/file/ai-at-stanford-report.pdf",
      "publisher": "Office of the Provost",
      "last_updated": "January 9, 2025",
      "scope": "university-wide",
      "policy_types": [
        "integrity",
        "teaching-guidance",
        "student-guidance",
        "data-privacy",
        "research",
        "other"
      ],
      "summary_bullets": [
        "Identifies potential policy gaps and offers recommendations for responsible AI use across university administration, education, and research.",
        "Establishes flexible guiding principles for AI at Stanford, including Human Oversight, Human Alignment, Human Professionalism, and an 'AI Golden Rule'.",
        "Addresses implications for academic integrity (Honor Code, course policies), research (authorship, data use, AI detector limitations), and administrative functions (hiring, admissions).",
        "Encourages experimentation with AI while ensuring core university principles are honored, cautioning against fixed, rigid policies."
      ]
    },
    {
      "policy_title": "Generative AI Policy Guidance",
      "policy_url": "https://communitystandards.stanford.edu/generative-ai-policy-guidance",
      "publisher": "Office of Community Standards",
      "last_updated": "February 16, 2023",
      "scope": "university-wide",
      "policy_types": [
        "integrity",
        "student-guidance"
      ],
      "summary_bullets": [
        "Establishes a default Honor Code implication: absent clear instructor policy, generative AI use is treated as assistance from another person, requiring disclosure.",
        "Prohibits using generative AI tools to substantially complete assignments or exams unless explicitly permitted by the instructor.",
        "Grants individual course instructors the freedom to set their own generative AI policies, which must be clearly communicated in syllabi.",
        "Recommends instructors provide advance notice if they may use detection software for generative AI."
      ]
    },
    {
      "policy_title": "Responsible AI at Stanford",
      "policy_url": "https://uit.stanford.edu/security/responsibleai",
      "publisher": "University IT",
      "last_updated": "",
      "scope": "university-wide",
      "policy_types": [
        "data-privacy",
        "security",
        "ethics",
        "research",
        "teaching-guidance",
        "student-guidance"
      ],
      "summary_bullets": [
        "Provides guidelines for responsible and secure use of AI tools by Stanford faculty, staff, and students, emphasizing data privacy and security.",
        "Advises on risks including data privacy, intellectual property, hallucinations, bias, and environmental impact.",
        "Classifies data risk (low, moderate, high) and specifies appropriate AI tools for each type, recommending Stanford-approved secure platforms like Stanford AI Playground for sensitive data.",
        "Outlines best practices for using AI tools securely and ethically, ensuring verification of AI outputs and respecting intellectual property."
      ]
    }
  ]
}