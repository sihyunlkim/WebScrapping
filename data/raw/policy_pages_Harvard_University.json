[
  {
    "query": "Harvard University generative AI policy",
    "title": "Guidelines for Using ChatGPT and other Generative AI tools at ...",
    "url": "https://provost.harvard.edu/guidelines-using-chatgpt-and-other-generative-ai-tools-harvard",
    "text": "Guidelines for Using ChatGPT and other Generative AI tools at Harvard | Office of the Provost[\nSkip to main contentarrow\\_circle\\_down\n] \n[![Harvard University]] \n[\nOffice of the Provost\n] \nmenucloseMenu\nSearch\nSearchsearch\n[\nOffice of the Provost\n] \n# Guidelines for Using ChatGPT and other Generative AI tools at Harvard\nDear Members of the Harvard Community,\nWe write today with initial guidelines on the use and procurement of generative artificial intelligence (AI) tools, such as OpenAI’s ChatGPT and Google Bard. The University supports responsible experimentation with generative AI tools, but there are important considerations to keep in mind when using these tools, including information security and data privacy, compliance, copyright, and academic integrity.\nGenerative AI is a rapidly evolving technology, and the University will continue to monitor developments and incorporate feedback from the Harvard community to update our guidelines accordingly.\n***Initial guidelines for use of generative AI tools:***\n* **Protect confidential data:**You should not enter data[classified as confidential] (Level 2 and above), including non-public research data, into publicly-available generative AI tools, in accordance with the University’s[Information Security Policy]. Information shared with generative AI tools using default settings is not private and could expose proprietary or sensitive information to unauthorized parties.\n* **You are responsible for any content that you produce or publish that includes AI-generated material:**AI-generated content can be inaccurate, misleading, or entirely fabricated (sometimes called “hallucinations”), or may contain copyrighted material. Review your AI-generated content before publication.\n* **Adhere to current policies on academic integrity:**Review your School’s student and faculty handbooks and policies. We expect that Schools will be developing and updating their policies as we better understand the implications of using generative AI tools. In the meantime, faculty should be clear with students they’re teaching and advising about their policies on permitted uses, if any, of generative AI in classes and on academic work. Students are also encouraged to ask their instructors for clarification about these policies as needed.\n* **Be alert for AI-enabled phishing:**Generative AI has made it easier for malicious actors to create sophisticated scams at a far greater scale. Continue to[follow security best practices] and report suspicious messages to[phishing@harvard.edu].\n* **Connect with HUIT before procuring generative AI tools:**The University is working to ensure that tools procured on behalf of Harvard have the appropriate privacy and security protections and provide the best use of Harvard funds.\n* If you have procured or are considering procuring generative AI tools or have questions, contact HUIT at[ithelp@harvard.edu].\n* Vendor generative AI toolsmust be[assessed for risk by Harvard’s Information Security and Data Privacy officeprior to use].\nIt is important to note that these guidelines are not new University policy; rather, they leverage existing University policies. You can find more information about generative AI, including a survey to collect data on its potential use,[on the HUIT website], which will be updated as new information becomes available. Sincerely,\nAlan M. Garber\nProvost\nMeredith Weenick\nExecutive Vice President\nKlara Jelinkova\nVice President and University Chief Information Officer"
  },
  {
    "query": "Harvard University generative AI policy",
    "title": "Generative AI Guidelines | Harvard University Information Technology",
    "url": "https://www.huit.harvard.edu/ai/guidelines",
    "text": "Generative AI Guidelines | Harvard University Information Technology[\nSkip to main contentarrow\\_circle\\_down\n] \nSearch\nSearchsearch\n[\n![Harvard University Information Technology] \n![Harvard University Information Technology] \n] \nmenucloseMenu\nSearch\nSearchsearch\n[\n![Harvard University Information Technology] \n![Harvard University Information Technology] \n] \n# Generative AI Guidelines\n# Guidelines for the use of Generative AI tools at Harvard\nPolicies &amp; guidelines\n![Woman works on her laptop in a library.] \n## Overview\nGenerative AI is a type of artificial intelligence that can learn from and mimic large amounts of data tocreate content such as text, images, music, videos, code, and more, based on inputs or prompts.The University supports responsible experimentation with[generative AI tools], but there are important considerations to keep in mind when using these tools, including information security and data privacy, compliance, copyright, and academic integrity. These guidelines are updated periodically.\n## Protect confidential data\nYou should not enter data[classified as confidential] (Level 2 and above, including non-public research data, finance, HR, student records, medical information, etc.) into publicly-available generative AI tools, in accordance with the University’s[Information Security Policy]. Information shared with generative AI tools using default settings is not private and could expose proprietary or sensitive information to unauthorized parties.\nLevel 2 and above confidential data must only be entered into generative AI tools that have been assessed and approved for such use by Harvard’s Information Security and Data Privacy office. See below for more information about approved tools.\n## Review content before publishing or sharing\nAI-generated content can be inaccurate, misleading, or entirely fabricated (sometimes called “hallucinations”) or may contain copyrighted material. You are responsible for any content that you publish or share that includes AI-generated material.\n## Adhere to local academic and administrative policies\nReview your School or Unit’s local policies around the use of generative AI. Many Schools have developed or updated policies around the use of generative AI in the classroom.[You can find links to local resources on the University’s generative AI website].\nFaculty should be clear with students they’re teaching and advising about their policies on permitted uses, if any, of generative AI in classes and on academic work. Students are also encouraged to ask their instructors for clarification about these policies as needed.\n## Be alert for phishing\nGenerative AI has made it easier for malicious actors to create sophisticated phishing emails and “deepfakes” (i.e., video or audio intended to convincingly mimic a person’s voice or physical appearance without their consent) at a far greater scale. Continue to[follow security best practices] and report suspicious messages to[phishing@harvard.edu].\n## Use approved tools for Harvard work\nHUIT and School IT providers have procured a range of generative AI tools with important contractual protections for use in Harvard work. These include security and privacy protections that ensure the tools are appropriate for use with certain types of confidential data, and assurances that the data entered will not be used to train vendor models.\n* [A list of available tools provided by HUIT can be found here]. More tools may be available from[your School IT provider].\n* AI meeting assistants should not be used in Harvard meetings, with the exception of approved tools with contractual protections. Consult the[AI Assistant Guidelines] for more information and how to manage unwanted AI assistants in meetings.\n* If you are considering procuring a generative AI tool not currently offered or have questions,[please contact HUIT]. All vendor generative AI tools must be[assessed for risk by Harvard's Information Security and Data Privacy office] prior to use in Harvard work.\n## Additional guidelines\n* [**AI Assistant Guidelines**]: Guidance on the use ofautomated meeting assistants (aka “AI note takers” or “bots”) in online meetings.\n* [**EU AI Act Prohibited Use Cases**]: Regulation on the use of AI technologies that may be developed or used in the European Union, or whose output may be used in the European Union."
  },
  {
    "query": "Harvard University generative AI policy",
    "title": "Generative AI Guidance - Office of Undergraduate Education",
    "url": "https://oue.fas.harvard.edu/faculty-resources/generative-ai-guidance/",
    "text": "Generative AI Guidance &#8211; Office of Undergraduate Education\n[Skip to content] \n[![Harvard University homepage]] \n[HARVARD.EDU] \n![Students use laptop comuters.] \n[HOME] /[FACULTY RESOURCES] \n# Generative AI Guidance\nResources for instructors regarding appropriate use of generative AI in courses.\nBackground video of aerial view of Harvard University and other b roll video of the inside of campus buidlings\n## **On This Page**\n[SAMPLE AI POLICIES] \n[AI RESOURCES] \n[EVENT RECORDINGS] \n[FREQUENTLY ASKED QUESTIONS] \nHarvard supports responsible experimentation with generativeAItools, but there are important considerations to keep in mind when using these tools, including information security and data privacy, compliance, copyright, and academic integrity.\n## Announcements\nStarting in Fall 2025, faculty can find Respondus, a new browser lockdown tool, on their Canvas site(s) to use for in-person seated exams and quizzes to ensure that students do not use AI unless the course asks them to do so.[Contact the Academic Technology Group] with questions or to get started.\n## Policies for the use of AI in courses\nAll faculty are required to inform students of the policies governing generative AI use in class.Whether students in your course are forbidden from using ChatGPT or expected to explore its limits, a policy helps ensure that your expectations forappropriate interaction with generative AI tools are clear to students.Once you decide on a policy, make sure you articulate it clearly for your students, so that they know what is expected of them. More specifically,**you should post your policy on your Canvas site**.\nYou can choose from among the below example policies to add to your Canvas site, or you can design your own to suit the needs of your course.\nA maximally restrictive draft policy:\n> *> We expect that all work students submit for this course will be their own. In instances when collaborative work is assigned, we expect for the assignment to list all team members who participated. We specifically forbid the use of ChatGPT or any other generative artificial intelligence (AI) tools at all stages of the work process, including preliminary ones. Violations of this policy will be considered academic misconduct. We draw your attention to the fact that different classes at Harvard could implement different AI policies, and it is the student’s responsibility to conform to expectations for each course.&nbsp;\n*\n> A fully-encouraging draft policy:\n> *> This course encourages students to explore the use of generative artificial intelligence (GAI) tools such as ChatGPT for all assignments and assessments. Any such use must be appropriately acknowledged and cited. It is each student’s responsibility to assess the validity and applicability of any GAI output that is submitted; you bear the final responsibility. Violations of this policy will be considered academic misconduct. We draw your attention to the fact that different classes at Harvard could implement different AI policies, and it is the student’s responsibility to conform to expectations for each course.&nbsp;\n*\n> Mixed draft policy:\n> *> Certain assignments in this course will permit or even encourage the use of generative artificial intelligence (GAI) tools such as ChatGPT. The default is that such use is disallowed unless otherwise stated. Any such use must be appropriately acknowledged and cited. It is each student’s responsibility to assess the validity and applicability of any GAI output that is submitted; you bear the final responsibility. Violations of this policy will be considered academic misconduct. We draw your attention to the fact that different classes at Harvard could implement different AI policies, and it is the student’s responsibility to conform to expectations for each course.&nbsp;\n*\n> ## Additional AI Resources\n![] ### [AI Pedagogy Project] \nVisit the[AI Pedagogy Project (AIPP)], developed by the metaLAB at Harvard, for an introductory guide to AI tools, an LLM Tutorial, additional AI resources, and curated assignments to use in your own classroom. The metaLAB has also published a quick start guide for[Getting Started with ChatGPT] \n![Derek Bok Center for Teaching and Learning logo.] ### [Teaching and Artificial Intelligence] \nVisit the Bok Center for Teaching and Learning website for resources on teaching in the age of AI that includes information ondesigning courses and assessments, communicating with students about AI, and examples for using AI in your teaching.\n### [Teaching at the Faculty of Arts and Sciences] \nThe Teaching at FAS website, a collaborative project between several college and university offices, offers[a list of resources] for Harvard faculty related to designing and teaching courses.\n## Generative AI event recordings\nIn August 2023, Amanda Claybaugh, Dean of Undergraduate Education, and Christopher Stubbs, Dean of Science, hostedinformational sessions on the use of generative AI incourses. In each session, faculty presented examples of new assignments they have developed, as well as advice on how to “AI-proof” familiar assignments, and shared thoughts about how to guide students in using these technologies responsibly.\n### Generative AI and Your Writing Course\nAugust 9, 2023\n[![Embedded YouTube video]] \n### Generative AI and Your STEM Course\nAugust 8, 2023\n[![Embedded YouTube video]] \n## FAQ\nWhat is ChatGPT?\n Generative artificial intelligence (GAI) tools such as Chat-GPT represent a significant advance in natural-language interaction with computers. On the basis of a ‘prompt’ a GAI system can produce surprisingly human-like responses including narrative passages and responses to technical questions. Moreover, an iterative exchange with the AI system can produce refined and tuned responses. This technology is evolving very rapidly. GAI systems have demonstrated the ability to pass the medical licensing exam, pass the bar exam, to generate art and music, answer graduate level problems from physics courses. These GAI systems are far from perfect, and some of the material they provide as factual are incorrect. GAI technology is a disruptive and rapidly changing new technology that will impact many aspects of our lives.\nWeaknesses of many GAIs at present include their inability to perform basic arithmetic calculations, and the propensity for ‘hallucinations’. Also, the GAI responses will reflect the biases and inaccuracies that are contained in the training data. It’s important to realize that there is an intentional ‘random’ element in the responses for most GAI systems. The same input does not always produce the same output. Also, the provenance of information that is used in responses does not flow through to the output, and this limits our ability to perform validation. But GAI capabilities are changing rapidly and we should anticipate ongoing refinements and progress. We currently don’t think twice about use spell-checking and grammar-checking tools in word processors, pickin"
  },
  {
    "query": "Harvard University generative AI policy",
    "title": "HGSE AI Policy | Office of the Registrar",
    "url": "https://registrar.gse.harvard.edu/learning/policies-forms/ai-policy",
    "text": "HGSE AI Policy | Office of the Registrar[\nSkip to main contentarrow\\_circle\\_down\n] \n[![Harvard Graduate School of Education]] \n[\nOffice of the Registrar\nHarvard Graduate School of Education\n] \nmenucloseMenu\nSearch\nSearchsearch\n[\nOffice of the Registrar\nHarvard Graduate School of Education\n] \n# HGSE AI Policy\n**HGSE POLICY ON STUDENT USE OF GENERATIVE ARTIFICIAL INTELLIGENCE IN ACADEMIC WORK**\n**Academic Year 2025-2026**\nGenerative Artificial Intelligence (AI) poses both great opportunities and great challenges for the field of education. Tools such as ChatGPT, DALL-E, and GitHub Copilot are having a profound influence on teaching and learning –and on your role as education practitioners and leaders. Your time at HGSE is an opportunity to learn to leverage such tools to produce more equitable access to and deeper engagement in education.\nHGSE encourages responsible experimentation with generative AI tools, but there are important considerations to keep in mind when using these tools, including information security and data privacy, copyright issues, the trustworthiness of the content they generate, and academic integrity. The implications of using generative AI for your own learning are equally salient. It might be possible to use this technology to complete some class assignments while doing little work yourself, but short cutting the process of thinking and writing in this way would rob you of the learning you came to HGSE to experience. At its best, generative AI can be like a tutor or thought partner with unlimited time to help you learn –but it should not be used to do the cognitive work for you, or else your own learning will be greatly diminished.\nThe following guidelines aim to ensure that, in your academic work at HGSE, you use generative AI when it can help you learn and not when it is a hindrance. If you have any doubt about whether a specific use of generative AI is permitted for an assignment or course, you are responsible for discussing it with your instructor prior to using it.\n1. Unless otherwise specified by your instructor, it is a violation of the HGSE Academic Integrity Policy to use generative AI to create all or part of an assignment for a course (e.g., a paper, memo, presentation, or short response) and submit it as your own. This rule parallels other rules. You may not ask another person to complete your assignment for a course. You may not copy from something someone else has created or re-write in your own words something someone else has written, without proper attribution.\n2. Permissible uses of generative AI in HGSE coursework include seeking clarification on concepts, brainstorming ideas, or generating scenarios that help contextualize what you are learning. For instance, it is fine to use AI-powered web search and to have “conversations” with tools like ChatGPT to help you explore ideas, refine your thinking, identify examples, and better understand course material. It is also acceptable to use generative AI to draft emails to instructors, students, and others in the HGSE community that are not being submitted as coursework.\n3. For any permitted use of GenAI tools, you must acknowledge and document that use in your assignment submission by explaining what tool(s) you used, prompts you provided (if applicable), and how you integrated the output into your work. If you cite directly from the tool, use proper citation format to credit the source. For more details and examples, see these APA guidelines:[How to cite ChatGPT].\n4. Keep in mind that the information provided by generative AI tools like ChatGPT is generated from unverified crowd-sourced information. Large language models can produce false claims or “hallucinations” and will regenerate any biases in the corpus of texts on which they are trained. You therefore should not trust the information as if it were equivalent to published research. You are ultimately responsible for the accuracy of the work you submit.\n5. The use of generative AI may also have implications for the protection of your own intellectual property. For example, if you upload your own original content to a generative AI tool, that content may become part of the tool’s models, which others may encounter and use. Conversely, if you use generative AI to develop your own original work, it may unexpectedly include others' copyrighted material.\n6. Certain uses of AI also infringe on copyright laws applicable to U.S. universities or contravene existing expectations for student conduct in HGSE courses. For example, the HGSE Student Handbook notes that “Students may not post, publish, sell, or otherwise publicly distribute course materials without the written permission of the course instructor. Such materials include, but are not limited to, the following: lecture slides, video, or audio recordings, assignments, problem sets, examinations, other students’ work, and answer keys. Students may not make recordings of course material for their own use without written permission of the instructor.” In keeping with these guidelines:\n7. Uploading any substantial course content —including text, video, readings, discussion-board pages, or audio recordings —is only allowable through the[Harvard-approved AI Sandbox], which ensures data entered is kept in a secure environment and not used to train public AI tools. The Sandbox is available through individual courses; if you have questions about the Sandbox, discuss with your instructor.\n8. It is forbidden to make your own recording of any course meetings, with or without AI tool integrations. If you require or would prefer that course meetings be recorded, discuss this request with your instructor. More broadly, if you require AI technology as part of an assistive technology solution to enable you to participate fully in the course, you must coordinate your usage with the Office of Student Affairs.\n9. Given the wide range of learning goals in courses at HGSE, individual instructors may create course-specific policies that differ from and supersede these guidelines. Again, if you have any doubt about whether a specific use of generative AI is permitted for an assignment or course, you are responsible for discussing it with your instructor prior to using it.\nNew ways of teaching and learning will emerge as generative AI becomes increasingly ubiquitous and robust. We thus anticipate that this policy will also evolve, with feedback from students and instructors.\n##### Featured Links\n[arrow\\_forwardmy.Harvard] [arrow\\_forwardStudent Handbook] [arrow\\_forwardRecords Request] [arrow\\_forwardRegistrar Communications]"
  },
  {
    "query": "Harvard University AI policy academic integrity",
    "title": "Academic Integrity and Teaching With(out) AI",
    "url": "https://oaisc.fas.harvard.edu/academic-integrity-and-teaching-without-ai/",
    "text": "[Skip to content] \n\n[HARVARD.EDU] \n\n## **Resources for course design in the age of AI.**\n\nArtificial intelligence presents a dual-edged sword. On one hand, it offers unprecedented opportunities for pedagogical innovation, enabling personalized learning experiences, automating administrative tasks, and facilitating advanced data analysis. On the other hand, the integration of AI in academic settings raises pressing concerns about academic integrity, as these powerful tools can sometimes undermine the authenticity of student work and blur the lines of original thought. The list of resources below provides resources and strategies tailored for faculty members who either encourage or discourage the use of AI in their classes. By focusing on maintaining academic integrity, these resources and strategies can help faculty navigate the integration or exclusion of AI in a way that reinforces academic integrity, caters to their teaching philosophy, and addresses students’ ethical development.\n\nIn addition to the resources below, you may also want to view the [list of resources] for instructors regarding appropriate use of generative AI in courses compiled by the Office of Undergraduate Education, the Bok Center’s resources for [teaching with AI], the metaLAB’s  [AI Pedagogy Project], the Teaching at FAS website’s [list of resources]  for designing and teaching courses, Generative AI @ Harvard [resources to faculty] and [resources for students], as well as [the University guidelines] on the use and procurement of AI tools.\n\nFaculty with questions about academic integrity may contact Qussay Al-Attabi, Assistant Dean for Academic Integrity and Secretary of the Harvard College Honor Council.\n\n### On This Page:\n\n**[Resources for Faculty Encouraging AI Use in Their Courses] **\n\n**[Resources for Faculty Discouraging AI Use in Their Courses] **\n\n[BACK TO RESOURCES OVERVIEW] \n\n## **Resources for Faculty Encouraging AI Use in Their Courses**\n\nArtificial intelligence may be used as a powerful catalyst for pedagogical innovation, offering novel ways to enhance learning and engage students. However, alongside its promising opportunities, AI also introduces significant challenges, particularly concerning academic integrity. As educators, it is crucial to maintain a vigilant approach, thoughtfully integrating AI into course design and instruction. This ensures that we harness its potential while upholding the principles of honesty, fairness, and ethical conduct. By remaining mindful of these considerations, instructors can create enriching educational experiences that respect the integrity of the academic environment. If you intend to integrate AI into your courses, we hope that you find the following resources helpful.\n\n_Course Design_\n\n- **Understand AI Tools**: Stay informed about the latest AI applications relevant to your field. Resources like AI literacy workshops and toolkits can be invaluable.\n- **Design with AI in Mind**: Develop assignments that promote critical thinking and creativity, encouraging students to use AI for idea generation or problem-solving.\n- **Case Studies on AI**: Integrate case studies discussing ethical AI use, helping students understand both potential benefits and pitfalls.\n- **Collaborative Projects**: Use projects that leverage AI tools for collaboration, teaching students how to use these tools responsibly.\n\n_Syllabus Structure_\n\n- **Explicit AI Guidelines**: Clearly define how AI can be used in the course syllabus. Include examples of acceptable AI applications, such as data analysis or language translation tools.\n- **Ethical AI Use Statement**: Offer a detailed statement on ethical AI use, reinforcing integrity while encouraging experimentation within set boundaries.\n- **Resource Provision**: Provide students with a well-curated list of AI tools that can support their learning, along with guidelines for their ethical use.\n\n_Assignments_\n\n- **Integration of AI Tasks**: Create assignments that involve AI tools, tasking students with evaluating AI-generated outputs or improving on them.\n- **Reflective AI Use Journals**: Ask students to maintain a journal documenting how they utilized AI throughout the course, underscoring ethical considerations.\n- **Scaffolded Assignments**: Design multi-part assignments where AI can be used for specific stages, but not others, providing a balanced approach to technology use.\n\n_Assessments_\n\n- **AI-Enhanced Projects**: Encourage the creation of projects that include AI components, emphasizing innovation and ethical tool use in assessments.\n- **Oral Defenses**: Use oral presentations to evaluate comprehension, allowing students to explain their process, including AI application.\n- **Ethical Use Evaluations**: Have students submit a section with their assignments where they outline how AI assisted their work, focusing on ethics.\n\n_Classroom Practices_\n\n- **AI Literacy Promotion**: Offer sessions on AI functionality and ethical use, empowering students to use technology responsibly.\n- **Peer Review Focus**: Structure peer reviews to critique both the technical and ethical aspects of AI use in projects.\n\n_Feedback and Reflection_\n\n- **Frequent Feedback**: Provide regular feedback on AI usage, helping students refine their skills and understanding of appropriate applications.\n- **Self-Assessment**: Incorporate self-assessment tools that encourage students to reflect on their ethical use of AI.\n- **Ethical Debates**: Facilitate debates on AI’s role in specific disciplines, fostering a nuanced understanding of its ethical implications.\n\n## **Resources for Faculty Discouraging AI Use in Their Courses**\n\nFrom an academic integrity perspective, prohibiting AI use in course requires careful consideration of several critical factors. The challenge lies not merely in the existence of AI technology, but in its widespread presence, sophisticated capabilities, and the ease with which it can be accessed and used. Faculty who wish to prevent their students from using AI tools must be especially deliberate in their approach to course design, ensuring that both requirements and assessments are structured in a way that intrinsically discourages the misuse of AI. This might include creating assignments that require unique, personalized responses or demonstrating processes that AI cannot easily replicate. Clear communication of expectations and the reasons behind AI restrictions can also help cultivate an understanding of the importance of independent learning. Additionally, implementing assessments that focus on critical thinking and problem-solving skills can effectively uphold the integrity of the educational process. By being intentional in approaching restricting or banning AI in their courses, instructors can foster a learning environment that prioritizes authenticity and academic honesty, even in the face of advancing technology. If you plan to restrict or prohibit the use of AI in your courses, we hope that you find the following resources "
  },
  {
    "query": "Harvard University ChatGPT policy students",
    "title": "1.3.3 Using ChatGPT & Artificial Intelligence (AI) Tools | MBA",
    "url": "https://www.hbs.edu/mba/handbook/standards-of-conduct/academic/chatgpt-and-ai",
    "text": "1.3.3 Using ChatGPT &amp; Artificial Intelligence (AI) Tools | MBA\n[Skip to Main Content] \n[Harvard Business School\nHarvard Business School Logo\n] \n[MBA] \n[MBA] \nMore\n[Apply] \n# 1.3.3 Using ChatGPT &amp; Artificial Intelligence (AI) Tools\n1.3 Academic Standards of Conduct\nThe University supports responsible experimentation with generative AI tools, but there are important considerations to keep in mind when using these tools, including information security and data privacy, copyright and academic integrity. Generative AI is a rapidly evolving technology and HBS’ policies may be updated from time to time. Students are expected to remain informed of all current policies.\nFaculty may allow the use of ChatGPT and similar technologies in some circumstances, but students must ensure that such use is permitted and must make sure they understand any limitations on such use before using this technology. In using ChatGPT or other generative AI tools, students must be aware of their limits and apply best practices to their use:\n* Protect confidential data: Students should not enter data classified as confidential (Level 2 and above), including non-public research data, into publicly-available generative AI tools, in accordance with the University’s[Information Security Policy]. Information shared with generative AI tools using default settings is not private and could expose proprietary or sensitive information to unauthorized parties.\n* Students are responsible for any content that they produce or publish that includes AI-generated material: AI-generated content can be inaccurate, misleading, or entirely fabricated (sometimes called “hallucinations”), or may contain copyrighted material. Students must review all AI-generated content very carefully, recognizing that they are ultimately responsible for the accuracy of any work they submit.\n* As clarified in the[HBS Citation Guide], students must cite their use of these AI tools appropriately. Not doing so violates the[MBA Honor Code], just as would failing to cite any other source.\n* Students must contact HBS IT before procuring any generative AI tools. HBS IT will coordinate with Harvard University IT (HUIT), as the University is working to ensure that any AI tools procured on behalf of Harvard or used in the Harvard environment have the appropriate privacy and security protections. Students who are considering procuring generative AI tools or have questions about AI tools should contact HBS IT at[mbaithelp@hbs.edu]. All vendor-generative AI tools must be assessed for risk by[Harvard’s Information Security and Data Privacy office] prior to use.\nAll HBS students are expected to understand and follow the complementary guidelines for the responsible use of AI that have been issued by[Harvard University] and by[HBS (login required)]."
  },
  {
    "query": "Harvard University provost generative AI guidance",
    "title": "Guidelines for Using ChatGPT and other Generative AI tools at Harvard - July 13, 2023",
    "url": "https://provost.harvard.edu/links/guidelines-using-chatgpt-and-other-generative-ai-tools-harvard-july-13-2023",
    "text": "Guidelines for Using ChatGPT and other Generative AI tools at Harvard - July 13, 2023 | Office of the Provost[\nSkip to main contentarrow\\_circle\\_down\n] \n[![Harvard University]] \n[\nOffice of the Provost\n] \nmenucloseMenu\nSearch\nSearchsearch\n[\nOffice of the Provost\n] \n# Guidelines for Using ChatGPT and other Generative AI tools at Harvard - July 13, 2023\nDear Members of the Harvard Community,\nWe write today with initial guidelines on the use and procurement of generative artificial intelligence (AI) tools, such as OpenAI’s ChatGPT and Google Bard. The University supports responsible experimentation with generative AI tools, but there are important considerations to keep in mind when using these tools, including information security and data privacy, compliance, copyright, and academic integrity.\nGenerative AI is a rapidly evolving technology, and the University will continue to monitor developments and incorporate feedback from the Harvard community to update our guidelines accordingly.\n***Initial guidelines for use of generative AI tools:***\n* **Protect confidential data:**You should not enter data[classified as confidential] (Level 2 and above), including non-public research data, into publicly-available generative AI tools, in accordance with the University’s[Information Security Policy]. Information shared with generative AI tools using default settings is not private and could expose proprietary or sensitive information to unauthorized parties.\n* **You are responsible for any content that you produce or publish that includes AI-generated material:**AI-generated content can be inaccurate, misleading, or entirely fabricated (sometimes called “hallucinations”), or may contain copyrighted material. Review your AI-generated content before publication.\n* **Adhere to current policies on academic integrity:**Review your School’s student and faculty handbooks and policies. We expect that Schools will be developing and updating their policies as we better understand the implications of using generative AI tools. In the meantime, faculty should be clear with students they’re teaching and advising about their policies on permitted uses, if any, of generative AI in classes and on academic work. Students are also encouraged to ask their instructors for clarification about these policies as needed.\n* **Be alert for AI-enabled phishing:**Generative AI has made it easier for malicious actors to create sophisticated scams at a far greater scale. Continue to[follow security best practices] and report suspicious messages to[phishing@harvard.edu].\n* **Connect with HUIT before procuring generative AI tools:**The University is working to ensure that tools procured on behalf of Harvard have the appropriate privacy and security protections and provide the best use of Harvard funds.\n* If you have procured or are considering procuring generative AI tools or have questions, contact HUIT at[ithelp@harvard.edu].\n* Vendor generative AI toolsmust be[assessed for risk by Harvard’s Information Security and Data Privacy officeprior to use].\nIt is important to note that these guidelines are not new University policy; rather, they leverage existing University policies. You can find more information about generative AI, including a survey to collect data on its potential use,[on the HUIT website], which will be updated as new information becomes available. Sincerely,\nAlan M. Garber\nProvost\nMeredith Weenick\nExecutive Vice President\nKlara Jelinkova\nVice President and University Chief Information Officer\nSee also:\n* [Reports]"
  },
  {
    "query": "Harvard University provost generative AI guidance",
    "title": "Harvard’s New Playbook for Teaching with AI",
    "url": "https://www.harvardmagazine.com/teaching-learning/harvard-redesigning-assignments-ai",
    "text": "Harvard’s New Playbook for Teaching with AI | Harvard Magazine[Skip to main content] \n[![Home]] \nYour*independent*source for Harvard news since 1898\n**Menu\n**Toggle Search\n[Donate] \nFollow*Harvard Magazine:*\nYour*independent*source for Harvard news since 1898\nAdvertisement\nAdvertisement\n**[Teaching &amp; Learning] **|October 14, 2025\n# Harvard’s New Playbook for Teaching with AI\n## Faculty across Harvard are rethinking assignments to integrate AI.\nby[Olivia Farrar] \n![Loading icon surrounded by books, an apple, and a notepad with writing.] \n**AI policies and assignments are “buffering” across Harvard schools**| MONTAGE BY NIKO YAITANES/*HARVARD MAGAZINE*; IMAGES BY UNSPLASH\nAs generative AIbecomes as common as word processors and spreadsheets, educators are shifting from debating whether to allow it in classrooms to creating clear guidelines for how to use it effectively.\nAt[Harvard’s Initiative for Learning and Teaching (HILT)] conference in late September, faculty from across the University shared some of the ways they’re rethinking assignments and instruction with AI in mind.\nIn a panel organized by Esther Kotecha, the associate director for teaching and learning technologies at Harvard Medical School (HMS), and Mae Klinger, the associate director of teaching and learning innovation at Harvard Kennedy School (HKS), educators explored how AI can support, not substitute, deep learning among students.\n## **Rethinking Assignments with AI at the Kennedy School**\n![Teddy Svoronos sitting at a panel table] **Teddy Svoronos**| PHOTOGRAPH By NEal Hamberg; COURTESY OF Harvard Initiative for Learning and Teaching (HILT)\nTeddy Svoronos, a senior lecturer in public policy at HKS, introduced a “traffic light” framework for AI use in his courses this semester. Green means AI can be used without restrictions; yellow means AI use is allowed with limitations, and red signals that AI use is prohibited (often involving tasks in which the learning objective would be compromised by the use of AI).\nRed-light tasks often precede in-class discussions where students must build and defend arguments collaboratively. Green-light tasks, by contrast, encourage experimentation. In those cases, students work with AI platforms or custom tutor bots and are prompted to reflect on questions such as: What did the AI assist with? What did it fail to address? What was learned through its use?\nSvoronos also introduced AI-facilitated oral exams. Students engage in a Socratic dialogue with a conversational AI trained on course material. The AI doesn’t grade; instead, instructors review transcripts to assess performance. This preserves the human role in evaluation while exploring new learning formats.\nIn another assignment from Svoronos, students first create a data visualization in Excel (a task drawing on their existing skill set). Then, they use AI to generate a more advanced version (a task that pushes beyond, or is wholly outside, their current capabilities). And in a final phase, students critically audit the AI-generated output with questions like: What aspects were accurate? What content appeared fabricated? What would require verification before public use or academic submission?\n## **AI as a “Thinking Partner” at Harvard Medical School**\nTari Tan, a lecturer on neurobiology and the assistant dean for educational scholarship and innovation at HMS, described how her students interact with AI in the context of lesson planning.\n![Tari Tan at a podium with an audience in a foreground] **Tari Tan**| PHOTOGRAPH By NEal Hamberg; COURTESY OF Harvard Initiative for Learning and Teaching (HILT)\nStudents first annotate their own lesson materials, then submit them to ChatGPT and compare the results. They reflect on the quality of their prompts, potential bias in the output, and how the AI’s responses align with their goals. This helps reinforce a key lesson, she said: while generative AI may mimic fluency, it doesn’t replicate human reasoning. As a consequent, students begin to conceive of it not as an infallible source of information, but as a thinking partner.\nTan also had students co-develop the class AI policy, with the goal of increasing transparency over expectations and giving them ownership over learning objectives. The exercise also reinforced a broader pedagogical principle: students who help teach, even indirectly, often learn more deeply.\nTan emphasized the importance of metacognition, or “thinking about one’s own thinking.” When students can articulate how they’re using AI, she said, they’re better able to identify when they’re learning and when they’re outsourcing thought. She also noted that using AI in this way deliberately adds “cognitive load,” requiring students to assess the quality, relevance, and accuracy of AI outputs. In some cases, the effort of managing the tool becomes a distraction from the task itself.\nCritically, Tan does not grade her students’ AI-generated content. Instead, she assesses their reflections and their ability to use AI meaningfully. Over time, students get better at writing effective prompts and critiquing the AI’s output. They learn to identify hallucinations, jargon that masks weak logic, and content that sounds plausible but lacks substance.\nTan’s broader takeaway from the experiment is that AI won’t make teaching obsolete. It may, however, render disengaged or uncritical teaching practices obsolete.\n## **Reshaping Executive Education at Harvard Business School**\nAs generative AI becomes central to the modern workplace, Harvard Business School is rethinking how to prepare students for using it in the real world. During[Boston AI Week], which took place from September 26 to October 3, HBS faculty and staff discussed experiments with AI-powered tools, particularly custom GPTs, to enhance instruction and provide additional student support.\nFritz Kocher, a senior application analyst at HBS, introduced a GPT model that helps faculty process course feedback by turning lengthy student comments into actionable insights and visual summaries. The tool, he said, serves as a “warm handoff” to faculty, not a replacement for human judgment.\n“You go from 50 pages of feedback, straight into an appointment to work on the insights it gives you,” Kocher said. The tool also provides structured visualizations and is aligned with teaching principles from the[C. Roland Christensen Center for Teaching and Learning].\nDustin Hilt, the director of HBS’s Live Online Classrooms initiative, and Jaye Schneider, the associate director of business relationship management, said it was important to accustom faculty to use generative AI. Schneider’s team developed scaffolded “prompt libraries,” or standardized, pre-written phrasing to ease the learning curve and support successful adoption.\nWendy Riseborough, a senior creative producer at HBS, described an experiment in which AI-generated avatars were used to populate virtual classrooms when live participants were not present. The goal of this proje"
  },
  {
    "query": "Harvard University teaching and learning generative AI guidance",
    "title": "Teaching and Learning with Generative AI",
    "url": "https://tll.gse.harvard.edu/teaching-and-learning-generative-ai",
    "text": "[Skip to main contentarrow\\_circle\\_down] \n\n# Teaching and Learning with Generative AI\n\n# Teaching and Learning with Generative AI\n\nIn the wake of recent evolutions of generative Artificial Intelligence (AI) tools such as ChatGPT, DALL-E and GitHub Copilot, these guides offer sets of resources curated for the HGSE teaching community. Because this is a rapidly-changing landscape, we expect to update these resources regularly, particularly as more faculty develop and use these tools in their courses. We welcome your input, suggestions and questions!\n\nIf you’d like to talk with a TLL consultant about any aspect of these issues in your teaching or your students’ learning, please contact [Allison Pingree]  for residential courses and [Bill Wisser] for online courses.\n\n[**Fundamentals of Teaching with Generative AI**] \n\nLearn about the basics of generative AI for teaching, including guidance related to student use of AI at HGSE.\n\n[**AI in the HGSE Classroom**] \n\nLearn how faculty members at HGSE and beyond are using generative AI in their courses.\n\n[**Learning Explorations in AI Pedagogy (LEAP) Initiative**] \n\nHGSE initiative to build faculty’s knowledge, skills, and confidence to more effectively integrate AI into their teaching practice and support student learning. This initiative meets faculty where they are, providing multiple entry points."
  },
  {
    "query": "Harvard University teaching and learning generative AI guidance",
    "title": "Teach with Generative AI",
    "url": "https://www.harvard.edu/ai/teaching-resources/",
    "text": "Teach with Generative AI - Generative AI @ Harvard\n[Skip to main content] \n[![A logo that says Generative AI at Harvard]] \nGenerative AI**\n# Teach with Generative AI\nResources for faculty\n## Overview\nWhen it comes to the future of education, virtually no recent technology has sparked as much debate as generative AI (GenAI) and large language models (LLMs). Some have seen this technology as destructive, with school districts from[Los Angeles] to[New York] initially banning its use, and others have touted its[transformative impact] and possibility of changing the game for educators and students alike.\nHarvard has consistently tried to embrace new technology across our classrooms, residential and virtual. GenAI has been no different.\nFaculty and students have access to a range of tools. Some of these tools are free and open to all faculty, students and staff behind Harvard Key (Harvard Sandbox) other tools require a license or approval.[See a list of tools].\nAs our faculty and students have engaged with these technologies we have invited faculty to reflect on questions such as the following:\n* What is the challenge you were trying to address?\n* How did you use generative AI tools to tackle it?\n* What did you learn?\nOut of this there have been several learnings worth considering:\n1. GenAI tools have raised concerns about how they may compromise student assessments, promote academic dishonesty, and facilitate “lazy learning.” Our faculty colleagues who experimented with these tools were not oblivious to these concerns; indeed, many share them. At the same time, faculty are looking to understand how GenAI tools can enhance the educational experience and build more vibrant classrooms.\n2. Several colleagues are leveraging LLM features that everyone should keep in mind:\n1. **Beyond text:**For[visual aids] and[images],[coding],[analysis],[games],[simulations], and more.\n2. **Prompt design:**There’s an old saying: &#8220;garbage in, garbage out.&#8221; The output of LLMs is only as good as the input, and it’s essential to learn (and perhaps teach) how to write a prompt that works. This is highlighted through discussions on the critical role of deliberate prompt formulation, from[having students iterate on their prompts through the course], to engaging students in debate on the[ethics of AI use], to[making advanced statistical concepts accessible to diverse learners]. Our new**[System Prompt Library] **offers a range of effective prompts that can be used by educators.\n3. **Interrogate hallucinations**: Errors arise not just because of algorithmic or data limitations but, importantly, because LLMs are fundamentally probabilistic. Faculty have found that errors can be reduced through[detailed prompt engineering] and[balanced AI-human partnership].\n4. Some consistent patterns and learnings emerge from how GenAI has been implemented for use by our colleagues:\n1. **Going beyond the simple question-and-answer interface:**Sal Khan popularized the idea of using LLMs to ask questions of a student, not just answer them. Several faculty colleagues take this further, illustrating how LLMs can be used to simulate any persona you want, and to ask anything of them. Examples include simulating[experts],[peers],[graders],[course designers,] and[personal chatbots].\n2. **More than the “first draft”:**GenAI needn’t compromise student creativity; in fact, it can augment it. Some colleagues are using it to help students[refine project prototypes] and[polish final drafts].\n3. **Work alongside what you already have:**Many faculty used LLMs to improve different (and sometimes mundane) aspects of existing teaching and learning “workflows,” such as[producing course materials],[personalizing feedback],[generating assignments],[summarizing real-time student responses], and[tutoring students].\n4. **Identify, and overcome, hidden or invisible barriers:**Students and educators sometimes confront hidden prerequisites that present barriers for teaching and learning. GenAI can assist with overcoming these skill gaps:[coding for a business class], foreign languages for research, art skills for building visual aids, and even[building games for class engagement.] \n5. **Reimagining the classroom**: While we’re still in the early days of GenAI, some of these examples already start to surface more profound questions: What does a class with GenAI at its core look like? Ultimately, what is the role of a teacher?\n6. Questions around genAI’s efficacy on learning arise: can we use GenAI tools—specifically tutor bots—to improve the way students learn? One faculty member created a tutor bot that[answered questions like course staff]. Beyond such research on students’ interactions with genAI tools, it might be helpful to imagine how it can help you and your students now, in other ways as well: by increasing task efficiency, improving student engagement, increasing their confidence, or even improving learning outcomes.\n7. The risks of LLMs present valid concerns. While popular debates often focus on “big picture” concerns like algorithmic biases, digital divides, and fake content, some faculty explore the risks[at a micro scale], within our classrooms, such as hallucinations,[failed reasoning], or superficial thinking,[pushing students] to understand these issues more deeply.\nVideo interviews that fed these reflections are featured here in the first[**Harvard GenAI Library for Teaching and Learning**]. And across Harvard there have and will continue to be convenings large and small bringing together faculty, students, staff, and administrators. As you think about what’s relevant for your course, support exists across Harvard to help you and your team experiment as well.\n## Frequently asked questions\nThe following information offers advice for educators interested in using generative AI tools in their teaching and course preparation. As this technology is constantly evolving, this page will be updated frequently with new resources and advice.\n### How can I use generative AI to help prepare my curriculum?\nCreating materials for courses—syllabi, lesson plans, assignments—takes time. Generative AI tools aren’t just useful at broad, general prompts, but, as our colleagues have shown, they are useful in tackling the preparations before a student even arrives in the classroom:\n* **Preparing to teach:**Starting a syllabus or a lesson plan from a blank page is daunting. AI can help you[outline your course, create learning objectives, and suggest assignments or in-class activities,] while making content that fits your course by[feeding it specific reference materials].\n* **Assignments:**Reusing the same assignments across multiple years can be time efficient, but it creates challenges for assessments. Some faculty have explored how AI tools can help write, modify, or create question sets.[The more information] you put in about the structure and concepts you want it to use,[the better it will be]. And it can even[make a rubric] for it.\n* *"
  },
  {
    "query": "Harvard University teaching and learning generative AI guidance",
    "title": "Generative AI in Teaching and Learning at the GSD - Harvard ...",
    "url": "https://www.gsd.harvard.edu/resources/ai/",
    "text": "Generative AI in Teaching and Learning at the GSD - Harvard Graduate School of Design[Skip to main content] \n[Harvard Graduate School of Design] \nPrimary Menu\n[] \n[] \nClose Primary Menu\nOpen Search\nSubmit SearchClose Search\n# Generative AI in Teaching and Learning at the GSD\n![A computer-generated image spells the words Made by A I with pink mylar balloons] Image generated by Adobe Firefly (beta)\nThis page provides policies, information, and guidance for courses regarding the use of generative AI in teaching and learning at the GSD. Generative AI is artificial intelligence trained on large data sets that can predict letters, words, sounds, images, code, etc., based on the likelihood of those so-called ‘tokens’ occurring together. Note that generative AI is not intelligent and doesn’t think or apply reason as we understand it but produces output that mimics the data it was trained on, flaws included.\n*Updated 10/24/2024*\n## Policies\n*What do I have to keep in mind when using generative AI in teaching and learning?*\nInformation security and data privacy\n* Never submit personal information or any information[classified by HUIT as Level 2 or higher] into publicly available generative AI tools.\n* Be vigilant and[follow security best practices] as AI-driven scams are becoming more sophisticated.\nCompliance and copyright\n* You are responsible for the accuracy and compliance of your content.\n* Depending on the tools and parameters you use, AI-generated content can be inaccurate, misleading, entirely fabricated, or may contain material protected by copyright.\n* Do not submit work to which you don’t have rights into a generative AI tool and always be prepared to disclose your usage of any such tool.\nAcademic integrity\n* The GSD’s academic integrity policy can be found in the Student Handbook and any reference to unauthorized human or non-human support and aids in producing academic work applies equally to generative AI tools.\n* As a rule of thumb, wherever it is inappropriate for you to ask a human contributor to do work for you or where you don’t have explicit permission to share the work of one person with another, it is equally inappropriate for you to prompt an AI tool to do work for you or upload the work of others into an AI tool.\n* Instructors determine what constitutes appropriate use of generative AI in their courses just like they have the authority to determine what constitutes appropriate use of established technological aids and reliance on human collaboration.\n* Students are expected to be familiar with and abide by the School’s standards for academic integrity and conduct, and consult their instructor if they need clarification.\n* It is suggested that instructors be proactive and communicate expectations for academic conduct and the use of generative AI tools for their courses (see “Guidance for GSD courses” below).\n## Tools and General Information\n*What tools are available, and where can I learn more about generative AI?*\nGenerative AI tools available at Harvard\n* Harvard University IT provides up-to-date[information about available AI tools online].\n* If you have questions about the risk of using a specific tool or are interested in learning whether HUIT may be able to provide a secure environment for experimenting with a specific tool, please contact[HUIT] \nHarvard Resources on Generative AI\n* [Harvard’s central information hub around generative AI] provides a wealth of information, recommendations, scenarios, and testimonials for different user groups: faculty, students, scholars and researchers, and staff.\n* [HUIT’s website on generative AI] provides up-to-date information about available tools, usage considerations, and related resources.\n* [The Derek Bok Center’s Resources on Teaching and Artificial Intelligence] in Canvas include a wealth of useful information about AI in teaching settings.\n* [metaLAB (at) Harvard’s Proposed Harvard AI Code of Conduct] provides key points and suggestions for the responsible use of AI in alignment with the Harvard College Honor Code.\nNon-Harvard Resources on Generative AI\n* [TheresAnAIForThat.com] is an AI-generated database that indexes and tracks 15,000+ (and counting) publicly available AI tools across the internet.\n* [“A Generative AI Primer” by Michael Webb] explains generative AI technology and its expected impact on higher education.\n* [unesco’s quick start guide on “ChatGPT and Artificial Intelligence in higher education”] illustrates the challenges and ethical implications of AI.\n## Guidance for GSD Courses\n*What usage of AI tools is appropriate in GSD courses?*\nPolicy for the use of AI in courses\nWe encourage all instructors to include a policy in course syllabi regarding the use and misuse of generative AI.Whether students in your course are forbidden from using ChatGPT or expected to explore its limits, a policy helps ensure that your expectations forappropriate interaction with generative AI tools are clear to students. Once you decide on a policy, make sure you articulate it clearly for your students, so that they know what is expected of them.Below is sample language you may adopt for your own policy. Feel free to modify it or create your own to suit the needs of your course.\n* **Restrictive draft policy:***We expect that all work students submit for this course will be their own. In instances when collaborative work is assigned, we expect for the assignment to list all team members who participated.*We strictly prohibit the use of ChatGPT, AI-based image generators, or any generative artificial intelligence (GAI) tool at any stage of the work process, including initial or preliminary stages.*Violations of this policy will be considered academic misconduct. We draw your attention to the fact that different classes at Harvard could implement different AI policies, and it is the student’s responsibility to conform to expectations for each course.*\n* **Fully encouraging draft policy:***This course encourages students to explore the use of generative artificial intelligence (GAI) tools such as ChatGPT or an AI-based image generator for all assignments and assessments. Any such use must be appropriately acknowledged and cited. It is each student’s responsibility to assess the validity and applicability of any GAI output that is submitted; you bear the final responsibility. Violations of this policy will be considered academic misconduct. We draw your attention to the fact that different classes at Harvard could implement different AI policies, and it is the student’s responsibility to conform to expectations for each course.*\n* **Mixed draft policy:***Certain assignments in this course will permit or even encourage the use of generative artificial intelligence (GAI) tools such as ChatGPT or an AI-based image generator. The default is that such use is disallowed unless otherwise stated. Any such use must be appropriately acknowledged and cited. It is each student’s responsibility to assess the validity and applica"
  }
]