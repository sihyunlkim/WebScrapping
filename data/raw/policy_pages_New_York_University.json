[
  {
    "query": "New York University generative AI policy",
    "title": "Frequently Asked Questions About Teaching and AI",
    "url": "https://www.nyu.edu/faculty/teaching-and-learning-resources/teaching-with-generative-tools/frequently-asked-questions.html",
    "text": "Frequently Asked Questions About Teaching and AI\nMenu[Skip to All NYU Navigation] [Skip to Main Content] \n[NYU] \nSearchSearch SiteAll NYU\n[NYU Home] \n[Login toNYU Home] \nAll NYU\n[NYU] \nSearch Site\n# Frequently Asked Questions About Teaching and AI\n#### **[Generative AI] **\n**[What is generative AI? How can I experiment with it?] \n[How can I experiment with generative AI?] \n[What are some limitations of generative AI use?] \n[What is NYU's policy about student AI use in coursework?] \n[What risks of learning loss can generative AI create?] **\n#### **[Recommendations for Faculty Use of AI] **\n**[What recommendations apply to faculty use of AI?] \n[What are the recommendations around data use?\n] [How should I communicate my preferences for AI use to my students?] \n[When and how can I get access to NYU’s private generative AI service?] **\n#### **[Generative AI Ethics and Responsible Use] **\n[**Academic Integrity and Generative AI\n**] **[What uses of AI constitute cheating?] \n[How should faculty respond to suspected cases of cheating with AI?] \n[Why doesn't NYU license an AI detector?] **\n#### **[Additional Office of the Provost Resources around Generative AI at NYU] **\n**[Conversations at NYU about AI] **\n### **Generative AI\n**\n**What is generative AI? How can I experiment with it?**\nGenerative AI is a label for tools such as ChatGPT,[Gemini],[NotebookLM], or Midjourney, and describes AI services that generate novel responses to prompting by a user. These services create output as a response to prompting by the user, based on training on billions of examples of text, images, code, etc.\nThough there are many types of generative AI, the “large language models” like[Gemini] from Google, ChatGPT from OpenAI; LLaMa from Meta; or Claude from Anthropic, have the widest range of uses in academic settings. These models can generate relevant responses to many kinds of prompts, meaning they can be used—and are being used—in some way or another in most classes. The opportunity is that students use them to explore ideas and test their knowledge. The threat is that students use the tools to opt out of the effort needed for them to learn.\n**How can I experiment with generative AI?**\nNYU now offers access and support for both Google’s[Gemini] and[NotebookLM] to faculty, staff, and students. Learn more about these tools in this[fact sheet] from NYU IT.\nThere are many kinds of generative tools, for creating text, audio, images, video, and code. More recently, more tools are multimodal, producing combined output —text and images, web pages and code —that increase the complexity of what is possible.\nText-generating tools are the most widely used at NYU, and their most notable feature is producing surprisingly competent written responses to relatively complex questions.\nIf you would like to try it, below are sample prompts you can input into[Google’s Gemini].\n* Can you quiz me on the nature of aliphatic compounds?\n* What are some critical tradeoffs in the design and deployment of public transportation in American cities?\n* Can you write a python script that calculates the Fibonacci sequence to the 50th place?\n* Can you write an outline, with opening and closing paragraphs, comparing the work of Mark Rothko and Willem de Kooning?\nIt is possible to use more complex prompts with these tools, by including the role you are asking the model to play (which generally improves the answers), and the question you want a response to. Here are three sample prompts you can use with large language models:\n1. You are a professor of biology, teaching an introductory course. Please write a description of meiosis vs. mitosis, highlighting similarities and differences in the two processes.\n2. You are an art historian of Chinese ceramics. Please describe the technical and aesthetic changes in ceramic production from the Shang Dynasty to the Warring States period.\n3. You are a screenwriter pitching a film. Please write three loglines for science fiction movies where one of the protagonists is not human.\nTrying one or more of these prompts, modifying them, or creating your own will demonstrate the basic capabilities of text-generating tools. It will be especially valuable if you try these tools with material from your own courses. You can also try[image generation],[voice generation],[code generation],[research support], and so on.\nArts and Science has developed a Brightspace course open to all NYU instructors,[Getting Started with Generative AI for Instructors], that provides more in-depth experience with these tools.\n**What are some limitations of generative AI use?**\n* **Random responses**\nRandomness is built in. You'll get a different answer every time even when you use the same prompt.\n* **Trained for plausibility, not accuracy**\nGenerative AI is designed to produce plausible instances (i.e., to make things up). “Hallucination” describes the inclusion of incorrect or invented information in responses to user prompting.\n* **Bias**\n* Generative AI tools are trained from a wide range of sources, so output may follow bias absorbed from those sources. Bias can also take the form of a lack of coverage of particular disciplines, languages, regions, and so on.\n* Generative AI tools have typically been trained on data that tends towards stereotypical answers—“Doctors are men whereas nurses are women” kinds of biases that extend to many circumstances. All users of these tools should be aware that these biases exist and should use their judgment in using or editing the output.\n* **Digital Divide\n**Access is not equitable. There are gaps between who has access and who doesn’t, largely as a result of differences in tools between free and paid tiers of access, and between students who can afford more expensive computers and phones that have AI capabilities built-in, vs. those using cheaper models.\n* **Intellectual Property and Copyright Issues\n**These models are often trained on copyrighted materials, though it is not yet clear whether such training violates copyright law.\n**What is NYU’s policy about student AI use in coursework?**\n1. The instructor approves.\n2. The student abides by any requirements or limitations the instructor may have.\n3. The use does not violate[NYU’s Academic Integrity Policy], which forbids “submitting work (papers, homework assignments, computer programs, experimental results, artwork, etc.) that was created by another, substantially or in whole, as one's own.”\nGenerative AI is a new arrival in the academic environment and can be used in a wide variety of ways. Because of this novelty and flexibility, there are few standard approaches to its use beyond an institution-wide restriction on taking credit for AI output without acknowledging its use. Most policies will be set by the schools or by individual faculty members. Check with your school or department to see if there are local policies.\n**What risks of learning loss can generative AI create?**\n**Using AI can*feel*like learning**. Though much of the"
  },
  {
    "query": "New York University generative AI policy",
    "title": "Generative AI Guidelines for NYU Communicators",
    "url": "https://www.nyu.edu/employees/resources-and-services/media-and-communications/nyu-brand-guidelines/creating-messaging-and-visual-assets/best-practices/generative-ai-guidelines-for-nyu-communicators.html",
    "text": "Generative AI Guidelines for NYU Communicators\nMenu[Skip to All NYU Navigation] [Skip to Main Content] \n[NYU] \nSearchSearch SiteAll NYU\n[NYU Home] \n[Login toNYU Home] \nAll NYU\n[NYU] \nSearch Site\n# Generative AI Guidelines for NYU Communicators\nNYU is a world-renowned research institution, and as such, we approach the subject of artificial intelligence (AI) with genuine curiosity. While AI is already incorporated into many communications tools and presents positive opportunities for our community, it is a developing technology that also comes with unique challenges. Using generative AI for marketing communications on NYU’s behalf requires a firm understanding of its use cases and limitations, knowledge of the ethical considerations involved, and most importantly—human oversight.\nThe following guidelines are to help NYU communicators leverage generative AI as a tool for effective content generation. Here, the word ‘content’ is used in a broad sense: text, graphics, photography, videos, music, etc. These guidelines do not apply to educational and classroom settings and should not be construed as official NYU policy.\nPlease note that because AI technology is advancing quickly, this is a living document that will be updated as best practices evolve.\n### Guiding Principles\nGenerative AI tools are “trained on” existing content, and, in response to user input, synthesize new material. Generative AI tools are statistical models that generate responses based on patterns in their training content. Generative AI does not understand the concept of “truth” and, as such, has demonstrated that it can have biases and “hallucinate” i.e. make up facts, and pull information from source data without regard for citations or intellectual property rights. It does not engage with moral or ethical considerations, cannot think critically, and is not a replacement for human imagination or discernment. For these reasons, it is important that NYU communicators stick to these guiding principles when using generative AI tools:\n#### Human-Centered Activity\nGenerative AI tools are just that: tools. They should assist—not replace—the people who make content. The breadth of your communications should never be turned over to AI, but it can support your process. AI is no substitute for the creativity, empathy, and attention to detail practiced by NYU communications professionals, but it can be used to enhance our work.\n#### Review Everything\nWe are ultimately accountable for the content we create. Generative AI tools are statistical models and cannot be regarded as an authority on any topic. Their output is influenced by existing material, and this material can be biased, without context, out-of-date, and incorrect. Generative AI also does not fact-check or reliably take copyright or other intellectual property rights into account. You can, however, ask for citations in your prompts, which we recommend. Regardless of citations, it is critical to review and edit any outputs produced by AI to eliminate bias, fact-check content, and avoid plagiarism.\n#### Protect Data and Privacy\nSome generative AI tools may store what you input and use it in future output(s), and this information also may not be encrypted. Do not input any information that is personal or confidential (yours, NYU’s, or anyone else’s), as this may be in violation of university policy as well as state or federal privacy laws such as FERPA (Family Education Rights and Privacy Act). Some examples of protected information include names, demographic information, birthdays, original ideas and code, etc.\nAdditionally, do not input licensed, copyrighted, or proprietary content such as NYU logos or wordmarks.\n#### Be Transparent\nBe forthright when you are using AI-generated content. If you have used AI to meaningfully change an image or other content, consider a citation to that effect, referencing the specific tool you used (e.g. ChatGPT, Open AI, etc.).\n### When to Use AI\nAI tools can be especially helpful with tasks like creative brainstorming, taking notes, refining ideas, generating code, formatting text, and editing images. It can also help synthesize information, take first passes at editing content (e.g. to match AP or Chicago styles), or improve SEO. Still, AI tools should never be used as the final source for facts or editing. Instead, they can help save time on routine tasks and provide a jumping-off point for creative ideation. Following are some examples of acceptable and unacceptable ways to incorporate generative AI into content creation and communications.\n#### Examples of Acceptable Use\n**Brainstorming or creating mood boards:**\nGenerative AI tools can create first draft images or compile pictures and images to use as inspiration.\n**Research and synthesis:**\nGenerative AI tools can create summaries for quick overviews of new topics. This research must be verified by humans, and is not a substitute for scholarly research. For example, you could use generative AI to quickly summarize news articles about a current event, which could help you decide what to explore in more depth.\n**Search Engine Optimization (SEO):**\nGenerative AI tools can help you conduct keyword research, report on readability, optimize headlines and subheads, and structure information for better navigability, etc.\n**Editorial help:**\nYou can have generative AI tools take a first pass at editing your content to match Chicago style, AP style, etc. But be aware that it may not be using the most up-to-date versions of these manuals and your content will still need to be read by a person. Generative AI tools can also make suggestions for shortening your content, looking for repeated words or ideas or suggesting more efficient language. All final editorial reviews should be conducted with human oversight before publication: see the NYU[Editorial Guide] for best practices.\n**Note-taking and transcription**:\nGenerative AI tools can help you take notes and transcribe interviews or meetings to save time. The results are imperfect and should not be assumed to be a verbatim transcript. AI-generated transcripts should be carefully reviewed before they are shared for anything more than your personal use and reference.\n**Editing images:**\nGenerative AI can help you augment or enhance an image, like retouching an existing image, cleaning up a grainy image, or expanding an image (e.g. adding extra sky to the top of a photograph to adjust the aspect ratio). People, places, and other characteristic elements that tell the NYU story should not be generated by AI for the reasons stated above. Adhere to existing best practices for photo editing and stay true to the goal of presenting factual information.\n**Creating abstract imagery:**\nGenerative AI can be used to create images (not photographs) that are not intended to be interpreted as portraying reality. After you have created the image, use a web image search tool to make sure it has not been plagiarized from another source. Be transpare"
  },
  {
    "query": "New York University generative AI policy",
    "title": "Academic Integrity and Syllabus Support",
    "url": "https://steinhardt.nyu.edu/faculty-and-staff/academic-affairs/steinhardt-ai-hub/academic-integrity-and-syllabus-support-age",
    "text": "Academic Integrity and Syllabus Support | NYU Steinhardt[Skip to main content] \n[![Steinhardt School of Culture, Education, and Human Development]] \nSearch\nOpen Main MenuClose Main Menu\n## Search NYU Steinhardt\nSearch\nClose Search\n![NYU building with University flag] \n# Academic Integrity and Syllabus Support in the Age of Generative AI\nCreating clear policies around AI use is essential to maintaining academic integrity and setting student expectations. These policies should outline when and how AI tools like ChatGPT, Perplexity.ai, or Grammarly can be used and ensure students understand the ethical implications of AI in academic work.\nIf you’re interested,[check out this AI Chatbot we created] that can provide you with sample syllabus statements based on your unique course information and preferences.\n## Considerations for AI Policy Creation\n### Permitted Use Cases\nClearly define what AI tools can be used for in your course (e.g., brainstorming, idea generation, or drafting) and where they are prohibited (e.g., completing graded assignments without supervision).\n**Example Policy Statement:***\"Students may use AI tools like ChatGPT for initial idea generation and draft creation, but final submissions must reflect the student's original thoughts and revisions.\"*\n### Prohibited Use Cases\nEstablish boundaries for AI use to prevent academic misconduct, such as using AI to generate full essays or solutions to homework problems.\n**Example Policy Statement:***\"Using AI tools to generate any work is considered plagiarism and will result in disciplinary action.\"*\n### Ethical AI Use\nInclude guidelines on ethical AI usage, including proper attribution when AI-generated content is used in assignments.\n**Example Policy Statement:***\"Any AI-generated content used in assignments must be properly attributed. Failure to disclose AI assistance may result in plagiarism charges.\"*\n## AI Syllabus Statement Templates\nTo help streamline the process of adding AI policies to your syllabus, here are templates and examples that can be adapted for your course. These templates ensure students are fully informed about when AI can be used and how to properly acknowledge AI-generated content. Remember that you can establish different AI policies for each assignment, depending on how you want the tools to be used (or not used). Just make sure to clearly communicate this decision to your students.\n### General AI Use Template\n* \"AI tools, such as ChatGPT or Grammarly, may be used for brainstorming or refining ideas, but all work submitted must be your own. If AI assistance is used in drafting, please include a note explaining how the tool was used.\"\n* \"AI tools, such as DALL-E or MidJourney, may be used for brainstorming or idea generation in art projects, but the student must create and refine all final artwork. If AI tools are used in any part of the creative process, students must disclose their role and provide a written reflection or recorded demonstration about how AI contributed to their creative decisions.\"\n* \"AI tools, such as AIVA or Amper Music, may be used for generating initial musical ideas or experimenting with different styles. However, students are required to modify and develop their compositions independently. Any AI-generated musical elements must be disclosed, and students must provide a written reflection on how they used AI in their compositional process.\"\n### AI in Writing and Research Assignments\n* \"Students may use AI tools to help with research, but all final written content must be original. Cite all sources, including AI-generated suggestions, where appropriate.\"\n* \"AI tools can be used to assist in music analysis or transcription tasks, such as identifying chord progressions or analyzing harmonic structures. However, students must critically evaluate AI output and include their own insights. AI tools must not be used to bypass critical analysis and understanding.\"\n### AI in Group Projects\n* \"In group work, AI can be used as a collaborative tool for idea generation or outlining, but students must document the specific AI tool used and how it contributed to the project.\"\n* \"AI tools can be used to assist in collaborative art projects for idea generation or visual research. However, the final artwork must be original and primarily created by students. All AI-generated concepts or visuals must be properly credited and documented in the project submission.\"\n### Templates for Reflecting on AI Use in Art &amp; Music\n* \"If AI tools are used during the creative process, students must include a 1-2 page reflection outlining how the AI contributed to their project, the specific tools used, and how they adapted or refined the AI-generated content to fit their vision.\n* If art or music-based, “The reflection should also address the ethical implications of using AI in creative arts.\"\n## Engaging Students in AI Policy Discussions\nTo foster a better understanding of AI’s role in education, engage students early in conversations about how AI should be used in academic work. These discussions can help students grasp the ethical responsibilities and critical thinking skills required to effectively and responsibly use AI.\n[] \n* [### Classroom Discussions\n] \n* [### Reflection Assignments\n] [] \nStart the semester with an open discussion on using AI tools, including the ethical implications and expectations for proper use.\n#### Discussion Prompts\n\"How do you think AI will impact your learning experience? What are the potential risks and benefits?\"\n“How do you think AI should be used in our classroom? How can we establish agreed-upon norms for AI usage?”\n[**Discussion Guide**(NetID Login Required)] \nAssign students a reflection on how AI may assist them in their work and the importance of critical thinking beyond relying on AI-generated responses.\n#### Example Assignments\n\"Write a reflection on how you used AI for your project and explain how it influenced your thinking process.\"\n“Reflect on how relying on AI may have influenced your problem-solving approach and identify any gaps in understanding that could arise from over-reliance on AI-generated outputs.”\n## Privacy and Data Security Considerations\nWhen using AI tools, it’s essential to consider privacy and data security. Do not share work containing student identifiers with any third-party services—no student names or other unique identifiers like NetID or N-numbers. Sharing such identifiers with services like ChatGPT or Google Gemini violates the Federal Educational Records Privacy Act (FERPA), which mandates careful handling of student records and restricts their disclosure to third parties. Sharing data that identifies students with tools that NYU has not licensed will never be FERPA-compliant, as FERPA requires the institution to have a specific sort of business relationship. ([NYU’s Academic Integrity for Students at NYU].)\n## Addressing Academic Integrity Concerns\nWith the rise of AI tools like ChatGPT and other generative AI application"
  },
  {
    "query": "New York University generative AI policy",
    "title": "Student Learning with Generative AI",
    "url": "https://www.nyu.edu/faculty/teaching-and-learning-resources/Student-Learning-with-Generative-AI.html",
    "text": "\n NYU now offers access and support for both Google’s Gemini and NotebookLM to faculty, staff, and students. Learn more about these tools in this fact sheet from NYU IT. \n Student Generative AI Guide \n *Adapted from General Principles for Use of AI from The University of Sydney for students by students Generative AI course ( Further Resources). \n Academic integrity, ethics, critical thinking, and creative thinking should foreground your use of generative AI for learning. Below are some general principles to consider when using generative AI in your studies. \n Follow Your Instructor’s Guidance For Each Course \n \n Follow your instructor’s guidance on how generative AI tools can be used for your course or assignments. \n Ensure that any use of generative AI has been acknowledged according to the syllabus or assignment guidelines. \n Maintain academic integrity. \n \n Document Your Process And Use Of Generative AI When Completing Assignments Using Generative AI \n \n Save copies of each step to create a record that can be shared with your instructors to facilitate conversations about your work. For example, keep copies of your previous drafts before and after interacting with generative AI. \n \n Ensure that your final work is your own and is not simply copied and pasted from a generative AI tool \n \n Your own style and voice should be evident. \n Simply rephrasing AI-generated content is not enough for it to be considered your own work! You must still apply your own critical and creative thinking to ensure learning.  \n Foreground intellectual virtues and beware of cognitive biases from the Open Inquiry Toolkit. \n \n Fact-check and Cross-Verify Any Information You Use From Generative AI \n \n Note the limitations of generative AI, most notably that content generated by AI may be biased, made up, inaccurate, not up to date, etc. \n Apply critical thinking at all times! It is important to fact-check and cross-verify any information generative AI gives you. \n Using generative AI is not the same as using a search engine. \n \n Think for yourself \n \n Form your own perspectives and points of view. Do not rely solely on information generated by generative AI tools. \n \n Prepare yourself for the future of work \n \n \n \"AI won't take your job,\" Richard Baldwin, an economist and professor at the Geneva Graduate Institute in Switzerland, said during a panel at the 2023 World Economic Forum's Growth Summit. \"It's somebody using AI that will take your job.\" \n \n"
  },
  {
    "query": "New York University AI policy academic integrity",
    "title": "GenAI & Academic Integrity",
    "url": "https://sites.google.com/stern.nyu.edu/teaching-learning-gen-ai/academic-integrity",
    "text": "Academic Integrity\nSearch this site\nEmbedded Files\nSkip to main content\nSkip to navigation\n[![]] \n# GenAI &amp; Academic Integrity\n## [\n] \nWhat is NYU&#39;s Policy on the use of generative AI?\nYou can find NYU’s official policy on the use of generative AI, plus more[here].\n## [\n] \nHow should I discuss the use of AI and academic integrity with my students?\nDiscussing academic integrity with students requires that you first determine what plagiarism and cheating are in the context of your course, based on your learning goals. As such, you will need to clearly define what unauthorized use of generative AI looks like.  Below are a few suggestions to help get that conversation started.\n1. Have an open conversation with your students as early as possible. This gives students the opportunity to understand what academic dishonesty and appropriate use of generative tools look like in your classroom.  Students may assume another course’s policies are the same as yours or may have a different cultural understanding of academic integrity.\n1. Emphasize how generative tools may support or interfere with learning goals and be explicit about the value you expect students to get out of the course and specific assignments.\n1. Consider giving students a live demonstration using a generative tool to show students what appropriate usage looks like and highlight the shortcomings of the technology.\n1. Give students multiple opportunities and ways to ask clarifying questions. Be available to continue conversations - either in or outside of class - on an ongoing basis. New developments may prompt more discussion.\n![] \n### [\n] \nYour Syllabus should be explicit\nIncluding language that is clear on when and how students can and cannot use generative AI is critical.\n[\nCheck out our Syllabus guide\n] \n## [\n] \nHow can I tell if students are using LLMs like chatGPT or other generative tools to complete assignments?\nIt is increasingly difficult to differentiate AI-generated text from human writing. Detection tools that claim to be able to detect LLM-generated language have been proven to be easily[defeated] and are prone to[false positives].\nThe[NYU Office of the Provost], the Learning Science Lab, and the educational technology community largely recommend that instructorsnotrely on the use of third-party detection tools, like TurnItIn, to detect use of generative tools in student work. Use of these tools can[inadvertently target specific populations of students] and lead to false accusations.\nThere is no easy answer here. Short-term and long-term solutions will involve developing courses, assignments, and assessments with generative tool use as a given.\n### [\n] \nAI detectors are not recommended\nIn the arms race of generative AI tools vs detectors, advances in AI will very likely always outpace the capabilities of detectors.  Their lack of rigorous review and tendency to result in false positives can make them unreliable as evidence.\nReport abuse\nPage details\nPage updated\nReport abuse"
  },
  {
    "query": "New York University AI policy academic integrity",
    "title": "Academic Integrity for Students at NYU",
    "url": "https://www.nyu.edu/about/policies-guidelines-compliance/policies-and-guidelines/academic-integrity-for-students-at-nyu.html",
    "text": "Academic Integrity for Students at NYU\nMenu[Skip to All NYU Navigation] [Skip to Main Content] \n[NYU] \nSearchSearch SiteAll NYU\n[NYU Home] \n[Login toNYU Home] \nAll NYU\n[NYU] \nSearch Site\nPolicy# Academic Integrity for Students at NYU\n## Policy Contents\n* [STATEMENT OF POLICY] \n* [To Whom the Policy Applies] \n* [POLICY AND PROCEDURES] \n* [Notes] \n## STATEMENT OF POLICY\n[top] \nThis policy sets forth core principles and standards with respect to academic integrity for students at New York University. Each school at New York University may establish its own detailed supplemental guidelines for academic integrity, consistent with its own culture, and consistent with the University-wide general guidelines described in this document.\n## To Whom the Policy Applies\n[top] \nThis policy applies to all students at NYU.\n## POLICY AND PROCEDURES\n[top] \nAt NYU, a commitment to excellence, fairness, honesty, and respect within and outside the classroom is essential to maintaining the integrity of our community. By accepting membership in this community, students take responsibility for demonstrating these values in their own conduct and for recognizing and supporting these values in others. In turn, these values will create a campus climate that encourages the free exchange of ideas, promotes scholarly excellence through active and creative thought, and allows community members to achieve and be recognized for achieving their highest potential.\nIn pursuing these goals, NYU expects and requires its students to adhere to the highest standards of scholarship, research and academic conduct. Essential to the process of teaching and learning is the periodic assessment of students' academic progress through measures such as papers, examinations, presentations, and other projects. Academic dishonesty compromises the validity of these assessments as well as the relationship of trust within the community.  Students who engage in such behavior will be subject to review and the possible imposition of penalties in accordance with the standards, practices, and procedures of NYU and its colleges and schools. Violations may result in failure on a particular assignment, failure in a course, suspension or expulsion from the University, or other penalties.\nFaculty are expected to guide students in understanding other people's ideas, in developing and clarifying their own thinking, and in using and conscientiously acknowledging resources - an increasingly complex endeavor given the current environment of widely available and continually emerging technologies that can produce text, images, code, video and the like. In addition, students come to NYU from diverse educational contexts and may have understandings regarding academic expectations that differ from those at NYU. NYU values and respects all academic traditions; however, while at NYU, students are expected to adhere to the norms and standards of academic integrity espoused by the NYU community and will be assessed in accordance with these standards. Students should ask their professors for guidance regarding these standards, including where instructor permission might override these definitions, as well as style guide preferences for citation or acknowledgement of sources for assignments in their courses.\nFollowing are examples of behaviors that compromise the academic and intellectual community of NYU. The list is not exhaustive.  Students should consult the websites and guidelines of their individual schools for an extended list of examples and for further clarification.\n1. Plagiarism: Plagiarism is a form of fraud. It involves presenting work without adequate acknowledgement of its source (e.g., another person, your own earlier work, an AI tool, etc.), as though it were one’s own current work. We all stand on the shoulders of others, and we must give credit to the creators of the works that we incorporate into products that we call our own.  Some examples of plagiarism:\n·a sequence of words incorporated without quotation marks\n·an unacknowledged passage paraphrased from another's work\n·the use of ideas or materials from another source as  though it were one’s own\n2. Cheating: deceiving a faculty member or other individual who assess student performance into believing that one’s mastery of a subject or discipline is greater than it is by a range of dishonest methods, including but not limited to:\n·bringing or accessing unauthorized materials during an examination (e.g., notes, books, or other information accessed via cell phones, computers, other technology or any other means)\n·providing assistance to acts of academic misconduct/dishonesty (e.g., sharing copies of exams via cell phones, computers, other technology or any other means, allowing others to copy answers on an exam)\n·submitting the same or substantially similar work in multiple courses, either in the same semester or in a different semester, without the express approval of all  instructors\n·submitting work (papers, homework assignments, computer programs, experimental results, artwork, etc.) that was created by another, substantially or in whole, as one's own\n· submitting answers on an exam that were obtained from the work of another source; or providing answers or assistance to others during an exam\n·submitting evaluations of group members’ work for an assigned group project which misrepresent the work that was performed by another group member\n·altering or forging academic documents, including but not limited to admissions materials, academic records, grade reports, add/drop forms, course registration forms, etc.\n3. Participating in any adverse action against an individual for making a good faith report of prohibited conduct or for participating in any academic integrity proceeding under this policy or the academic policies set forth by the student's NYU School, department, or division.\n4. Any behavior that violates the academic policies set forth by the student’s NYU School, department, or division.\n###### Notes\n[top] \n1. Dates of official enactment and amendments: Aug 1, 2011\n2. History: enacted August 1, 2011, updated May 24, 2024; Last Updated August 25, 2025\n3. Cross References: N/A\n## About This Policy\nEffective DateAug 25, 2025SupersedesMay 24, 2024Issuing AuthorityProvostResponsible OfficerVice Provost for Undergraduate Academic Affairs\nDefinitions\nNone\nRelated Policies\nSchool Policies as found in the[New York University Bulletins]"
  },
  {
    "query": "New York University ChatGPT policy students",
    "title": "New York University AI Policy for College Applications - GradPilot",
    "url": "https://gradpilot.com/ai-policies/new-york-university",
    "text": "New York University AI Policy: Can You Use ChatGPT? (2026) | GradPilot\n[# GRADPILOT\n] \n# New York UniversityAI Policy for College Applications\nGeneral Policy:L1•AI use permittedD0•No disclosure requiredE1•Manual review possible\n**Important:**Some programs have stricter policies - see details below\n## Quick Answer: Can you use AI atNew York University?\n**It depends on your program:**\n* •**General/Undergraduate:**AI use permitted\n* •**NYU Stern Graduate Programs:**AI use prohibited\nLast verified:2025-09-18• Confidence:High\n## Policy Evidence\n### University General Policy\n> “> No specific published AI policy for undergraduate admissions\n> ”> > —[> > NYU Undergraduate Admissions\n] > > (Updated: > > 2024\n> > )\n> “> essays must be written entirely by you\n> ”> > —[> > NYU Stern Admissions Requirements\n] > > (Updated: > > 2024\n> > )\n### Program-Specific Policies\n#### NYU Stern Graduate Programs\nL4•AI use prohibitedD0•No disclosure requiredE2•Uses screening tools\n> “> essays must be written entirely by you\n> ”> > —[> > View source\n] > > (Updated: > > 2024\n> > )\n**Applies to:**application essays\n## Policy Summary by Program\n|Program|AI Allowed?|Disclosure|Enforcement|\nGeneral/Undergraduate|AI use permitted|No disclosure required|E1•Manual review possible|\nNYU Stern Graduate Programs|AI use prohibited|No disclosure required|E2•Uses screening tools|\n## Sources Verified\nAll sources checked (5)\n#### Policy Sources:\n* [https://www.nyu.edu/admissions/undergraduate-admissions.html] \n* [https://www.stern.nyu.edu/programs-admissions/] \n#### Additional Sources Checked:\n* [https://www.nyu.edu/admissions/] \n* [https://gsas.nyu.edu/admissions/] \n* [https://www.law.nyu.edu/admissions/] \n**Confidence:**High**Last verified:**2025-09-18\n## Additional Context\nNYU has no explicit undergraduate admissions AI policy but graduate programs (NYU Stern) clearly state essays must be written entirely by student. General academic guidelines suggest AI use requires faculty approval. AI detection tools disabled due to unreliability.\n## Frequently Asked Questions\n### DoesNew York Universityallow ChatGPT for essays?\nYes, New York University permits AI use in application essays. Students may include AI-generated content as long as it&#x27;s accurate and they take responsibility for it.\n### Do I need to disclose AI use toNew York University?\nNew York University does not require disclosure of AI use in admissions materials.\n### How doesNew York Universitycheck for AI?\nNew York University may conduct manual reviews to check for AI use, looking for inconsistencies in voice or style.\n### WhichNew York Universityprograms have different AI policies?\nNYU Stern Graduate Programshave specific policies that differ from the general university policy.Programs that prohibit AI entirely: NYU Stern Graduate Programs.\nSee outdated information? Let us know: support@gradpilot.com"
  },
  {
    "query": "New York University ChatGPT policy students",
    "title": "Adapting Assignments to Generative AI",
    "url": "https://www.nyu.edu/faculty/teaching-and-learning-resources/teaching-with-generative-tools/adapting-assignments-to-generative-AI.html",
    "text": "Adapting Assignments to Generative AI\nMenu[Skip to All NYU Navigation] [Skip to Main Content] \n[NYU] \nSearchSearch SiteAll NYU\n[NYU Home] \n[Login toNYU Home] \nAll NYU\n[NYU] \nSearch Site\n# Adapting Assignments to Generative AI\nWhile there are many individual strategies faculty can adopt for assignments, they can be broadly grouped into three categories:\n* Integrating: Students are allowed or required to use generative AI, so long as that use stays within guidelines and is acknowledged\n* Avoiding: Assignments are (re)designed so that generative AI is less relevant\n* Forbidding: Students are told they should not use generative AI\nNote that as adoption of AI continues to grow, strategies of avoiding and forbidding are becoming less effective, as students can use AI in most assignments in most classes.\n### 1. Integrating Use of Generative AI\nIntegrating use of generative AI involves giving students explicit permission to use the tool in a course or on an assignment, but in approved ways. The list of possible ways these tools can be integrated into coursework is large and growing: a[list of strategies collected by UNESCO] on page 9 runs to nearly a dozen items.\nThe advantage of integrating these tools is that it will encourage students to discuss their use in the context of the class. The disadvantage is that understanding student use will require new effort by the instructor. Involving students in this way will also make them more like co-designers of the assignments, which has both advantages (more engagement) and disadvantages (less predictability.)\nSample statement for syllabus:\nUse of Gemini and related tools is allowed in this class, but only in ways noted in the assignments. (Taking credit for work you did not create is a violation of NYU’s Academic Integrity policy.) As with all assignments, learning from the work is your responsibility. You must use the tools in a way that involves effort you learn from.\nFor every assignment, you should also describe:\n* Which tools and techniques you used and for which parts of the assignment\n* What you learned from the work\n* Be prepared to discuss your work in class or in conversation with me\nWhere an instructor decides to design assignments that integrate generative AI, they should consider one or more of the following strategies:\n* Share examples of effective uses of the tool for brainstorming and iterating the output, rather than just copying and pasting the results of a single query\n* Highlight the student’s responsibility for the accuracy of any work they submit, and the need to verify any references or claims in the text\n* Design multi-step assignments that invite student deliberation, analysis, critique, and decision during the creation process### 2. Avoiding Use of Generative AI\nMaking generative AI less relevant means designing an assignment to require the kind of work where humans still significantly outperform machines.\nThe advantage of avoiding use of these tools is that assignments will be designed to require student effort. The disadvantage is that these assignments will be a moving target, as things the tools cannot do well this semester may become possible next semester, requiring regular review of their effectiveness. Strategies that worked in 2023, like asking for integrated text and images, are no longer effective for students using contemporary AIs.\nSample statement for syllabus:\nThough you are welcome to use generative AI tools to brainstorm in the early phases of an assignment, you are expected to produce the assignments themselves on your own. (Taking credit for work you did not create is a violation of NYU’s Academic Integrity policy.) The assignments have been designed around tasks or outputs the tools do not perform well, and your work will be graded down, perhaps substantially, if it fails to meet those expectations regardless of how it was created.\nWhere an instructor decides to design assignments that make use of generative AI less relevant, they should consider one or more of the following strategies:\n* Collect early student thoughts about an assignment in class, to get a sense of how they work unaided\n* Design assignments with greater emphasis on process —iterative work, submission of rough drafts, preserving edit history\n* Ask for specific references or quotes from material studied in class\n* Design assignments that require integration of discussions in class\n* Design assignments tightly tied to specific course readings or concepts\n* Design assignments that require oral presentation or in-class discussion### 3. Advising Against Use of Generative AI\nPersuading students not to use these tools for some or all assignments will require explaining that the things you want them to learn from the assignment require that they do the work themselves. It also asks students to self-police, as there is no regular way to detect use of these tools. Note that this strategy works less well than it did in 2023, as a majority of students have now adopted these tools.\nThe advantage of asking students not to use these tools is that this strategy can preserve some of the design of individual assignments or a whole course. The disadvantage is that while you can recommend against use of these tools, you cannot prevent their use. Given the relative difficulty in detecting use of these tools, academic integrity cases can be harder to adjudicate, because most evidence is circumstantial.\nSample statement for syllabus:\nYou will only learn from these assignments if you do the work yourself. You should not use Gemini or other AI tools as a shortcut or substitute for drafting and editing work in this class. Taking credit for work you do not do is a violation of NYU’s Academic Integrity policy.\nAdvising against use of generative AI is compatible with designing assignments to avoid use of generative AI. Faculty may want to consider using elements of both strategies, instructing students not to use these tools and designing assignments that cannot easily be completed by these tools."
  },
  {
    "query": "New York University provost generative AI guidance",
    "title": "Teaching with Generative AI - NYU",
    "url": "https://www.nyu.edu/faculty/teaching-and-learning-resources/teaching-with-generative-tools.html",
    "text": "# Teaching with Generative AI\n\nStudents and faculty report growing use of generative AI—tools that produce human-like writing (e.g ChatGPT), images (e.g. MidJourney), code (e.g. Microsoft Co-Pilot) and the like. The flexibility of these tools mean that there is no current default for acceptable vs. unacceptable use of these tools in coursework, and student adoption is moving faster than faculty adaptation. Many students are using AI without clear directions from their instructors about which uses are acceptable.\n\n**Faculty should explain to students what is and is not allowed** around AI use in their classes. (We know some faculty believe students are not using AI in their classes. If this is you, we assure you you are wrong.) The Provost’s Office recommends that faculty adopt the following three principles for student use of AI:\n\n1. When a student uses these tools, they should acknowledge that use\n2. The student is responsible for the content and accuracy of any work they submit, however created\n3. Students only learn from productive effort, and should understand how misuse or overuse of AI threatens that effort\n\nIn order to help students understand these things, we recommend that instructors:\n\n- [Explain your AI policy in your syllabus], and discuss the reasons you adopted it in class\n- Be specific about Dos and Don’ts—“Do acknowledge and describe any AI use”, or “Don’t use any AI for anything other than suggesting topics and sources”\n- Explain the [limitations of generative AI].\n- Remember that students generally want to learn, and explain to them what they can learn from doing the work, not just the potential punishments for cheating\n\nAdditional details can be found in the [AI FAQ] and in [Adapting Assignments to AI].\n\n### Academic Integrity and Generative AI\n\nWith AI being integrated into a wide range of student work, there is no longer any obvious line dividing acceptable from unacceptable use. Using AI to generate ideas, our outlines, or drafts to be edited might be allowed (or even required) for an assignment or it might be forbidden. There is no way for a student to know which it is without guidance.\n\nToo often, academic integrity is presented as a list of behaviors to avoid. We need to present academic integrity as a positive virtue, a description of the conditions necessary for students to learn. The best long-term strategy is to design courses to have more, lower-stakes assessments that offer rapid feedback and an opportunity to make incremental progress on an assignment. Even with course designed around those principles, however, there may be students who use AI in ways that violate faculty requirements.\n\nDetecting and adjudicating inappropriate use of generative AI is harder than detecting simple cut and pasting from public sources. Every student now has no-cost access to a service that can answer a question or write an essay for them; the familiar paid essay writing services are now effectively ubiquitous and free. Intervening when an instructor suspects AI misuse relies far more on the instructor’s judgment about the student’s capabilities than when the source material exists online or in a database.\n\nIf an instructor suspects a student of an academic integrity violation:\n\n- Document reasons for believing the writing is not the student’s own. Possible evidence includes:\n - **Internal Patterns:** Grammatical perfection, consistent but bland style, sudden changes in style or tone, vague or unsubstantiated claims, spurious or incorrect references, and list structures masquerading as development of an idea.\n - **External Patterns:** Writing does not match a student's previous work  (particularly work produced in class), lack of rough drafts or evidence of editing, footnotes or references not related to the body of the text, footnotes or references pointing to work that does not exist.\n- Ask the student if they used generative AI on the assignment in inappropriate or unacknowledged ways, given the evidence. One possible response if they say Yes (and if it is in line with your school’s policies) is to require them to redo the work, providing evidence of editing\n- If they deny using these tools but you continue to suspect that they used them, involve your school administration.\n\nWhile there are a number of products that purport to positively identify AI-generated writing, they have high error rates, especially for students for whom English is an additional language. NYU does not license or endorse use of any of these tools.\n\n* * *\n\n#### A Curated List of AI Resources\n\n- [nyu.edu/ai] \n - [Private Generative AI Pilot] \n- Office of the Provost:\n - [NYU Teaching and Learning with AI]  (web page)\n - [Adapting Writing Assignments to Generative AI]  (Google Doc)\n - [Generative AI Primer]   (Google Slides)\n - [Hands-On with ChatGPT]  (Google Slides)\n - [(Re)designing Assignments & Assessments]  (Google Slides)\n- NYU Schools\n - Abu Dhabi's Hilary Ballon Center for Teaching and Learning: [Teaching with Generative AI]  (NYU Stream)\n - Arts and Science [Getting Started with Generative AI for Instructors]  (Brightspace course open to all NYU Instructors.)\n - Steinhardt\n\n\n - [AI: Creating Prompts with AI]  (web page)\n - [AI: Class Policies]  (web page)\n - [AI: Tips for Writing Assignments]  (web page)\n - [Stern]  (website)\n - Tisch:\n - [Game Center AI Policy]  (web page)\n- NYU Libraries\n - [Evaluating and Acknowledging AI-Generated Text]  (Slides)\n - [Understanding ChatGPT and the Concept of AI Language Generators]  (website)\n - [Machines and Society (NYU Shanghai Library)]  (website)\n\n[⌃ back to top]"
  },
  {
    "query": "New York University provost generative AI guidance",
    "title": "Colleges should go 'medieval' on students to beat AI cheating, NYU ...",
    "url": "https://fortune.com/2025/08/31/ai-cheating-colleges-universities-medieval-education-oral-instruction-exams/",
    "text": "Colleges should go ‘medieval’ on students to beat AI cheating, NYU official says | Fortune\nSearch\n[] \nSubscribe\n* [Home] \n* [Latest] \n* [Fortune 500] \n* [Finance] \n* [Tech] \n* [Leadership] \n* [Lifestyle] \n* [Rankings] \n* [Multimedia] \n[AI] [Colleges and Universities] \n# Colleges should go ‘medieval’ on students to beat AI cheating, NYU official says\n![Jason Ma] \nBy\n[Jason Ma] \nJason Ma\nWeekend Editor\nDown Arrow Button Icon\n![Jason Ma] \nBy\n[Jason Ma] \nJason Ma\nWeekend Editor\nDown Arrow Button Icon\nAugust 31, 2025, 6:24 PM ET\nAdd us on\n![In medieval times, students often listened to teachers read from books, and some schools even discouraged students from writing down what they heard, NYU’s Clay Shirky said.] \nIn medieval times, students often listened to teachers read from books, and some schools even discouraged students from writing down what they heard, NYU’s Clay Shirky said.Getty Images\n* **Amid the raging debate over the proper role of generative AI in schools,**a vice provost at New York University suggested colleges revive some educational practices that date back to medieval times, namely focusing on oral instruction and examination in the classroom. That comes as students have increasingly relied on chatbots to complete assignments.\nEducators have been struggling over how students should or should not use artificial intelligence, but one New York University official suggests going old-school—really, really old-school.\nRecommended Video\nIn a[*New York Times*op-ed] on Tuesday, NYU’s vice provost for AI and technology in education, Clay Shirky, said he previously had counseled more “engaged uses” of AI, where students use the technology to explore ideas and seek feedback, rather than “lazy AI use.”\nBut that didn’t work, as students continued using AI to write papers and skip the reading. Meanwhile, tools meant to detect AI cheating produce too many false positives to be reliable, he added.\n“Now that most mental effort tied to writing is optional, we need new ways to require the work necessary for learning,” Shirky explained. “That means moving away from take-home assignments and essays and toward in-class blue book essays, oral examinations, required office hours, and other assessments that call on students to demonstrate knowledge in real time.”\nSuch a shift would mark a return to much older practices that date back to Europe’s medieval era, when books were scarce and a university education focused on oral instruction instead of written assignments.\nIn medieval times, students often listened to teachers read from books, and some schools even discouraged students from writing down what they heard, Shirky said. The emphasis on writing came hundreds of years later in Europe and reached U.S. schools in the late 19th century.\n“Which assignments are written and which are oral has shifted over the years,” he added. “It is shifting again, this time away from original student writing done outside class and toward something more interactive between student and professor or at least student and teaching assistant.”\nThat may entail device-free classrooms as some students have used AI chatbots to answer questions when called on during class.\nHe acknowledged logistical challenges given that some classes have hundreds of students. In addition, an emphasis on in-class performance favors some students more than others.\n“Timed assessment may benefit students who are good at thinking quickly, not students who are good at thinking deeply,” Shirky said. “What we might call the medieval options are reactions to the sudden appearance of AI, an attempt to insist on students doing work, not just pantomiming it.”\nTo be sure, professors are also using AI, not just students. While some use it to help develop a course syllabus, others are using it to[help grade essays]. In some cases, that means AI is grading an AI-generated assignment.\nAI use by educators has also generated backlash among students. A senior at Northeastern University even filed a formal complaint and[demanded a tuition refund] after discovering her professor was secretly using AI tools to generate lecture notes.\nMeanwhile, students are also getting mixed messages, hearing that the use of AI in school counts as cheating but also that not being able to use AI will hurt their job prospects. At the same time, some schools have no guidelines on AI.\n“Whatever happens next, students know AI is here to stay, even if that scares them,” Rachel Janfaza, founder of Gen Z–focused consulting firm Up and Up Strategies,[wrote in the*Washington Post*] on Thursday.\n“They’re not asking for a one-size-fits-all approach, and they’re not all conspiring to figure out the bare minimum of work they can get away with. What they need is for adults to act like adults—and not leave it to the first wave of AI-native students to work out a technological revolution all by themselves.”\n**Join us at the Fortune Workplace Innovation Summit**May 19–20, 2026, in Atlanta. The next era of workplace innovation is here—and the old playbook is being rewritten. At this exclusive, high-energy event, the world’s most innovative leaders will convene to explore how AI, humanity, and strategy converge to redefine, again, the future of work.[Register now].\nAbout the Author\n[![Jason Ma]] \nBy[Jason Ma] Weekend Editor\nJason Ma is the weekend editor at*Fortune*, where he covers markets, the economy, finance, and housing.\n[See full bioRight Arrow Button Icon] \nLatest in AI\nFinance\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam\nBy Fortune Editors\nOctober 20, 2025\nFinance\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam\nBy Fortune Editors\nOctober 20, 2025\nFinance\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam\nBy Fortune Editors\nOctober 20, 2025\nFinance\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam\nBy Fortune Editors\nOctober 20, 2025\nFinance\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam\nBy Fortune Editors\nOctober 20, 2025\nFinance\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam\nBy Fortune Editors\nOctober 20, 2025\nMost Popular\nFinance\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam\nBy Fortune Editors\nOctober 20, 2025\nFinance\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam\nBy Fortune Editors"
  },
  {
    "query": "New York University provost generative AI guidance",
    "title": "AI Use Guidance - Office of The Provost - Baruch College - CUNY",
    "url": "https://provost.baruch.cuny.edu/artificial-intelligence-think-tank/ai-use-guidance/",
    "text": "AI Use Guidance - Office of The Provost | Baruch College[Skip to content] \nQuick Links\n* Quick Links\n* [BaruchHUB] \n* [Bearcat Bookstore] \n* [Blackboard] \n* [Brightspace] \n* [Blogs@Baruch] \n* [Consumer Information] \n* [CUNYBuy] \n* [CUNYfirst] \n* [Degree Works] \n* [ePAF] \n* [Faculty &amp; Staff] \n* [Email] \n* [Office 365] \n* [Dropbox] \n* [Interfolio] \n* [MyInfo] \n* [SmartEvals] \n* [Student Email] \n* [Time and Leave] \n* [Full Time] \n* [Part Time] \n* [Zoom] \n* [Calendar] \n* [Directory] \n* [Library] \n* [President's Office] \n* [News Center] \n* [Technology] \n* [Donate] \n[Baruch college |![Baruch College-logo]![Baruch College-logo]] [City University of New York![CUNY-logo]] \nMenu\nMain Search\nOffice ofthe Provost\nDepartment Links\n* [Division of Academic Affairs] \n* [Office of the Provost] \n* [Provost Initiatives] \n* [Artificial Intelligence Think Tank] \n* [Faculty Grants and Awards for 2025-2026] \n* [Mental Health Awareness Week 2026] \n* [Leadership] \n* [Faculty Affairs, Research &amp; Innovation] \n* [Academic Administration] \n* [Reappointment, Tenure, CCE, and Promotion] \n* [Baruch College Faculty P&amp;B Guidelines] \n* [Department Chairs and Faculty Personnel Committees] \n* [List of Department Chairs] \n* [Representatives to Faculty Personnel Committes] \n* [Faculty Workload Reporting and Compliance] \n* [Faculty Leaves] \n* [New Faculty] \n* [International Faculty] \n* [Faculty Appointments] \n* [Faculty Affairs] \n* [Faculty Convocation] \n* [Research] \n* [Faculty Handbook] \n* [Learning and Student Success] \n* [Experiential and Community Engaged Learning (ExCEL)] \n* [College Agreements] \n* [Academic Honesty] \n* [Academic Support for Students] \n* [Support for Faculty] \n* [Pedagogy &amp; Online Programs] \n* [National Council for State Authorization Reciprocity Agreements (NC-SARA)] \n* [Assessment, Accreditation &amp; Institutional Effectiveness] \n* [Institutional Effectiveness] \n* [Data-driven Decision Making] \n* [Program Review] \n* [Assessment] \n* [Assessment Spotlight Series] \n* [MSCHE Institutional Accreditation] \n* [Interview with MSCHE Liaison, Dr. Tiffany Lee] \n* [Specialized Accreditation] \n* [NYSED –Academic Program Registration] \n* [National Collegiate Athletic Association (NCAA)] \n* [Communications Archive] \n* [From the Provost] \n* [From the Associate Provost for Teaching, Learning, and Student Success] \n* [From the Associate Provost for Academic Admin. and Research] \n# AI Use Guidance\n## Guidelines for AI Use at Baruch College\nDeveloped by the AI Think Tank Governance and Operations Subcommittee with input of the campus community\nUpdate August 19, 2025\nNote: Guidelines will be updated as AI technology evolves. Thus, this is a living document.\nI. General Principles\nTechnologies assist people in their work, problem-solving, and day-to-day lives. Technologies enhance our capacities as teachers, students, scholars, and administrators. The rapid development of generative AI has begun and will continue to fundamentally alter the way we find, use, create, and disseminate knowledge and information (including data). These guidelines are intended to assist the Baruch College community in using artificial intelligence tools effectively and ethically.\nBaruch College uses CoPilot as its default generative AI tool because, as specified in the CUNY Microsoft 365 contract, CoPilot will not share data input by CUNY users beyond the CUNY environment. In other words, when we use CoPilot, we are training only the CUNY instance of CoPilot and not its underlying model.\nThe key guideline for the use of generative AI is a simple one: disclose.\n* Disclose that content was generated by AI while providing details when appropriate (for example, the prompts used to generate content).\n* Disclose if AI was used to aid in decision-making, including the platform, prompt, and date.\n*IP and Data Security.*Course materials are covered by copyright and as such should not be used to train a large language model (LLM) without the express consent of the copyright owner (for course materials, this is usually the faculty member). Faculty and staff are thus advised to use caution when uploading their intellectual property to Gen AI LLMs outside of the CUNY Copilot environment. Similarly,**institutional data may not be used with Gen AI platforms outside of the CUNY CoPilot environment.**\nGen AI “has no stake in the knowledge it produces and is thus likely prone to offering irresponsible outputs.”[[1]] Thus**AI outputs must be confirmed by human critical thinkers before using it in operations, teaching, learning, or research.**\nII. Teaching and Learning\nThe easy accessibility of generative AI (GenAI) tools means that students, faculty, and staff are already using AI tools in their work. (Examples of GenAI Tools include MS Copilot, ChatGPT, Google Gemini.) Further, students will be graduating into a workforce that uses AI of all kinds and perhaps even create AI tools themselves. Thus, as an educational institution, there is an obligation to provide students with opportunities to learn to use AI effectively, responsibly, and ethically.\n1. Syllabi. Faculty are encouraged to integrate artificial intelligence education into their courses as appropriate to their disciplines, but are not obligated to do so. All syllabi should include a course- and discipline-appropriate policy on the use of generative AI. Faculty should clearly indicate on their syllabus when, whether, and to what extent AI use is allowable in a class. This should specify whether AI tools are allowable for use in editing (e.g. Grammarly) even if disallowed for content generation (e.g. ChatGPT, CoPilot, Gemini, etc.). Faculty should also remind students of these guidelines and expectations throughout the semester. To reduce student confusion about what is permissible across multiple classes, faculty should share their expectations clearly and frequently. Possible sanctions should also be listed on the course syllabus (eg, reduction in points or the grade on an assignment, failure on an assignment, or for egregious cases, failure of a course).[Sample syllabus policies] are available on the[AI Resource Hub]. Such course policy should set clear expectations about the use of GenAI tools and should provide rationale for how and when they can be used in the course. For example, GenAI tools can be helpful in some contexts by encouraging critical thinking and improving the quality of the deliverables for other assignments, yet for other assignments, it may be appropriate to prohibit the use of GenAI tools when the assignment is meant, for example, to assess learning of foundational concepts. ([Sample syllabus policies] are available on the[AI Resource Hub].)\n2. Assignments in which generative AI is integrated or allowed should clearly state the parameters of such use. These parameters should include:\ni. Disclosure that the content was generated by AI\nii. Student responsibility to verify the accuracy of AI-generated content\niii. Documentation of prompts used and oth"
  },
  {
    "query": "New York University teaching and learning generative AI guidance",
    "title": "Enhancing Teaching and Learning with Generative AI",
    "url": "https://steinhardt.nyu.edu/faculty-and-staff/academic-affairs/steinhardt-ai-hub/enhancing-teaching-and-learning-generative-ai",
    "text": "Enhancing Teaching and Learning with Generative AI | NYU Steinhardt[Skip to main content] \n[![Steinhardt School of Culture, Education, and Human Development]] \nSearch\nOpen Main MenuClose Main Menu\n## Search NYU Steinhardt\nSearch\nClose Search\n![NYU classroom] \n# Enhancing Teaching and Learning with Generative AI\n## Integrating AI into the Classroom\nThis guide is designed for educators seeking to integrate AI into their teaching practices. It offers actionable strategies, practical resources, and detailed examples to help enrich student learning with AI tools. AI can enhance personalized learning, automate routine tasks, and boost student engagement, but aligning its use with clear learning objectives and ethical guidelines is essential for effective implementation.\n### Best Practices for AI Integration\n#### Define Clear Objectives for AI Use\n**Purpose-driven AI integration:**Before using AI, clarify the goals it will support. Define how AI can enhance learning outcomes, such as personalized feedback, content creation, or research assistance.\n**Example:**Use AI to brainstorm project topics. Explicitly tell students when they should stop utilizing generative AI for this project.\n#### Maintain Transparency with Students\n**Explain AI’s role in the classroom:**Be transparent with students about how AI will be used and explain its capabilities and limitations. This promotes ethical use and helps students understand AI’s strengths and weaknesses.\n**Example:**Introduce students to AI tools like ChatGPT by explaining how it generates responses and the importance of critically evaluating AI-generated content. Create an introductory assignment that requires students to use ChatGPT to generate written work. Ask that students critically evaluate the output and submit that for grading and large &amp; small group reflection.\n#### Encourage the Ethical Use of AI\n**Teach responsible AI use:**Develop guidelines around AI usage, such as proper attribution of AI-generated content and the ethical considerations of using AI for assignments.\n**Example:**Incorporate early discussions on academic integrity, plagiarism, and the appropriate use of AI for research and writing assistance.\n#### Use AI to Foster Critical Thinking\n**Complement, don’t replace:**AI should be used to complement learning, not as a substitute for critical thinking and problem-solving. Encourage students to critically assess AI-generated suggestions or solutions.\n**Example:**Have students use AI tools for brainstorming or drafting, but require them to analyze and refine the output with their own insights. Require students to reflect on these exercises using in-class discussions or asynchronous online discussions utilizing NYU Brightspace.\n#### Personalize Learning Experiences\n**Leverage AI for adaptive learning:**Use AI-powered tools to tailor instruction based on individual student needs, providing personalized learning experiences that adapt to student progress.\n**Example:**Create personalized study plans for your different learning styles. Try imputing your activity or assignment into chatGPT and asking it to provide you with ideas on how to adjust the assignment for learners with anxiety or depression or for students who might be new to the subject matter and need more scaffolding.\n#### Integrate AI with Collaborative Learning\n**Facilitate group projects with AI:**Use AI to enhance collaboration by allowing students to engage in AI-driven group discussions, idea generation, and content refinement.\n**Example:**Students can use AI to collectively generate project ideas or feedback, fostering peer learning and critical evaluation of AI outputs. Ask students to assess the AI output for bias and misinformation.\n#### Continuously Assess and Adjust AI Use\n**Monitor effectiveness:**Regularly assess the impact of AI on student learning outcomes. Be prepared to adjust its use based on feedback and learning progress.\n**Example:**Conduct regular check-ins with students to gauge how AI aids their learning and where it may need adjustment or further guidance. You can facilitate this through a reflective discussion, anonymous feedback via Google Forms, or anonymous discussions on NYU Brightspace.\n#### Create Clear Policies\n**Develop AI usage policies:**Set clear policies on how AI can and cannot be used in coursework. Include these guidelines in the syllabus and ensure students understand the expectations.\n**Example:**Clearly state that AI-generated text must be cited or only used in specific parts of an assignment (e.g., brainstorming).\n#### Offer Training and Support\n**Provide AI tool training:**Ensure students are adequately trained in using AI tools. Offer tutorials or resources to help everyone use AI effectively and ethically. Don’t assume that just because your learners are younger, they’re comfortable with AI!\n**Example:**Request that the*Digitial Innovation and Learning*Team host an AI workshop at the start of the semester to familiarize students with the AI tools they’ll be using in class.\n#### Address AI’s Limitations\n**Be mindful of AI’s weaknesses:**Educate students about AI’s limitations, such as potential biases, factual inaccuracies, or lack of contextual understanding, and how these can impact output quality.\n**Example:**Have students cross-check AI-generated research content with primary sources to verify accuracy. Additionally, have students intentionally examine the output for*bias*and share the findings with the larger audience.\n## Sample Classroom Activities\nThese lesson plans are designed to support critical thinking, creativity, and engagement through the thoughtful use of AI. Whether you're new to AI or looking to enhance your existing lessons, these plans offer practical ways to bring AI into various subjects, helping students develop digital literacy and navigate AI's role in education. Explore ready-to-use templates and ideas for fostering interactive, AI-supported learning experiences.\n### Ctrl+Alt+Debate: AI-Powered Argumentation and Debate Strategies\n**Best for:**Undergraduate &amp; Graduate\n**Activity Type:**Discussion &amp; Critical Thinking\n**Description:**Students use AI to generate arguments for or against a topic and then engage in a structured debate. This activity helps students analyze AI-generated reasoning, refine arguments, and improve their debate skills.\n**Lesson Plan Steps:**\n1. Assign students a debate topic related to the course material.\n2. Have students use an AI tool (like ChatGPT or Gemini) to generate arguments for both sides.\n3. Pair students and assign them positions (pro/con).\n4. Students refine AI-generated responses with evidence from course readings.\n5. Conduct live debates in class.\n**Materials Needed:**\n1. Access to an AI chatbot\n2. Course readings\n3. Debate rubric\n**Prep Time:**15-20 minutes\n**Activity Duration:**30-45 minutes\n[Activity Lesson Plan] \n### AI Writes, You Refine: A Storytelling Activity\n**Best for:**Undergraduate\n**Activity Type:**Creative Writing &amp; AI In"
  },
  {
    "query": "New York University teaching and learning generative AI guidance",
    "title": "Generative AI in Teaching & Learning - York University",
    "url": "https://www.yorku.ca/teachingandlearning/gen-ai/",
    "text": "[Skip to main content] [Skip to local navigation] \n\n![] \n\n![] \n\n**Generative Artificial Intelligence (GenAI) offers new opportunities for enhancing teaching and learning, while at the same time posing challenges for both educators and learners. York University invites students, faculty, and staff to take a thoughtful and principled approach to this new technology. We embrace the five principles of Transparency, AI Literacy, Choice, Academic Integrity, and Alignment with Core Values, which you can explore below. These principles also inform the resources and supports you will find throughout this website**.\n\n## Guiding Principles\n\n### Transparency\n\nTransparent disclosure of where and how GenAI has been used in research, teaching, learning, and other work builds trust and supports a culture of openness, innovation, and integrity. Transparency works to demystify AI, helping our community better understand its impact and potential.\n\nHow to practice Transparency:\n\n- Disclose when you have used GenAI and how it was used.\n- Prioritise clarity and open communication regarding specific GenAI use guidelines at the course, department, or Faculty level.\n- Stay informed! As AI becomes embedded in our digital workspaces, it can be challenging to know when a tool is powered by AI.\n\n### Choice\n\nEnsuring choice for students, staff, and faculty when it comes to GenAI respects the autonomy of our community members and recognizes that the technology behind GenAI, and the ways it can be deployed, are complex and not value-neutral. You are encouraged to learn about these complexities and should be free to use GenAI (or not) in ways that align with personal values and beliefs.​\n\nHow to practice Choice:\n\n- Faculty have the choice to restrict the use of GenAI in a specific course or assignment. These restrictions should be clearly communicated at multiple points.\n- If you are asking peers, colleagues, or students to make use of GenAI, be prepared to provide an option for those that prefer traditional methods. Opting out should not disadvantage student learning.\n- Protect others’ freedom of choice regarding sharing their work with GenAI tools – don’t upload work that is not your own into any GenAI tool.\n\n### Alignment with York Values\n\nAs a community we have strong existing values when it comes to teaching and learning, reflected in our commitments to DEDI, sustainability, experiential education, and student access and success. While some aspects of GenAI challenge these values, in other ways it can help support them if used thoughtfully and effectively. ​\n\nHow to find your alignment with core values:\n\n- Learn more about how GenAI poses both opportunities and challenges to our values on the [Ethics] page.\n- Consider emerging research and resources on the impacts of GenAI for sustainability, equity, decolonization and student access, such as this [UNESCO report].\n- Explore how your peers and scholars are approaching these issues in your own disciplinary and professional contexts.\n\n### AI Literacy\n\nGiven its undeniable influence in reshaping higher education and the future of our society, York students, faculty, and staff should all work towards a deeper understanding of GenAI technology, suitable to each person’s needs and context. GenAI literacy touches not only on technological knowledge and the use of specific tools, but also on critical thinking, ethical considerations, and responsible usage.\n\nHow to increase your AI Literacy:\n\n- Start with [GenAI 101].\n- Faculty: Visit the Teaching Commons site to learn about courses and workshops for faculty related to GenAI.\n- Students: Discover more resources on the [For Students] page.\n\n### Academic Integrity\n\nYork is committed to maintaining the highest standards of academic integrity in all areas of academic life, including teaching, learning, and research. In response to GenAI, updating and revising existing academic integrity practices, course assessments, and degree-level standards may be necessary.\n\nHow to practice Academic Integrity:\n\n- Review York’s [Academic Conduct Policy]. Sections 5.2 and 6.2 pertain to GenAI use in course work.\n- Faculty: Practice integrity in your own teaching practices.  You can find additional support [here].\n- Students: Ensure you know the policy on GenAI use for each course, as instructors may vary in their approaches. You can find additional support [here].​\n\n[Gen AI 101] \n\n[Ethics] \n\n[For Students] \n\n[For Faculty] \n\n[For Grad Students] \n\n[Gen AI 101]"
  }
]