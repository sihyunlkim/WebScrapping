university_name,scope,policy_title,policy_url,publisher,last_updated,policy_types,summary_bullets
New York University,university-wide,Academic Integrity for Students at NYU,https://www.nyu.edu/about/policies-guidelines-compliance/policies-and-guidelines/academic-integrity-for-students-at-nyu.html,Provost,"Aug 25, 2025",academic-integrity|student-guidance,"Sets forth core principles and standards with respect to academic integrity for all students at New York University. || Each school may establish its own detailed supplemental guidelines, consistent with this university-wide policy. || Defines plagiarism as presenting work without adequate acknowledgment of its source, explicitly including 'an AI tool'. || Defines cheating as deceiving faculty, including 'submitting work... that was created by another, substantially or in whole, as one's own'. || Faculty are expected to guide students in understanding proper use and acknowledgment of resources, especially with emerging technologies."
New York University,university-wide,Teaching with Generative AI,https://www.nyu.edu/faculty/teaching-and-learning-resources/teaching-with-generative-tools.html,Office of the Provost / Teaching and Learning Resources,,teaching-guidance|student-guidance|academic-integrity,"Instructs faculty to clearly explain their AI policy in syllabi and discuss it in class, acknowledging widespread student AI use. || The Provostâ€™s Office recommends three principles for student AI use: acknowledge use, student responsibility for content/accuracy, and understanding that learning comes from productive effort. || Faculty should be specific about permitted/forbidden AI uses and explain the limitations of generative AI. || Notes that detecting and adjudicating inappropriate AI use is challenging, and NYU does not license or endorse third-party AI detection tools due to high error rates."
New York University,university-wide,Frequently Asked Questions About Teaching and AI,https://www.nyu.edu/faculty/teaching-and-learning-resources/teaching-with-generative-tools/frequently-asked-questions.html,Office of the Provost / Teaching and Learning Resources,,teaching-guidance|academic-integrity|student-guidance,"Clarifies NYU's general policy on student AI use in coursework: allowed if instructor approves, student abides by requirements, and use does not violate the Academic Integrity Policy. || Emphasizes an 'institution-wide restriction on taking credit for AI output without acknowledging its use'. || States that most detailed policies for AI use will be set by individual schools or faculty. || Provides an overview of generative AI, its limitations (randomness, plausibility over accuracy, bias, digital divide, intellectual property/copyright), and faculty recommendations for communicating AI preferences."
University of Washington,university-wide,Update on the work of the AI Task Force,https://www.washington.edu/provost/2024/09/24/update-on-the-work-of-the-ai-task-force/,Office of the Provost,2024-09-24,research|teaching-guidance|student-guidance|other,"Announces progress on the provost's initiative for AI at the UW and outlines next steps for community involvement. || Highlights the formation of the AI Task Force to develop a UW-wide strategy for AI. || Introduces the Washington AI Initiative for Society, Teaching, and Research (WAISTAR) framework, covering Education, Research, Student Experience, and Operations. || Emphasizes the UW's responsibility to lead in ethical and equitable AI use and to build basic AI understanding within the community. || Calls for feedback via a survey and announces a series of town halls focusing on different aspects of AI at UW."
University of Washington,university-wide,Generative Artificial Intelligence General Use Guidelines,https://it.uw.edu/guides/security-authentication/artificial-intelligence-guidelines/,UW-IT,2025-09-16,data-privacy|integrity|other|student-guidance|teaching-guidance|research,"Supports responsible GenAI use for UW's mission, aligning with UW values and privacy principles. || Mandates use of only UW-approved services and applications with University data to ensure policy and legal compliance. || Stresses individual responsibility and accountability for GenAI use and its outcomes. || Requires review of GenAI output to minimize harm, avoid biases, and emphasizes human judgment. || Advises transparency in disclosing GenAI use, maintaining detailed records, and adhering to confidentiality and privacy rules (e.g., data classification levels)."
University of Washington,university-wide,AI tools and academic integrity,https://www.washington.edu/studentlife/2023/10/11/ai-tools-and-academic-integrity/,Vice President for Student Life,2023-10-11,student-guidance|integrity,"Communicates the University's expectations to students regarding AI tools and academic integrity. || Emphasizes academic integrity as a commitment to honesty, trust, and responsibility. || Warns that using AI content generators without instructor permission may violate academic standards and the Student Conduct Code. || Advises students to read course syllabi, ask for clarification on AI use, and review the Student Conduct Code. || Highlights available academic support programs and UW Libraries services for students."
Carnegie Mellon University,university-wide,Carnegie Mellon University Policy on Academic Integrity,https://www.cmu.edu/policies/student-and-student-life/academic-integrity.html,Office of the Vice President for Student Affairs,"August 15, 2024",integrity,"Academic credit should represent the work of the individual; collaboration or assistance on graded academic work is not permitted unless explicitly authorized by the course instructor(s). || The policy implicitly covers generative AI tools as a form of unauthorized assistance if not explicitly permitted by the instructor. || Students are required to cite all sources and acknowledge any authorized collaboration or assistance. || Instructors must communicate their specific expectations for collaboration, assistance, citation, and acknowledgement within each course, and students are responsible for understanding these standards."
Carnegie Mellon University,university-wide,Use AI Safely at CMU,https://www.cmu.edu/computing/services/ai/meet-ai/secure-ai.html,Computing Services - Office of the CIO,,data-privacy|other,"Emphasizes awareness of data privacy, security, ethical, and legal concerns when using Generative AI tools. || Lists CMU-approved AI services (e.g., ChatGPT Edu, Google NotebookLM, Microsoft Copilot Chat) that have university contract terms in place and can be used with any CMU data except Controlled Unclassified Information (CUI). || Provides a checklist for safe AI use, including reviewing Data Classification Guidelines, reporting suspicious activity, exercising caution with copyright, and verifying AI outputs for accuracy. || Differentiates between 'Public AI Tools' (personal accounts, not CMU-approved) and 'Protected AI Tools' (CMU-licensed), highlighting risks like loss of data control, data training, and potential sale of data with public tools."
Carnegie Mellon University,university-wide,CMU's Generative AI + Education Modules,https://www.cmu.edu/teaching/gaitar/genaimodules/index.html,Eberly Center and Office of the Vice Provost for Teaching and Learning Innovation,,student-guidance|teaching-guidance,"Provides instructional modules designed as a primer for CMU students to support their effective and responsible use of generative AI tools. || Aims for students to understand how generative AI tools work, analyze ethical implications, and identify appropriate strategies for responsible use. || Covers topics such as the basics of LLMs, the role of training data, risks of hallucinations, attribution for AI-generated content, ethical frameworks, and strategies for appropriate and responsible use (Decide, Verify, Cite, Rectify, Lateral Reading). || Developed as part of CMU's broader strategy regarding Generative AI and education, involving subject-matter experts from multiple departments and students as co-creators."
Stanford University,university-wide,Report of the AI at Stanford Advisory Committee,https://provost.stanford.edu/sites/g/files/sbiybj29391/files/media/file/ai-at-stanford-report.pdf,Office of the Provost,"January 9, 2025",integrity|teaching-guidance|student-guidance|data-privacy|research|other,"Identifies potential policy gaps and offers recommendations for responsible AI use across university administration, education, and research. || Establishes flexible guiding principles for AI at Stanford, including Human Oversight, Human Alignment, Human Professionalism, and an 'AI Golden Rule'. || Addresses implications for academic integrity (Honor Code, course policies), research (authorship, data use, AI detector limitations), and administrative functions (hiring, admissions). || Encourages experimentation with AI while ensuring core university principles are honored, cautioning against fixed, rigid policies."
Stanford University,university-wide,Generative AI Policy Guidance,https://communitystandards.stanford.edu/generative-ai-policy-guidance,Office of Community Standards,"February 16, 2023",integrity|student-guidance,"Establishes a default Honor Code implication: absent clear instructor policy, generative AI use is treated as assistance from another person, requiring disclosure. || Prohibits using generative AI tools to substantially complete assignments or exams unless explicitly permitted by the instructor. || Grants individual course instructors the freedom to set their own generative AI policies, which must be clearly communicated in syllabi. || Recommends instructors provide advance notice if they may use detection software for generative AI."
Stanford University,university-wide,Responsible AI at Stanford,https://uit.stanford.edu/security/responsibleai,University IT,,data-privacy|security|ethics|research|teaching-guidance|student-guidance,"Provides guidelines for responsible and secure use of AI tools by Stanford faculty, staff, and students, emphasizing data privacy and security. || Advises on risks including data privacy, intellectual property, hallucinations, bias, and environmental impact. || Classifies data risk (low, moderate, high) and specifies appropriate AI tools for each type, recommending Stanford-approved secure platforms like Stanford AI Playground for sensitive data. || Outlines best practices for using AI tools securely and ethically, ensuring verification of AI outputs and respecting intellectual property."
Harvard University,university-wide,Guidelines for Using ChatGPT and other Generative AI tools at Harvard,https://provost.harvard.edu/links/guidelines-using-chatgpt-and-other-generative-ai-tools-harvard-july-13-2023,Office of the Provost,"July 13, 2023",integrity|teaching-guidance|student-guidance|data-privacy|research|other,"The University supports responsible experimentation with generative AI tools, but emphasizes considerations for information security, data privacy, compliance, copyright, and academic integrity. || Confidential data (Level 2 and above), including non-public research data, should not be entered into publicly-available generative AI tools. || Users are responsible for any content they produce or publish that includes AI-generated material, noting that AI content can be inaccurate, misleading, or fabricated. || All members must adhere to current policies on academic integrity; faculty should clearly communicate their policies on permitted AI uses in classes. || Users should be alert for AI-enabled phishing and follow security best practices. || HUIT must be contacted before procuring generative AI tools to ensure appropriate privacy and security protections and risk assessment."
Harvard University,university-wide,Generative AI Guidelines,https://www.huit.harvard.edu/ai/guidelines,Harvard University Information Technology,,data-privacy|integrity|teaching-guidance|student-guidance|research|other,"Reinforces the University's support for responsible experimentation with generative AI tools, while highlighting critical considerations such as information security, data privacy, compliance, copyright, and academic integrity. || Prohibits entering confidential data (Level 2 and above) into publicly-available generative AI tools; approved tools, assessed by Harvard's Information Security and Data Privacy office, are required for such data. || Emphasizes user responsibility for reviewing AI-generated content for accuracy, potential fabrications ('hallucinations'), or copyrighted material before publishing or sharing. || Advises adherence to local academic and administrative policies, encouraging faculty to clarify AI use policies in their courses. || Warns about the increased sophistication of AI-enabled phishing and 'deepfakes,' recommending continued adherence to security best practices. || Directs users to HUIT and School IT providers for a list of approved generative AI tools with contractual protections and mandates risk assessment by Harvard's Information Security and Data Privacy office for any unapproved vendor tools prior to use."
Harvard University,university-wide,Teach with Generative AI,https://www.harvard.edu/ai/teaching-resources/,Generative AI @ Harvard,,teaching-guidance|integrity|student-guidance|other,"Serves as a central resource for Harvard faculty on integrating generative AI into teaching, recognizing both the challenges and transformative potential. || Shares key learnings and insights from faculty experimentation, covering topics like effective prompt design, strategies for interrogating 'hallucinations,' and using AI beyond simple Q&A interactions. || Provides advice for educators on leveraging generative AI tools for curriculum preparation, including outlining courses, creating learning objectives, suggesting assignments, and generating rubrics. || Explores how AI can enhance student engagement, improve learning outcomes, and increase student confidence by assisting with tasks, providing personalized feedback, and overcoming skill gaps. || Discusses risks of LLMs at a micro-scale within classrooms, such as failed reasoning or superficial thinking, and encourages students to understand these issues more deeply."
