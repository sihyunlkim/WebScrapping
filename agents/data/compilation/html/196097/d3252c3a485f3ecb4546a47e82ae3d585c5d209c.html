<!DOCTYPE html><html lang="en"><head><meta http-equiv="X-UA-Compatible" content="IE=Edge" /><meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>Critical Perspectives on AI - Guide to Generative AI - Research & Subject Guides at Stony Brook University</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="robots" content="noarchive" />
<!-- favicon.twig -->
<link rel="apple-touch-icon" sizes="180x180" href="//d2jv02qf7xgjwx.cloudfront.net/apps/common/favicon/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="//d2jv02qf7xgjwx.cloudfront.net/apps/common/favicon/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="//d2jv02qf7xgjwx.cloudfront.net/apps/common/favicon/favicon-16x16.png">
<link rel="manifest" href="//d2jv02qf7xgjwx.cloudfront.net/apps/common/favicon/site.webmanifest">
<link rel="mask-icon" href="//d2jv02qf7xgjwx.cloudfront.net/apps/common/favicon/safari-pinned-tab.svg" color="#5bbad5">
<link rel="shortcut icon" href="//d2jv02qf7xgjwx.cloudfront.net/apps/common/favicon/favicon.ico">
<meta name="msapplication-TileColor" content="#ffc40d">
<meta name="msapplication-config" content="//d2jv02qf7xgjwx.cloudfront.net/apps/common/favicon/browserconfig.xml">
<meta name="theme-color" content="#ffffff">
<!-- !favicon.twig -->



<!-- public_metadata.twig -->

    <!-- auto generated dublin core metadata -->
    <meta name="DC.Title" content="Research & Subject Guides: Guide to Generative AI: Critical Perspectives on AI"/>
    <meta name="DC.Creator" content="Chris Kretz"/>
    <meta name="DC.Subject" content="Artificial Intelligence Resources, Citations & Plagiarism, Resources for Faculty, Resources for Graduate Students, Resources for Undergraduate Students, Technology & Society"/>
    <meta name="DC.Description" content="A guide to tools, resources, and issues regarding ChatGPT and other generative AI technologies in academics and research."/>
    <meta name="DC.Publishers" content="Stony Brook University"/>
    <meta name="DC.Rights" content="Copyright Stony Brook University 2026"/>
    <meta name="DC.Language" content="en"/>
    <meta name="DC.Identifier" content="https://guides.library.stonybrook.edu/genai/ethics"/>
    <meta name="DC.Date.Created" content="Feb 24, 2023"/>
    <meta name="DC.Date.Modified" content="Dec 3, 2025"/>
    

<meta property="og:title" content="Research &amp; Subject Guides: Guide to Generative AI: Critical Perspectives on AI">
<meta property="og:description" content="A guide to tools, resources, and issues regarding ChatGPT and other generative AI technologies in academics and research.">
<meta property="og:type" content="website">
<meta property="og:url" content="https://guides.library.stonybrook.edu/genai/ethics">
    <meta property="og:image" content="https://guides.library.stonybrook.edu/ld.php?screenshot=bdaebjb.png&amp;size=facebook&amp;cb=1771349926">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="627">
    <meta name="twitter:image" content="https://guides.library.stonybrook.edu/ld.php?screenshot=bdaebjb.png&amp;size=twitter&amp;cb=1771349926">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@springshare">



<link rel="stylesheet" href="https://static-assets-us.libguides.com/web/jquery/css/jquery-ui.min.css?2691" />

<link rel="stylesheet" href="https://netdna.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css"/>

<link rel="stylesheet" type="text/css" href="https://static-assets-us.libguides.com/web/slick-1.8.1/slick/slick.css">
<link rel="stylesheet" type="text/css" href="https://static-assets-us.libguides.com/web/slick-1.8.1/slick/slick-theme.css">

    <link rel="stylesheet" href="https://static-assets-us.libguides.com/web/css3.23.5/lg-public.min.css" />

<script type="text/javascript" src="https://static-assets-us.libguides.com/web/jquery/js/1.12.4_jquery.min.js"></script>
<script>
    jQuery(document).ready(function () {
        jQuery(".dropdown-toggle").on("click", function(e){
            jQuery(this).siblings("ul.s-lg-subtab-ul.dropdown-menu").toggle();
        });
                        var s_lg_guide_name = jQuery('#s-lg-guide-name');
        if (s_lg_guide_name.length) {
            if (jQuery.trim(s_lg_guide_name.text()) === '') {
                s_lg_guide_name.remove();
            }
        }
    });
</script>

    <script src="//code.jquery.com/ui/1.13.2/jquery-ui.min.js"></script>
    <script>
        jQuery.ui ||
        document.write('<script src="https://static-assets-us.libguides.com/web/jquery/js/jquery-ui.min.js?2691">\x3C/script>');
    </script>

    <script type="text/javascript" src="https://static-assets-us.libguides.com/web/js3.23.5/lg-public.min.js"></script>
<style>/** bootstrap_tab_css.twig **/
#s-lg-tabs-container .nav-tabs > li > a,
#s-lg-tabs-container .nav-tabs > li > button,
#s-lg-tabs-container .nav-pills > li > a,
#s-lg-tabs-container .nav-pills > li > button {
    border: 1px solid transparent; -webkit-border-radius: 4px; -moz-border-radius: 4px; border-radius: 4px;
    background-color: #990000;
    color: #ffffff;
    font-weight: bold;
    padding: 4px 15px;
}

#s-lg-tabs-container .nav-tabs {
    border-bottom: 0;
}

#s-lg-tabs-container .nav-tabs > li#s-lg-admin-tab-add > a {
    -webkit-border-radius: 4px 4px 0 0;
    -moz-border-radius: 4px 4px 0 0;
    border-radius: 4px 4px 0 0;
}

#s-lg-tabs-container .nav-tabs > li > a:hover,
#s-lg-tabs-container .nav-tabs > li > button:hover,
#s-lg-tabs-container .nav-pills > li > a:hover,
#s-lg-tabs-container .nav-pills > li > button:hover {
    border: 1px solid transparent; -webkit-border-radius: 4px; -moz-border-radius: 4px; border-radius: 4px;
    background-color: #000000;
    color: #ffffff;
}

#s-lg-tabs-container .nav-tabs > .active > a,
#s-lg-tabs-container .nav-tabs > .active > button,
#s-lg-tabs-container .nav-pills > .active > a,
#s-lg-tabs-container .nav-pills > .active > button {
    color: #ffffff;
    cursor: default;
    background-color: #000000;
    border: 1px solid transparent; -webkit-border-radius: 4px; -moz-border-radius: 4px; border-radius: 4px;
    border-bottom-color: transparent;
    font-weight: bold;
}

#s-lg-tabs-container .nav-tabs > .active > .s-lg-subtab-ul > .active > a,
#s-lg-tabs-container .nav-tabs > .active > .s-lg-subtab-ul > .active > button {
    color: #ffffff;
    cursor: default;
    background-color: #000000;
    border-bottom-color: transparent;
}

#s-lg-tabs-container .nav-tabs > .active > a:hover,
#s-lg-tabs-container .nav-pills > .active > a:hover,
#s-lg-tabs-container .nav-tabs > .active > button:hover,
#s-lg-tabs-container .nav-pills > .active > button:hover {
    color: #ffffff;
    cursor: pointer;
    background-color: #000000;
    border: 1px solid transparent; -webkit-border-radius: 4px; -moz-border-radius: 4px; border-radius: 4px;
    border-bottom-color: transparent;
    font-weight: bold;
}

#s-lg-tabs-container .nav .dropdown-toggle .caret {
    border-top-color: #e1e1e1;
}

#s-lg-tabs-container .nav-tabs button.dropdown-toggle .caret {
    margin-left: 2px;
    margin-top: -3px;
}

#s-lg-tabs-container .nav-tabs > li > a.s-lg-tab-drop {
    border-radius: 0 4px 4px 0;
    padding: 4px 6px 4px 3px;
    border-left: 1px solid transparent;
}

#s-lg-tabs-container .nav-tabs > li > button.s-lg-tab-drop {
    border-radius: 0 4px 4px 0;
    padding: 4px 6px 0px 3px;
    border-left: 1px solid transparent;
    margin-right: 2px;
}

#s-lg-tabs-container .nav-tabs > li > a.s-lg-tab-drop:hover {
    border-radius: 0 4px 4px 0;
    border-left: 1px solid #bbb;
    padding: 4px 6px 4px 3px;
}

#s-lg-tabs-container .nav-tabs > li > button.s-lg-tab-drop:hover {
    border-radius: 0 4px 4px 0;
    border-left: 1px solid #bbb;
    padding: 4px 6px 0px 3px;
}

#s-lg-tabs-container .nav-tabs > li > a.s-lg-tab-top-link,
#s-lg-tabs-container .nav-tabs > li > a.s-lg-tab-top-link:hover,
#s-lg-tabs-container .nav-tabs > li > button.s-lg-tab-top-link,
#s-lg-tabs-container .nav-tabs > li > button.s-lg-tab-top-link:hover {
    border-radius: 4px;
    font-weight: bold;
    padding: 4px 5px 4px 10px;
}

.nav-tabs > li > a.s-lg-tab-top-link,
.nav-tabs > li > button.s-lg-tab-top-link {
    margin-right: 0px;
}

#s-lg-tabs-container .nav-pills > li > a.s-lg-tab-drop,
#s-lg-tabs-container .nav-pills > li > button.s-lg-tab-drop {
    border-radius: 0 4px 4px 0;
    padding: 4px 8px 4px 8px;
    border-left: 1px solid transparent;
    position: absolute;
    right: 0;
}

#s-lg-tabs-container .nav-pills > li > a.s-lg-tab-drop:hover,
#s-lg-tabs-container .nav-pills > li > button.s-lg-tab-drop:hover {
    border-radius: 0 4px 4px 0;
    border-left: 1px solid #bbb;
    padding: 4px 8px 4px 8px;
}

#s-lg-tabs-container .nav-pills > li > a.s-lg-tab-top-link,
#s-lg-tabs-container .nav-pills > li > a.s-lg-tab-top-link:hover,
#s-lg-tabs-container .nav-pills > li > button.s-lg-tab-top-link,
#s-lg-tabs-container .nav-pills > li > button.s-lg-tab-top-link:hover {
    width: 100%;
    float: left;
    border-radius: 4px;
    font-weight: bold;
    padding: 4px 15px 4px 15px;
}

/** !bootstrap_tab_css.twig **/
 .s-lib-box {border-color: #cccccc;
                border-width: 1px;
                box-shadow: 0 8px 6px -6px #AAAAAA;
                border-radius: 4px 4px 4px 4px;
                background-color: #fff;
            }
            .s-lib-box-std .s-lib-box-title {background-color: #f1f1f1; background-image: none;color: #888;
                border-bottom: 1px solid #cccccc;
            }
            .s-lib-box .s-lib-box-title {background-color: #f1f1f1; background-image: none;color: #888;
                border-bottom: 1px solid #cccccc;
                border-radius: 3px 3px 0px 0px;
            }
            .s-lib-box .s-lg-box-footer {
                border-radius: 0px 0px 3px 3px;
            }</style><link href="https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&family=Open+Sans:ital,wght@0,300;0,400;0,600;0,700;0,800;1,300;1,400;1,600;1,700;1,800&display=swap" rel="stylesheet">
<style>
.homepage li a { color: #990000;font-weight: 500; font-size:13px; }
.homepage div#col1 a { font-size:14.5px; }
.homepage li { line-height: 1.10em; margin-bottom:.7em; }
.homepage h2 { font-size:20px; font-weight:700 }
.homepage ul { padding-inline-start:15px }
.homepage h1 {font-family:"Montserrat", sans-serif; font-size: 2.3em;font-weight:700;text-transform:uppercase; display: inline; }
.homepage #col2 { background-color:#f5f5f5;padding-top:15px; }
.homepage .container {
width: 80%;
}
.footer-flex { display: flex; justify-content: center;}
.footer-flex div {padding-left: 2em; padding-right: 2em;}
.custom-footer { background-color:#990000; width:100%; font-family: sans-serif;color:#f9f9f9; font-size:10pt; }
/* Hide the Database Types dropdown on the A-Z list */
#col-vendors {display:none;}
/* Format text */
body {font-size:1.4em;font-family:"Open Sans", sans-serif;}
a {color:#990000; font-weight:600;}
a:hover {color:#202020;}
#s-lg-guide-header-info h1, .s-lib-header h1 {font-family:"Montserrat", sans-serif; font-size: 2.3em;font-weight:700;text-transform:uppercase; display: inline; }
#s-lg-guide-header-info {padding-bottom: 1em;}
/* Format box style */
.s-lib-box .s-lib-box-title {font-family:"Montserrat", sans-serif; font-size: 1.7em; font-weight:600;background-color: #ebebeb;color: black; background-image: none; border-right: 0px solid #4b4b4b;border-left:0px solid #4b4b4b;border-top:0px solid #4b4b4b;border-bottom:1px solid #4b4b4b; }
.s-lib-box {border: 1px solid #4b4b4b; box-shadow:none ; border-radius: 3px; }
.s-lib-box-er-course-list, .s-lib-box-idx-blog-post-list, .s-lib-box-idx-er-course-list, .s-lib-box-idx-guide-list { border-right: 0px solid white; border-left: 0px solid white; border-top: 0px solid white; border-bottom: 1px solid #ECECEC }
.s-lg-box-admin .s-lib-box-title, .s-lib-box-std .s-lib-box-title { background-image: none; }
.s-lg-db-panel-title { font-size: 1.5em; }
.s-lib-public-side-header h2 { font-family: "Open Sans", sans-serif; }



/* Navigation tabs */
/* Navigation tabs when not selected and hovered/focused */
#s-lg-tabs-container .nav-tabs > li > a:focus, #s-lg-tabs-container .nav-tabs > li > a:hover,
#s-lg-tabs-container .nav-tabs > li > button:focus, #s-lg-tabs-container .nav-tabs > li > button:hover,
#s-lg-tabs-container .nav-pills > li > a:focus, #s-lg-tabs-container .nav-pills > li > a:hover,
#s-lg-tabs-container .nav-pills > li > button:focus, #s-lg-tabs-container .nav-pills > li > button:hover
{ background-color: #f4e5e5; border: 1px solid #990000; border-radius: 3px; color:black;text-decoration: underline;}
/* Navigation tabs when selected*/
#s-lg-tabs-container .nav-tabs > .active > a,
#s-lg-tabs-container .nav-tabs > .active > button,
#s-lg-tabs-container .nav-pills > .active > a,
#s-lg-tabs-container .nav-pills > .active > button { background-color: #990000; color:white;}
/* Navigation tabs when not selected*/
#s-lg-tabs-container .nav-tabs > li > a,
#s-lg-tabs-container .nav-tabs > li > button,
#s-lg-tabs-container .nav-pills > li > a,
#s-lg-tabs-container .nav-pills > li > button { font-family: "Montserrat", sans-serif; font-weight:600; background-color: white; border: 1px solid #4b4b4b; border-radius: 3px; color:#4b4b4b;}
/* Navigation tabs when selected and hovered/focused */
#s-lg-tabs-container .nav-tabs > .active > a:focus, #s-lg-tabs-container .nav-tabs > .active > a:hover,
#s-lg-tabs-container .nav-tabs > .active > button:focus, #s-lg-tabs-container .nav-tabs > .active > button:hover,
#s-lg-tabs-container .nav-pills > .active > a:focus, #s-lg-tabs-container .nav-pills > .active > a:hover,
#s-lg-tabs-container .nav-pills > .active > button, #s-lg-tabs-container .nav-pills > .active > button:hover { background-color: #990000; border:1px solid #990000; border-radius:3px; text-decoration: none; color:white;}


/*mystery as of May 2021 ccp */
#s-lg-az-nav, #s-lg-er-nav, #s-lg-hp-nav, #s-lg-profile-nav, #s-lg-srch-nav {background:#900;}
#s-lg-er-nav-bottom, #s-lg-hp-nav-bottom, #s-lg-srch-nav-bottom {background:#ffffff;}
.nav .s-lg-index-nav-btn>button {font-size: 16px; font-weight: 300; color: #ffffff;}
.btn-info {background-color: #900; border-color: #900;}
.btn-link {color: #000000;}
.s-lib-footer {border-top: 0px; background-color: #ffffff;}
.s-lib-main {padding-top: 25px;}
#s-lg-guide-tabs-title-bar {border-top: 0px;}
#s-lg-er-count-btn, #s-lg-profile-count-btn, #s-lg-srch-btn {padding-top: 10px; color: #fff;}
/* unclear #s-lg-profile-count, #s-lg-sb-count */

.s-lg-gmeta { display: none; }
/*shows guide count in panels*/

.badge {background-color: #000;}

/* for labels like "email me"*/
.s-lib-profile-email.label {background-color: #990000;}
a.label.label-info:hover, a.label.label-info:focus {background-color: #6b000d; text-decoration: underline;}

/*formats bootstrap alert style */
.alert-info {color: #000000; background-color: #ffffff; border-color: #ffffff}

/*styles certain font awesome icon */
.fa-external-link {color: #fff;}

/* Labels for databases on A-Z list */
.s-lg-az-result-badge-featured {background-color: #ff9800;}
.s-lg-az-result-badge-new {background-color: #03A9F4;}

/* Designs accordions, such as on liaison directory */

a{
  text-decoration: none;
}
.ac-container{
  background: #fff;
 width: "60%";
 margin: 10px auto 10px auto;
}
.ac-container label{
  background: #fff;
color: #990000;
font-size: 20px;
 font-family: Arial, sans-serif;
 padding: 5px 20px;
        border-radius: 5px;
 position: relative;
 z-index: 20;
 display: block;
 cursor: pointer;
 line-height: 33px;
}
.ac-container label:hover{
 background: #990000;
color: #fff;
}
.ac-container input:checked + label,
.ac-container input:checked + label:hover{
 background: #990000;
 color: #fff;
}
.ac-container label:hover:after,
.ac-container input:checked + label:hover:after{
        content: '';
 position: absolute;
 width: 24px;
 height: 24px;
 right: 13px;
 top: 7px;
 background: transparent url(https://s3.amazonaws.com/libapps/accounts/30365/images/arrow_down.png) no-repeat center center;
}
.ac-container input:checked + label:hover:after{
 background-image: url(https://s3.amazonaws.com/libapps/accounts/30365/images/arrow_up.png);
}
.ac-container input{
 display: none;
}
.ac-container article{
 background: rgba(255, 255, 255, 0.5);
 margin-top: -1px;
 overflow: hidden;
 height: 0px;
 position: relative;
 z-index: 10;
}
.ac-container input:checked ~ article{
}
.ac-container article p{
 color: #000;
 line-height: 23px;
 font-size: 14px;
 padding: 20px;
}
.ac-container input:checked ~ article.ac-small{
 height: 100%;
width: 100%;
}
.ac-container input:checked ~ article.ac-medium{
 height: 180px;
}
.ac-container input:checked ~ article.ac-large{
 height: 230px;
}

/* for small screens */
@media
only screen and (max-width: 760px),
(min-device-width: 768px) and (max-device-width: 1024px)  {

	/* Force table to not be like tables anymore */
	table, thead, tbody, th, td, tr {
		display: block;
	}

	/*Hide table headers (but not display: none;, for accessibility) */
thead tr {
		position: absolute;
		top: -9999px;
		left: -9999px;
	}

	tr { border: 0px solid #ccc; }

	td {
		/* Behave  like a "row" */
	border: none;
		border-bottom: 0px solid #eee;
		position: relative;
		padding-left: 50%;
	}

	td:before {
		/* Now like a table header */
position: absolute;
		/* Top/left values mimic padding */
	top: 6px;
		left: 6px;
		width: 45%;
		padding-right: 10px;
		white-space: nowrap;
	}
</style>

<script src="https://api.library.stonybrook.edu/FitzTest.js"></script><script>
    var springStats = springStats || {};
    springStats.saConfig = springStats.saConfig || {
        site_id: 186,
        tracking_parameters: {"_st_guide_id":1304191,"_st_page_id":10882453,"_st_site_id":186},
        tracking_server_host: "libguides-proc.springyaws.com"
    };
</script>
<script  src="https://static-assets-us.libguides.com/web/js/sa.min.js?3116"></script>
<script>
			springSpace.Common = springSpace.Common || { };
			springSpace.Common.constant = {
					PROCESSING: {
						ACTION_DISPLAY_POLL: 159
					}
			};
			springSpace.Common.baseURL = "https://guides.library.stonybrook.edu/";
			
			handleScroll=function() {
                if (false) {
					var target_elt = "#s-lg-page-section-10882453";
					jQuery("html, body").animate({ scrollTop: jQuery(target_elt).offset().top }, 750);
					if (jQuery(this).scrollTop() > 220) {
						jQuery("#s-lib-scroll-top").fadeIn(750);
					}
				}
			}
	   </script>
        <script>
            // Enable tooltips.
            jQuery(function () {
                try {
                    springSpace.UI.initPopOvers(false);
                    jQuery(".az-bs-tooltip").tooltip();
                } catch (e) { }
            });
        jQuery(document).ready(function () {
            springSpace.springTrack.trackPage({_st_type_id: '1',_st_group_id: '9340',_st_guide_id: '1304191',_st_page_id: '10882453'});
        });
            jQuery(document).ready(function() {
                handleScroll();
            });
        </script><!-- BEGIN: Analytics code --><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-18601952-2', 'auto');
  ga('send', 'pageview');

</script><!-- END: Analytics code --></head><!-- SIDE NAV -->
	<body class="s-lg-guide-body">
		<a id="s-lg-public-skiplink" class="alert-info" href="#s-lg-guide-main">Skip to Main Content</a>
        
        <!-- BEGIN: Page Header -->
        <div class="container" style="padding-top:30px;">
<!-- Save for Web Slices (library-logo.png) -->

<script src="https://api.library.stonybrook.edu/libguides.js">

<div style="float: right; margin-top: +30px;" 
id="libchat_64058dae996859e05266d92b3d08374c"></div><script type="text/javascript" src="//v2.libanswers.com/load_chat.php?hash=64058dae996859e05266d92b3d08374c"></script>


<table style="float:left; margin-top: -10px;">	
<a href="https://library.stonybrook.edu"><img src="https://api.library.stonybrook.edu/wp-content/uploads/2016/06/librarylogo2.jpg" width="60%" border="0" alt="Stony Brook University"></a>
</table>


</div></div>
        <!-- END: Page Header -->
        <!-- BEGIN: Guide Header -->
  		<div id="s-lg-guide-header" class="container s-lib-header s-lib-side-borders">
          <div style="padding-top:30px;">
			<div class="pull-right">
				
				
			</div></div>
            <div id="s-lg-guide-header-info">
                <h1 id="s-lg-guide-name">Guide to Generative AI</h1>
                <div id="s-lg-guide-desc-container">
                    <span id="s-lg-guide-description">A guide to tools, resources, and issues regarding ChatGPT and other generative AI technologies in academics and research.</span>
                </div>
            </div>
        </div>
        <!-- END: Guide Header -->
        <div id="s-lg-guide-tabs-title-bar" class="container s-lib-side-borders"></div>
        <div id="s-lg-side-nav-content" class="container s-lib-side-borders pad-top-med">
            <div class="row">
                <div class="col-md-3 s-lg-tabs-side pad-bottom-med">
                    <div id="s-lg-tabs-container">
                        <div id="s-lg-guide-tabs" role="navigation" aria-label="Guide Page Menu">
                            <ul class="nav nav-pills nav-stacked split-button-nav" role="menu">


    <li class="">
        <a title="" class="" 
           href="https://guides.library.stonybrook.edu/genai/home" 
            
            
           >
            <span>Home</span>
            
        </a>
        
    </li>



    <li class="">
        <a title="" class="" 
           href="https://guides.library.stonybrook.edu/genai/ai-tools" 
            
            
           >
            <span>AI Tools</span>
            
        </a>
        
    </li>



    <li class="">
        <a title="" class="" 
           href="https://guides.library.stonybrook.edu/genai/prompt-engineering" 
            
            
           >
            <span>Prompt Engineering</span>
            
        </a>
        
    </li>



    <li class="">
        <a title="" class="" 
           href="https://guides.library.stonybrook.edu/genai/citing-ai" 
            
            
           >
            <span>AI and Citation Styles</span>
            
        </a>
        
    </li>



    <li class="active">
        <a title="" class="active" 
           href="https://guides.library.stonybrook.edu/genai/ethics" 
            
            
           >
            <span>Critical Perspectives on AI</span>
            
        </a>
        <ul class="list-group s-lg-boxnav"><li class="list-group-item"><a href="#s-lg-box-34550627">Key Issues to Consider</a></li><li class="list-group-item"><a href="#s-lg-box-34596542">Accuracy, Transparency & Bias</a></li><li class="list-group-item"><a href="#s-lg-box-34596548">Privacy & Data Security</a></li><li class="list-group-item"><a href="#s-lg-box-34596554">Copyright Law & Intellectual Property</a></li><li class="list-group-item"><a href="#s-lg-box-34596560">Environmental & Labor Impacts</a></li><li class="list-group-item"><a href="#s-lg-box-34596574">AI Detection & Its Limitations</a></li></ul>
    </li>



    <li class="">
        <a title="" class="" 
           href="https://guides.library.stonybrook.edu/c.php?g=1304191&amp;p=10981039" 
            
            
           >
            <span>AI in Library Resources</span>
            
        </a>
        
    </li>



    <li class="">
        <a title="" class="" 
           href="https://guides.library.stonybrook.edu/c.php?g=1304191&amp;p=10994046" 
            
            
           >
            <span>SBU Related AI Resources</span>
            
        </a>
        
    </li>



    <li class="">
        <a title="" class="" 
           href="https://guides.library.stonybrook.edu/c.php?g=1304191&amp;p=11005316" 
            
            
           >
            <span>AI Myths and Misconceptions</span>
            
        </a>
        
    </li>

</ul>
                            <div class="s-lg-row margin-top-med"><div id="s-lg-col-0"><div class="s-lg-col-boxes"></div></div></div>
                        </div>
                    </div>
                </div>
                <div class="col-md-9">
                    <div class="s-lg-tab-content">
                        <div id="s-lg-guide-main" class="tab-pane active">
                            <div class="row s-lg-row"><div id="s-lg-col-1" class="col-md-12"><div class="s-lg-col-boxes"><div id="s-lg-box-wrapper-40628304" class="s-lg-box-wrapper-40628304">


    <div id="s-lg-box-34550627-container" class="s-lib-box-container">
        <div id="s-lg-box-34550627" class="s-lib-box s-lib-box-std">
                            <h2 class="s-lib-box-title">
                    Key Issues to Consider
                                    </h2>
                        <div id="s-lg-box-collapse-34550627" >
                <div class="s-lib-box-content">
                    <div id="s-lg-content-81298748" class="  clearfix">
    <p>The development, use, and management of AI tools pose a number of major legal, ethical, philosophical, and environmental problems and issues, including concerns surrounding intellectual property, energy use, labor, privacy, bias, human agency, and potential misuse of tools.</p>

<p>The AAC&amp;U Student Guide to AI summarizes some of these concerns on the <a href="https://drive.google.com/file/d/131PqZuvgKLNJopXnpeUnUhNJZeh08Z6b/view?usp=sharing">&quot;AI Ethics&quot; page of their guide (link opens in new window)</a>. And a key paper that outlined many of the problematic issues of large language models before the public launch of ChatGPT in November 2022 is,&nbsp;<a href="https://dl.acm.org/doi/10.1145/3442188.3445922">&quot;On the Dangers of Stochastic Parrots: Can Language Models Be Too Big&quot; (March 2021)</a>.&nbsp;</p>

<p>Being AI literate means having an understanding of both the risks and rewards that these tools bring to society. Below are brief descriptions of some of these concerns, with links out to more information.</p>


    </div>
                </div>
                
            </div>
        </div>
    </div>
</div><div id="s-lg-box-wrapper-40684138" class="s-lg-box-wrapper-40684138">


    <div id="s-lg-box-34596542-container" class="s-lib-box-container">
        <div id="s-lg-box-34596542" class="s-lib-box s-lib-box-std">
                            <h2 class="s-lib-box-title">
                    Accuracy, Transparency & Bias
                                    </h2>
                        <div id="s-lg-box-collapse-34596542" >
                <div class="s-lib-box-content">
                    <div id="s-lg-content-81410365" class="  clearfix">
    <p><strong>Accuracy</strong></p>

<p>Generative AI models can produce inaccurate outputs, often due to limitations in their training data and the probabilistic nature of the generation process. A key problem is &quot;hallucinations,&quot; which occur when AI produces false or misleading information that is presented as a fact. The &quot;voice&quot; of the AI system presents as confident and authoritative, making such false information often difficult to detect unless the user is an expert. The outputs can be plausible-sounding but completely fabricated, making it challenging to discern truth from fiction without external verification. An example of a hallucination is when AI generates made-up sources, with perhaps a real journal title and real author name, but a made-up article title and page range. It&#39;s important to remember that text generators like ChatGPT, Gemini, and Copilot are designed to generate grammatically correct text, but not accurate information or sources. All information must be verified by authoritative sources.</p>

<ul>
	<li>Jeremy Hsu, <a href="https://www.newscientist.com/article/2479545-ai-hallucinations-are-getting-worse-and-theyre-here-to-stay/">&quot;AI Hallucinations Are Getting Worse -- And They&#39;re Here to Stay,&quot;</a> New Scientist, May 9, 2025.</li>
	<li><a href="https://mitsloanedtech.mit.edu/ai/basics/addressing-ai-hallucinations-and-bias/">&quot;When AI Gets It Wrong, Addressing AI Hallucinations and Bias,&quot;</a> MIT Management</li>
	<li>High profile examples of non-existent studies / cases being cited in official documents include the following: <a href="https://www.abccolumbia.com/2025/07/24/fda-ai-tools-cites-nonexistent-studies/">FDA&#39;s ELSA AI tool created studies that don&#39;t exist</a>&nbsp;(July 2025);<a href="https://www.reuters.com/technology/artificial-intelligence/ai-hallucinations-court-papers-spell-trouble-lawyers-2025-02-18/"> warnings about fictitious case citations in lawsuit documents</a> (Feb 2025); <a href="https://www.science.org/content/article/trump-officials-downplay-fake-citations-high-profile-report-children-s-health">Health and Human Services report</a> (May 2025)</li>
</ul>

<p><strong>Transparency</strong></p>

<p>Issues of transparency (or lack of transparency) arise across multiple AI topics. For companies creating AI systems, being transparent about training data and processes helps to build trust and expose potential biases. For users of AI systems, being clear about AI-use reinforces accountability, human agency, and promotes responsible engagement with information. Most scholarly journals, for example, have clear policies regarding whether, how, and in what situations AI-use is permitted, and provide guidance on how to acknowledge that use. If it is appropriate to use AI for a project, you might consider some different ways of being transparent about your AI use. Ideas include: notating the text to show different types of AI-use, providing a short paragraph (perhaps in a Methods or Acknowledgments section) that explains your AI use, or using formal citation methods if appropriate.</p>

<ul>
	<li>For a more comprehensive discussion of transparency in AI, see Ian Heinig&#39;s article,<a href="https://sendbird.com/blog/ai-transparency-guide"> &quot;AI Transparency: A Complete Guide &amp; Overview,&quot; </a>May 8, 2025.</li>
	<li>For an example of an AI policy in a scholarly journal, see <a href="https://www.nature.com/nature/editorial-policies/ai">Nature&#39;s AI editorial policies</a>.</li>
</ul>

<p><strong>Bias</strong></p>

<p>The data that AI is trained on can often reflect existing societal inequities and historical prejudices. This means that AI outputs might be stereotypical or discriminatory, thereby perpetuating or amplifying biases that exist in the real world. These biases can have critical impacts on many potential uses of AI, including in areas such as healthcare and criminal justice. The &quot;black box&quot; nature (that is, lack of transparency) of many generative AI models can make these biases difficult to pinpoint or correct. It&#39;s always important to be aware of the risk of bias when using generative AI.</p>

<ul>
	<li>For a summary of bias concerns surrounding using AI in the classroom, see Aniya Greene-Santos,&nbsp;<a href="https://www.nea.org/nea-today/all-news-articles/does-ai-have-bias-problem">&quot;Does AI Have a Bias Problem?&quot;</a> National Education Association, February 22, 2024.</li>
	<li>For a discussion of examples of bias in image generators, see <a href="http://proxy.library.stonybrook.edu/login?url=https://www.proquest.com/usmajordailies/newspapers/ai-generated-images-show-world-stereotypes/docview/2888705247/sem-2?accountid=14172">&quot;AI-generated images show a world of stereotypes,&quot;</a> Washington Post, November 12, 2023 (SBU login needed).</li>
	<li>For a UNESCO report on gender bias, see <a href="https://unesdoc.unesco.org/ark:/48223/pf0000388971">&quot;Challenging Systematic Prejudices: An Investigation in Gender Bias in Large Language Models,&quot;</a> 2024.</li>
</ul>


    </div>
                </div>
                
            </div>
        </div>
    </div>
</div><div id="s-lg-box-wrapper-40684146" class="s-lg-box-wrapper-40684146">


    <div id="s-lg-box-34596548-container" class="s-lib-box-container">
        <div id="s-lg-box-34596548" class="s-lib-box s-lib-box-std">
                            <h2 class="s-lib-box-title">
                    Privacy & Data Security
                                    </h2>
                        <div id="s-lg-box-collapse-34596548" >
                <div class="s-lib-box-content">
                    <div id="s-lg-content-81410374" class="  clearfix">
    <p>Depending on the AI system and what version you are using, you may not have knowledge or control over how the information you provide to the system could be accessed and used. Here are some tips to protect the privacy of your own data and that of others:</p>

<ul>
	<li>Use SBU-licensed tools available on <a href="https://it.stonybrook.edu/guides/ai">DoIT&#39;s AI Tools page</a>&nbsp;(link opens in new window). In general, the tools licensed to SBU&nbsp;have more privacy protections than free versions.</li>
	<li>Never share information with an AI system that you are not authorized to share including, for example, any HIPPA-protected health information, and avoid inputting anyone&#39;s personal information into an AI system without their knowledge and permission.</li>
	<li>When possible, use versions of AI with privacy protections and configure&nbsp;the AI settings to make sure the data you provide is not used for training new models. For example, if using the basic/&quot;free&quot; version of ChatGPT, you can make it so your data is not used to train their models by changing the settings:
	<ul>
		<li>Log in &gt; Settings &gt; Data Controls &gt; Improve the Model for Everyone &gt; Choose &quot;Off&quot;</li>
	</ul>
	</li>
</ul>

<p style="text-align: center;"><img alt="" loading="lazy" src="https://d2jv02qf7xgjwx.cloudfront.net/accounts/220807/images/OpenAI_settings_screenshot_cropped__1_.png" style="width: 400px; height: 152px;" /></p>

<p>&nbsp;</p>

<p>To learn more about the impacts of generative AI on privacy and data security issues:</p>

<ul>
	<li>&quot;<a href="https://hai.stanford.edu/policy/white-paper-rethinking-privacy-ai-era-policy-provocations-data-centric-world">Rethinking Privacy in the AI Era: Policy Provocations for a Data-Centric World</a>,&quot; White Paper,&nbsp;Stanford University Human-Centered Artificial Intelligence, February 2024</li>
	<li>&quot;<a href="https://jipel.law.nyu.edu/privacy-of-personal-data-in-the-generative-ai-data-lifecycle/">Privacy of Personal Data in the Generative AI Data Lifecycle</a>,&quot; <em>Journal of Intellectual Property and Entertainment Law</em>, NYU Law, July 8, 2024</li>
</ul>


    </div>
                </div>
                
            </div>
        </div>
    </div>
</div><div id="s-lg-box-wrapper-40684153" class="s-lg-box-wrapper-40684153">


    <div id="s-lg-box-34596554-container" class="s-lib-box-container">
        <div id="s-lg-box-34596554" class="s-lib-box s-lib-box-std">
                            <h2 class="s-lib-box-title">
                    Copyright Law & Intellectual Property
                                    </h2>
                        <div id="s-lg-box-collapse-34596554" >
                <div class="s-lib-box-content">
                    <div id="s-lg-content-81410391" class="  clearfix">
    <p>AI models are often trained on copyrighted works without the permission of the original creators of those works, posing a number of challenges to current copyright law. When possible, use AI tools that are transparent about their training data, and educate yourself on the range of legal risks and concerns. Here are some resources to help:&nbsp;</p>

<ul>
	<li>To understand the U.S. Copyright Office&#39;s current interpretation of the issues surrounding AI, read their 3-part&nbsp;<a href="https://www.copyright.gov/ai/">Report on Copyright and Artificial Intelligence</a>.&nbsp;</li>
	<li>Joshua M. Gerben&nbsp;from the American Bar Association briefly summarizes the current intellectual property&nbsp;(IP) landscape in<a href="https://www.americanbar.org/groups/business_law/resources/business-law-today/2025-february/ip-age-of-ai/">&nbsp;&quot;IP in the Age of AI,&quot; February 13, 2025.</a></li>
	<li>Wired.com is&nbsp;tracking the AI copyright lawsuits in the United States in<a href="https://www.wired.com/story/ai-copyright-case-tracker/">&nbsp;&quot;Every AI Copyright Lawsuit in the U.S., Visualized.&quot;</a></li>
	<li>Techtarget.com has&nbsp;<a href="https://www.techtarget.com/whatis/feature/AI-lawsuits-explained-Whos-getting-sued">a general introduction to AI &amp; IP issues along with a&nbsp;summary of current lawsuits (as of summer 2025).</a></li>
	<li>For a discussion of the complex issues that arise from AI-generated research, see &quot;<a href="https://www-nature-com.proxy.library.stonybrook.edu/articles/d41586-025-02616-5">What counts as plagiarism? AI-generated papers pose new risks</a>,&quot; <em>Nature</em>, August 20, 2025.</li>
</ul>


    </div>
                </div>
                
            </div>
        </div>
    </div>
</div><div id="s-lg-box-wrapper-40684160" class="s-lg-box-wrapper-40684160">


    <div id="s-lg-box-34596560-container" class="s-lib-box-container">
        <div id="s-lg-box-34596560" class="s-lib-box s-lib-box-std">
                            <h2 class="s-lib-box-title">
                    Environmental & Labor Impacts
                                    </h2>
                        <div id="s-lg-box-collapse-34596560" >
                <div class="s-lib-box-content">
                    <div id="s-lg-content-81410413" class="  clearfix">
    <p><strong>Environmental Impact</strong></p>

<p>Many AI systems run on GPUs (Graphics Processing Units), which tend to have much higher energy consumption levels than CPUs (Central Processing Units), leading to a higher carbon footprint and therefore impacts to climate change. In addition, large data centers can consume large amounts of water for cooling purposes, and can therefore put a strain on local water supply. The ecological footprint of AI presents a growing sustainability problem that needs urgent attention, and it is important to avoid thinking of AI systems as limitless resources that can be used for trivial purposes.</p>

<ul>
	<li>For a report from the International Energy Agency, see&nbsp;<a href="https://www.iea.org/reports/energy-and-ai"><em>Energy and AI</em></a>, April 2025.</li>
	<li><a href="http://proxy.library.stonybrook.edu/login?url=https://www.proquest.com/usmajordailies/newspapers/ai-is-energy-hog-strain-on-power-grid-data/docview/3093003607/sem-2?accountid=14172">&quot;AI Is An Energy Hog,&quot;</a>&nbsp;<em>Los Angeles Times</em>, August 15, 2024.</li>
</ul>

<p><strong>Labor Impacts &amp; Human Agency</strong></p>

<p>Generative AI intersects with labor issues in many different ways. For one, generative AI systems rely on &quot;invisible labor,&quot; often performed by low-wage workers in the Global South who are tasked with labeling and moderating training data. In addition, many are concerned about the potential for AI to displace jobs, and also excited about new job categories related to AI development, maintenance, and oversight. Many believe that generative AI will reshape the nature of work and require reevaluation of labor protections, skill development, and equitable distribution of benefits and burdens.</p>

<ul>
	<li>International Labour Organization,&nbsp;<a href="https://www.ilo.org/resource/article/artificial-intelligence-illusion-how-invisible-workers-fuel-automated">&quot;The Artificial Intelligence Illusion: How Invisible Workers Fuel the &quot;Automated&quot; Economy,&quot;</a>&nbsp;December 10, 2024.</li>
	<li>Yiwen Lu,&nbsp;<a href="http://proxy.library.stonybrook.edu/login?url=https://www.proquest.com/usmajordailies/newspapers/help-wanted-smart-humans-tutor-chatbots-part-time/docview/3035366387/sem-2?accountid=14172">&quot;Help Wanted: Smart Humans to Tutor Chatbots, Part Time,&quot;</a>&nbsp;<em>New York Times</em>, April 11, 2024.</li>
</ul>


    </div>
                </div>
                
            </div>
        </div>
    </div>
</div><div id="s-lg-box-wrapper-40684173" class="s-lg-box-wrapper-40684173">


    <div id="s-lg-box-34596574-container" class="s-lib-box-container">
        <div id="s-lg-box-34596574" class="s-lib-box s-lib-box-std">
                            <h2 class="s-lib-box-title">
                    AI Detection & Its Limitations
                                    </h2>
                        <div id="s-lg-box-collapse-34596574" >
                <div class="s-lib-box-content">
                    <div id="s-lg-content-81410486" class="  clearfix">
    <p><strong>What Is AI Detection?</strong></p>

<p>AI detection tools (or AI detectors) are tools that claim to determine whether a piece of content (e.g., text, image, code) was generated by AI. &nbsp;In educational settings, they are often used to detect potential AI-generated or AI-assisted writing and are sometimes viewed as a way to preserve academic integrity by distinguishing between human-authored and AI-generated content.</p>

<p>However, no AI detection tool is 100% accurate. All of them are susceptible to false positives (i.e., flagging human-authored content as AI-generated) and false negatives (i.e., failing to detect actual AI-generated content). While some tools claim to be 99% accurate, research has shown that such claims are often exaggerated. A few tools may exceed 90% accuracy in certain conditions, but others perform no better than chance, which essentially is as reliable as flipping a coin.</p>

<p>In addition to inconsistency in accuracy, there are several other concerns when relying on AI detection tools, including:</p>

<ul>
	<li>Bias against certain (writing) styles or groups of authors, especially those whose writing may differ from the data the tools were trained on.</li>
	<li>Lack of transparency in how detection decisions are made.</li>
	<li>Potential misuse or overreliance, such as treating tool results as definitive without human judgment or context.</li>
	<li>Ethical and pedagogical risks, including unfair accusations and strained trust between educators and students.</li>
</ul>

<p>Ultimately, while AI detection tools can offer helpful signals, they should not be used as the final arbiter of whether content was AI-generated. Context, transparency, and human judgment remain essential in interpreting and responding to their results.</p>

<p><strong>How AI Detection Works</strong></p>

<p>Most AI detectors operate using proprietary, black-box algorithms, meaning the internal logic or criteria used to make judgments about a piece of content are not publicly disclosed. This lack of transparency makes it difficult for users to fully understand how decisions are made or to independently verify the accuracy and fairness of the results.</p>

<p>At a high level, AI detection tools are based on statistical stylometry (i.e., the analysis of writing style through quantifiable features). These tools scan the input for statistical patterns that may differ between human-authored and AI-generated content. For example, common features analyzed in texts include:</p>

<ol>
	<li><strong>Perplexity</strong><br />
	A measure of how &quot;surprised&quot;&nbsp;a language model is by a given text. Human writing tends to be more varied and less predictable, which leads to higher perplexity scores. AI-generated text, by contrast, often follows smoother, more statistically likely word patterns, resulting in lower perplexity.</li>
	<li><strong>Burstiness</strong><br />
	This refers to the variation in sentence length and complexity. Human writing typically displays irregularity and shifts in rhythm, while AI-generated content often maintains a more uniform or mechanical pattern. A lack of burstiness may raise suspicion of AI authorship.</li>
	<li><strong>Redundancy and repetition</strong><br />
	AI-generated texts may reuse phrases or sentence structures in ways that feel unnatural or overly consistent. Detectors may flag this as a sign of non-human generation.</li>
	<li><strong>Syntactic and lexical features</strong><br />
	Some detectors examine the frequency of certain word types (e.g., adverbs, conjunctions) or sentence structures, based on the idea that humans and AIs tend to differ in how they construct language at a granular level.</li>
</ol>

<p>Nevertheless, it&rsquo;s important to emphasize that there is no standardized method or agreed-upon benchmark for AI detection.&nbsp;Because each tool uses its own detection criteria and thresholds, it is not uncommon for the same content to receive conflicting results from different detectors. This variability raises questions about reliability and consistency, especially when these tools are used in high-stakes environments like education or publishing.</p>

<p><strong>Limitations &amp; Challenges</strong></p>

<p>A wide body of literature has shown several limitations and challenges in AI detection, for example:</p>

<p><strong>1. Model Drift &amp; Arms Race</strong></p>

<blockquote>
<p>&quot;... this benchmark understanding is missing in the literature, and hence it is <strong>difficult to build a universal classifier</strong>&nbsp;that can detect AI-generated text across various domains.&quot;</p>
</blockquote>

<p>Agarwal, A., &amp; Uzair, M. (2025). Robustness of Classifiers for AI-Generated Text Detectors for Copyright and Privacy Protected Society. In <em>International Conference on Pattern Recognition</em> (pp. 55-71). Springer, Cham.&nbsp;<a href="https://doi.org/10.1007/978-3-031-78498-9_5" target="_blank">https://doi.org/10.1007/978-3-031-78498-9_5</a></p>

<blockquote>
<p>&quot;Detecting AI-generated images is <strong>increasingly challenging</strong> owing to the continual development of more image generative models that produce better and higher-quality images.&quot;</p>
</blockquote>

<p>Park, D., Na, H., &amp; Choi, D. (2024). Performance comparison and visualization of ai-generated-image detection methods.&nbsp;<i>IEEE Access</i>.&nbsp;<a href="https://doi.org/10.1109/ACCESS.2024.3394250Â " target="_blank">https://doi.org/10.1109/ACCESS.2024.3394250&nbsp;</a></p>

<h5>&nbsp;</h5>

<p><strong>2. Bias Against Non-Native English</strong></p>

<blockquote>
<p>&quot;GPT detectors<strong> frequently misclassify non-native English writing </strong>as AI generated, raising concerns about fairness and robustness.&quot;</p>
</blockquote>

<p>Liang, W., Yuksekgonul, M., Mao, Y., Wu, E., &amp; Zou, J. (2023). GPT detectors are biased against non-native English writers.&nbsp;<i>Patterns</i>,&nbsp;<i>4</i>(7).&nbsp;<a href="https://doi.org/10.1016/j.patter.2023.100779" target="_blank">https://doi.org/10.1016/j.patter.2023.100779</a></p>

<blockquote>
<p>&quot;In other words, <strong>one in four non-native authors </strong>who use AI to help refine their text is at risk of being accused of having submitted an entirely AI-generated text by GPTZero, while the risk for native authors is closer to one in ten.&quot;</p>
</blockquote>

<p>Pratama, A. R. (2025). The accuracy-bias trade-offs in AI text detection tools and their impact on fairness in scholarly publication.&nbsp;<i>PeerJ Computer Science</i>,&nbsp;<i>11</i>, e2953.&nbsp;<a href="https://doi.org/10.7717/peerj-cs.2953" target="_blank">https://doi.org/10.7717/peerj-cs.2953</a></p>

<h5>&nbsp;</h5>

<p><strong>3. Privacy and Data Protection</strong></p>

<blockquote>
<p>&quot;While <strong>we retain a copy of submitted text</strong>, we do not reproduce the text or disclose it to third parties. This means while <strong>a copy of your submission is stored</strong>, it is never shown to a third party and you retain ownership of the submission.&quot;</p>
</blockquote>

<p>GPTZero (2025). GPTZero FAQs:&nbsp;<a href="https://support.gptzero.me/hc/en-us/articles/16916733825943-Do-I-retain-ownership-of-the-work-after-passing-it-through-GPTZero" target="_blank">Do I retain ownership of the work after passing it through GPTZero?</a>&nbsp;</p>


    </div>
                </div>
                
            </div>
        </div>
    </div>
</div></div></div></div>
                        </div>
                    </div>
                    <ul id="s-lg-page-prevnext" class="pager s-lib-hide">
    <li class="previous">
        <a class="page-link" href="https://guides.library.stonybrook.edu/genai/citing-ai">&lt;&lt; <strong>Previous:</strong> AI and Citation Styles</a>
    </li>
    <li class="next">
        <a class="page-link" href="https://guides.library.stonybrook.edu/c.php?g=1304191&p=10981039"><strong>Next:</strong> AI in Library Resources &gt;&gt;</a>
    </li>
</ul>


                </div>
            </div>
        </div>
        <!-- BEGIN: Page Footer -->
        <div id="s-lib-footer-public" class="s-lib-footer footer container  s-lib-side-borders">
            <div id="s-lg-guide-header-meta" class="pad-top-sm pad-left-med clearfix">
     <div id="s-lib-footer-login-link" class="pull-right pad-right-med">
                    <a href="https://stonybrook.libapps.com/libapps/login.php?site_id=186&target64=L2xpYmd1aWRlcy9hZG1pbl9jLnBocD9nPTEzMDQxOTEmcD0xMDg4MjQ1Mw==">Login to LibApps</a>                </div>
            </div>
            <div class="pad-bottom-sm clearfix">
                <div id="s-lib-footer-support-link" class="pull-right pad-right-med">
                   
               </div>
            </div>
        </div>
        <!-- END: Page Footer -->
        
			<div id="s-lib-scroll-top">
				<a href="javascript:void(0);" onclick="jQuery('html, body').animate({scrollTop: 0}, 750);" title="Back to Top" aria-label="Back to Top"
				aria-hidden="true">
					<span class="fa-stack fa-lg">
					  <i class="fa fa-square-o fa-stack-2x"></i>
					  <i class="fa fa-angle-double-up fa-stack-1x" style="position:relative; bottom:2px;"></i>
					</span>
				</a>
			</div>        <div id="s-lib-alert" title="">
                            <div id="s-lib-alert-content"></div>
                       </div>        
                <!-- BEGIN: Custom Footer -->
                
<div âclass="custom-footer" style="background-color:#990000; width:100%; color:#f9f9f9; font-size:10pt;">
<div class="footer-flex">
<div><h2 style="font-size:1.5em; font-weight: 700; text-transform:uppercase;">Library</h2>
<ul>
<li><a href="https://stonybrookuniversity.co1.qualtrics.com/jfe/form/SV_23kfhayPVV8NCfj" style="color:#f9f9f9; font-weight:100;">Request a Class</a></li>
<li><a href="https://library.stonybrook.edu/libraries/" style="color:#f9f9f9; font-weight:100;">Hours & Locations</a></li>
<li><a href="https://library.stonybrook.edu/research/ask-a-librarian/" style="color:#f9f9f9; font-weight:100;">Ask a Librarian</a></li>
<li><a href="https://library.stonybrook.edu/special-collections-university-archives/" style="color:#f9f9f9; font-weight:100;">Special Collections</a></li>

<br/>
<li><a href="https://library.stonybrook.edu/about-us/employment/" style="color:#f9f9f9; font-weight:100;">Employment</a></li>
<li><a href="https://library.stonybrook.edu/about-us/directory/" style="color:#f9f9f9; font-weight:100;">Library Faculty & Staff</a></li>
<li><a href="https://library.stonybrook.edu/staffweb/" style="color:#f9f9f9; font-weight:100;">Staffweb</a></li>
</ul>
<p><strong>Library Administration: 631.632.7100</strong></p>
</div>


<div><h2 style="font-size:1.5em; font-weight: 700; text-transform:uppercase;">Resources</h2>
<ul>
<li><a href="https://www.stonybrook.edu/" style="color:#f9f9f9; font-weight:100;">Stony Brook Home</a></li>
<li><a href="https://it.stonybrook.edu/services/solar" style="color:#f9f9f9; font-weight:100;">SOLAR</a></li>
<li><a href="https://it.stonybrook.edu/services/brightspace" style="color:#f9f9f9; font-weight:100;">Brightspace</a></li>
<li><a href="https://www.stonybrook.edu/site-directory/" style="color:#f9f9f9; font-weight:100;">Directory</a></li>
<li><a href="https://www.stonybrook.edu/maps-and-directions/" style="color:#f9f9f9; font-weight:100;">Campus Maps</a></li>
<br />
<li><a href="https://library.stonybrook.edu/web-accessibility/" style="color:#f9f9f9; font-weight:100;">Web Accessibility Information</a></li>
<li><a href="https://docs.google.com/forms/d/e/1FAIpQLScW_Uc4kfzvlKlgwoJCHSJ2EG_6bd-LjcHowxnNGKV0309uxg/viewform?gxids=7628" style="color:#f9f9f9; font-weight:100;">Accessibility Barrier Report Form</a></li></ul>
<a href="https://www.stonybrook.edu/campaign/"><img src="https://api.library.stonybrook.edu/wp-content/uploads/2017/01/campaign-tile-145x90-CAMPAIGN.jpg" alt="campaign for stony brook"></a>
</div>

<div><h2 style="font-size:1.5em; font-weight: 700; text-transform:uppercase;">Follow Us</h2>
<ul>
<li><a href="https://www.twitter.com/sbulibraries" style="color:#f9f9f9; font-weight:100;">Twitter</a></li>
<li><a href="https://www.facebook.com/stonybrooklibrary/" style="color:#f9f9f9; font-weight:100;">Facebook</a></li>
<li><a href="https://www.instagram.com/sbulibraries/" style="color:#f9f9f9; font-weight:100;">Instagram</a></li>
<li><a href="https://www.youtube.com/channel/UC0GLFf4_bVEGUBHEZCkx-SQ" style="color:#f9f9f9; font-weight:100;">Youtube</a></li>
</div></div>
<br/>
<div class="footer-flex">
<p><a href="https://library.stonybrook.edu/about-us/comments-suggestions/" style="color:#f9f9f9; font-weight:100;" >Comments or Suggestions?</a>  |  <a href="mailto:libraryit@stonybrook.edu" style="color:#f9f9f9; font-weight:100;" >Library Webmaster</a></p><br/>
<br/></div>
<div class="footer-flex"><a rel="license" href="https://creativecommons.org/licenses/by-nc/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc/4.0/88x31.png" /></a></div>
<div class="footer-flex"><p>Except where otherwise noted, this work by <a xmlns:cc="https://creativecommons.org/ns#" href="https://library.stonybrook.edu" property="cc:attributionName" rel="cc:attributionURL" style="color:#f9f9f9;  font-weight:500;">SBU Libraries</a> is licensed under a <a rel="license" href="https://creativecommons.org/licenses/by-nc/4.0/" style="color:#f9f9f9;  font-weight:500;">Creative Commons Attribution-NonCommercial 4.0 International License</a>.</p></div>
</div>

		<!-- END: Custom Footer -->
	</body></html>