<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta name="description" content="">
	<meta name="author" content="">

	<title>Deep Learning for Precision Health Lab</title>

	<!-- Bootstrap Core CSS -->
	<link href="css/bootstrap.min.css" rel="stylesheet" type="text/css">

	<!-- Fonts -->
	<link href="font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
	<link href="css/animate.css" rel="stylesheet" />
	<!-- Squad theme CSS -->
	<link href="css/style.css" rel="stylesheet">
	<link href="color/default.css" rel="stylesheet">
	<link rel="icon" href="img/tab.png">
	
	<!-- dropdown import -->
	<link href="css/dropdown.css" rel="stylesheet" type="text/css">
	
  <!-- Custom CSS for Scroll Offset -->
  <style>
    #researchOverview {       padding-top: 110px;       margin-top: -110px;     }
    #researchTrustworthy {       padding-top: 110px;      margin-top: -110px;    }   
    #researchMultimodal {       padding-top: 110px;       margin-top: -110px;    }   
    #researchSampleEfficiency {       padding-top: 110px;       margin-top: -110px;     }    
    #researchCausal {       padding-top: 110px;       margin-top: -110px;     }
    #researchCompNeurosci {       padding-top: 110px;      margin-top: -110px;    }   
    #researchClinical {       padding-top: 110px;       margin-top: -110px;    }         
    #PostdoctoralFellowshipPositions {       padding-top: 110px;       margin-top: -110px;     }
    #ResearchScientistPositions {       padding-top: 110px;      margin-top: -110px;    }   
    #PhDStudentResearchAssistantPositions {       padding-top: 110px;       margin-top: -110px;    }   
    #PostdocExplainableCausalML {       padding-top: 110px;       margin-top: -110px;     }    
    #PostdocImageAnalysis {       padding-top: 110px;       margin-top: -110px;     }
    #PostdocImageGuidedCancerSurgery {       padding-top: 110px;      margin-top: -110px;    }   
    #PostdocComputationalLinguistics {       padding-top: 110px;       margin-top: -110px;    }         
    #ResScientistBiomedicalDataAnalysis {       padding-top: 110px;       margin-top: -110px;    }      
  </style>
  
  <style>

    /* Reduce space after the h4 heading */
    h4 {
        margin-bottom: 15px; /* Adjust this value to control spacing below the h4 */
    }
</style>

<!-- <style>
  /* Apply the same style to paragraphs and lists using .subtitle */
  .subtitle, .subtitle li {
    font-size: 1rem;        /* match your paragraph font size */
    line-height: 1.6;       /* match line spacing */
    font-family: inherit;   /* inherit from the parent body or container */
  }
</style>
-->

<style>
  /* Style for all citation links */
  .citation-link {
    text-decoration: underline;
    color: #0066cc; /* Change this if you want a different color */
    font-weight: normal;
  }

  .citation-link:hover {
    color: #004499; /* Optional: darker color on hover */
  }
</style>


<style>
  /* Reduce space for The PI section  */
  .bio-block h4 {
    margin-top: 1.5em;
    margin-bottom: 0.3em;
    text-align: left;
  }

  .bio-block p.subtitle {
    margin: 0.3em 0;
    text-align: left;
  }

  .bio-block h3 {
    text-align: left;
    margin-bottom: 0.7em;
  }
</style>


	<!-- =======================================================
	Theme Name: Squadfree
	Theme URL: https://bootstrapmade.com/squadfree-free-bootstrap-template-creative/
	Author: BootstrapMade
	Author URL: https://bootstrapmade.com
	======================================================= -->

</head>


<!-- Note: style.css loads the brain_banner.jpg -->

<!-- AAM adding an offset for scrolling to account for title bar. -->
<body id="page-top" data-spy="scroll" data-target=".navbar-custom">
  <!-- Preloader -->
  <div id="preloader">
    <div id="load"></div>
  </div>

  <nav class="navbar navbar-custom navbar-fixed-top" role="navigation">
    <div class="container">
      <div class="navbar-header page-scroll">
        <a class="navbar-brand" href="index.html">
          <h1>Deep Learning for Precision Health Lab (Montillo lab)</h1>
        </a>
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-main-collapse">
                    <i class="fa fa-bars"></i>
                </button>
      </div>

      <!-- Collect the nav links, forms, and other content for toggling -->
      <div class="collapse navbar-collapse navbar-right navbar-main-collapse">
        <ul class="nav navbar-nav">
          <li class="active"><a href="#intro">Home</a></li>
          <li><a href="#team">Team</a></li>	
		      <li class="dropdown">
            <a href="#" class="dropdown-toggle" data-toggle="dropdown">Research<b class="caret"></b></a>
            <ul class="dropdown-menu">
              <li><a href="#researchOverview">Research overview</a></li>
              <li><a href="#researchTrustworthy">Trustworthy, explainable AI</a></li>
              <li><a href="#researchMultimodal">Multimodal data fusion</a></li>
              <li><a href="#researchSampleEfficiency">Sample efficient learning</a></li>
              <li><a href="#researchCausal">Causal analysis</a></li>
              <li><a href="#researchClinical">Clinical applications of AI</a></li>                
              <li><a href="#researchCompNeurosci">Computational Neuroscience and Neuroinformatics</a></li>
            </ul>
          </li>	                   	
		      <li class="dropdown">
            <a href="#" class="dropdown-toggle" data-toggle="dropdown">Positions Available<b class="caret"></b></a>
            <ul class="dropdown-menu">
              <li><a href="#GeneralPositionInformation">General information about the positions</a></li>
              <li><a href="#PostdoctoralFellowshipPositions">Postdoctoral Fellowship Positions</a></li>
              <li><a href="#ResearchScientistPositions">Research Scientist Positions </a></li>
              <li><a href="#PhDStudentResearchAssistantPositions">PhD Student Research Assistant Positions </a></li>
            </ul>
          </li>	            
		      <li><a href="#publications">Publications</a></li>
		      <li><a href="#Teaching">Teaching</a></li>          
		      <li><a href="#code">Code</a></li>			  
		      <li class="dropdown">
            <a href="#" class="dropdown-toggle" data-toggle="dropdown">More <b class="caret"></b></a>
            <ul class="dropdown-menu">
              <li><a href="#contact">Contact us</a></li>
              <li><a href="#news">News</a></li>
              <li><a href="#FormerLabMembers">Alumni</a></li>
			        <li><a href="#gallery">Gallery</a></li>
            </ul>
          </li>	
        </ul>
      </div>
      <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
  </nav>

  <!-- Section: intro -->
  <section id="intro" class="intro">

    <div class="slogan">
      <h2>
		<span>Welcome to the Deep Learning for Precision Health Lab</span> 
      </h2>
      <h3 style="color: white; background-color: #003366; padding: 10px; display: inline-block;">We develop the theory and application of deep learning to improve healthcare.</h3>
    </div>
    <div class="page-scroll">
      <a href="#research" class="btn btn-circle">
				<i class="fa fa-angle-double-down animated"></i>
			</a>
    </div>
  </section>
  <!-- /Section: intro -->


  
    <!-- Section: Team -->
  <section id="team" class="home-section text-center">
    <div class="heading-about">
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-lg-offset-2">
            <div class="wow fadeInDown" data-wow-delay="0.4s">
              <div class="section-heading">
                <h2>Team</h2>
                <i class="fa fa-2x fa-angle-down"></i>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    <div class="container">

      <div class="row">
        <div class="col-lg-2 col-lg-offset-5">
          <hr class="marginbot-50">
        </div>
      </div>
	  
	  <div class="row">
        <div class="col-md-4 col-md-offset-4">
          <div class="wow fadeInLeft" data-wow-delay="0.2s">
            <div class="team boxed-grey">
              <div class="inner">
                <h2>The PI</h2>
                <h4>Albert Montillo, Ph.D.</h4>
                <div class="avatar"><img src="img/team/montillo.jpg" alt="" class="img-responsive img-circle" style="margin:auto"/></div>
				        <!-- <a href="https://profiles.utsouthwestern.edu/profile/163266/albert-montillo.html" target="_blank"><p class="subtitle">Faculty Page</p></a> -->
              </div>
            </div>
          </div>
        </div>
      </div>
	  <br>

	  <div class="container">
      <div class="wow fadeInLeft" data-wow-delay="0.2s">
        <div class="team boxed-grey">
            <div class="inner">		
				  <br>

          <div class="bio-block">
            <h3 style="text-align: left;">Albert Montillo, Ph.D.</h3>

            <h4>Associate Professor</h4>
            <p class="subtitle">Department of Bioinformatics</p> 
            <p class="subtitle">Department of Biomedical Engineering</p> 
            <p class="subtitle">University of Texas Southwestern</p> 

            <h4>Adjunct Professor</h4>
            <p class="subtitle">Department of Computer Science</p> 
            <p class="subtitle">Department of Biomedical Engineering</p> 
            <p class="subtitle"><a href="https://engineering.utdallas.edu/" target="_blank">University of Texas Dallas</a></p> 

            <h4>Investigator</h4>
            <p class="subtitle"><a href="https://odonnellbraininstitute.utsouthwestern.edu/" target="_blank">O’Donnell Brain Institute</a></p> 
            <p class="subtitle">University of Texas Southwestern</p> 

            <h4>Ph.D. Medical Image Analysis and Computer Science</h4>
            <p class="subtitle">University of Pennsylvania</p> 

            <h4>M.S. Computer and Information Science</h4>
            <p class="subtitle">University of Pennsylvania</p> 

            <h4>B.S. Computer Science; Electrical Engineering, Cognitive Neuroscience</h4>
            <p class="subtitle">Rensselaer Polytechnic Institute (RPI)</p>  
          </div>
                         
          <br>
          <h4 style="text-align: left;">Outlook</h4>          
					<p class="subtitle" align="justify">
            
            This is an exciting time to build artificial intelligence (AI) to support healthcare and life science research. Modern healthcare and research generate vast, heterogeneous data that span different types, different physical acquisitions and contrasts, and include both cross-sectional and longitudinal data, all of which offer unique, complementary information about health and disease. Recent advances in AI reflect the tantalizing potential AI has to improve healthcare practices, providing support for diagnoses, prognoses, and treatment decisions, as well as supporting life science, facilitating the discovery of the mechanisms of disease and therapy. Accordingly, our lab works on the main challenges of AI in healthcare: (1) trustworthy, understandable AI, (2) multimodal data fusion, (3) causality for life sciences,  (4) data sample efficiency, as well as applications of advanced AI to (5) the clinic and (6) computational neuroscience. Our research lies at the intersection of medical image analysis, machine learning, and biomedical informatics, where we develop algorithms to analyze and understand neuroimages, brain recordings, voice and video recordings, genetic data, and electronic health records, including clinical reports. Our lab develops clinical solutions for oncology (breast and H&N cancer), as well as neurological disorders, including neurodegenerative disease (AD, PD), neurodevelopmental disorders (ASD, epilepsy, speech impairment), and psychiatric disorders (MDD, TRD). I am also drawn to academia to foster career development of aspiring young scientists, mentoring in all aspects of science in a fun and diverse environment, that values creativity and innovation. 
            Since 2022, I have been running our department-wide Causality Journal Club covering the latest advances in causal analysis. Email me if interested.</p>
            <!-- Our PI, Albert Montillo is an Associate Professor in the departments of <a href="https://www.utsouthwestern.edu/departments/bioinformatics/" target="_blank"> Bioinformatics </a> and <a href="https://www.utsouthwestern.edu/departments/biomedical-engineering/" target="_blank">Biomedical Engineering</a>. He is also an 
            Investigator at the <a href="https://odonnellbraininstitute.utsouthwestern.edu/" target="_blank">O’Donnell Brain Institute</a>. He maintains close collaborations with faculty in our School of Medicine including the departments of: <a href="https://www.utsouthwestern.edu/education/medical-school/departments/radiology/" target="_blank">Radiology</a>, <a href="https://www.utsouthwestern.edu/departments/neurology/" target="_blank">Neurology</a>, <a href="https://www.utsouthwestern.edu/education/medical-school/departments/psychiatry/" target="_blank">Psychiatry</a>, <a href="https://www.utsouthwestern.edu/education/medical-school/departments/neuroscience/" target="_blank">Neuroscience</a>, and <a href="https://www.utsouthwestern.edu/departments/otolaryngology/" target="_blank">Otolaryngology</a>, and the <a href="https://www.utsouthwestern.edu/education/medical-school/departments/airc/" target="_blank">Advanced Imaging Research Center</a>. He is also an Adjunct Professor at 
            <a href="https://engineering.utdallas.edu/" target="_blank">UT Dallas in the School of Engineering</a> in Computer Science and Biomedical Engineering.</p> -->
					<!-- 
            <p class="subtitle" align="justify">Dr. Montillo obtained a PhD in Medical Imaging and <a href="https://www.cis.upenn.edu/" target="_blank">Computer Science</a> from the University of Pennsylvania, where he studied automated image analysis of 4D cardiac MRI and neuroimage co-registration and parcellation (automated quantitative neuroanatomical structure volumetry) with applications to Alzheimer's. He received a master of science degree in Computer and Information Science at UPenn and a Bachelor’s in <a href="https://www.cs.rpi.edu/" target="_blank">Computer Science from RPI</a> where he also studied <a href="https://www.ecse.rpi.edu/" target="_blank">Electrical Engineering</a> and <a href="https://hass.rpi.edu/cognitive-science" target="_blank">Cognitive neuroscience/Psychology</a>. 
            
            Through his research, Dr. Montillo developed the leading artifact suppression method for magnetoencephalography (MEG), which is in use at labs nationally including at the MEG Core lab of the National Institutes of Health in Bethesda, and is used worldwide through the Enigma Working group. He also developed a core neuroanatomical structure labeling algorithm which has been adopted into <a href="https://surfer.nmr.mgh.harvard.edu/" target="_blank">FreeSurfer</a>, while at 
            <a href="https://www.nmr.mgh.harvard.edu/" target="_blank">Harvard/MIT Martinos Center for Biomedical Imaging</a>, and is now used worldwide. A variant of the algorithm has received 
            <a href="https://www.cortechs.ai/products/neuroquant/" target="_blank">FDA approval</a> --the first brain parcellation algorithm to do so. Dr. Montillo developed a deep learning approach for the decision forest, known as entanglement, which improves prediction accuracy and increases prediction speed while he was a researcher at the Machine Intelligence and Perception group of Microsoft Research in Cambridge, United Kingdom. While a Lead Scientist at 
            <a href="https://www.ge.com/research" target="_blank">General Electric Research Center</a> in upstate New York, he led the development of machine learning based methods for analyzing high volume neuroimaging data. His efforts led to automated methods for brain parcellation (patented), brain lesion quantification, and automated brain-connectivity based prognoses for mild traumatic brain injury (mTBI) &#8211; all using advanced multi-contrast MRI.   His efforts also led to machine learning algorithms that rank features in imaging genomics studies of Alzheimer’s and methods for radiation dosage reduction in computed tomography via ML-based scout-scan analysis. </p>
            -->
          <p class="subtitle" align="justify">The lab is supported by funding from multiple active grants from federal agencies (e.g., NIH), industry sponsorship, and institutional support from multiple departments.</p>

          <p class="subtitle" align="justify">The lab is an active part of the departments of  <a href="https://www.utsouthwestern.edu/departments/biomedical-engineering/" target="_blank">Biomedical Engineering</a> and <a href="https://www.utsouthwestern.edu/departments/bioinformatics/" target="_blank">Bioinformatics</a>. The lab is closely aligned with the <a href="https://odonnellbraininstitute.utsouthwestern.edu/" target="_blank">O'Donnell Brain Institute</a> for basic and translational neuroscience research. We actively participate in multiple academic programs, such as the <a href="https://www.utsouthwestern.edu/education/graduate-school/programs/biomedical-engineering/" target="_blank">Biomedical Engineering academic program</a>, the <a href="https://www.utsouthwestern.edu/education/graduate-school/programs/computational-and-systems-biology/" target="_blank">Computational Biology program</a>, the <a href="https://www.utsouthwestern.edu/departments/radiation-oncology/education-training/physics-training-program/bme/" target="_blank">Medical Physics</a> track, the
                      <a href=" https://www.utsouthwestern.edu/education/graduate-school/programs/molecular-biophysics/" target="_blank">Molecular Biophysics</a> academic program, and the
                      <a href=" https://www.utsouthwestern.edu/education/graduate-school/programs/neuroscience/" target="_blank"> Neuroscience</a> academic program. We maintain close collaborations with faculty in our School of Medicine including the departments of: 
                      <a href="https://www.utsouthwestern.edu/departments/neurology/" target="_blank">Neurology</a>, 
                      <a href="https://www.utsouthwestern.edu/education/medical-school/departments/psychiatry/" target="_blank">Psychiatry</a>, 
                      <a href="https://www.utsouthwestern.edu/education/medical-school/departments/radiology/" target="_blank">Radiology</a>,
                      <a href="https://www.utsouthwestern.edu/education/medical-school/departments/neuroscience/" target="_blank">Neuroscience</a>, and <a href="https://www.utsouthwestern.edu/departments/otolaryngology/" target="_blank">Otolaryngology</a>, and the <a href="https://www.utsouthwestern.edu/education/medical-school/departments/airc/" target="_blank">Advanced Imaging Research Center</a>.
					</p>


          <br>
          <h4 style="text-align: left;">Industry experience</h4>
          <p class="subtitle" style="text-align: left;">Beyond formal education, my time in industry (~10 years) has prepared me well to mentor trainees no matter their future path, and exemplifies the kind of impact AI can have on healthcare and life science/neuroscience research. While working at the 
            <a href="https://www.nmr.mgh.harvard.edu/" target="_blank">Harvard/MIT Martinos Center for Biomedical Imaging</a>, I developed a core Bayesian machine learning-based algorithm to label neuroanatomical structures throughout the entire brain, accurately and automatically, which has been adopted into FreeSurfer, and is now used worldwide. A variant of the algorithm has received 
            <a href="https://www.cortechs.ai/products/neuroquant/" target="_blank">FDA approval</a> --the first brain parcellation algorithm to do so.  While a research scientist at the Machine Intelligence and Perception group of Microsoft Research in Cambridge, United Kingdom, I developed a deep learning approach for the decision forest, known as entanglement, which improves prediction accuracy and increases prediction speed, a variant of which has since been FDA approved. Subsequently, while a Lead Scientist at the 
            <a href="https://www.ge.com/research" target="_blank">General Electric Research Center</a>, I led the development of machine learning-based methods for analyzing multimodal neuroimaging. These efforts led to automated methods for brain parcellation (US patent), brain lesion quantification, and automated brain-connectivity-based prognoses for mild traumatic brain injury (mTBI) – all using advanced multiparametric MRI. I’ve also developed algorithms (US patents) for machine vision, while working at Cognex, an MIT AI-lab spin-off. </p> 
          <!-- Media Links -->
          <div style="text-align: center; margin-top: 20px;">
            <a href="https://scholar.google.com/citations?hl=en&user=zNhYHHIAAAAJ&view_op=list_works&sortby=pubdate" target="_blank" rel="noopener noreferrer">
              <img src="img/GoogleScholar.png" alt="GoogleScholar" title="GoogleScholar"  width="85" style="vertical-align: middle; border: none;">
            </a>              
            <a href="https://github.com/DeepLearningForPrecisionHealthLab" target="_blank" rel="noopener noreferrer">
              <img src="img/Github.png" alt="GitHub" title="GitHub"  width="170" style="vertical-align: middle; border: none;">
            </a>
            <a href="https://www.linkedin.com/in/albert-montillo-0748361/ " target="_blank" rel="noopener noreferrer">
              <img src="img/LinkedIn.png" alt="LinkedIn" title="LinkedIn"  width="85" style="vertical-align: middle; border: none;">
            </a>              
            <a href="https://x.com/MontilloLab" target="_blank" rel="noopener noreferrer">
              <img src="img/TwitterX.png" alt="TwitterX" title="TwitterX"  width="85" style="vertical-align: middle; border: none;">
            </a>            
          
          </div>

					<br>
				</div>
			</div>
		</div>
	  </div>

    <div class="row">
	  
      <div class="col-md-4" style="margin-bottom:20px">
        <div class="wow fadeInLeft" data-wow-delay="0.5s">
          <div class="team boxed-grey">
            <div class="inner">
              <h5>Son Nam Nguyen, Ph.D.</h5>
              <p class="subtitle">Postdoctoral Fellow</p>
              <p class="subtitle">Deep Learning Theory </p>              
              <div class="avatar"><img src="img/team/SonNamNguyen.jpg" alt="" class="img-responsive img-circle" style="margin:auto"/></div>
              <p>
              Son earned a Ph.D. in Electrical Engineering with a focus on machine learning from the University of Texas at Arlington. He has developed advanced extensions to the backpropagation algorithms using second order training methods to substantially improve their convergence speed. He has adapted and demonstrated his approaches for 4D neural networks for breast cancer prognostics (survival time prediction) and diagnostics (metastases prediction) yielding well-recieved publications using DCE MRI. He has also developed advanced frameworks to alleviate biases in deep learning for any prediction task where there are repeat measures (e.g., data with longitudinal, multisite, or batch effects). He has developed expertise in Tensorflow, PyTorch, and distributed Bayesian algorithms for network architecture optimization. 
              </p>
            </div>
          </div>
        </div>
      </div>			  

      <div class="col-md-4" style="margin-bottom:20px">
        <div class="wow fadeInLeft" data-wow-delay="0.5s">
          <div class="team boxed-grey">
            <div class="inner">
              <h5>Aixa X. Andrade, M.S.</h5>
			        <p class="subtitle">PhD student</p>              
              <p class="subtitle">Medical Physics program</p>
              <div class="avatar"><img src="img/team/AixaAndradeHernandez.jpg" alt="" class="img-responsive img-circle" style="margin:auto"/></div>
              <p>
              Aixa earned her Master's in Medical Radiation Physics from McGill and a Bachelor's in Physics from the Nat. Autonomous Univ. of Mexico. She is developing novel deep learning frameworks to visualize batch effects in single-cell/nucleus RNA-seq data providing new insight into biology and avenues to optimize experimental protocols. She is also developing multimodal neuroimage analysis deep learning pipelines to predict disease severity and trajectories in movement disorders. Aixa's hobbies include dancing, basketball, painting, and reading.
              </p>
            </div>
          </div>
        </div>
      </div>
      
    
      <div class="col-md-4" style="margin-bottom:20px">
        <div class="wow fadeInLeft" data-wow-delay="0.5s">
          <div class="team boxed-grey">
            <div class="inner">
              <h5>Austin Marckx</h5>
              <p class="subtitle">PhD student</p>				
              <p class="subtitle">Computational Biology program</p>              
              <div class="avatar"><img src="img/team/AustinMarckx.jpg" alt="" class="img-responsive img-circle" style="margin:auto"/></div>
              <p>
              After obtaining a Bachelor’s in Neuroscience and Classics, Austin studied hippocampal learning in preclinical neurodegenerative disease models. He joined the Montillo lab to develop 1) advanced causal discovery algorithms suitable for precise recovery of effective connectivity from brain recordings, 2) new deep learning mixed effects models that handle advanced forms of clustering that bias traditional deep learning approaches, and 3) Bayesian counterfactual estimation. Outside of the lab, Austin is a passionate boulderer, volleyball player, and enjoys novels by Brandon Sanderson.
              </p>
            </div>
          </div>
        </div>
      </div>	


    
    </div>  <!-- end row -->


	  <div class="row">	
      <div class="col-md-4" style="margin-bottom:20px">
        <div class="wow fadeInLeft" data-wow-delay="0.5s">
          <div class="team boxed-grey">
            <div class="inner">
              <h5>Brandon Henley, Ph.D.</h5>
              <p class="subtitle">Research Scientist</p>
              <div class="avatar"><img src="img/team/Brandon_Henley.jpg" alt="" class="img-responsive img-circle" style="margin:auto"/></div>
              <p>
              Brandon earned his Ph.D. in BME from the Univ. of Southern California in 2016, and was a postdoctoral fellow at Emory University, where he developed protocols to monitor physiological signals and their contribution to dementia. Since 2023, he has been a Research Scientist at UTSW, where he develops signal processing algorithms, natural language processing techniques, and foundation model frameworks to analyze speech and physiological data for the early diagnosis of cognitive decline. He is co-supervised by Dr. Albert Montillo and Dr. Ihab Hajjar, M.D., in the Department of Neurology.
              </p>
            </div>
          </div>
        </div>
      </div>    



        <div class="col-md-4" style="margin-bottom:20px">
          <div class="wow fadeInLeft" data-wow-delay="0.5s">
            <div class="team boxed-grey">
              <div class="inner">
                <h5>Ramcharan Chandrashekar, Ph.D</h5>
                <p class="subtitle">Computational Scientist</p>
                <div class="avatar"><img src="img/team/Ram_Chandrashekar.jpg" alt="" class="img-responsive img-circle" style="margin:auto"/></div>
                <p>
                  Ram received his Ph.D. in Electrical Engineering in 2022 from the University of Texas at Dallas, where he worked with Professor John Hansen in the CRSS-CI Lab. His research developed methods to improve the perception of non-linguistic sounds among cochlear implant recipients. Since then, he has been a Computational Scientist at UTSW, where he develops high-performance computing solutions, as well as natural language processing and deep learning architectures for speech and audio processing. He is co-supervised by Liqiang Wang and Dr.  Montillo.
                </p>
              </div>
            </div>
          </div>
        </div>      
	  

      <div class="col-md-4" style="margin-bottom:20px">
        <div class="wow fadeInLeft" data-wow-delay="0.5s">
          <div class="team boxed-grey">
            <div class="inner">
              <h5>Krishna Kanth Chitta, M.S.</h5>
              <p class="subtitle">Research Scientist</p>
              <div class="avatar"><img src="img/team/krishna.jpg" alt="" class="img-responsive img-circle" style="margin:auto"/></div>
              <p>
              Krishna has formal training in medical image analysis, deep learning, and computer vision with special emphasis on the physics and clinical applications of Magnetic Resonance Imaging. He has experience in methods for detecting and quantitating structures/lesions in MRI datasets, Fluorescent microscopy images, and colonoscopy. He is developing machine learning algorithms including advanced convolutional neural networks to solve image analysis challenges involving multi-modal medical imaging. 
              </p>
            </div>
          </div>
        </div>
      </div>


    </div>  <!-- end row -->

    <div class="row">	     
      <div class="col-md-4" style="margin-bottom:20px">
        <div class="wow fadeInLeft" data-wow-delay="0.5s">
          <div class="team boxed-grey">
            <div class="inner">
              <h5>Taosha Gao, M.S.</h5>
			        <p class="subtitle">PhD student</p>                            
              <p class="subtitle">Computational Biology program</p>
              <div class="avatar"><img src="img/team/Taosha_Gao.jpg" alt="" class="img-responsive img-circle" style="margin:auto"/></div>
              <p>
              Taosha earned her master’s degree in Computer and Information Science from Case Western Reserve University in 2021. She then worked as a research assistant at the Institute of Neuroscience, Chinese Academy of Sciences in Shanghai, China, until 2024. Since then, she has been pursuing a Ph.D. in the Computational Biology program at UT Southwestern. Under the mentorship of Drs. Gary Hon and Albert Montillo, she is developing machine learning–based causal discovery algorithms to identify causal relationships within transcription factor regulatory networks using large longitudinal Perturb-seq datasets involving multiple CRISPR interventions.
              </p>
            </div>
          </div>
        </div>
      </div>



      <div class="col-md-4" style="margin-bottom:20px">
        <div class="wow fadeInLeft" data-wow-delay="0.5s">
          <div class="team boxed-grey">
            <div class="inner">
              <h5>Adam Wang</h5>
              <p class="subtitle">Undergraduate Research Assistant</p>
              <p class="subtitle">Biomedical Engineering</p>        
              <div class="avatar"><img src="img/team/AdamWang.jpg" alt="" class="img-responsive img-circle" style="margin:auto"/></div>
              <p>
              Adam is studying Biomedical Engineering as an undergraduate at Harvard Univ. and is being advised remotely by Dr. Montillo as part of an ongoing research project that began at UTSW and as part of Harvard’s CS91r supervised research course. In this undergraduate research experience, Adam is implementing bias reduction methods for deep learning models with development and external validation in both healthcare and financial application domains. Adam is a native of Texas, who enjoys programming, mathematical modeling, machine learning and life science applications.
              </p>
            </div>
          </div>
        </div>
      </div>



    </div>  <!-- end row -->


      <div class="col-xs-6 col-md-3" style="margin-bottom:20px">
      </div>        
      </div>  <!-- end class="container" -->
	  
	  

  </section>
  <!-- /Section: team -->
 

 <!-- Section: FormerLabMembers -->
 <section id="FormerLabMembers" class="home-section text-center">
    <div class="heading-about">
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-lg-offset-2">
            <div class="wow fadeInDown" data-wow-delay="0.4s">
              <div class="section-heading">
                <h2>Alumni</h2>
                <i class="fa fa-2x fa-angle-down"></i>

              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    <div class="container">

      


      <div class="row">


          <div class="col-xs-6 col-md-3" style="margin-bottom:20px">
            <div class="wow fadeInLeft" data-wow-delay="0.5s">
              <div class="team boxed-grey">
                <div class="inner">
                  <h5>Alex Treacher</h5>
                  <p class="subtitle">Electrical Engineering</p>
                  <p class="subtitle">Computational Scientist</p>
                  <div class="avatar"><img src="img/team/Merve_Apalak.jpg" alt="" class="img-responsive img-circle" style="margin:auto"/></div>
                  Merve Apalak, Ph.D., earned her Ph.D. in Electrical Engineering from the University of Texas at Dallas, where she conducted research with Prof. Kamran Kiasaleh in the Optical Communications Lab. Subsequently, she worked as a Computational Scientist at UT Southwestern, collaborating with Dr. Albert Montillo and Dr. Liqiang Wang. She is currently a Data Scientist at Texas Instruments.
                </div>
              </div>
            </div>
          </div>



        <div class="col-xs-6 col-md-3" style="margin-bottom:20px">
          <div class="wow fadeInLeft" data-wow-delay="0.5s">
            <div class="team boxed-grey">
              <div class="inner">
                <h5>Alex Treacher</h5>
                <p class="subtitle">Molecular Biophysics</p>
                <p class="subtitle">PhD student</p>
                <div class="avatar"><img src="img/team/AlexTreacher.jpg" alt="" class="img-responsive img-circle" style="margin:auto"/></div>
                Alex earned a Bachelor's in physics from the University of North Texas and then joined the Montillo Lab as a PhD student through the Molecular Biophysics program, where he spearheaded the development of Module-Adaptive Bayesian Optimization speeding multimodal deep learning optimization by 10-12x, and co-developed the leading algorithm for artifact suppression in MEG brain recordings. He is presently a Principal Data Scientist at the Parkland Center for Clinical Innovation developing AI/ML solutions for healthcare. 
              </div>
            </div>
          </div>
        </div>
              
  
          <div class="col-xs-6 col-md-3" style="margin-bottom:20px">
            <div class="wow fadeInLeft" data-wow-delay="0.5s">
              <div class="team boxed-grey">
                <div class="inner">
                  <h5>Kevin Nguyen</h5>
                  <p class="subtitle">Biomedical Engineering</p>
                  <p class="subtitle">MD/PhD student</p>
                  <div class="avatar"><img src="img/team/KevinNguyen.jpg" alt="" class="img-responsive img-circle" style="margin:auto"/></div>
                  Kevin earned his BS in BME at Yale University in 2016, where he developed an interest in computer vision, medical image analysis, and machine learning. He obtained MD and PhD (BME) degrees at UT Southwestern, with a focus on fundamental new frameworks to correct biases in deep learning and translational AI for treatment planning and prognosis in psychiatric and neurological disorders. Kevin is a physician scientist in radiology at UCSF.
                </div>
              </div>
            </div>
          </div>
                
          <div class="col-xs-6 col-md-3" style="margin-bottom:20px">
            <div class="wow fadeInLeft" data-wow-delay="0.5s">
              <div class="team boxed-grey">
                <div class="inner">
                  <h5>Cooper Mellema</h5>
                  <p class="subtitle">Biomedical Engineering</p>
                  <p class="subtitle">MD/PhD student</p>
                  <div class="avatar"><img src="img/team/CooperMellema.jpg" alt="" class="img-responsive img-circle" style="margin:auto"/></div>
                  Cooper triple majored in Biophysics, Computational Neurobiology, and Biochemistry at the University of Washington. He obtained MD and PhD (BME) degrees at UT Southwestern, with research focused on signal processing and causal analysis of brain recordings and fMRI, and the applications of effective connectivity to inform diagnoses and prognoses in neurodevelopmental and neurodegenerative diseases. Cooper is currently a physician scientist in Anesthesiology on the PANTHER research Track at UPMC in Pittsburgh.
                </div>
              </div>
            </div>
          </div>
      </div>  <!--  end row -->



      <div class="row">
          <div class="col-xs-6 col-md-3" style="margin-bottom:20px">
            <div class="wow fadeInLeft" data-wow-delay="0.5s">
              <div class="team boxed-grey">
                <div class="inner">
                  <h5>Vyom Raval, B.S.</h5>
                  <p class="subtitle">Neuroscience. UTSW Greenfellow</p>
                  <p class="subtitle">Undergraduate Researcher</p>
                  <div class="avatar"><img src="img/team/Vyom_picture_cropped.jpg" alt="" class="img-responsive img-circle" style="margin:auto"/></div>
                  Vyom obtained a BS in Neuroscience from the Brain Sciences school at the University of Texas at Dallas. While there, he developed analytical and deep learning methods with Dr Montillo to suppress motion in fMRI, and integrate functional connectivity, biomechanical measures of gait, and postural stability to predict long term outcomes in movement disorders, resulting in first author conference and journal publications. Vyom is presently a MD/PhD student at the University of Washington.
                </div>
              </div>
            </div>
          </div>	 



          <div class="col-xs-6 col-md-3" style="margin-bottom:20px">
            <div class="wow fadeInLeft" data-wow-delay="0.5s">
              <div class="team boxed-grey">
                <div class="inner">
                  <h5>Prabhat Garg, M.D.</h5>
                  <p class="subtitle">School of Medicine</p>
                    <p class="subtitle">Physician Scientist</p>
                  <div class="avatar"><img src="img/team/PrabhatGarg_cropped.jpg" alt="" class="img-responsive img-circle" style="margin:auto"/></div>
                  Prabhat joined UTSW as a physician scientist under the guidance of Dr. Montillo to develop multimodal convolutional deep learning networks to integrate brain time series and image data for the suppression of artifacts in magnetoencephalography. This resulted in the leading algorithm, currently in use at NIH and labs across the USA, and multiple publications. Prabhat is presently a physician scientist at Baylor Scott and White Medical Center. 
                </div>
              </div>
            </div>
          </div>	 
      
  
          <div class="col-xs-6 col-md-3" style="margin-bottom:20px">
            <div class="wow fadeInLeft" data-wow-delay="0.5s">
              <div class="team boxed-grey">
                <div class="inner">
                  <h5>Janis Iourovitski</h5>
                    <p class="subtitle">Biomedical Engineering</p>
                    <p class="subtitle">  </p>
                  <div class="avatar"><img src="img/team/JanisIourovitski_cropped.jpg" alt="" class="img-responsive img-circle" style="margin:auto"/></div>
                  Janis joined as a summer researcher at UTSW through the AMGEN scholars program, developing advanced analytical methods to assess structural connectivity from diffusion MRI. Janis is presently a Clinical Development research engineer at Intuitive Surgical.
                </div>
              </div>
            </div>
          </div>	          

          <div class="col-xs-6 col-md-3" style="margin-bottom:20px">
            <div class="wow fadeInLeft" data-wow-delay="0.5s">
              <div class="team boxed-grey">
                <div class="inner">
                  <h5>Meyer Zinn</h5>
                  <p class="subtitle">Researcher intern</p>
                  <p class="subtitle"></p>
                  <div class="avatar"><img src="img/team/meyer.jpg" alt="" class="img-responsive img-circle" style="margin:auto"/></div>
                  Meyer came aboard for a summer research opportunity at UTSW under the guidance of Dr Montillo, where he developed a full quantitative pipeline for the reconstrution and analysis of quantitative susceptibility mapping (QSM) MRI. He is presently a Kernel research engineer at Apple in Cupertino, CA.
                </div>
              </div>
            </div>
          </div>

      </div>  <!--  end row -->

 
	<div class="row">

        <div class="col-xs-6 col-md-3" style="margin-bottom:20px">
          <div class="wow fadeInLeft" data-wow-delay="0.5s">
            <div class="team boxed-grey">
              <div class="inner">
                <h5>Yenho Chen, B.S.</h5>
                <p class="subtitle">UTD/UTSW Greenfellow</p>
		        		<p class="subtitle">Undergraduate Researcher</p>
                <div class="avatar"><img src="img/team/YenhoChen_cropped.jpg" alt="" class="img-responsive img-circle" style="margin:auto"/></div>
                Following his green fellows scholarship at UTSW working with Dr Montillo to developming machine learning based methods to analyze MRI of traumatic brain injury, Yenho became a machine learning research scientist at NIH. 
              </div>
             </div>
           </div>
        </div>


        <div class="col-xs-6 col-md-3" style="margin-bottom:20px">
          <div class="wow fadeInLeft" data-wow-delay="0.2s">
            <div class="team boxed-grey">
              <div class="inner">
                <h5>Behrouz Saghafi, Ph.D.</h5>
                <p class="subtitle">Postdoctoral Fellow</p>
                <div class="avatar"><img src="img/team/behrouz.jpg" alt="" class="img-responsive img-circle" style="margin:auto"/></div>
                Behrouz obtained his PhD in Computer Science from Nanyang Technological University, Singapore, and subsequently joined Dr Montillo's group as a postdoctoral fellow, developing machine learning algorithms to predict outcomes in diabetes and aging studies. He is presently a Principal Machine Learning Engineer developing analytical algorithms at Capital One.
              </div>
            </div>
          </div>
        </div>

        <div class="col-xs-6 col-md-3" style="margin-bottom:20px">
          <div class="wow fadeInLeft" data-wow-delay="0.5s">
            <div class="team boxed-grey">
              <div class="inner">
                <h5>Anand Kadumberi, M.S.</h5>
                <p class="subtitle">Research Scientist</p>
                <div class="avatar"><img src="img/team/Kadumberi_Anand.jpg" alt="" class="img-responsive img-circle" style="margin:auto"/></div>
                Anand Kadumberi earned a Master's in BME from UT Arlington, and was a research scientist in the Montillo Lab, where he developed machine learning based pipelines for the analysis of neuroimaging, including multicontrast MRI. Anand is presently a Lead Data Scientist developing discovery, eClinical, and imaging solutions for the pharmaceutical industry.
              </div>
            </div>
          </div>
        </div>

           
        <div class="col-xs-6 col-md-3" style="margin-bottom:20px">
          <div class="wow fadeInLeft" data-wow-delay="0.5s">
            <div class="team boxed-grey">
              <div class="inner">
                <h5>Atef Ali</h5>
                <p class="subtitle">Undergraduate Research Assistant</p>
                <div class="avatar"><img src="img/team/Atef_Ali.jpg" alt="" class="img-responsive img-circle" style="margin:auto"/></div>
                <p>
                  Atef earned a Bachelor's in mathematics from the Univ. of Minnesota and joined the Montillo lab for a remote year of research during the COVID pandemic, where he developed image preprocessing and machine learning algorithms for Breast Cancer prognostics, using DCE MRI on high performance distributed computing platforms. He is presently a Bioinformatician in the School of Medicine at the Univ. of Minnesota. 
                </p>
              </div>
            </div>
          </div>
        </div>


        <div class="col-xs-6 col-md-3" style="margin-bottom:20px">
          <div class="wow fadeInLeft" data-wow-delay="0.2s">
            <div class="team boxed-grey">
              <div class="inner">
                <h5>Danni Luo, M.S.</h5>
        				<p class="subtitle">Research Scientist</p>
                <div class="avatar"><img src="img/team/DanniLuo.jpg" alt="" class="img-responsive img-circle" style="margin:auto"/></div>
                Danni earned her Master's in Information Technology from UT Pan American, and was a research scientist in Dr Montillo's group, developing machine learning frameworks for the analysis of fMRI for developmental disorders and Alzheimer's disease. She is presently a Lead Scientific Programmer in the School of Public Health at UT Southwestern. 
              </div>
            </div>
          </div>
        </div>			
	    </div>  <!--  end row -->

	  
    </div>   <!--  end container -->
  </section>
  <!-- /Section: FormerLabMembers -->  
 
 <!-- Section: research -->
  <section id="research" class="home-section text-center bg-gray">
    <section id="researchOverview"></section>
    <div class="heading-about">
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-lg-offset-2">
            <div class="wow fadeInDown" data-wow-delay="0.4s">
              <div class="section-heading">
                <h2>Research directions</h2>
                <!-- <i class="fa fa-2x fa-angle-down"></i> -->
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    <div class="container">

      <!---
      <div class="row">
        <div class="col-lg-2 col-lg-offset-5">
          <hr class="marginbot-50">
        </div>
      </div>
    -->


	  <div class="row">
        <div class="col-lg-12">
          <div class="wow fadeInLeft" data-wow-delay="0.2s">
            <div class="team boxed-grey">
                <div class="inner">
                  <p class="subtitle" align="justify">The development of the theory and application of AI to support healthcare and life science holds <em>high potential to improve lives</em>. This potential stems from the confluence of (1) healthcare and life science research generating vast, heterogeneous data, (2) growing compute, and (3) improving AI methodologies. In healthcare, <strong>AI can support diagnoses, prognoses, and treatment decisions, while keeping the doctor in command</strong>. In life science, <strong>AI supports hypothesis generation</strong> through the discovery of mechanisms of disease and therapy. To realize these potentials, the <strong>research directions of our lab center on the main challenges of AI in healthcare/life science</strong>: (1) <em>trustworthy AI</em>, (2) <em>multimodal data fusion</em>, (3) <em>causal analysis</em>, (4) <em>sample efficiency</em>, as well as (5) <em> clinic applications of AI</em> and (6) <em>computational neuroscience</em>.</p>

                  <p align="justify"> 
                  Our research lies at the intersection of medical image analysis, machine learning, and biomedical informatics, where we develop algorithms to analyze and understand high dimensional data, including:</p>
                  <div style="text-align: left;"> 
                    <ul style="font-size: 16px;">
                    <li><strong>neuroimaging</strong> (e.g., advanced analytics for multiparametric MRI: fMRI, HARDI/DSI/NODDI/DKI, QSM, MRS, T1/T2/FLAIR; PET/SPECT; CT; U/S; OCT/OCTA)</li>
                    <li><strong>brain recordings</strong> (e.g., MEG, EEG, sEEG/ECoG/Neuropixels, fUS)</li>
                    <li><strong>voice and video recordings,</strong></li>
                    <li><strong>multiomics data</strong> (sc/snRNA-seq, ATAC/ChIP-seq, spatial transcriptomics; proteomics; metabolomics)</li>            
                    <li><strong>EHR</strong> (longitudinal/multimodal data, free-form notes; functional/cognitive assessments)</li>
                    </ul>
                  </div>  

                  <p class="subtitle" style="text-align: left;">
                  Working closely with physicians in neurology, psychiatry, radiology and neuroscientists, we have amassed a record of AI innovation and impact, including multimodal signatures and mechanisms of Parkinson’s disease, Alzheimer’s Disease, Autism, Epilepsy, Depression, and cancer. Below, we describe our lab’s research directions.</p>
                  </br>
                </div>  
          <!-- editable source is: Final_ResearchDescriptionsForWeb_ShortForm_v1.8.doc.docx -->

          <br>
          <section id="researchTrustworthy"></section>
          <h3 style="text-align: left;">Trustworthy, explainable AI </h3>          
					<p class="subtitle" align="justify">
            
            AI can improve healthcare, providing support for diagnoses, prognoses, and treatment decisions, and bolster life science research, uncovering mechanisms of disease and therapy;  however, this potential remains locked away until AI systems become fully trustworthy. In our lab, this includes, but is not limited to: 1) Building safe models that do no harm, providing sensible outputs even when faced with abnormal or noisy inputs; 2) Constructing AI tools that ensure human agency, keeping clinicians and life scientists in the loop and in command, supporting them, rather than making unchecked, autonomous decisions; 3) Designing models with explainable decisions down to the level of the individual, 4) Ensuring performance that holds up across use cases not part of the training data, and 5) Providing equitable performance across subpopulations. 
            </p>

          <p align="justify">Examples of our success include: 1) The development of a mixed-effects deep learning framework, which improves generalization performance on data not seen during training [<a href="https://ieeexplore.ieee.org/document/10016237" class="citation-link" target="_blank" rel="noopener noreferrer">IEEE TPAMI, 2023</a>]. 2) The development of methods to enhance fairness, ensuring improved performance across subpopulations [<a href="https://arxiv.org/abs/2310.03146" class="citation-link" target="_blank" rel="noopener noreferrer">arXiv, 2025</a>]. 3) The use of advanced methods to explain imaging (modern attention maps) and clinical features (SHAP analyses) used for cancer survival prediction [<a href="https://pubs.rsna.org/doi/10.1148/rycan.230107" class="citation-link" target="_blank" rel="noopener noreferrer">Radiology: Imaging Cancer, 2024</a>]. 4) The  development of deep learning frameworks that provide calibrated prediction confidence with each prediction, and p-values for each covariate [<a href="https://arxiv.org/abs/2211.15888" class="citation-link" target="_blank" rel="noopener noreferrer">UQ-MEDL, 2022</a>]. The construction of AI methodologies to fully engender these and additional trustworthiness principles is an ongoing process, with multiple research avenues to pursue.
          </p>

          <br>
          <section id="researchMultimodal"></section>
          <h3 style="text-align: left;">Multimodal data fusion</h3>
          <p class="subtitle" style="text-align: left;">
            Modern healthcare generates heterogeneous data of different types (images and text, genomics and proteomics, speech and video), different acquisitions (e.g., PET vs. MRI, fMRI vs. MEG/EEG), contrasts (QSM vs. diffusion MRI), and granularity (cross-sectional vs. longitudinal), offering complementary information about health and disease. Fully combining such data could improve predictive power and disentangle complex biological mechanisms underlying disease and treatment response. However, it is difficult, even for domain experts, to manually align the data and recognize intricate inter-modality relationships. Traditional computational methods struggle to integrate these high-dimensional, diverse data streams or capture their relationships. However, <strong>deep multimodal fusion</strong> offers a promising path forward, leveraging advanced neural architectures to holistically and efficiently merge diverse data, unlocking richer predictive insights and new avenues for precision medicine. Examples of fruitful deep fusion include attention-based approaches (e.g., cross-modal, co-attention), which weight components within and across modalities, and generative fusion (e.g., diffusion models), which align modality distributions, regularizing feature spaces and enhancing cross-modal consistency. </p>
     
            <p align="justify">Our lab has addressed key fusion challenges, including: 1) handling differences in statistical properties, e.g., clustered (site/batch-confounded) samples, 2) increasing explainability, while 3) keeping training and model search time manageable. For example, to guide treatment selection in depression [<a href="https://doi.org/10.1016/j.biopsych.2021.09.011" class="citation-link" target="_blank" rel="noopener noreferrer">Biological Psychiatry, 2022</a>;  <a href="https://www.ncbi.nlm.nih.gov/pubmed/31709423/" class="citation-link" target="_blank" rel="noopener noreferrer">MICCAI, 2019</a>] and to improve prognosis for breast cancer [<a href="https://pubs.rsna.org/doi/10.1148/rycan.230107" class="citation-link" target="_blank" rel="noopener noreferrer">Radiology: Imaging Cancer, 2024</a>], we developed deep learning models that fuse imaging and clinicodemographic data, and use attention maps and SHAP analysis to explain multimodal decisions. Meanwhile, our Module Adaptive Bayesian Optimization speeds the development of multimodal fusion networks by 16x, and improves final prediction performance [<a href="https://arxiv.org/abs/2202.11841" class="citation-link" target="_blank" rel="noopener noreferrer">ArXiv, 2023</a>]. Many additional challenges remain, including the development of constraint-based fusion and graph neural networks to align modality representations and integrate structural and relational information. We are actively pursuing these and other fusion approaches. 
          </p>

          <br>
          <section id="researchSampleEfficiency"></section>
          <h3 style="text-align: left;">Sample efficient learning</h3>          
					<p class="subtitle" align="justify">
            
            Traditional AI methods work well with abundant, carefully curated data. However, in modern healthcare, there is an inherent scarcity and high cost to obtain large-scale, high-quality labeled datasets due to privacy concerns, clinical constraints, and the need for expert annotation. Consequently, developing methodologies that achieve strong predictive performance with minimal labeled data is crucial. 
            </p>

             <p align="justify">Our lab develops sample-efficient deep learning, by maximizing predictive generalization while minimizing data demands, and broadly enabling AI systems for diagnosis, prognosis, and treatment planning. For example, we developed an embedding-based meta-learning framework, which projects data from batches unseen during training, onto those seen during training, enabling rapid adaptation to new data (e.g., different hospitals or scanner types) [<a href="https://ieeexplore.ieee.org/document/10016237" class="citation-link" target="_blank" rel="noopener noreferrer">IEEE TPAMI, 2023</a>, <a href="https://arxiv.org/abs/2211.15888" class="citation-link" target="_blank" rel="noopener noreferrer">UQ-MEDL, 2022</a>]. We developed a transfer learning-based approach, which produces statistically significant gains in prediction accuracy without requiring any additional data [<a href="https://arxiv.org/abs/2202.11841" class="citation-link" target="_blank" rel="noopener noreferrer">ArXiv, 2023</a>], and have adapted self-supervised foundation models, run in-house, to achieve high accuracy for early Alzheimer’s diagnostics from speech [<a href="https://2025.myana.org/" class="citation-link" target="_blank" rel="noopener noreferrer">AmerNeuroAssoc, 2025</a>]. We developed the first data augmentation approach for 4D rs-fMRI which increasing by 3x the ability to detect an effect, reducing the required sample size for effective Parkinson’s and Major Depressive Disorder studies [<a href="https://www.liebertpub.com/doi/10.1089/brain.2021.0186" class="citation-link" target="_blank" rel="noopener noreferrer">Brain Connectivity, 2022</a>; <a href="https://doi.org/10.1016%2Fj.nicl.2024.103571" class="citation-link" target="_blank" rel="noopener noreferrer">NeuroImage: Clinical 2023</a>]. This research direction has numerous applications; accordingly, we are actively developing new approaches (e.g., few-shot learning and expert knowledge integration) for sample-efficient learning.
          </p>

          <br>
          <section id="researchCausal"></section>
          <h3 style="text-align: left;">Causal analysis</h3>
          <p class="subtitle" style="text-align: left;">
            For decades, machine learning has been identifying predictor-to-target <strong>correlations</strong> rather than quantifying mechanistic, causal relationships; however, <strong>causal analysis</strong> methods hold the potential to alleviate this gap, transforming medicine and life sciences.  <strong>Causal discovery</strong> methods enable researchers to identify genes, proteins, and exposures that play key roles in disease progression, while <strong>causal inference</strong> methods quantify treatment effects using observational data—such as EHR—when RCTs are impractical. Further work is needed, as existing methods make unrealistic assumptions, e.g., 1) an acyclic structure, 2) linear relationships between variables, and 3) positivity/coverage across treatment levels and covariate profiles, making them brittle in clinical and neuroscience settings.  
            </p>
            <p align="justify">We develop innovative causal analysis methods, alleviating these and other limitations, to unlock their full potential. For example, we developed causal discovery methods that integrate prior knowledge, fusing structural connectivity from diffusion MRI with functional connectivity from fMRI, to extract causal (effective) connectivity robustly from neuroimaging MRI. Our approach combines the strengths of Granger Causality to handle feedback loops, with an efficient machine learning implementation, scaling to nodes spanning the entire brain, and enabling unprecedented accuracy in predicting motor and cognitive trajectories in neurodegenerative disorders [<a href="https://doi.org/10.1088/1741-2552/ad0c5f" class="citation-link" target="_blank" rel="noopener noreferrer">J of Neural Engineering, 2023</a>; <a href="https://doi.org/10.1016%2Fj.nicl.2024.103571" class="citation-link" target="_blank" rel="noopener noreferrer">NeuroImage: Clinical 2023</a>]. Recently, we have developed novel methods for causal inference, including a framework for counterfactual mixed-effects deep learning, by combining the potential outcomes framework with deep learning. This enables precise ITE estimation, rather than merely average treatment effects, e.g., ATT, ATE, even when traditional ML assumptions (<em>iid</em> data) are unmet. Numerous topics are ready for further exploration, such as additional incorporation of expert knowledge and observational/interventional data integration. If you are interested, reach out to the PI.
          </p>          
          
          <br>
          <section id="researchClinical"></section>
          <h3 style="text-align: left;">Clinical applications of AI</h3>
          <p class="subtitle" style="text-align: left;">
          Disease heterogeneity, look-alike syndromes, and multiple options for care, make it challenging for clinicians in neurology, psychiatry, and radiology to consistently identify disease during prodromal stages, forecast disease trajectories, and optimally match patients to treatments. Integrating high-dimensional, heterogeneous data—including MRI and PET scans, genomics, proteomics, and structured EHRs —holds potential, but their integration typically exceeds the limits of manual review, as well as conventional statistical methods. To alleviate this gap, our lab develops trustworthy, sample-efficient deep learning models for cross-modality representation alignment. Our models <em>keep the doctor in control</em>, integrating their expertise to guide the learning, and produce explainable predictions that uncover latent multimodal signatures to support diagnoses, prognoses, and treatment decisions. Complementing this, we develop reinforcement learning techniques for closed-loop neuromodulation, tailoring stimulation protocols based on dynamic neural activity. All research is conducted in close collaboration with clinical partners, who co-curate data and imaging protocols and evaluate real-world tool utility. The following applications are representative of our joint impact.</p>

          <div style="text-align: left;"> 
            <ul style="font-size: 16px;">
            <li>In <strong>Major Depressive Disorder</strong> 30% of patients receive inadequate symptom relief after a year of standard care. To address this, we developed a DL model that predicts individualized responses to multiple treatments from pretreatment brain activity, providing the physician with an additional positive outcome for every four patients treated (NNT=2-4). The work, lauded as “the first model to include reward fMRI for individualized response prediction" by the CIMH, Germany, appeared  in <a href="https://doi.org/10.1016/j.biopsych.2021.09.011" class="citation-link" target="_blank" rel="noopener noreferrer">Biological Psychiatry, 2022</a>.</li>
            <li>In <strong>Autism Spectrum Disorder</strong> how gene expression associates with brain function has been poorly understood. To alleviate this, we integrate brain activity from fMRI with gene expression from RNA-seq and apply rigorous statistics to identify genes whose expression is associated with activity in multiple brain regions disrupted in ASD. This work appeared  in <a href="https://doi.org/10.1038/s41467-022-31053-5" class="citation-link" target="_blank" rel="noopener noreferrer">Nature Communications, 2022</a>.</li>
            <li>For <strong>Parkinson’s disease</strong> there is no accepted tool to predict the disease trajectory, hampering physicians’ ability to counsel patients or recommend fast progressors to enrich clinical trials that evaluate candidate neurotherapeutics. To remedy this, we developed a predictive model of motor and cognitive progression, achieving state-of-the-art accuracy through novel causal (effective) brain connectivity  [<a href="https://doi.org/10.1016/j.parkreldis.2021.02.026" class="citation-link" target="_blank" rel="noopener noreferrer">Parkinsonism and Related Disorders, 2021</a>;  <a href="https://doi.org/10.1016/j.nicl.2024.103571" class="citation-link" target="_blank" rel="noopener noreferrer"> NeuroImage: Clinical, 2024</a>; <a href="https://doi.org/10.1088/1741-2552/ad0c5f" class="citation-link" target="_blank" rel="noopener noreferrer">J of Neural Engineering, 2023</a>], fostering the development of disease-modifying drugs by empowering short-duration clinical trials with fast progressors.</li>
            </ul>
          </div>  

           <p class="subtitle" style="text-align: left;">
              We are actively developing new clinical applications, adapting foundation models, and integrating expert knowledge; we welcome new clinical partners and budding researchers to join us!</p>          

          <br>
          <section id="researchCompNeurosci"></section>
          <h3 style="text-align: left;">Computational neuroscience and neuroinformatics</h3>          
					<p class="subtitle" align="justify">
            Computational neuroscience and neuroinformatics is an interdisciplinary research area dedicated to understanding brain function and dysfunction through advanced mathematical modeling, machine learning, and large-scale data analysis. Despite remarkable progress, neuroscientists still face substantial gaps in understanding fundamental disease mechanisms underlying neurodevelopmental disorders (such as autism spectrum disorder, epilepsy, and cerebellar dysfunction) and neuropsychiatric conditions like treatment-resistant depression. Furthermore, there is limited understanding regarding how experimental neuromodulation therapies—including transcranial direct current stimulation (tDCS), transcranial magnetic stimulation (TMS), and deep brain stimulation (DBS)—exert their therapeutic effects, and regarding the optimal patient profiles, target sites, and stimulation parameters for maximal clinical benefit.</p>
            
            <p align="justify">To address these challenges, our research develops AI-powered methods to identify imaging biomarkers—patterns of brain activity and connectivity—from MRI, MEG, or intracranial recordings [<a href="https://doi.org/10.1016/j.parkreldis.2021.02.026" class="citation-link" target="_blank" rel="noopener noreferrer">Parkinsonism and Related Disorders, 2021</a>; <a href="https://doi.org/10.1038/s41467-022-31053-5" class="citation-link" target="_blank" rel="noopener noreferrer">Nature Communications, 2022</a>; <a href="https://doi.org/10.1016/j.biopsych.2021.09.011" class="citation-link" target="_blank" rel="noopener noreferrer">Biological Psychiatry, 2022</a>], and integrate them into predictive and explanatory models of disease. These models can help identify patient subtypes, predict treatment outcomes, and reveal critical mechanisms of disease. Methodologically, we employ foundation models, graph neural networks, as well as graph theory, and causal discovery techniques to precisely quantify effective connectivity patterns and differentiate between healthy and pathological neural states. Numerous open challenges remain, such as refining computational methods to better capture complex patient-specific dynamics, disentangling causal from correlational structure, designing interpretable and generalizable models of brain-behavior relationships that guide neuromodulation, and handling protocol variations including acquisition time and brain coverage —all of which are compelling avenues for researchers passionate about pioneering advancements in brain science and therapeutic innovation.
          </p>


          <!-- 
                    <div class="row">
                        <div class="col-lg-6 col-sm-12">
                            <h3>Building new fundamental Deep Learning frameworks</h3>
                            <img src="img/ProjectNN.png" alt="image" style="max-width:60%; max-height:30%">
                            <p class="subtitle" align="justify", style="padding:20px">
                              How can we make our deep learning models more interpretable, and output statistically meaningful results? How can uncertainty (e.g., aleatoric, epistemic, dataset) be accounted for in our deep learning models?  How can deep learning models be optimally tailored to each new problem to maximize prediction performance, despite the use of multimodal data and finite computing resources?
                                How can domain expertise from clinicians be embedded into deep learning models? 
                                How can causal information be extracted in longitudinal data to reduce Type I and II errors commonly resulting from most correlation-based  machine learning in use today?
                                We are tackling these problems and more, with a combination of innovative algorithmic development for automated hyperparameter optimization, Bayesian Probability theory, and Information theory. 
                                Our focus is on making customized deep learning solutions available to any researcher, including those without machine learning expertise. 
                                Our approaches optimize the use of limited labeled training data and provide detailed information about what the models have learned to reveal how predictions are made. 
                            </p>
                        </div>
                        <div class="col-lg-6 col-sm-12">
                            <h3>Developing impactful biomedical applications of deep learning </h3>
                            <img src="img/ProjectBrain.png" alt="image" style="max-width:60%; max-height:30%">
                            <p class="subtitle" align="justify", style="padding:20px">
                            How can we improve our current subjective diagnoses of subtypes of brain disorders and diseases that have overlapping symptoms?  How can we identify new gene targets for spectrum disorders using the exquisite phenotypes provided by multimodal functional neuroimaging? How do we identify pre-treatment biomarkers of therapy response so that optimal patient management decisions can be made before therapy starts?
                            We are addressing these critical biomedical questions by building deep learning predictive models that combine quantitative, multimodal neuroimaging data with multi-omic data and clinical information to reduce uncertainty and improve patient care. This helps patients receive the correct treatment sooner, when it can do the most good.  Working together with our clinical collaborators, our models are used to cluster disease subtypes, quantify causal treatment effects before treatment ensues, and help identify the best treatment for each individual patient.
                            </p>
                        </div>
                    </div>
                  -->

                    <br> 
                    <br>
                </div>
            </div>
          </div>
        </div>
      </div>
	  <br>
    </div>
  </section>
  <!-- /Section: research -->


  <!-- Section: publications -->
  <section id="publications" class="home-section text-center bg-gray">
    <div class="heading-about">
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-lg-offset-2">
            <div class="wow fadeInDown" data-wow-delay="0.4s">
              <div class="section-heading">
                <h2>Publications</h2>
                <!-- <i class="fa fa-2x fa-angle-down"></i> -->

              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    <div class="container">


    <!--Template for citation
        Example:
        Author list
        <span class="pubtitle">Title.</span>
        Journal/Venue, year month;
        </br>
        <div class="dropdown">
          <button onclick="dropDown{n+1}()" class="dropbtn">Abstract</button>
          <div id="myDropdown{n+1}" class="dropdown-content">
            {Abstract text}
          </div>
        </div>
        <script>function dropDown{n+1}() {
          document.getElementById("myDropdown{n+1}").classList.toggle("show");
        }</script>
            [
              <a href="./publications/name_of_paper.pdf" target="_blank">pdf</a>
            | <a href="./publications/name_of_paper.bib" target="_blank">bib</a>
            | doi: <a href="https://doi.org/<doi number here>" target="_blank">doi number here</a>
            | PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/<PMID number>" target="_blank">PMID number here</a>
            | <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/<PMCID number>" target="_blank">PMCID</a>
            | <a href="https://www.arxiv.com/abs/<ArXiv ID>" target="_blank">ArXiv</a>
            | <a href="./publications/path_to_slides.pdf" target="_blank">slides</a>
            | <a href="video URL" target="_blank">talk</a>
            | <a href="./publications/path_to_poster.pdf" target="_blank">poster</a>
            | <a href="GitHub URL" target="_blank">code</a>
            ]
            (Delete fields that don't apply)
            Full order: [abstract | pdf | bib | DOI | PMID | PMCID |  ArXiv | slides | talk | poster | code |
                    project page ]
            </br>
            </br>
      -->      

	  <div class="row">
          <div class="wow fadeInUp" data-wow-delay="0.2s">
            <div class="team boxed-grey">
              <div class="inner" style="text-align: left">
                ** = Corresponding author</br><br>

        Hajjar I, Henley B, Yang Z, Apalak M, Chandrashekar R, Obideen M, Goldstein F, Montillo A, 
				<span class="pubtitle">AI-based voice biomarkers detect Mild Cognitive Impairment and Alzheimer’s Disease biomarker positivity</span>, 
				American Neurological Association, Annual Meeting, Baltimore, MD, Sept 2025.  
				</br>
				<div class="dropdown">
					<button onclick="dropDown60()" class="dropbtn">Abstract</button>
					<div id="myDropdown60" class="dropdown-content">
            Introduction: Alzheimer’s disease is underdiagnosed by ~40%, in part due to the time intensive cognitive tests that can take several hours  to conduct and require interpretation by a skilled clinician. A non-invasive, fast and efficient screening tool, which identifies subjects at high risk for MCI and a candidate for more extensive testing, would better utilize healthcare resources. Brain biomarkers, such as the CSF phosphorylated tau to amyloid-beta 42 ratio (pTAR), are one such route to ascertain the risk of MCI. Such biomarkers enjoy improved objectivity, but require an invasive lumbar puncture. Accumulating evidence suggests that audio recordings can predict cognitive performance; however, there is comparatively much less evidence that audio recordings can predict biomarker status, which would enable efficient patient screening without lumbar puncture invasiveness. 
            Conclusion: Our approach incorporates state-of-the art AI approaches and allows for rapid patient screening through the prediction of pTAR biomarker positivity with significant accuracy using a ~5-minute protocol.   Further development of these approaches may provide additional accuracy improvements and precision for disease progression tracking and enable patient screening to reduce the under diagnosis of AD.
					</div>
				</div>
				<script>function dropDown60() {
					document.getElementById("myDropdown60").classList.toggle("show");
				}</script>
				[<a href="./publications/Hajjar_Henley_Montillo_ANA2025_BiomarkerStatusPredictionFromVoiceBiomarkers.txt" target="_blank">bib</a>|
				<a href="./publications/Hajjar_Henley_Montillo_ANA2025_BiomarkerStatusPredictionFromVoiceBiomarkers.pdf" target="_blank">pdf</a>|
        ]
				<br><br>

        Andrade A, Nguyen S,  Montillo A, 
				<span class="pubtitle">Autoencoder Mixed Effects Deep Learning for the interpretable analysis of scRNA-seq data by separately modeling batch-specific and -agnostic effects</span>, 
				Great Lakes Bioinformatics Conference, Minneapolis MN, May 2025.  
				</br>
				<div class="dropdown">
					<button onclick="dropDown60()" class="dropbtn">Abstract</button>
					<div id="myDropdown60" class="dropdown-content">
            Single-cell RNA sequencing data can provide unprecedented insights into cellular heterogeneity, yet batch effects arising from both technical and biological factors can obscure meaningful signals. We propose an autoencoder Mixed Effects Deep Learning framework, called aMEDL, that separately models batch-invariant and batch-specific variation to improve the suppression of batch effects, while preserving biologically relevant information. The aMEDL framework comprises two complementary autoencoder networks: an adversarial network that learns a batch-invariant representation, and a probabilistic network that learns batch-specific signals. This dual network approach explicitly models batch distributions rather than discarding them, capturing crucial biological variation that might otherwise be lost. We evaluate aMEDL across diverse datasets, including a single-cell dataset from cardiovascular tissue of healthy donors1 and a single-nucleus dataset from subjects with Autism Spectrum Disorder (ASD) and Typically Developing (TD) individuals2 The framework is compared to the traditional method for scRNA-seq processing, principal component analysis (PCA), and to a newer neural network approach for data abstraction that uses a single autoencoder (AE) network. In both cases, the proposed framework outperforms the comparable methods. In the Healthy Heart dataset, while measuring batch separability via the mean Average Silhouette Width (ASW) with a range of -1.0 to +1.0, we find that aMEDL’s random effects subnetwork accurately captures batch differences (higher is better) with an ASW of +0.37, outperforming PCA (−0.48) and AE (−0.45). Meanwhile, its fixed effects component effectively suppresses batch signals in the latent space (lower is better), with an ASW of −0.50 compared to −0.48 (PCA) and −0.45 (AE). Additionally, using UMAP-based visualizations, aMEDL is observed regularly outperforming the comparable methods. For example in the ASD dataset, it preserved cell type information that PCA did not and avoided spurious clusters observed from the AE approach. Similar favorable results were obtained in the ASD dataset, where the random effects subnetwork reliably captured donor-specific variations, demonstrating aMEDL’s ability to disentangle donor variability from shared biological signals. Overall, aMEDL not only eliminates undesired batch effects, but also maintains batch-specific differences, preventing overcorrection and false clustering. As the first deep learning framework to simultaneously model batch-invariant and batch-specific signals, aMEDL provides an interpretable, generative platform for uncovering disease mechanisms, donor variability, and technical artifacts in single-cell transcriptomics, ultimately paving the way for deeper insights into health and disease.
					</div>
				</div>
				<script>function dropDown60() {
					document.getElementById("myDropdown60").classList.toggle("show");
				}</script>
				[<a href="./publications/Andrade_2025_GLBIO_Autoencoder Mixed Effects Deep Learning for the interpretable analysis of scRNAseq.txt" target="_blank">bib</a>|
				<a href="./publications/Andrade_2025_GLBIO_Autoencoder Mixed Effects Deep Learning for the interpretable analysis of scRNAseq.pdf" target="_blank">pdf</a>|
        ]
				<br><br>        
        
				Germani E, Baghwat N, Dugre M, Gau R, Montillo AA, Nguyen KP, Sokolowski A, Sharp M, Poline JB, Glatard T, 
				<span class="pubtitle">Predicting Parkinson’s disease trajectory using clinical and functional MRI features: a reproduction and replication study</span>, 
				PLOS-ONE, Vol 20, No 2: e0317566, Feb 2025.
       	</br>
				<div class="dropdown">
					<button onclick="dropDown60()" class="dropbtn">Abstract</button>
					<div id="myDropdown60" class="dropdown-content">
          Parkinson’s disease (PD) is a common neurodegenerative disorder with a poorly understood physiopathology and no established biomarkers for the diagnosis of early stages and for prediction of disease progression. Several neuroimaging biomarkers have been studied recently, but these are susceptible to several sources of variability related for instance to cohort selection or image analysis. In this context, an evaluation of the robustness of such biomarkers to variations in the data processing workflow is essential. This study is part of a larger project investigating the replicability of potential neuroimaging biomarkers of PD. Here, we attempt to fully reproduce (reimplementing the experiments with the same methods, including data collection from the same database) and replicate (different data and/or method) the models described in (Nguyen et al., 2021) to predict individual’s PD current state and progression using demographic, clinical and neuroimaging features (fALFF and ReHo extracted from resting-state fMRI). We use the Parkinson’s Progression Markers Initiative dataset (PPMI, ppmi-info.org), as in (Nguyen et al., 2021) and aim to reproduce the original cohort, imaging features and machine learning models as closely as possible using the information available in the paper and the code. We also investigated methodological variations in cohort selection, feature extraction pipelines and sets of input features. Different criteria were used to evaluate the reproduction attempt and compare the results with the original ones. Notably, we obtained significantly better than chance performance using the analysis pipeline closest to that in the original study (R2 > 0), which is consistent with its findings. In addition, we performed a partial reproduction using derived data provided by the authors of the original study, and we obtained results that were close to the original ones. The challenges encountered while attempting to reproduce (fully and partially) and replicating the original work are likely explained by the complexity of neuroimaging studies, in particular in clinical settings. We provide recommendations to further facilitate the reproducibility of such studies in the future.
					</div>
				</div>
				<script>function dropDown60() {
					document.getElementById("myDropdown60").classList.toggle("show");
				}</script>
				[<a href="./publications/Germani_2025_PLOS-ONE_PredictingPDtrajectory.txt" target="_blank">bib</a>|
				<a href="./publications/Germani_2025_PLOS-ONE_PredictingPDtrajectory.pdf" target="_blank">pdf</a>|
				PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/39982930/" target="_blank">39982930 </a>| 
				doi: <a href="https://doi.org/10.1371/journal.pone.0317566" target="_blank">10.1371/journal.pone.0317566</a>]
				<br><br>        
				
				Polat D, Nguyen S, Wang L, Çobanoglu MC, Montillo A**, Dogan B, 
				<span class="pubtitle">Prediction of Lymph Node Metastasis Using a Primary Breast Cancer DCE-MRI-Based 4D Convolutional Neural Network</span>, 
				Radiology: Imaging Cancer, Vol 6, No 3, 2024.  
				</br>
				<div class="dropdown">
					<button onclick="dropDown60()" class="dropbtn">Abstract</button>
					<div id="myDropdown60" class="dropdown-content">
						Purpose</br>
						To develop a custom deep convolutional neural network (CNN) for noninvasive prediction of breast cancer nodal metastasis.</br>
						Material and Methods</br>
						This retrospective study included patients with newly diagnosed primary invasive breast cancer with known pathologic (pN) and clinical nodal (cN) status who underwent dynamic contrast-enhanced (DCE) breast MRI at the authors’ institution between July 2013 and July 2016. Clinicopathologic data (age, estrogen receptor and human epidermal growth factor 2 status, Ki-67 index, and tumor grade) and cN and pN status were collected. A four-dimensional (4D) CNN model integrating temporal information from dynamic image sets was developed. The convolutional layers learned prognostic image features, which were combined with clinicopathologic measures to predict cN0 versus cN+ and pN0 versus pN+ disease. Performance was assessed with the area under the receiver operatingcharacteristic curve (AUC), with fivefold nested cross-validation.</br>
						Results</br>
						Data from 350 female patients (mean age, 51.7 years ± 11.9 [SD]) were analyzed. AUC, sensitivity, and specificity values of the 4D hybrid model were 0.87 (95% CI: 0.83, 0.91), 89% (95% CI: 79%, 93%), and 76% (95% CI: 68%, 88%) for differentiating pN0 versus pN+ and 0.79 (95% CI: 0.76, 0.82), 80% (95% CI: 77%, 84%), and 62% (95% CI: 58%, 67%), respectively, for differentiating
						cN0 versus cN+.</br>
						Conclusion</br>
						The proposed deep learning model using tumor DCE MR images demonstrated high sensitivity in identifying breast cancer lymph node metastasis and shows promise for potential use as a clinical decision support tool.
					</div>
				</div>
				<script>function dropDown60() {
					document.getElementById("myDropdown60").classList.toggle("show");
				}</script>
				[<a href="./publications/2024_rycan_230107.txt" target="_blank">bib</a>|
				<a href="./publications/2024_rycan_230107.pdf" target="_blank">pdf</a>|
				PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/38607282" target="_blank">38607282 </a>| 
				doi: <a href="https://pubs.rsna.org/doi/10.1148/rycan.230107" target="_blank">10.1148/rycan.230107</a>]
				<br><br>

				
				Mellema C, Nguyen KP, Andrade AX, Pouratian N, Sharma V, O'Suilleabhain P, Montillo A**, 
				<span class="pubtitle">Longitudinal Prognosis of Parkinson’s Outcomes using Causal Connectivity</span>, 
				Neuroimage: Clinical, 2024.
				</br>
				<div class="dropdown">
					<button onclick="dropDown61()" class="dropbtn">Abstract</button>
					<div id="myDropdown61" class="dropdown-content">
					Despite the prevalence of Parkinson’s disease (PD), there are no clinically-accepted neuroimaging biomarkers to predict the trajectory of motor or cognitive decline or differentiate Parkinson’s disease from atypical progressive parkinsonian diseases. Since abnormal connectivity in the motor circuit and basal ganglia have been previously shown as early markers of neurodegeneration, we hypothesize that patterns of interregional connectivity could be useful to form patient-specific predictive models of disease state and of PD progression. We use fMRI data from subjects with Multiple System Atrophy (MSA), Progressive Supranuclear Palsy (PSP), idiopathic PD, and healthy controls to construct predictive models for motor and cognitive decline and differentiate between the four subgroups. Further, we identify the specific connections most informative for progression and diagnosis. When predicting the one-year progression in the MDS-UPDRS-III1* and Montreal Cognitive assessment (MoCA), we achieve new state-of-the-art mean absolute error performance. Additionally, the balanced accuracy we achieve in the diagnosis of PD, MSA, PSP, versus healthy controls surpasses that attained in most clinics, underscoring the relevance of the brain connectivity features. Our models reveal the connectivity between deep nuclei, motor regions, and the thalamus as the most important for prediction. Collectively these results demonstrate the potential of fMRI connectivity as a prognostic biomarker for PD and increase our understanding of this disease.
					</div>
				</div>
				<script>function dropDown61() {
					document.getElementById("myDropdown61").classList.toggle("show");
				}</script>
				[<a href="./publications/2024_Cooper.txt" target="_blank">bib</a>|
				<a href="./publications/2024_Cooper.pdf" target="_blank">pdf</a>|
				doi: <a href="https://doi.org/10.1016/j.nicl.2024.103571" target="_blank">10.1016/j.nicl.2024.103571</a>| 
				PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/38471435" target="_blank">38471435</a>| 
				PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10944096/" target="_blank">PMC10944096</a>]
				<br><br>

				
				Mellema C, Montillo A**, 
				<span class="pubtitle">Novel machine learning approaches for improving the reproducibility and reliability of functional and effective (causal) connectivity from functional MRI</span>, 
				Journal of Neural Engineering, Vol 20 (6), December 2023. 
				</br>
				<div class="dropdown">
					<button onclick="dropDown62()" class="dropbtn">Abstract</button>
					<div id="myDropdown62" class="dropdown-content">
					Objective.</br> 
					New measures of human brain connectivity are needed to address gaps in the existing measures and facilitate the study of brain function, cognitive capacity, and identify early markers of human disease. Traditional approaches to measure functional connectivity (FC) between pairs of brain regions in functional MRI, such as correlation and partial correlation, fail to capture nonlinear aspects in the regional associations. We propose a new machine learning based measure of FC (ML.FC) which efficiently captures linear and nonlinear aspects.</br> 
					Approach</br>
					To capture directed information flow between brain regions, effective connectivity (EC) metrics, including dynamic causal modeling and structural equation modeling have been used. However, these methods are impractical to compute across the many regions of the whole brain. Therefore, we propose two new EC measures. The first, a machine learning based measure of effective connectivity (ML.EC), measures nonlinear aspects across the entire brain. The second, Structurally Projected Granger Causality (SP.GC) adapts Granger Causal connectivity to efficiently characterize and regularize the whole brain EC connectome to respect underlying biological structural connectivity. The proposed measures are compared to traditional measures in terms of reproducibility and the ability to predict individual traits in order to demonstrate these measures' internal validity. We use four repeat scans of the same individuals from the Human Connectome Project and measure the ability of the measures to predict individual subject physiologic and cognitive traits. </br>
					Main results</br>
					The proposed new FC measure of ML.FC attains high reproducibility (mean intra-subject R2 of 0.44), while the proposed EC measure of SP.GC attains the highest predictive power (mean R2 across prediction tasks of 0.66).</br>
					Significance</br>
					The proposed methods are highly suitable for achieving high reproducibility and predictiveness and demonstrate their strong potential for future neuroimaging studies.
					</div>
				</div>
				<script>function dropDown62() {
					document.getElementById("myDropdown62").classList.toggle("show");
				}</script>
				[<a href="./publications/2023_Cooper.txt" target="_blank">bib</a>|
				<a href="./publications/2023_Cooper.pdf" target="_blank">pdf</a>|
				doi: <a href="https://doi.org/10.1088/1741-2552/ad0c5f" target="_blank">10.1088/1741-2552/ad0c5f</a>| 
				PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/37963396" target="_blank">37963396</a>]
				<br><br>


                Treacher AH, Chitta K, McDonald J, German D, Montillo A.
                <span class="pubtitle"> A metabolomics blood test for Parkinson’s disease.</span>  AD/PD 2023 Conference. April, 2023.
                </br>
                </br>
                Nguyen K, Treacher, AH, Montillo, A. 
                <span class="pubtitle"> Adversarially-regularized mixed effects deep learning (ARMED) models for improved interpretability, performance, and generalization on clustered (non-iid) data.</span> IEEE Transactions on Pattern Analysis and Machine Intelligence. vol. 45, no. 7, pp. 8081-8093, 1 July 2023.
                </br>
                <div class="dropdown">
                  <button onclick="dropDown58()" class="dropbtn" id="2">Abstract</button>
                  <div id="myDropdown58" class="dropdown-content">
                    Natural science datasets frequently violate assumptions of independence. Samples may be clustered (e.g., by study site, subject, or experimental batch), leading to spurious associations, poor model fitting, and confounded analyses. While largely unaddressed in deep learning, this problem has been handled in the statistics community through mixed effects models, which separate cluster-invariant fixed effects from cluster-specific random effects. We propose a general-purpose framework for Adversarially-Regularized Mixed Effects Deep learning (ARMED) models through non-intrusive additions to existing neural networks: 1) an adversarial classifier constraining the original model to learn only cluster-invariant features, 2) a random effects subnetwork capturing cluster-specific features, and 3) an approach to apply random effects to clusters unseen during training. We apply ARMED to dense, convolutional, and autoencoder neural networks on 4 datasets including simulated nonlinear data, dementia prognosis and diagnosis, and live-cell image analysis. Compared to prior techniques, ARMED models better distinguish confounded from true associations in simulations and learn more biologically plausible features in clinical applications. They can also quantify inter-cluster variance and visualize cluster effects in data. Finally, ARMED matches or improves performance on data from clusters seen during training (5-28% relative improvement) and generalization to unseen clusters (2-9% relative improvement) versus conventional models. 
                  </div>
                </div>
                <script>function dropDown58() {
                  document.getElementById("myDropdown58").classList.toggle("show");
                }</script>
                [<a href="./publications/ARMED.txt" target="_blank">bib</a>
                |
                doi: <a href="https://doi.org/10.1109/TPAMI.2023.3234291" target="_blank">10.1109/TPAMI.2023.3234291</a>
                | PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/37018678" target="_blank">37018678</a>
                | code: <a href="https://deeplearningforprecisionhealthlab.github.io/ARMED_MixedEffectsDL/" target="_blank">ARMED documentation</a>
               ]
                </br>
                </br>
				
                  Nguyen, K, Raval, A, Minhajuddin, A, Carmody, T, Trivedi, MH, Dewey, RB, Montillo, A
                  <span class="pubtitle"> BLENDS: Augmentation of Functional Magnetic Resonance Images for Machine Learning Using Anatomically Constrained Warping.</span> Brain connectivity. 2022. pp 1-26.
                  </br>
                  <div class="dropdown">
                    <button onclick="dropDown58()" class="dropbtn" id="2">Abstract</button>
                    <div id="myDropdown58" class="dropdown-content">
                      Introduction:</br> 
                      Data augmentation improves the accuracy of deep learning models when training data are scarce by synthesizing additional samples. This work addresses the lack of validated augmentation methods specific for synthesizing anatomically realistic four-dimensional (4D) (three-dimensional [3D] + time) images for neuroimaging, such as functional magnetic resonance imaging (fMRI), by proposing a new augmentation method.

                      </br> 
                      Methods:</br> 
                      The proposed method, Brain Library Enrichment through Nonlinear Deformation Synthesis (BLENDS), generates new nonlinear warp fields by combining intersubject coregistration maps, computed using symmetric normalization, through spatial blending. These new warp fields can be applied to existing 4D fMRI to create new augmented images. BLENDS was tested on two neuroimaging problems using de-identified data sets: (1) the prediction of antidepressant response from task-based fMRI (original data set n = 163), and (2) the prediction of Parkinson's disease (PD) symptom trajectory from baseline resting-state fMRI regional homogeneity (original data set n = 43).

                      </br> 
                      Results:</br> 
                      BLENDS readily generates hundreds of new fMRI from existing images, with unique anatomical variations from the source images, that significantly improve prediction performance. For antidepressant response prediction, augmenting each original image once (2Xthe original training data) significantly increased predictionXR2 from 0.055 to 0.098 (p <1e-6), whereas at 10X augmentation R2 increased to 0.103. For the prediction of PD trajectory, 10X augmentation R2 increased from -0.044 to 0.472 (p <1e-6).
                      </br> 
                      Conclusion:</br>
                      Augmentation of fMRI through nonlinear transformations with BLENDS significantly improved the performance of deep learning models on clinically relevant predictive tasks. This method will help neuroimaging researchers overcome data set size limitations and achieve more accurate predictive models.
                      


                    </div>
                  </div>
                <script>function dropDown58() {
                  document.getElementById("myDropdown58").classList.toggle("show");
                }</script>
                [<a href="./publications/blends.txt" target="_blank">bib</a>
                |doi: <a href="https://doi.org/10.1089/brain.2021.0186" target="_blank">10.1089/brain.2021.0186</a>
                | PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/36097756" target="_blank">36097756</a>
               ]
                </br>
                </br>


        Kooner KS, Angirekula A, Treacher AH, Al-Humimat G, Marzban, MF, Chen A, Pradhan R, Tunga N, Wang C, Ahuja P, Zuberi H, Montillo AA. 
        <span class="pubtitle"> Glaucoma Diagnosis Through the Integration of Optical Coherence Tomography/Angiography and Machine Learning Diagnostic Models.</span> Clinical ophthalmology (Auckland, N.Z.). 2022 August 18. 16, 2685-2697.
        </br>
        <div class="dropdown">
					<button onclick="dropDown58()" class="dropbtn" id="2">Abstract</button>
					<div id="myDropdown58" class="dropdown-content">
						Purpose:</br> 
            To establish optical coherence tomography (OCT)/angiography (OCTA) parameter ranges for healthy eyes (HE) and glaucomatous eyes (GE) for a North Texas based population; to develop a machine learning (ML) tool and to identify the most accurate diagnostic parameters for clinical glaucoma diagnosis. 
            </br> 
            Patients and methods:</br> 
            In this retrospective cross-sectional study, we included 1371 eligible eyes, 462 HE and 909 GE (377 ocular hypertension, 160 mild, 156 moderate, 216 severe), from 735 subjects. Demographic data and full OCTA parameters were collected. A Kruskal-Wallis test was used to produce the normative database. Models were trained to solve a two-class problem (HE vs GE) and four-class problem (HE vs mild vs moderate vs severe GE). A rigorous nested, stratified, group, 5×10 fold cross-validation strategy was applied to partition the data. Six ML algorithms were compared using classical and deep learning approaches. Over 2500 ML models were optimized using random search, with performance compared using mean validation accuracy. Final performance was reported on held-out test data using accuracy and F1 score. Decision trees and feature importance were produced for the final model.</br> 
            Results:</br> 
            We found differences across glaucoma severities for age, gender, hypertension, Black and Asian race, and all OCTA parameters, except foveal avascular zone area and perimeter (p<0.05). The XGBoost algorithm achieved the highest test performance for both the two-class (F1 score 83.8%; accuracy 83.9%; standard deviation 0.03%) and four-class (F1 score 62.4%; accuracy 71.3%; standard deviation 0.013%) problem. A set of interpretable decision trees provided the most important predictors of the final model; inferior temporal and inferior hemisphere vessel density and peripapillary retinal nerve fiber layer thickness were identified as key diagnostic parameters.</br> 
            Conclusion:</br> 
            This study established a normative database for our North Texas based population and created ML tools utilizing OCT/A that may aid clinicians in glaucoma management. 
					</div>
				</div>
				<script>function dropDown58() {
					document.getElementById("myDropdown58").classList.toggle("show");
				}</script>
        [<a href="./publications/Kooner.txt" target="_blank">bib</a>
        |doi: <a href="https://doi.org/10.2147/OPTH.S367722" target="_blank">10.2147/OPTH.S367722</a>
        | PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/36003072" target="_blank">36003072</a>
        | PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9394657/" target="_blank">PMC9394657</a>
        ]
        </br>
        </br>
        
        Berto S*, Treacher AH*, Caglayan E*, Luo D, Haney JR, Gandal MJ, Geschwind DH, Montillo AA**, Konopka G**. 
        <span class="pubtitle"> Association between resting-state functional brain connectivity and gene expression is altered in autism spectrum disorder.</span> Nature Communications. 2022 June 9; Vol 13(1):3328.
        </br>
        <div class="dropdown">
					<button onclick="dropDown58()" class="dropbtn" id="2">Abstract</button>
					<div id="myDropdown58" class="dropdown-content">
						Gene expression covaries with brain activity as measured by resting state functional magnetic resonance imaging (MRI). However, it is unclear how genomic differences driven by disease state can affect this relationship. Here, we integrate from the ABIDE I and II imaging cohorts with datasets of gene expression in brains of neurotypical individuals and individuals with autism spectrum disorder (ASD) with regionally matched brain activity measurements from fMRI datasets. We identify genes linked with brain activity whose association is disrupted in ASD. We identified a subset of genes that showed a differential developmental trajectory in individuals with ASD compared with controls. These genes are enriched in voltage-gated ion channels and inhibitory neurons, pointing to excitation-inhibition imbalance in ASD. We further assessed differences at the regional level showing that the primary visual cortex is the most affected region in ASD. Our results link disrupted brain expression patterns of individuals with ASD to brain activity and show developmental, cell type, and regional enrichment of activity linked genes.
					</div>
				</div>
				<script>function dropDown58() {
					document.getElementById("myDropdown58").classList.toggle("show");
				}</script>
        [
        <a href="./publications/BertoS_2022_GeneExpressionToImagingAssociationAltersInASD.bib" target="_blank">bib</a>
        | doi: <a href="https://doi.org/10.1038/s41467-022-31053-5" target="_blank">10.1038/s41467-022-31053-5</a>
        | PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/34274419" target="_blank">35680911</a>
        | PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9184501/" target="_blank">9184501</a>
        ]
        </br>
        </br>

				Kalecky, K, German, D, Montillo, A, Bottiglieri, R**. 
				<span class="pubtitle">Targeted Metabolomic Analysis in Alzheimer’s Disease Plasma and Brain Tissue in Non Hispanic Whites.</span> Journal of Alzheimer's Disease. 2022 Feb 28. 
				</br>
				<div class="dropdown">
					<button onclick="dropDown59()" class="dropbtn" id="1">Abstract</button>
					<div id="myDropdown59" class="dropdown-content">
						Background:</br>
						Metabolites are biological compounds reflecting the functional activity of organs and tissues. Understanding metabolic changes in Alzheimer’s disease (AD) can provide insight into potential risk factors in this multifactorial disease and suggest new intervention strategies or improve non-invasive diagnosis.</br>
						Objective:</br>
						In this study, we searched for changes in AD metabolism in plasma and frontal brain cortex tissue samples and evaluated the performance of plasma measurements as biomarkers.</br>
						Methods:</br>
						This is a case-control study with two tissue cohorts: 158 plasma samples (94 AD, 64 controls; Texas Alzheimer’s Research and Care Consortium – TARCC) and 71 post-mortem cortex samples (35 AD, 36 controls; Banner Sun Health Research Institute brain bank). We performed targeted mass spectrometry analysis of 630 compounds (106 small molecules: UHPLC-MS/MS, 524 lipids: FIA-MS/MS) and 232 calculated metabolic indicators with a metabolomic kit (Biocrates MxP® Quant 500).</br>
						Results:</br>
						We discovered disturbances (FDR ≤ 0.05) in multiple metabolic pathways in AD in both cohorts including microbiome-related metabolites with pro-toxic changes, methylhistidine metabolism, polyamines, corticosteroids, omega-3 fatty acids, acylcarnitines, ceramides, and diglycerides. In AD, plasma reveals elevated triglycerides, and cortex shows altered amino acid metabolism. A cross-validated diagnostic prediction model from plasma achieves AUC=82% (CI95=75-88%); for females specifically, AUC=88% (CI95=80-95%). A reduced model using 20 features achieves AUC=79% (CI95=71-85%); for females AUC=84% (CI95=74-92%).</br>
						Conclusion:</br>
						Our findings support the involvement of gut environment in AD, and encourage targeting multiple metabolic areas in the design of intervention strategies, including microbiome composition, hormonal balance, nutrients, and muscle homeostasis.
					</div>
				</div>
				<script>function dropDown59() {
					document.getElementById("myDropdown59").classList.toggle("show");
				}</script>
				[
				<a href="https://pubmed.ncbi.nlm.nih.gov/35253754/" target="_blank">Epub</a>
				| PMID<a href="https://pubmed.ncbi.nlm.nih.gov/35253754/" target="_blank"> 35253754</a>
				| doi: <a href="https://pubmed.ncbi.nlm.nih.gov/35253754/" target="_blank">10.3233/JAD-215448</a>   
				]
				</br>
				</br>
				
				Raval, V, Nguyen, KP, Pinho, M, Dewey, RB, Trivedi, M, Montillo, AA**. 
				<span class="pubtitle">Pitfalls and Recommended Strategies and Metrics for Suppressing Motion Artifacts in Functional MRI.</span>
				Neuroinformatics. 2022. 
				</br>
				<div class="dropdown">
					<button onclick="dropDown58()" class="dropbtn" id="2">Abstract</button>
					<div id="myDropdown58" class="dropdown-content">
						In resting-state functional magnetic resonance imaging (rs-fMRI), artefactual signals arising from subject motion can dwarf and obfuscate the neuronal activity signal. Typical motion correction approaches involve the generation of nuisance regressors, which are timeseries of non-brain signals regressed out of the fMRI timeseries to yield putatively artifact-free data. Recent work suggests that concatenating all regressors into a single regression model is more effective than the sequential application of individual regressors, which may reintroduce previously removed artifacts. This work compares 18 motion correction pipelines consisting of head motion, independent components analysis, and non-neuronal physiological signal regressors in sequential or concatenated combinations. The pipelines are evaluated on a dataset of cognitively normal individuals with repeat imaging and on datasets of studies of Autism Spectrum Disorder, Major Depressive Disorder, and Parkinson’s Disease. Extensive metrics of motion artifact removal are measured, including resting state network recovery, Quality Control-Functional Connectivity (QC-FC) correlation, distance-dependent artifact, network modularity, and test-retest reliability of multiple rs-fMRI analyses. The results reveal limitations in previously proposed metrics, including the QC-FC correlation and modularity quality, and identify more robust motion correction metrics. The results also reveal limitations in the concatenated regression approach, which is outperformed by the sequential regression approach in the test-retest reliability metrics. Finally, pipelines are recommended that perform well based on quantitative and qualitative comparisons across multiple datasets and robust metrics. These new insights and recommendations help address the need for effective motion artifact correction to reduce noise and confounds in rs-fMRI.
					</div>
				</div>
				<script>function dropDown58() {
					document.getElementById("myDropdown58").classList.toggle("show");
				}</script>
				[
				<a href="./publications/Raval2022_Article_PitfallsAndRecommendedStrategi.pdf" target="_blank">pdf</a>
				| <a href="./publications/Raval2022_MotionSupression.txt" target="_blank">bib</a>
				| PMID<a href="https://pubmed.ncbi.nlm.nih.gov/35291020/" target="_blank"> 35291020</a>
				| doi: <a href="https://doi.org/10.1007/s12021-022-09565-8" target="_blank">10.1007/s12021-022-09565-8</a>   
				]
				</br>
				</br>
				
				Mellema, CJ, Nguyen, KP, Treacher, A, Montillo, A**. 
				<span class="pubtitle">Reproducible neuroimaging features for diagnosis of autism spectrum disorder with machine learning. </span>
				Scientific Reports. 2022.
				</br>
				<div class="dropdown">
					<button onclick="dropDown57()" class="dropbtn">Abstract</button>
					<div id="myDropdown57" class="dropdown-content">
						Autism spectrum disorder (ASD) is the fourth most common neurodevelopmental disorder, with a prevalence of 1 in 160 children. Accurate diagnosis relies on experts, but such individuals are scarce. This has led to increasing interest in the development of machine learning (ML) models that can integrate neuroimaging features from functional and structural MRI (fMRI and sMRI) to help reveal central nervous system alterations characteristic of ASD. We optimized and compared the performance of 12 of the most popular and powerful ML models. Each was separately trained using 15 different combinations of fMRI and sMRI features and optimized with an unbiased model search. Deep learning models predicted ASD with the highest diagnostic accuracy and generalized well to other MRI datasets. Our model achieves state-of-the-art 80% area under the ROC curve (AUROC) in diagnosis on test data from the IMPAC dataset; and 86% and 79% AUROC on the external ABIDE I and ABIDE II datasets (with further improvement to 93% and 90% after supervised domain adaptation). The highest performing models identified reproducible putative biomarkers for accurate ASD diagnosis in accord with known ASD markers as well as novel cerebellar biomarkers. Such reproducibility lends credence to their tremendous potential for defining and using a set of truly generalizable ASD biomarkers that will advance scientific understanding of neuronal changes in ASD.
					</div>
				</div>
				<script>function dropDown57() {
					document.getElementById("myDropdown57").classList.toggle("show");
				}</script>
				[
				<a href="./publications/Mellema2022_ASD_Features.pdf" target="_blank">pdf</a>
				| <a href="./publications/Mellema2022_ASD.txt" target="_blank">bib</a>
				| doi: <a href="https://doi.org/10.1038/s41598-022-06459-2" target="_blank">10.1038/s41598-022-06459-2</a>
				| PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/35197468/" target="_blank">35197468</a>
				| PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8866395/" target="_blank">PMC8866395</a>
				| <a href="./publications/{Mellema_ISBI2019.ppx}" target="_blank">ISBI 2019 slides</a>        
				| <a href="./videos?title=Mellema%20ISBI2020.&link=https://www.youtube.com/embed/G063eogsZd8">ISBI 2020 presentation</a>
				| <a href="https://github.com/DeepLearningForPrecisionHealthLab/ConsistentASDCorrelates" target="_blank">code</a>   
				]
				</br>
				</br>
				
                Treacher A, Garg P, Davenport E, Godwin R, Proskovec A, Bezerra LG, Murugesan G, Wagner B, Whitlow CT, Stitzel JD , Maldjian JA, Montillo A**. 
                <span class="pubtitle">MEGnet: Automatic ICA-based artifact removal for MEG using spatiotemporal convolutional neural networks. </span> 
				NeuroImage, 2021; Vol 241, pp. 118402.
                </br>
				<div class="dropdown">
					<button onclick="dropDown56()" class="dropbtn">Abstract</button>
					<div id="myDropdown56" class="dropdown-content">
						Magnetoencephalography (MEG) is a functional neuroimaging tool that records the magnetic fields induced byneuronal activity; however, signal from non-neuronal sources can corrupt the data. Eye-blinks, saccades, and cardiac activity are three of the most common sources of non-neuronal artifacts. They can be measured by affixing eye proximal electrodes, as in electrooculography (EOG), and chest electrodes, as in electrocardiography (ECG), however this complicates imaging setup, decreases patient comfort, and can induce further artifacts from movement. This work proposes an EOG- and ECG-free approach to identify eye-blinks, saccades, and cardiac activity signals for automated artifact suppression.
						The contribution of this work is three-fold. First, using a data driven, multivariate decomposition approach based on Independent Component Analysis (ICA), a highly accurate artifact classifier is constructed as an amalgam of deep 1-D and 2-D Convolutional Neural Networks (CNNs) to automate the identification and removal of ubiquitous whole brain artifacts including eye-blink, saccade, and cardiac artifacts. The specific architecture of this network is optimized through an unbiased, computer-based hyperparameter random search. Second, visualization methods are applied to the learned abstraction to reveal what features the model uses and to bolster user confidence in the model’s training and potential for generalization. Finally, the model is trained and tested on both resting-state and task MEG data from 217 subjects, and achieves a new state-of-the-art in artifact detection accuracy of 98.95% including 96.74% sensitivity and 99.34% specificity on the held out test-set. This work automates MEG processing for both clinical and research use, adapts to the acquired acquisition time, and can obviate the need for EOG or ECG electrodes for artifact detection.
					</div>
				</div>
				<script>function dropDown56() {
					document.getElementById("myDropdown56").classList.toggle("show");
				}</script>
                [
                <a href="./publications/Treacher_2021_MEGnet.txt" target="_blank">bib</a>
                | doi: <a href="https://doi.org/10.1016/j.neuroimage.2021.118402" target="_blank">10.1016/j.neuroimage.2021.118402</a>
                | PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/34274419" target="_blank">33730626</a>
				| <a href="./publications/Treacher_2021_MEGnet.pdf" target="_blank">pdf</a>  
				| <a href="https://github.com/DeepLearningForPrecisionHealthLab/MegNET_2020" target="_blank">code</a>
                ]
                </br>
                </br>
				
				
                Nguyen KP, Fatt CC, Treacher A, Mellema C, Cooper C, Jha MK, Kurian B, Fava M, McGrath PJ, Weissman M, Phillipes ML, Trivedi MH,  Montillo A**. 
                <span class="pubtitle">Patterns of Pre-Treatment Reward Task Brain Activation Predict Individual Antidepressant Response: Key Results from the EMBARC Randomized Clinical Trial.</span>
                Biological Psychiatry. 2022 Mar 15;91(6):550-560.
                </br>
				<div class="dropdown">
					<button onclick="dropDown55()" class="dropbtn">Abstract</button>
					<div id="myDropdown55" class="dropdown-content">
						Background</br>
						The lack of biomarkers to inform antidepressant selection is a key challenge in personalized depression treatment. This work identifies candidate biomarkers by building deep learning predictors of individual treatment outcomes using reward processing measures from functional MRI, clinical assessments, and demographics.</br>
						Methods</br>
						Participants in the Establishing Moderators and Biosignatures of Antidepressant Response in Clinical Care (EMBARC) study (n = 222) underwent reward processing task-based functional MRI at baseline and were randomized to 8 weeks of sertraline (n = 106) or placebo (n = 116). Subsequently, sertraline non-responders (n = 37) switched to 8 weeks of bupropion. The change in Hamilton Rating Scale for Depression (ΔHAMD) was measured after treatment. Reward processing, clinical measurements, and demographics were used to train treatment-specific deep learning models.</br>
						Results</br>
						The predictive model for sertraline achieved R2 of 48% (95% CI 33-61%, p &lt 10-3) in predicting ΔHAMD and number-needed-to-treat (NNT) of 4.86 participants in predicting response. The placebo model achieved R2 of 28% (95% CI 15-42%, p &lt 10-3) and NNT of 2.95 in predicting response. The bupropion model achieved R2 of 34% (95% CI 10-59%, p &lt 10-3) and NNT of 1.68 in predicting response. Brain regions where reward processing activity was predictive included the prefrontal cortex and cerebellar crus 1 for sertraline and the cingulate cortex, caudate, orbitofrontal cortex, and crus 1 for bupropion.</br>
						Conclusions</br>
						These findings demonstrate the utility of reward processing measurements and deep learning to predict antidepressant outcomes and to form multimodal treatment biomarkers.
					</div>
				</div>
				<script>function dropDown55() {
					document.getElementById("myDropdown55").classList.toggle("show");
				}</script>
                [
                <a href="./publications/Nguyen_2021_PatternsOfPreTreatmentRewardTaskBrain.txt" target="_blank">bib</a>
                | doi: <a href="https://doi.org/10.1016/j.biopsych.2021.09.011" target="_blank">10.1016/j.biopsych.2021.09.011</a>
				| PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/34916068/" target="_blank">34916068</a>
                | <a href="./publications/Nguyen_2021_PatternsOfPreTreatmentRewardTaskBrain.pdf" target="_blank">pdf_preprint</a>  
				| <a href="https://www.biologicalpsychiatryjournal.com/article/S0006-3223(21)01600-0/fulltext" target="_blank">link</a>  
				| <a href="./publications/Nguyen_2021_PatternsOfPreTreatmentRewardTaskBrain_suppletment.pdf" target="_blank">supplement</a>   
				| <a href="http://swlxwsvauthprd1edu.swmed.edu/newsroom/articles/year-2021/new-imaging-biomarkers.html" target="_blank">PressRelease</a>   
                ]
                </br>
                </br>
				
                Nguyen KP, Raval V, Treacher A, Mellema C, Yu FF, Pinho MC, Subramaniam RM, Dewey RB, Montillo A**. 
                <span class="pubtitle">Predicting Parkinson's disease trajectory using clinical and neuroimaging baseline measures.</span>
                Parkinsonism and Related Disorders. 2021 April; Vol 85, pp. 44-51.
                </br>
				<div class="dropdown">
					<button onclick="dropDown54()" class="dropbtn">Abstract</button>
					<div id="myDropdown54" class="dropdown-content">
						INTRODUCTION</br>
						Predictive biomarkers of Parkinson's Disease progression are needed to expedite neuroprotective treatment development and facilitate prognoses for patients. This work uses measures derived from resting-state functional magnetic resonance imaging, including regional homogeneity (ReHo) and fractional amplitude of low frequency fluctuations (fALFF), to predict an individual's current and future severity over up to 4 years and to elucidate the most prognostic brain regions.</br>
						METHODS</br>
						ReHo and fALFF are measured for 82 Parkinson's Disease subjects and used to train machine learning predictors of baseline clinical and future severity at 1 year, 2 years, and 4 years follow-up as measured by the Movement Disorder Society Unified Parkinson's Disease Rating Scale (MDS-UPDRS). Predictive performance is measured with nested cross-validation, validated on an external dataset, and again validated through leave-one-site-out cross-validation. Important predictive features are identified.</br>
						RESULTS</br>
						The models explain up to 30.4{\%} of the variance in current MDS-UPDRS scores, 55.8{\%} of the variance in year 1 scores, and 47.1{\%} of the variance in year 2 scores (p~{\textless}~0.0001). For distinguishing high and low-severity individuals at each timepoint (MDS-UPDRS score above or below the median, respectively), the models achieve positive predictive values up to 79{\%} and negative predictive values up to 80{\%}. Higher ReHo and fALFF in several regions, including components of the default motor network, predicted lower severity across current and future timepoints.</br>
						CONCLUSION</br>
						These results identify an accurate prognostic neuroimaging biomarker which may be used to better inform enrollment in trials of neuroprotective treatments and enable physicians to counsel their patients.
					</div>
				</div>
				<script>function dropDown54() {
					document.getElementById("myDropdown54").classList.toggle("show");
				}</script>
                [
                <a href="./publications/NguyenK_2021_PredictingParkinsonTrajectory.bib" target="_blank">bib</a>
                | doi: <a href="https://doi.org/10.1016/j.parkreldis.2021.02.026" target="_blank">10.1016/j.parkreldis.2021.02.026</a>
                | PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/33730626" target="_blank">33730626</a>
                ]
                </br>
                </br>

                Nguyen S, Polat D, Karbasi P, Moser D, Wang L, Hulsey K, Cobanoglu M, Dogan B, Montillo A**. 
                <span class="pubtitle">Preoperative Prediction of Lymph Node Metastasis from Clinical DCE MRI of the Primary Breast Tumor Using a 4D CNN.</span> 
                MICCAI: International Conference on Medical Image Computing and Computer-Assisted Intervention. 2020 September; Vol 2, pp. 326-334.
                </br>
				<div class="dropdown">
					<button onclick="dropDown53()" class="dropbtn">Abstract</button>
					<div id="myDropdown53" class="dropdown-content">
						In breast cancer, undetected lymph node metastases can spread to distal parts of the body for which the 5-year survival rate is only 27%, making accurate nodal metastases diagnosis fundamental to reducing the burden of breast cancer, when it is still early enough to intervene with surgery and adjuvant therapies. Currently, breast cancer management entails a time consuming and costly sequence of steps to clinically diagnose axillary nodal metastases status. The purpose of this study is to determine whether preoperative, clinical DCE MRI of the primary tumor alone may be used to predict clinical node status with a deep learning model. If possible then many costly steps could be eliminated or reserved for only those with uncertain or probable nodal metastases. This research develops a data-driven approach that predicts lymph node metastasis through the judicious integration of clinical and imaging features from preoperative 4D dynamic contrast enhanced (DCE) MRI of 357 patients from 2 hospitals. Innovative deep learning classifiers are trained from scratch, including 2D, 3D, 4D and 4D deep convolutional neural networks (CNNs) that integrate multiple data types and predict the nodal metastasis differentiating nodal stage N0 (non metastatic) against stages N1, N2 and N3. Appropriate methodologies for data preprocessing and network interpretation are presented, the later of which bolster radiologist confidence that the model has learned relevant features from the primary tumor. Rigorous nested 10-fold cross-validation provides an unbiased estimate of model performance. The best model achieves a high sensitivity of 72% and an AUROC of 71% on held out test data. Results are strongly supportive of the potential of the combination of DCE MRI and machine learning to inform diagnostics that could substantially reduce breast cancer burden.
					</div>
				</div>
				<script>function dropDown53() {
					document.getElementById("myDropdown53").classList.toggle("show");
				}</script>
                [
                <a href="./publications/Nguyen_2020_MICCAI_PredictingLympNodeMetastasis.pdf" target="_blank">pdf</a>
                | <a href="./publications/Nguyen_2020_MICCAI_PredictingLympNodeMetastasis.bib" target="_blank">bib</a>
                | doi: <a href="https://doi.org/10.1007/978-3-030-59713-9_32" target="_blank">10.1007/978-3-030-59713-9_32</a>
                | PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/33768221" target="_blank">33768221</a>
                | <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7990260" target="_blank">PMC7990260</a>
                | <a href="./publications/Nguyen_2020_MICCAI_PredictingLympNodeMetastasis_Presentation.pdf" target="_blank">slides</a>  
				| <a href="https://gitfront.io/r/DeepLearningForPrecisionHealthLab/fe605c8dc00730a376a2279d152691ac6245fd11/BreastCancerMetastasis-prediction/" target="_blank">code</a>  				
                | <a href=./videos?title=Preoperative%20Prediction%20of%20Lymph%20Node%20Metastasis%20from%20Clinical%20DCE%20MRI%20of%20the%20Primary%20Breast%20Tumor%20Using%20a%204D%20CNN&link=https://www.youtube.com/embed/GKf32DS8A6k>talk</a>
                ]
                </br>
                </br>

                Mellema CJ, Treacher A, Nguyen KP, Montillo A**. 
                <span class="pubtitle">Architectural configurations, atlas granularity and functional connectivity with diagnostic value in Autism Spectrum Disorder.</span> 
                International Symposium on Biomedical Imaging (ISBI). 2020 April; pp. 1022-1025.
                </br>
				<div class="dropdown">
					<button onclick="dropDown52()" class="dropbtn">Abstract</button>
					<div id="myDropdown52" class="dropdown-content">
						Currently, the diagnosis of Autism Spectrum Disorder (ASD) is dependent upon a subjective, time-consuming evaluation of behavioral tests by an expert clinician. Non-invasive functional MRI (fMRI) characterizes brain connectivity and may be used to inform diagnoses and democratize medicine. However, successful construction of predictive models, such as deep learning models, from fMRI requires addressing key choices about the model’s architecture, including the number of layers and number of neurons per layer. Meanwhile, deriving functional connectivity (FC) features from fMRI requires choosing an atlas with an appropriate level of granularity. Once an accurate diagnostic model has been built, it is vital to determine which features are predictive of ASD and if similar features are learned across atlas granularity levels. Identifying new important features extends our understanding of the biological underpinnings of ASD, while identifying features that corroborate past findings and extend across atlas levels instills model confidence. To identify aptly suited architectural configurations, probability distributions of the configurations of high versus low performing models are compared. To determine the effect of atlas granularity, connectivity features are derived from atlases with 3 levels of granularity and important features are ranked with permutation feature importance. Results show the highest performing models use between 2-4 hidden layers and 16-64 neurons per layer, granularity dependent. Connectivity features identified as important across all 3 atlas granularity levels include FC to the supplementary motor gyrus and language association cortex, regions whose abnormal development are associated with deficits in social and sensory processing common in ASD. Importantly, the cerebellum, often not included in functional analyses, is also identified as a region whose abnormal connectivity is highly predictive of ASD. Results of this study identify important regions to include in future studies of ASD, help assist in the selection of network architectures, and help identify appropriate levels of granularity to facilitate the development of accurate diagnostic models of ASD.
					</div>
				</div>
				<script>function dropDown52() {
					document.getElementById("myDropdown52").classList.toggle("show");
				}</script>
                [
                <a href="./publications/Mellema_ISBI2020_Granularity_Comparison.pdf" target="_blank">pdf</a>
                | <a href="./publications/Mellema_ISBI2020_Granularity_Comparison.bib" target="_blank">bib</a>
                | doi: <a href="https://doi.org/10.1109/ISBI45749.2020.9098555" target="_blank">10.1109/ISBI45749.2020.9098555</a>   
                | <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7990265" target="_blank">PMC7990265</a>
                | <a href="./publications/Mellema_ISBI2020_Granularity_Comparison.pptx" target="_blank">slides</a>     
                | <a href=./videos?title=Architectural%20configurations,%20atlas%20granularity%20and%20functional%20connectivity%20with%20diagnostic%20value%20in%20Autism%20Spectrum%20Disorder&link=https://www.youtube.com/embed/G063eogsZd8>talk</a>
                ]
                </br>
                </br>
                
                Raval V, Nguyen KP, Gerald A, Dewey RB, Montillo A**. 
                <span class="pubtitle">Improved Motion Correction for Functional MRI using an Omnibus Regression Model.</span> 
                International Symposium on Biomedical Imaging (ISBI). 2020 April; 1044-1047.
                </br>
				<div class="dropdown">
					<button onclick="dropDown51()" class="dropbtn">Abstract</button>
					<div id="myDropdown51" class="dropdown-content">
						Head motion during functional Magnetic Resonance Imaging acquisition can significantly contaminate the neural signal and introduce spurious, distance-dependent changes in signal correlations. This can heavily confound studies of development, aging, and disease. Previous approaches to suppress head motion artifacts have involved sequential regression of nuisance covariates, but this has been shown to reintroduce artifacts. We propose a new motion correction pipeline using an omnibus regression model that avoids this problem by simultaneously regressing out multiple artifacts using the best performing algorithms to estimate each artifact. We quantitatively evaluate its motion artifact suppression performance against sequential regression pipelines using a large heterogeneous dataset (n=151) which includes high-motion subjects and multiple disease phenotypes. The proposed concatenated regression pipeline significantly reduces the association between head motion and functional connectivity while significantly outperforming the traditional sequential regression pipelines in eliminating distance-dependent head motion artifacts.
					</div>
				</div>
				<script>function dropDown51() {
					document.getElementById("myDropdown51").classList.toggle("show");
				}</script>
                [
                <a href="./publications/Raval_2020_ISBI_ImprovedMotionCorrectionForFunctional.pdf" target="_blank"> pdf</a>
                | <a href="./publications/Raval_2020_ISBI_ImprovedMotionCorrectionForFunctional.bib" target="_blank">bib</a>
                | doi: <a href="https://doi.org/10.1109/ISBI45749.2020.9098688" target="_blank">10.1109/ISBI45749.2020.9098688</a>  
                | <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7990252" target="_blank">PMC7990252</a>  
                | <a href="./publications/Raval_ISBI_033020_v2_presentation.pdf" target="_blank">slides</a> 
                | <a href=./videos?title=Improved%20Motion%20Correction%20for%20Functional%20MRI%20using%20an%20Omnibus%20Regression%20Model.&link=https://www.youtube.com/embed/1A8VwO48wLE>talk</a>
                ]
                </br>
                </br>
                    
                Raval V, Nguyen KP, Gerald A, Dewey RB, Montillo A**. 
                <span class="pubtitle">Prediction of Individual Progression Rate in Parkinson's Disease Using Clinical Measures and Biomechanical Measures of Gait and Postural Instability.</span> 
                IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP). 2020 May; 1319-1323.
                </br>
				<div class="dropdown">
					<button onclick="dropDown50()" class="dropbtn">Abstract</button>
					<div id="myDropdown50" class="dropdown-content">
						Parkinson’s disease (PD) is a common neurological disorder characterized by gait impairment. PD has no cure, and an impediment to developing a treatment is the lack of any accepted method to predict disease progression rate. The primary aim of this study was to develop a model using clinical measures and biomechanical measures of gait and postural stability to predict an individual’s PD progression over two years. Data from 160 PD subjects were utilized. Machine learning models, including XGBoost and Feed Forward Neural Networks, were developed using extensive model optimization and cross-validation. The highest performing model was a neural network that used a group of clinical measures, achieved a PPV of 71% in identifying fast progressors, and explained a large portion (37%) of the variance in an individual’s progression rate on held-out test data. This demonstrates the potential to predict individual PD progression rate and enrich trials by analyzing clinical and biomechanical measures with machine learning.
					</div>
				</div>
				<script>function dropDown50() {
					document.getElementById("myDropdown50").classList.toggle("show");
				}</script>
                [
                <a href="./publications/Raval_2020_ICASSP_PredictionOfIndividualProgressionRate.pdf" target="_blank"> pdf</a>
                | <a href="./publications/Raval_2020_ICASSP_PredictionOfIndividualProgressionRate.bib" target="_blank">bib</a>
                | doi: <a href="https://doi.org/10.1109/ICASSP40776.2020.9054666" target="_blank">10.1109/ICASSP40776.2020.9054666</a>      
                | <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7944712" target="_blank">PMC7944712</a>   
                | <a href="./publications/Raval_ICASSP_041620_v5_presentation.pdf" target="_blank">slides</a>
                | <a href=./videos?title=Prediction%20of%20Individual%20Progression%20Rate%20in%20Parkinsons%20Disease%20Using%20Clinical%20Measures%20and%20Biomechanical%20Measures%20of%20Gait%20and%20Postural%20Instability&link=https://www.youtube.com/embed/sOEDl0aqg4w>talk</a>
                ]
                </br>
                </br>
                
                Nguyen KP, Chin Fatt C, Treacher A, Mellema C, Trivedi MH, Montillo A**. 
                <span class="pubtitle">Anatomically-Informed Data Augmentation for Functional MRI with Applications to Deep Learning.</span> 
                SPIE Medical Imaging. 2020 February; 113130T. 
                </br>
				<div class="dropdown">
					<button onclick="dropDown49()" class="dropbtn">Abstract</button>
					<div id="myDropdown49" class="dropdown-content">
						The application of deep learning to build accurate predictive models from functional neuroimaging data is often hindered by limited dataset sizes. Though data augmentation can help mitigate such training obstacles, most data augmentation methods have been developed for natural images as in computer vision tasks such as CIFAR, not for medical images. This work helps to fills in this gap by proposing a method for generating new functional Magnetic Resonance Images (fMRI) with realistic brain morphology. This method is tested on a challenging task of predicting antidepressant treatment response from pre-treatment task-based fMRI and demonstrates a 26% improvement in performance in predicting response using augmented images. This improvement compares favorably to state-of-the-art augmentation methods for natural images. Through an ablative test, augmentation is also shown to substantively improve performance when applied before hyperparameter optimization. These results suggest the optimal order of operations and support the role of data augmentation method for improving predictive performance in tasks using fMRI.
					</div>
				</div>
				<script>function dropDown49() {
					document.getElementById("myDropdown49").classList.toggle("show");
				}</script>
                [
                <a href="./publications/Nguyen_SPIE2020_Augmentation.pdf" target="_blank"> pdf</a>
                | <a href="./publications/Nguyen_SPIE2020_Augmentation.bib" target="_blank">bib</a>
                | doi: <a href="https://doi.org/10.1117/12.2548630" target="_blank">10.1117/12.2548630</a> 
                | <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7990266" target="_blank">PMC7990266</a>  
                | <a href="./publications/Nguyen_SPIE_2020_v3_presentation.pdf" target="_blank">slides</a>     
                | <a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11313/113130T/Anatomically-informed-data-augmentation-for-functional-MRI-with-applications-to/10.1117/12.2548630.full#divVideo6142081160001">talk</a>
                ]
                </br>
                </br>
                
                Nguyen KP, Chin Fatt C, Treacher A, Mellema C, Trivedi MH, Montillo A**.  
                <span class="pubtitle">Predicting Response to the Antidepressant Bupropion using Pretreatment fMRI.</span>
                Medical Image Computing and Computer-Assisted Intervention: PRIME. 2019 October;
                </br>
				<div class="dropdown">
					<button onclick="dropDown48()" class="dropbtn">Abstract</button>
					<div id="myDropdown48" class="dropdown-content">
						Major depressive disorder is a primary cause of disability in adults with a lifetime prevalence of 6-21% worldwide. While medical treatment may provide symptomatic relief, response to any given antidepressant is unpredictable and patient-specific. The standard of care requires a patient to sequentially test different antidepressants for 3 months each until an optimal treatment has been identified. For 30-40% of patients, no effective treatment is found after more than one year of this trial-and-error process, during which a patient may suffer loss of employment or marriage, undertreated symptoms, and suicidal ideation. This work develops a predictive model that may be used to expedite the treatment selection process by identifying for individual patients whether the patient will respond favorably to bupropion, a widely prescribed antidepressant, using only pretreatment imaging data. This is the first model to do so for individuals for bupropion. Specifically, a deep learning predictor is trained to estimate the 8-week change in Hamilton Rating Scale for Depression (HAMD) score from pretreatment task-based functional magnetic resonance imaging (fMRI) obtained in a randomized controlled antidepressant trial. An unbiased neural architecture search is conducted over 800 distinct model architecture and brain parcellation combinations, and patterns of model hyperparameters yielding the highest prediction accuracy are revealed. The winning model identifies bupropion-treated subjects who will experience remission with the number of subjects needed-to-treat (NNT) to lower morbidity of only 3.2 subjects. It attains a substantially high neuroimaging study effect size explaining 26% of the variance (R2 = 0.26) and the model predicts post-treatment change in the 52-point HAMD score with an RMSE of 4.71. These results support the continued development of fMRI and deep learning-based predictors of response for additional depression treatments.
					</div>
				</div>
				<script>function dropDown48() {
					document.getElementById("myDropdown48").classList.toggle("show");
				}</script>
                [
                <a href="./publications/Nguyen_2019_MICCAI_PredictingResponseToBupropion.pdf" target="_blank"> pdf</a>
                | <a href="./publications/Nguyen_2019_MICCAI_PredictingResponseToBupropion.bib" target="_blank">bib</a>				
                | doi: <a href="https://doi.org/10.1007/978-3-030-32281-6_6" target="_blank">10.1007/978-3-030-32281-6_6</a>
                | PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/31709423" target="_blank">31709423</a>
                | <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6839715" target="_blank">PMC6839715</a>
                | <a href=./videos?title=Predicting%20Response%20to%20the%20Antidepressant%20Bupropion%20using%20Pretreatment%20fMRI&link=https://www.youtube.com/embed/LkgQ2hjK_Vo>talk</a>
                ] 
                </br>
                </br>
                        
                Nguyen KP, Fatt CC, Mellema C, Trivedi MH, Montillo A**. 
                <span class="pubtitle">Sensitivity of Derived Clinical Biomarkers to rs-fMRI Preprocessing Software Versions.</span>
                IEEE International Symposium on Biomedical Imaging. 2019 April; 1:1581-1584.
                </br>
				<div class="dropdown">
					<button onclick="dropDown47()" class="dropbtn">Abstract</button>
					<div id="myDropdown47" class="dropdown-content">
						When common software packages (CONN and SPM) are used to process fMRI, results such as functional connectivity measures can substantially differ depending on the versions of the packages used and the tools used to convert image formats such as DICOM to NIFTI. The significance of these differences are illustrated within the context of a realistic research application: finding moderators of antidepressant response from a large psychiatric study of 288 major depressive disorder (MDD) patients. Significant differences in functional connectivity measurements and discrepancies in derived moderators were found between nearly all software configurations. These results should encourage researchers to be vigilant of software versions during fMRI preprocessing, to maintain consistency throughout each project, and to carefully report versions to facilitate reproducibility.
					</div>
				</div>
				<script>function dropDown47() {
					document.getElementById("myDropdown47").classList.toggle("show");
				}</script>
                [
                <a href="./publications/Nguyen_2019_ISBI_SensitivityOfDerivedClinicalBiomarkersTorsfMRIPreprocessingSWversions.pdf" target="_blank"> pdf</a>
                | <a href="./publications/Nguyen_2019_ISBI_SensitivityOfDerivedClinicalBiomarkersTorsfMRIPreprocessingSWversions.bib" target="_blank">bib</a>	
                | doi: <a href="https://doi.org/10.1109/ISBI.2019.8759526" target="_blank">10.1109/ISBI.2019.8759526</a>
                | PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/31741703" target="_blank">31741703</a>
                | <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6860361" target="_blank">PMC6860361</a>
                ]
                </br>
                </br>
                        
                Treacher A, Beauchamp D, Quadri B, Vij A, Fetzer D, Yokoo T, Montillo A**. 
                <span class="pubtitle">Deep learning convolutional neural networks for the estimation of liver fibrosis severity from ultrasound texture. Medical Imaging.</span>
                Computer-Aided Diagnosis (SPIE). 2019 February; 1:109503E1-8.
                </br>
				<div class="dropdown">
					<button onclick="dropDown46()" class="dropbtn">Abstract</button>
					<div id="myDropdown46" class="dropdown-content">
						Diagnosis and staging of liver fibrosis is a vital prognostic marker in chronic liver diseases. Due to the inaccuracies and risk of complications associated with liver core needle biopsy, the current standard for diagnosis, other less invasive methods are sought for diagnosis. One such method that has been shown to correlate well with liver fibrosis is shear wave velocity measured by ultrasound (US) shear wave elastography; however, this technique requires specific software, hardware, and training. A current perspective in the radiology community is that the texture pattern from an US image may be predictive of the stage of liver fibrosis. We propose the use of convolutional neural networks (CNNs), a framework shown to be well suited for real world image interpretation, to test whether the texture pattern in gray scale elastography images (B-mode US with fixed, subject-agnostic acquisition settings) is predictive of the shear wave velocity (SWV). In this study, gray scale elastography images from over 300 patients including 3,500 images with corresponding SWV measurements were preprocessed and used as input to 100 different CNN architectures that were trained to regress shear wave velocity. In this study, even the best performing CNN explained only negligible variation in the shear wave velocity measures. These extensive test results suggest that the gray scale elastography image texture provides little predictive information about shear wave velocity and liver fibrosis.
					</div>
				</div>
				<script>function dropDown46() {
					document.getElementById("myDropdown46").classList.toggle("show");
				}</script>
				[
                <a href="./publications/Treacher_SPIE2019_LiverFibrosis.pdf" target="_blank"> pdf</a>
                | <a href="./publications/Treacher_SPIE2019_LiverFibrosis.bib" target="_blank">bib</a>
                | doi: <a href="https://doi.org/10.1117/12.2512592" target="_blank">10.1117/12.2512592</a>
                | PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/31741550" target="_blank">31741550</a>
                | <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6859455" target="_blank">PMC6859455</a>
                ]
                </br>
                </br> 
                        
                Mellema C, Treacher A, Nguyen KP, Montillo A**. 
                <span class="pubtitle">Multiple Deep Learning Architectures Achieve Superior Performance Diagnosing Autism Spectrum Disorder Using Features Previously Extracted from Structural and Functional MRI.</span>
                IEEE International Symposium on Biomedical Imaging. 2019; 1:1891-1895. 
                </br>
				<div class="dropdown">
					<button onclick="dropDown45()" class="dropbtn">Abstract</button>
					<div id="myDropdown45" class="dropdown-content">
						The diagnosis of Autism Spectrum Disorder (ASD) is a subjective process requiring clinical expertise in neurodevelopmental disorders. Since such expertise is not available at many clinics, automated diagnosis using machine learning (ML) algorithms would be of great value to both clinicians and the imaging community to increase the diagnoses’ availability and reproducibility while reducing subjectivity. This research systematically compares the performance of classifiers using over 900 subjects from the IMPAC database, using the database’s derived anatomical and functional features to diagnose a subject as autistic or healthy. In total 12 classifiers are compared from 3 categories including: 6 nonlinear shallow ML models, 3 linear shallow models, and 3 deep learning models. When evaluated with an AUC ROC performance metric, results include: (1) amongst the shallow learning methods, linear models outperformed nonlinear models, agreeing with other results. (2) Deep learning models outperformed shallow ML models. (3) The best model was a dense feedforward network, achieving 0.80 AUC which compares to the recently reported 0.79±0.01 AUC average of the top 10 methods from the IMPAC challenge. These results demonstrate that even when using features derived from imaging data, deep learning methods can provide additional predictive accuracy over classical methods.
					</div>
				</div>
				<script>function dropDown45() {
					document.getElementById("myDropdown45").classList.toggle("show");
				}</script>
                [<a href="./publications/Mellema_ISBI_2019_MultipleDeepLearningArchitecturesAchieveSuperiorPerformanceDiagnosingAutismSpectrumDisorder.pdf" target="_blank"> pdf</a>				
                | <a href="./publications/Mellema_ISBI_2019_MultipleDeepLearningArchitecturesAchieveSuperiorPerformanceDiagnosingAutismSpectrumDisorder.bib" target="_blank">bib</a>
                | doi: <a href="https://doi.org/10.1109/ISBI.2019.8759193" target="_blank">10.1109/ISBI.2019.8759193</a>
                | PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/31741704" target="_blank">31741704</a>
                | <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6859452" target="_blank">PMC6859452</a>
                ]
                </br>
                </br>
                        
                Dash D, Ferrari P, Malik S, Montillo A, Maldjian J, Wang J**. 
                <span class="pubtitle">Determining the Optimal Number of MEG Trials: A Machine Learning and Speech Decoding Perspective.</span>
                Brain Informatics. 2018 December; 1:163-172. 
                </br>
				<div class="dropdown">
					<button onclick="dropDown44()" class="dropbtn">Abstract</button>
					<div id="myDropdown44" class="dropdown-content">
						Advancing the knowledge about neural speech mechanisms is critical for developing next-generation, faster brain computer interface to assist in speech communication for the patients with severe neurological conditions (e.g., locked-in syndrome). Among current neuroimaging techniques, Magnetoencephalography (MEG) provides direct representation for the large-scale neural dynamics of underlying cognitive processes based on its optimal spatiotemporal resolution. However, the MEG measured neural signals are smaller in magnitude compared to the background noise and hence, MEG usually suffers from a low signal-to-noise ratio (SNR) at the single-trial level. To overcome this limitation, it is common to record many trials of the same event-task and use the time-locked average signal for analysis, which can be very time consuming. In this study, we investigated the effect of the number of MEG recording trials required for speech decoding using a machine learning algorithm. We used a wavelet filter for generating the denoised neural features to train an Artificial Neural Network (ANN) for speech decoding. We found that wavelet based denoising increased the SNR of the neural signal prior to analysis and facilitated accurate speech decoding performance using as few as 40 single-trials. This study may open up the possibility of limiting MEG trials for other task evoked studies as well.
					</div>
				</div>
				<script>function dropDown44() {
					document.getElementById("myDropdown44").classList.toggle("show");
				}</script>
                [<a href="./publications/Dash_2018_BrainInformatics_DeterminingTheOptimalNumberOfMEGTrials.pdf" target="_blank">pdf</a>
                | <a href="./publications/Dash_2018_BrainInformatics_DeterminingTheOptimalNumberOfMEGTrials.bib" target="_blank">bib</a>
                | doi: <a href="https://doi.org/10.1007/978-3-030-05587-5_16" target="_blank">10.1007/978-3-030-05587-5_16</a>
                | doi: <a href="https://doi.org/10.1109/ISBI.2019.8759193" target="_blank">10.1109/ISBI.2019.8759193</a>
                | PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/31768504" target="_blank">31768504</a>
                | <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6876632" target="_blank">PMC6876632</a>
                ]
                </br>
                </br>
                
                      
                Murugesan GK, Saghafi B, Davenport EM, Wagner BC, Urban-Hobson J, Kelley M, Jones D, Powers A, Whitlow C, Stitzel JD, Maldjian JA, Montillo A**. 
                <span class="pubtitle">Single Season Changes in Resting State Network Power and the Connectivity between Regions Distinguish Head Impact Exposure Level in High School and Youth Football Players.</span>
                Medical Imaging: Computer-Aided Diagnosis (SPIE). 2018 February; 1:105750F1-8.
                </br>
				<div class="dropdown">
					<button onclick="dropDown43()" class="dropbtn">Abstract</button>
					<div id="myDropdown43" class="dropdown-content">
						The effect of repetitive sub-concussive head impact exposure in contact sports like American football on brain health is poorly understood, especially in the understudied populations of youth and high school players. These players, aged 9-18 years old may be particularly susceptible to impact exposure as their brains are undergoing rapid maturation. This study helps fill the void by quantifying the association between head impact exposure and functional connectivity, an important aspect of brain health measurable via resting-state fMRI (rs-fMRI). The contributions of this paper are three fold. First, the data from two separate studies (youth and high school) are combined to form a high-powered analysis with 60 players. These players experience head acceleration within overlapping impact exposure making their combination particularly appropriate. Second, multiple features are extracted from rs-fMRI and tested for their association with impact exposure. One type of feature is the power spectral density decomposition of intrinsic, spatially distributed networks extracted via independent components analysis (ICA). Another feature type is the functional connectivity between brain regions known often associated with mild traumatic brain injury (mTBI). Third, multiple supervised machine learning algorithms are evaluated for their stability and predictive accuracy in a low bias, nested cross-validation modeling framework. Each classifier predicts whether a player sustained low or high levels of head impact exposure. The nested cross validation reveals similarly high classification performance across the feature types, and the Support Vector, Extremely randomized trees, and Gradboost classifiers achieve F1-score up to 75%.
					</div>
				</div>
				<script>function dropDown43() {
					document.getElementById("myDropdown43").classList.toggle("show");
				}</script>
                [<a href="./publications/Murugesan_2018_MedicalImagingSPIE_SingleSeasonChangesInRestingStateNetworksFromHeadImpact.pdf" target="_blank">pdf</a>					
                | <a href="./publications/SingleSeasonChangesinRestingStateNetworkPower.bib" target="_blank">bib</a>
                | doi: <a href="https://doi.org/10.1117/12.2293199" target="_blank">10.1117/12.2293199</a>
                | PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/31787799" target="_blank">31787799</a>
                | <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6884358" target="_blank">PMC6884358</a>
                ]
                </br>
                </br>
                        
                Saghafi B, Murugesan G, Davenport E, Wagner B, Urban J, Kelley M, Jones D, Powers A, Whitlow C, Stitzel J, Maldjian J, Montillo A**. 
                <span class="pubtitle">Quantifying the Association between White Matter Integrity Changes and Subconcussive Head Impact Exposure from a Single Season of Youth and High School Football using 3D Convolutional Neural Networks.</span>
                Medical Imaging: Computer-Aided Diagnosis (SPIE). 2018 February; :105750E1-8.
                </br>
				<div class="dropdown">
					<button onclick="dropDown42()" class="dropbtn">Abstract</button>
					<div id="myDropdown42" class="dropdown-content">
						The effect of subconcussive head impact exposure during contact sports, including American football, on brain health is poorly understood particularly in young and adolescent players, who may be more vulnerable to brain injury during periods of rapid brain maturation. This study aims to quantify the association between cumulative effects of head impact exposure from a single season of football on white matter (WM) integrity as measured with diffusion MRI. The study targets football players aged 9-18 years old. All players were imaged pre- and post-season with structural MRI and diffusion tensor MRI (DTI). Fractional Anisotropy (FA) maps, shown to be closely correlated with WM integrity , were computed for each subject, co-registered and subtracted to compute the change in FA per subject. Biomechanical metrics were collected at every practice and game using helmet mounted accelerometers. Each head impact was converted into a risk of concussion, and the risk of concussion-weighted cumulative exposure (RWE) was computed for each player for the season. Athletes with high and low RWE were selected for a two-category classification task. This task was addressed by developing a 3D Convolutional Neural Network (CNN) to automatically classify players into high and low impact exposure groups from the change in FA maps. Using the proposed model, high classification performance, including ROC Area Under Curve score of 85.71% and F1 score of 83.33% was achieved. This work adds to the growing body of evidence for the presence of detectable neuroimaging brain changes in white matter integrity from a single season of contact sports play, even in the absence of a clinically diagnosed concussion.
					</div>
				</div>
				<script>function dropDown42() {
					document.getElementById("myDropdown42").classList.toggle("show");
				}</script>
                [<a href="./publications/Saghafi_2018_MedicalImagingSPIE_QuantifyingTheAssociationBtwnWMIntegrityAndHeadImpactExposure.pdf" target="_blank">pdf</a>					
                | <a href="./publications/Saghafi_2018_Quantifying_the_association_between_White_Matter.bib" target="_blank">bib</a>
                | doi: <a href="https://doi.org/10.1117/12.2293023" target="_blank">10.1117/12.2293023</a>
                | PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/31741549" target="_blank">31741549</a>
                | <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6859447" target="_blank">PMC6859447</a>
                ]
                </br>
                </br>
                        
                O'Neill TJ, Davenport EM, Murugesan G, Montillo A, Maldjian JA**. 
                <span class="pubtitle">Applications of Resting State Functional MR Imaging to Traumatic Brain Injury.</span>
                Neuroimaging Clin N Am. 2017 Nov;27(4):685-696. 
                </br>
				<div class="dropdown">
					<button onclick="dropDown41()" class="dropbtn">Abstract</button>
					<div id="myDropdown41" class="dropdown-content">
						-Resting state functional MR imaging (rs-fMR imaging) is typically not applicable to the individual in a clinical setting.</br>
						-Graph theory and machine learning methods are beginning to identify traumatic brain injury–specific features in rs-fMR imaging for group studies and starting to show promise as assistive tools for individual diagnoses.</br>
						-Resting state magnetoencephalography has a higher temporal resolution and may be able to supplement rs-fMR imaging findings.</br>
						-Moving rs-fMR imaging into the clinic should be approached with cautious optimism
					</div>
				</div>
				<script>function dropDown41() {
					document.getElementById("myDropdown41").classList.toggle("show");
				}</script>
                [<a href="./publications/O'Neill, Davenport et al. 2017 - Applications of Resting State Functional.pdf" target="_blank">pdf</a>
                | <a href="./publications/Oneill_applications_of_Reasting_State_Fubnctional_MRI.bib" target="_blank">bib</a>
                | doi: <a href="https://doi.org/10.1016/j.nic.2017.06.006" target="_blank">10.1016/j.nic.2017.06.006</a>
                | PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/28985937" target="_blank">28985937</a>
                | <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/28985937" target="_blank">PMC5708891</a>
                ]
                </br>
                </br>
                        
                Famili A, Murugesan G, Wagner B, Smith SC, Xu J, Divers J, Freedman B, Maldjian JA, Montillo A**. 
                <span class="pubtitle">Impact of Glycemic Control and Cardiovascular Disease Measures on Hippocampal Functional Connectivity in African Americans with Type 2 Diabetes: a resting state fMRI Study.</span>
                Radiological Society of North America; 2017 November; c2017
                </br>
				<div class="dropdown">
					<button onclick="dropDown40()" class="dropbtn">Abstract</button>
					<div id="myDropdown40" class="dropdown-content">
						This study tests the hypothesis that inadequate Type 2 diabetes (T2D) management, including fine gradations of glycemic control, increasing measures of cardiovascular disease (CVD) and renal disease, leads to decreased hippocampal connectivity in African Americans (AA).
					</div>
				</div>
				<script>function dropDown40() {
					document.getElementById("myDropdown40").classList.toggle("show");
				}</script>
                [
                <a href="./publications/Famili_2017_RSNA_ImpactOfGlycemicControlOnFunctionalConnectivityInDiabetes.pdf" target="_blank">pdf</a>	
                | <a href="./publications/Famili_2017_RSNA_ImpactOfGlycemicControlOnFunctionalConnectivityInDiabetes.bib" target="_blank">bib</a>				
                ]
                </br>
                </br>
                
                Garg P, Davenport EM, Murugesan G, Whitlow C, Maldjian J, Montillo A**. 
                <span class="pubtitle">Using Convolutional Neural Networks to Automatically Detect Eye-Blink Artifacts in Magnetoencephalography Without Resorting to Electrooculography.</span>
                Medical Image Computing and Computer-Assisted Intervention; 2017 September; 3:374-381.
                </br>
				<div class="dropdown">
					<button onclick="dropDown39()" class="dropbtn">Abstract</button>
					<div id="myDropdown39" class="dropdown-content">
						Magnetoencephelography (MEG) is a functional neuroimaging tool that records the magnetic fields induced by neuronal activity; however, signal from muscle activity often corrupts the data. Eye-blinks are one of the most common types of muscle artifact. They can be recorded by affixing eye proximal electrodes, as in electrooculography (EOG), however this complicates patient preparation and decreases comfort. Moreover, it can induce further muscular artifacts from facial twitching. We propose an EOG free, data driven approach. We begin with Independent Component Analysis (ICA), a well-known preprocessing approach that factors observed signal into statistically independent components. When applied to MEG, ICA can help separate neuronal components from non-neuronal ones, however, the components are randomly ordered. Thus, we develop a method to assign one of two labels, non-eye-blink or eye-blink, to each component.</br>
						Our contributions are two-fold. First, we develop a 10-layer Convolutional Neural Network (CNN), which directly labels eye-blink artifacts. Second, we visualize the learned spatial features using attention mapping, to reveal what it has learned and bolster confidence in the method’s ability to generalize to unseen data. We acquired 8-min, eyes open, resting state MEG from 44 subjects. We trained our method on the spatial maps from ICA of 14 subjects selected randomly with expertly labeled ground truth. We then tested on the remaining 30 subjects. Our approach achieves a test classification accuracy of 99.67%, sensitivity: 97.62%, specificity: 99.77%, and ROC AUC: 98.69%. We also show the learned spatial features correspond to those human experts typically use which corroborates our model’s validity. This work (1) facilitates creation of fully automated processing pipelines in MEG that need to remove motion artifacts related to eye blinks, and (2) potentially obviates the use of additional EOG electrodes for the recording of eye-blinks in MEG studies.
					</div>
				</div>
				<script>function dropDown39() {
					document.getElementById("myDropdown39").classList.toggle("show");
				}</script>
                [<a href="./publications/Montillo_2017_MICCAI_UsingCNNsToDetectEyeBlinkArtifacts.pdf" target="_blank">pdf</a>
                | <a href="./publications/Garg_2017_Using_convolutional_neural_networks_to_automatically_detect_eye-blink_artifacts_in_magnetoencephalography.bib" target="_blank">bib</a>
                | doi: <a href="https://doi.org/10.1007/978-3-319-66179-7_43" target="_blank">10.1007/978-3-319-66179-7_43</a>
                | PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31656959" target="_blank">31656959</a>
                | <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6814159" target="_blank"> PMC6814159</a>					
                ]
                </br>
                </br>
                        
              
                Saghafi B, Garg P, Wagner B, Smith C, Xu J, Divers J, Madhuranthakam A, Freedman B, Maldjian J, Montillo A**. 
                <span class="pubtitle">Quantifying the Impact of Type 2 Diabetes on Brain Perfusion using Deep Neural Networks.</span>
                Medical Image Computing and Computer Assisted Intervention. 2017 September.
                </br>
				<div class="dropdown">
					<button onclick="dropDown38()" class="dropbtn">Abstract</button>
					<div id="myDropdown38" class="dropdown-content">
						The effect of Type 2 Diabetes (T2D) on brain health is poorly understood. This study aims to quantify the association between T2D and perfusion in the brain. T2D is a very common metabolic disorder that can cause long term damage to the renal and cardiovascular systems. Previous research has discovered the shape, volume and white matter microstructures in the brain to be significantly impacted by T2D. We propose a fully-connected deep neural network to classify the regional Cerebral Blood Flow into low or high levels, given 16 clinical measures as predictors. The clinical measures include diabetes, renal, cardiovascular and demographics measures. Our model enables us to discover any nonlinear association which might exist between the input features and target. Moreover, our end-to-end architecture automatically learns the most relevant features and combines them without the need for applying a feature selection method. We achieved promising classification performance. Furthermore, in comparison with six (6) classical machine learning algorithms and six (6) alternative deep neural networks similarly tuned for the task, our proposed model outperformed all of them.
					</div>
				</div>
				<script>function dropDown38() {
					document.getElementById("myDropdown38").classList.toggle("show");
				}</script>
                [<a href="./publications/Montillo_2017_MICCAI_QuantifyingImpactOfType2DiabetesOnBrainPerfusion.pdf" target="_blank">pdf</a>				
                | <a href="./publications/Saghafi_2017_DeepFullyConnectedNNforEstimationofCaudatePerfusion.bib" target="_blank">bib</a>
                | doi: <a href="https://doi.org/10.1007/978-3-319-67558-9_18" target="_blank">10.1007/978-3-319-67558-9_18</a>
                | PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31650132" target="_blank">31650132</a>
                | <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6812498" target="_blank"> PMC6812498</a>					
                ]
                </br>
                </br>
                
                Murugesan G, Garg P, O'Neil T, Wagner B, Whitlow C, Maldjian J, Montillo A**. 
                <span class="pubtitle">Automatic Labeling of Resting State fMRI Networks using 3D Convolutional Neural Networks.</span>
                Pattern Recognition in Neuroimaging. 2017 June.
                </br>
				<div class="dropdown">
					<button onclick="dropDown37()" class="dropbtn">Abstract</button>
					<div id="myDropdown37" class="dropdown-content">
						No text available
					</div>
				</div>
				<script>function dropDown37() {
					document.getElementById("myDropdown37").classList.toggle("show");
				}</script>
                [
                <!-- [[ToDo]] pdf needed, fix fig 4 caption location-->
                <a href="./publications/Murugesan_2017_PRNI_LabelingRSNetworks.bib" target="_blank">bib</a>]				
                </br>
                </br>
                
                Garg P, Davenport E, Murugesan G, Wagner B, Whitlow C, Maldjian J, Montillo A**. 
                <span class="pubtitle">Automatic Multiple MEG Artifact Detection using 1-D Convolutional Neural Networks without Electrooculography or Electrocardiography.</span>
                Pattern Recognition in Neuroimaging. 2017 June; 1:1-4.
                </br>
				<div class="dropdown">
					<button onclick="dropDown36()" class="dropbtn">Abstract</button>
					<div id="myDropdown36" class="dropdown-content">
						Magnetoencephalography (MEG) is a functional neuroimaging tool that records the magnetic fields induced by electrical neuronal activity; however, signal from non-neuronal sources can corrupt the data. Eye-Blinks (EB) and Cardiac Activity (CA) are two of the most common types of non-neuronal artifacts. They can be measured by affixing eye proximal electrodes, as in electrooculography (EOG) and chest electrodes, as in electrocardiography (EKG), however this complicates imaging setup, decreases patient comfort, and often induces further artifacts from facial twitching and postural muscle movement. We propose an EOG- and EKG-free approach to identify eye-blink, cardiac, or neuronal signals for automated artifact suppression.</br>
						Our contributions are two-fold. First, we combine a data driven, multivariate decomposition approach based on Independent Component Analysis (ICA) and a highly accurate classifier constructed as a deep 1-D Convolutional Neural Network. Second, we visualize the features learned to reveal what features the model uses and to bolster user confidence in our model’s training and potential for generalization. We train and test three variants of our method on resting state MEG data from 49 subjects. Our cardiac model achieves a 96% sensitivity and 99% specificity on the set-aside test-set. Our eye-blink model achieves a sensitivity of 85% and specificity of 97%. This work facilitates automated MEG processing for both, clinical and research use, and can obviate the need for EOG or EKG electrodes.
					</div>
				</div>
				<script>function dropDown36() {
					document.getElementById("myDropdown36").classList.toggle("show");
				}</script>
                [<a href="./publications/Garg_2017_Automatic1DConvolutionalNNBasedDetectionOfArtifactsInMEG.pdf" target="_blank">pdf</a>
                | <a href="./publications/Garg_2017_Automatic1DConvolutionalNNBasedDetectionOfArtifactsInMEG.bib" target="_blank">bib</a>
                | doi: <a href="https://doi.org/10.1109/PRNI.2017.7981506" target="_blank">10.1109/PRNI.2017.7981506</a>
                | PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31656826" target="_blank">31656826</a>
                | <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6814172" target="_blank">PMC6814172</a>	
                ]
                </br>
                </br>
                        
                Murugesan G, Famili A, Davenport E, Wagner B, Urban J, Kelley M, Jones D, Whitlow C, Stitzel J, Maldjian J, Montillo A**.      
                <span class="pubtitle">Changes in resting state MRI networks from a single season of football distinguishes controls, low, and high head impact exposure.</span>
                IEEE International Symposium on Biomedical Imaging. 2017 May; 1:464-467. 
                </br>
				<div class="dropdown">
					<button onclick="dropDown35()" class="dropbtn">Abstract</button>
					<div id="myDropdown35" class="dropdown-content">
						Sub-concussive asymptomatic head impacts during contact sports may develop potential neurological changes and may have accumulative effect through repetitive occurrences in contact sports like American football. The effects of sub-concussive head impacts on the functional connectivity of the brain are still unclear with no conclusive results yet presented. Although various studies have been performed on the topic, they have yielded mixed results with some concluding that sub concussive head impacts do not have any effect on functional connectivity, while others concluding that there are acute to chronic effects. The purpose of this study is to determine whether there is an effect on the functional connectivity of the brain from repetitive sub concussive head impacts. First, we applied a model free group ICA based intrinsic network selection to consider the relationship between all voxels while avoiding an arbitrary choice of seed selection. Second, unlike most other studies, we have utilized the default mode network along with other extracted intrinsic networks for classification. Third, we systematically tested multiple supervised machine learning classification algorithms to predict whether a player was a non-contact sports youth player, a contact sports player with low levels of cumulative biomechanical force impacts, or one with high levels of exposure. The 10-fold cross validation results show robust classification between the groups with accuracy up to 78% establishing the potential of data driven approaches coupled with machine learning to study connectivity changes in youth football players. This work adds to the growing body of evidence that there are detectable changes in brain signature from playing a single season of contact sports.
					</div>
				</div>
				<script>function dropDown35() {
					document.getElementById("myDropdown35").classList.toggle("show");
				}</script>
                [<a href="./publications/Murugesan_2017_ISBI_ChangesInRestingStateMRIFromSingleSeasonsDistinguishesImpactExposure.pdf" target="_blank">pdf</a>
                | <a href="./publications/Murugesan_2017_ISBI_ChangesInRestingStateMRIFromSingleSeasonsDistinguishesImpactExposure.bib" target="_blank">bib</a>
                | doi: <a href="https://ieeexplore.ieee.org/document/7950561" target="_blank">10.1109/ISBI.2017.7950561</a>
                | PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31741701" target="_blank">31741701</a>
                | <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6859454" target="_blank">PMC6859454</a>
                ]
                </br>
                </br>
                        
                Li B, She H, Keupp J, Dimitrov I, Montillo A, Madhuranthakam A, Lenkinski R, Vinogradov E**. 
                <span class="pubtitle">Image registration with structuralized Mutual Information: application to CEST.</span>
                International Society of Magnetic Resonance In Medicine; 2017 April 22; c2017.
                </br>
				<div class="dropdown">
					<button onclick="dropDown34()" class="dropbtn">Abstract</button>
					<div id="myDropdown34" class="dropdown-content">
						In image registration, mutual information (MI) has proved to be an effetive similarity measure and iswidely used for medical image registration. Howver, the MI algorithm does not consider spatial dependencies of vozels and introduces significant errors when registering images with large intensity changes, like in Z-spectral images of CEST-MRI. This abstract shows that by the incorporation of structural information of the SMI algorithm demonstrates robust performance registering Z-spectral images with large and complex intensity variations.
					</div>
				</div>
				<script>function dropDown34() {
					document.getElementById("myDropdown34").classList.toggle("show");
				}</script>
                [<a href="./publications/BianLi_2017_ISMRM_ImageRegistrationWithStructuredMutualInformation.pdf" target="_blank">pdf</a>
                | <a href="./publications/BianLi_2017_ISMRM_ImageRegistrationWithStructuredMutualInformation.bib" target="_blank">bib</a>
                ]
                </br>
                </br>
                        
                Famili A, Krishnan G, Davenport E, Germi J, Wagner B, Lega B, Montillo A**. 
                <span class="pubtitle"> Automatic identification of successful memory encoding in stereo-EEG of refractory, mesial temporal lobe epilepsy.</span>
                IEEE International Symposium on Biomedical Imaging. 2017; 1:587-590. 
                </br>
				<div class="dropdown">
					<button onclick="dropDown33()" class="dropbtn">Abstract</button>
					<div id="myDropdown33" class="dropdown-content">
						Surgical resection of portions of the temporal lobe is the standard of care for patients with refractory mesial temporal lobe epilepsy. While this reduces seizures, it often results in an inability to form new memories, which leads to difficulties in social situations, learning, and suboptimal quality of life. Learning about the success or failure to form new memory in such patients is critical if we are to generate neuromodulation-based therapies. To this end, we tackle the many challenges in analyzing memory formation when their brains are recorded using stereoencephalography (sEEG) in a Free Recall task. Our contributions are threefold. First, we compute a rich measure of brain connectivity by computing the phase locking value statistic (synchrony) between pairs of regions, over hundreds of word memorization trials. Second, we leverage the rich information (over 400 values per pair of probed brain regions) to form consistent length feature vectors for classifier training. Third, we train and evaluate seven different types of classifier models and identify which ones achieve the highest accuracy and which brain features are most important for high accuracy. We assess our approach on data from 37 patients pre-resection surgery. We achieve up to 73% accuracy distinguishing successful from unsuccessful memory formation in the human brain from just 1.6 sec epochs of sEEG data.
					</div>
				</div>
				<script>function dropDown33() {
					document.getElementById("myDropdown33").classList.toggle("show");
				}</script>
                [<a href="./publications/Famili_2017_Automatic identification of successful memory.pdf" target="_blank">pdf</a>
                | <a href="./publications/Famili, Krishnan et al. 4 17 2017 - 4 20 2017 - Automatic identification of successful memory.bib" target="_blank">bib</a>
                | doi: <a href="https://doi.org/10.1109/ISBI.2017.7950589" target="_blank">10.1109/ISBI.2017.7950589</a>	
                | PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31741702" target="_blank">31741702</a>
                | <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6859446" target="_blank">PMC6859446</a>			
                ]
                </br>
                </br>
                        
                Muller H, Kelm BM, Arbel T, Cai WT, Cardoso MJ, Langs G, Menze B, Metaxas D, Montillo A, Wells III WM, Zhang S, Chung AC, Jenkinson M, Ribbens A, editors.
                <span class="pubtitle">Medical Computer Vision and Bayesian and Graphical Models for Biomedical Imaging.</span>
                London: Springer book publishers; 2016. 222p.
                </br>
				<div class="dropdown">
					<button onclick="dropDown32()" class="dropbtn">Abstract</button>
					<div id="myDropdown32" class="dropdown-content">
						Text not available
					</div>
				</div>
				<script>function dropDown32() {
					document.getElementById("myDropdown32").classList.toggle("show");
				}</script>
                [doi: <a href="https://www.springer.com/gp/book/9783319611877" target="_blank"> 10.1007/978-3-319-61188-4</a>
                ]
                </br>				
                </br>
                        
                Menze B, Langs G, Montillo A, Kelm BM, Muller H, Zhang S, Cai W, Metaxas D, editors.
                <span class="pubtitle">Medical Computer Vision: Algorithms for Big Data: International Workshop, MCV 2015.</span>
                Switzerland: Springer book publishers; 2016. 182p.
                </br>
				<div class="dropdown">
					<button onclick="dropDown31()" class="dropbtn">Abstract</button>
					<div id="myDropdown31" class="dropdown-content">
						Text not available
					</div>
				</div>
				<script>function dropDown31() {
					document.getElementById("myDropdown31").classList.toggle("show");
				}</script>
                <!-- [[ToDo]] ISBN or DOI needed to link to Spinger page, see MyBibliography.xlsx -->
                [<a href="./publications/MedicalComputerVision.bib" target="_blank">bib</a>
                | doi: <a href="https://www.springer.com/gp/book/9783319420158" target="_blank"> 10.1007/978-3-319-42016-5</a>
                ]
                </br>
                </br>
                        
                Liu X, Montillo A, inventors.
                <span class="pubtitle">Systems and methods for image segmentation using a deformable atlas.</span>
                U.S. issued patent #9208572. 2015 December.
                </br>
				<div class="dropdown">
					<button onclick="dropDown30()" class="dropbtn">Abstract</button>
					<div id="myDropdown30" class="dropdown-content">
						Text not available
					</div>
				</div>
				<script>function dropDown30() {
					document.getElementById("myDropdown30").classList.toggle("show");
				}</script>
                [<a href="./publications/Montillo-DeformableAtlasPatent-US20140226889.pdf" target="_blank">pdf</a>
                ]
                </br>
                </br>
                        
                Yin Z, Yao Y, Montillo A, Wu M, Edic PM, Kalra M, De Man B**. 
                <span class="pubtitle">Acquisition, preprocessing, and reconstruction of ultralow dose volumetric CT scout for organ-based CT scan planning.</span>
                Med Phys. 2015 May;42(5):2730-9.
                </br>
				<div class="dropdown">
					<button onclick="dropDown29()" class="dropbtn">Abstract</button>
					<div id="myDropdown29" class="dropdown-content">
						Text not available
					</div>
				</div>
				<script>function dropDown29() {
					document.getElementById("myDropdown29").classList.toggle("show");
				}</script>
                [<a href="./publications/Montillo_2015_MedPhys_3D_scout_orig.pdf" target="_blank">pdf</a>
                | <a href="./publications/Montillo_2015_MedPhys_3D_scout_orig.bib" target="_blank">bib</a>
                | doi: <a href="https://doi.org/10.1118/1.4921065" target="_blank">10.1118/1.4921065</a>
                | PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/25979071/" target="_blank">25979071</a>
                ]
                </br>
                </br>
                        
                Montillo A**, Song Q, Das B, Yin Z. 
                <span class="pubtitle">Hierarchical pictorial structures for simultaneously localizing multiple organs in volumetric pre-scan CT.</span>
                Medical Imaging: Image processing (SPIE). 2015 March; 1:94130T1-6.
                </br>
				<div class="dropdown">
					<button onclick="dropDown28()" class="dropbtn">Abstract</button>
					<div id="myDropdown28" class="dropdown-content">
						Text not available
					</div>
				</div>
				<script>function dropDown28() {
					document.getElementById("myDropdown28").classList.toggle("show");
				}</script>
                [<a href="./publications/Montillo-SPIE2015-MultiOrganLocalizationViaHierachicalPictorialStructures.pdf" target="_blank">pdf</a>
                | <a href="./publications/Montillo-SPIE2015-MultiOrganLocalizationViaHierachicalPictorialStructures.bib" target="_blank">bib</a>
                | doi: <a href="https://doi.org/10.1117/12.2082183" target="_blank">10.1117/12.2082183</a>
                | PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31798201" target="_blank">31798201</a>
                | <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6886528" target="_blank">PMC6886528</a>	
                ]
                </br>
                </br>
                        
                Montillo A**, Sharma S, Prastawa P. 
                <span class="pubtitle">Feature Selection and Imaging-Genetics Predictions Using a Sparse, Extremely Randomized Forest Regressor.</span>
                2014 September. Medical Image Computing and Computer-Assisted Intervention: Workshop on Imaging Genetics, MIT, Boston.
                </br>
				<div class="dropdown">
					<button onclick="dropDown27()" class="dropbtn">Abstract</button>
					<div id="myDropdown27" class="dropdown-content">
						Text not available
					</div>
				</div>
				<script>function dropDown27() {
					document.getElementById("myDropdown27").classList.toggle("show");
				}</script>
                [<a href="./publications/Montillo-MICCAIw-2014-ImagingGeneticsFeatureSelectionAndPredictionViaSparseERF.pdf" target="_blank">pdf</a>
                | <a href="./publications/Montillo-MICCAIw-2014-ImagingGeneticsFeatureSelectionAndPredictionViaSparseERF.bib" target="_blank">bib</a>
                ]
                </br>
                </br>
                        
                Menze B, Langs G, Montillo A, Kelm M, Muller H, Zhang S, editors.
                <span class="pubtitle">Medical Computer Vision: Algorithms for Big Data: International Workshop, MCV 2014.</span>
                Switzerland: Springer; 2014. 211p.
                </br>
				<div class="dropdown">
					<button onclick="dropDown26()" class="dropbtn">Abstract</button>
					<div id="myDropdown26" class="dropdown-content">
						Text not available
					</div>
				</div>
				<script>function dropDown26() {
					document.getElementById("myDropdown26").classList.toggle("show");
				}</script>
                [doi: <a href="https://www.springer.com/gp/book/9783319139715" target="_blank"> 10.1007/978-3-319-13972-2</a>
                ]
                </br>
                </br>				
                        
                Yin Z, Yao Y, Montillo A, Edic PM, Man BD**.               
                <span class="pubtitle">Feasibility study on ultra-low dose 3D scout of organ based CT scan planning. International Conference on Image Formation in X-Ray Computed Tomography.</span>
                ISBN: 9781510857131. 2014; 1:52-55.
                </br>
				<div class="dropdown">
					<button onclick="dropDown25()" class="dropbtn">Abstract</button>
					<div id="myDropdown25" class="dropdown-content">
						Text not available
					</div>
				</div>
				<script>function dropDown25() {
					document.getElementById("myDropdown25").classList.toggle("show");
				}</script>
                [<a href="./publications/Montillo-2014_ImageFormationXRayCT-LowDoseScout.pdf" target="_blank">pdf</a>
                <!-- [[ToDo]] bib needed-->
                | PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31788673" target="_blank">31788673</a>
                | <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6885018" target="_blank">PMC6885018</a>	
                ]
                </br>
                </br>
                        
                Yan Z, Zhang S, Liu X, Metaxas D, Montillo A**. 
                <span class="pubtitle">Accurate whole-brain segmentation for Alzheimer’s disease combining an adaptive statistical atlas and multi-atlas.</span>
                Medical Image Computing and Computer-Assisted Intervention. 2013 September;
                </br>
				<div class="dropdown">
					<button onclick="dropDown24()" class="dropbtn">Abstract</button>
					<div id="myDropdown24" class="dropdown-content">
						Text not available
					</div>
				</div>
				<script>function dropDown24() {
					document.getElementById("myDropdown24").classList.toggle("show");
				}</script>
                [<a href="./publications/montillo-MICCAIw-2013-CombiningMultiAtlasAndExtendedAdaptiveStatisticalAtlas.pdf" target="_blank">pdf</a>
                | <a href="./publications/montillo-MICCAIw-2013-CombiningMultiAtlasAndExtendedAdaptiveStatisticalAtlas.bib" target="_blank">bib</a>
                | doi: <a href="https://doi.org/10.1007/978-3-319-05530-5_7" target="_blank">10.1007/978-3-319-05530-5_7</a>		
                | PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31723945" target="_blank">31723945</a>
                | <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6853627" target="_blank">PMC6853627</a>		
                ]
                </br>
                </br>
                        
                Montillo A**, Song Q, Bhagalia R, Srikrishnan V. 
                <span class="pubtitle">Organ localization using joint AP/LAT view landmark consensus detection and hierarchical active appearance models.</span>
                Medical Image Computing and Computer-Assisted Intervention. 2013 September; 3:138-147. 
                </br>
				<div class="dropdown">
					<button onclick="dropDown23()" class="dropbtn">Abstract</button>
					<div id="myDropdown23" class="dropdown-content">
						Text not available
					</div>
				</div>
				<script>function dropDown23() {
					document.getElementById("myDropdown23").classList.toggle("show");
				}</script>
                [<a href="./publications/Montillo-JointViewLandmarkConsensusDetectionAndHierarchicalAAM.pdf" target="_blank">pdf</a>
                | <a href="./publications/Montillo-JointViewLandmarkConsensusDetectionAndHierarchicalAAM.bib" target="_blank">bib</a>
                | doi: <a href="https://doi.org/10.1007/978-3-319-05530-5_14" target="_blank">10.1007/978-3-319-05530-5_14</a>
                | PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31915754" target="_blank">31915754</a>
                | <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6947663" target="_blank">PMC6947663</a>				
                ]
                </br>
                </br>
                        
                Bianchi A, Miller JV, Tan ET, Montillo A**. 
                <span class="pubtitle">Brain tumor segmentation with symmetric texture and symmetric intensity-based decision forests.</span>
                Proc IEEE Int Symp Biomed Imaging. 2013 Apr;2013:748-751.
                </br>
				<div class="dropdown">
					<button onclick="dropDown22()" class="dropbtn">Abstract</button>
					<div id="myDropdown22" class="dropdown-content">
						Text not available
					</div>
				</div>
				<script>function dropDown22() {
					document.getElementById("myDropdown22").classList.toggle("show");
				}</script>
                [<a href="./publications/Montillo-ISBI-2013-BrainTumorSegmentationWithSymmetricTextureDrivenDecisionForests.pdf" target="_blank">pdf</a>
                | <a href="./publications/Montillo-ISBI-2013-BrainTumorSegmentationWithSymmetricTextureDrivenDecisionForests.bib" target="_blank">bib</a>
                | doi: <a href="https://doi.org/10.1109/ISBI.2013.6556583" target="_blank">10.1109/ISBI.2013.6556583</a>
                | PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/25404996" target="_blank">25404996</a>
                | <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4232942" target="_blank">PMC4232942</a>
                ]
                </br>
                </br>
                        
                Montillo A**, Song Q, Liu X, Miller JV. 
                <span class="pubtitle">Parsing radiographs by integrating landmark set detection and multi-object active appearance models.</span>
                Medical Imaging : Image processing (SPIE). 2013 Mar 13;8669:86690H.
                </br>
				<div class="dropdown">
					<button onclick="dropDown21()" class="dropbtn">Abstract</button>
					<div id="myDropdown21" class="dropdown-content">
						Text not available
					</div>
				</div>
				<script>function dropDown21() {
					document.getElementById("myDropdown21").classList.toggle("show");
				}</script>
                [<a href="./publications/Montillo-SPIE2013-ParsingRadiographsByIntegratingLandmarkSetDetectionAndAAM.pdf" target="_blank">pdf</a>
                | <a href="./publications/Montillo-SPIE2013-ParsingRadiographsByIntegratingLandmarkSetDetectionAndAAM.bib" target="_blank">bib</a>
                | doi: <a href="https://doi.org/10.1117/12.2007138" target="_blank">10.1117/12.2007138</a>
                | PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/25075265" target="_blank">25075265</a>
                | <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4112100" target="_blank">PMC4112100</a>
                ]
                </br>
                </br>
                        
                Liu X**, Montillo A, Tan E, Schenck J. 
                <span class="pubtitle">iSTAPLE: improved label fusion for segmentation by combining STAPLE with image intensity.</span>
                Medical Imaging : Image processing (SPIE). 2013 March; 1:86692O1-6.
                </br>
				<div class="dropdown">
					<button onclick="dropDown20()" class="dropbtn">Abstract</button>
					<div id="myDropdown20" class="dropdown-content">
						Text not available
					</div>
				</div>
				<script>function dropDown20() {
					document.getElementById("myDropdown20").classList.toggle("show");
				}</script>
                [<a href="./publications/Montillo-SPIE2013-iSTAPLE-LabelFusionCombiningSTAPLEandImageIntensity.pdf" target="_blank">pdf</a>
                | <a href="./publications/Montillo-SPIE2013-iSTAPLE-LabelFusionCombiningSTAPLEandImageIntensity.bib" target="_blank">bib</a>
                | doi: <a href="https://doi.org/10.1117/12.2006447" target="_blank">10.1117/12.2006447</a>
                | PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31741552" target="_blank">31741552</a>
                | <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6859448" target="_blank">PMC6859448</a>
                ]
                </br>
                </br>
                        
                Liu X**, Montillo A, Tan ET, Schenck JF, Mendonca P. 
                <span class="pubtitle">Deformable atlas for multi-structure segmentation.</span>
                Med Image Comput Comput Assist Interv. 2013;16(Pt 1):743-50.
                </br>
				<div class="dropdown">
					<button onclick="dropDown19()" class="dropbtn">Abstract</button>
					<div id="myDropdown19" class="dropdown-content">
						Text not available
					</div>
				</div>
				<script>function dropDown19() {
					document.getElementById("myDropdown19").classList.toggle("show");
				}</script>
                [<a href="./publications/Montillo-MICCAI-2013-DeformableAtlasForMultistructureSegmentation.pdf" target="_blank">pdf</a>
                | <a href="./publications/Montillo-MICCAI-2013-DeformableAtlasForMultistructureSegmentation.bib" target="_blank">bib</a>
                | doi: <a href="https://doi.org/10.1007/978-3-642-40811-3_93" target="_blank">10.1007/978-3-642-40811-3_93</a>
                | PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/24505734/" target="_blank">24505734</a>
                ]
                </br>
                </br>
                        
                Yan Z, Zhang S, Liu X, Metaxas DN, Montillo A**. 
                <span class="pubtitle">Accurate segmentation of brain images into 34 structures combining a non-stationary adaptive statistical atlas and a multi-atlas with applications to Alzheimer's disease.</span>
                IEEE International Symposium on Biomedical Imaging. 2013; 2:1202-1205. 
                </br>
				<div class="dropdown">
					<button onclick="dropDown18()" class="dropbtn">Abstract</button>
					<div id="myDropdown18" class="dropdown-content">
						Text not available
					</div>
				</div>
				<script>function dropDown18() {
					document.getElementById("myDropdown18").classList.toggle("show");
				}</script>
                [<a href="./publications/Montillo-ISBI-2013-ExtendedNonStationaryAdaptiveStatisticalAtlas.pdf" target="_blank">pdf</a>
                | <a href="./publications/Montillo-ISBI-2013-ExtendedNonStationaryAdaptiveStatisticalAtlas.bib" target="_blank">bib</a>
                | doi: <a href="https://doi.org/10.1109/ISBI.2013.6556696" target="_blank">10.1109/ISBI.2013.6556696</a>
                | PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31788155" target="_blank">31788155</a>
                | <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6884356" target="_blank">PMC6884356</a>
                ]
                </br>
                </br>
                        
                Montillo A**, Tu J, Shotton J, Winn J, Iglesias JE, Metaxas DN, Criminisi A. 
                <span class="pubtitle">Entangled Forests and Differentiable Information Gain Maximization.</span>
                Decision Forests for Computer Vision and Medical Image Analysis. London: Springer; 2013. Chapter 19; p.273-293.
                </br>
				<div class="dropdown">
					<button onclick="dropDown17()" class="dropbtn">Abstract</button>
					<div id="myDropdown17" class="dropdown-content">
						Text not available
					</div>
				</div>
				<script>function dropDown17() {
					document.getElementById("myDropdown17").classList.toggle("show");
				}</script>
                [<a href="./publications/Montillo-BookChapter19-DifferentiableInfoGainEntanglement.pdf" target="_blank">pdf</a>
                | <a href="./publications/Montillo-BookChapter19-DifferentiableInfoGainEntanglement.bib" target="_blank">bib</a>
                | doi: <a href="https://link.springer.com/chapter/10.1007/978-1-4471-4929-3_19" target="_blank">10.1007/978-1-4471-4929-3_19</a>
                ]
                </br>
                </br>
                        
                Menze B, Langs G, Lu L, Montillo A, Tu Z, Criminisi A, editors.
                <span class="pubtitle">Medical Computer Vision. Large Data in Medical Imaging.</span>
                Berlin: Springer-Verlag Berlin Heidelberg; 2013. 292p.
                </br>
				<div class="dropdown">
					<button onclick="dropDown16()" class="dropbtn">Abstract</button>
					<div id="myDropdown16" class="dropdown-content">
						Text not available
					</div>
				</div>
				<script>function dropDown16() {
					document.getElementById("myDropdown16").classList.toggle("show");
				}</script>
                [
                <!-- [[ToDo]] ISBN or DOI needed to link to Spinger page, see MyBibliography.xlsx -->
                doi: <a href="https://www.springer.com/gp/book/9783319055299" target="_blank"> 10.1007/978-3-319-05530-5</a>
                ]
                </br>
                </br>
                        
                Montillo A**. 
                <span class="pubtitle">Context Selective Decision Forests and their application to Lung Segmentation in CT Images.</span>
                Medical Image Computing and Computer-Assisted Intervention: PIA.  2011 September; 1:201-212.
                </br>
				<div class="dropdown">
					<button onclick="dropDown15()" class="dropbtn">Abstract</button>
					<div id="myDropdown15" class="dropdown-content">
						Text not available
					</div>
				</div>
				<script>function dropDown15() {
					document.getElementById("myDropdown15").classList.toggle("show");
				}</script>
                [<a href="./publications/Montillo-MICCAIw-2011-ContextSelectiveDecisionForests.pdf" target="_blank">pdf</a>
                | <a href="./publications/Montillo-MICCAIw-2011-ContextSelectiveDecisionForests.bib" target="_blank">bib</a>				
                | ISBN: 978-1-4662-0016-6		
                | <a href="http://www.lungworkshop.org/2011/" target="_blank">URL</a>
                ]
                </br>
                </br>
                        
                Montillo A**, Shotton J, Winn J, Iglesias JE, Metaxas D, Criminisi A. 
                <span class="pubtitle">Entangled decision forests and their application for semantic segmentation of CT images.</span>
                Inf Process Med Imaging. 2011;22:184-96.
                </br>
				<div class="dropdown">
					<button onclick="dropDown14()" class="dropbtn">Abstract</button>
					<div id="myDropdown14" class="dropdown-content">
						Text not available
					</div>
				</div>
				<script>function dropDown14() {
					document.getElementById("myDropdown14").classList.toggle("show");
				}</script>
                [<a href="./publications/Montillo-IPMI-2011-EntangledDecisionForests.pdf" target="_blank">pdf</a>
                | <a href="./publications/Montillo-IPMI-2011-EntangledDecisionForests.bib" target="_blank">bib</a>
                | PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/21761656/" target="_blank">21761656</a>
                ]
                </br>
                </br>
                        
                Iglesias JE, Konukoglu E, Montillo A, Tu Z, Criminisi A**. 
                <span class="pubtitle">Combining generative and discriminative models for semantic segmentation of CT scans via active learning.</span>
                IPMI 2011, LNCS 6801, pp. 25–36, 2011.
                </br>
				<div class="dropdown">
					<button onclick="dropDown13()" class="dropbtn">Abstract</button>
					<div id="myDropdown13" class="dropdown-content">
						Text not available
					</div>
				</div>
				<script>function dropDown13() {
					document.getElementById("myDropdown13").classList.toggle("show");
				}</script>
                [<a href="./publications/Montillo-IPMI-2011-ActiveLearning.pdf" target="_blank">pdf</a>
                | <a href="./publications/Montillo-IPMI-2011-ActiveLearning.bib" target="_blank">bib</a>
                | PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/21761643/" target="_blank">21761643</a>
                ]
                </br>
                </br>
                        
                Montillo A**, Metaxas DN, Axel L.   
                <span class="pubtitle">Incompressible biventricular model construction and heart segmentation of 4D tagged MRI: application to right ventricular hypertrophy.</span>
                Medical Image Computing and Computer-Assisted Intervention: CBM. 2010 October; 1:143-155.
                </br>
				<div class="dropdown">
					<button onclick="dropDown12()" class="dropbtn">Abstract</button>
					<div id="myDropdown12" class="dropdown-content">
						Text not available
					</div>
				</div>
				<script>function dropDown12() {
					document.getElementById("myDropdown12").classList.toggle("show");
				}</script>
                [<a href="./publications/Montillo-MICCAI-2010-IncompressibleModel.pdf" target="_blank">pdf</a>
                | <a href="./publications/Montillo-MICCAI-2010-IncompressibleModel.bib" target="_blank">bib</a>
                | doi: <a href="https://doi.org/10.1007/978-1-4419-9619-0_15" target="_blank"> 10.1007/978-1-4419-9619-0_15</a>
                | PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31742255" target="_blank">31742255</a>
                | <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6860908" target="_blank">PMC6860908</a>
                ]
                </br>
                </br>
                        
                Montillo A**, Ling H. 
                <span class="pubtitle">Age regression from faces using random forests. IEEE International Conference on Image Processing.</span>
                IEEE International Conference on Image Processing. 2010 February; 1:1-4.
                </br>
				<div class="dropdown">
					<button onclick="dropDown11()" class="dropbtn">Abstract</button>
					<div id="myDropdown11" class="dropdown-content">
						Text not available
					</div>
				</div>
				<script>function dropDown11() {
					document.getElementById("myDropdown11").classList.toggle("show");
				}</script>
                [<a href="./publications/Montillo-ICIP-2009-RandomForests.pdf" target="_blank">pdf</a>
                | <a href="./publications/Montillo-ICIP-2009-RandomForests.bib" target="_blank">bib</a>
                | doi: <a href="https://doi.org/10.1109/ICIP.2009.5414103" target="_blank">10.1109/ICIP.2009.5414103</a>
                | PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31772508" target="_blank">31772508</a>
                | <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6879191" target="_blank">PMC6879191</a>
                ]
                </br>
                </br>
                        
                Axel L**, Montillo A, Kim D. 
                <span class="pubtitle">Tagged magnetic resonance imaging of the heart: a survey.</span>
                Med Image Anal. 2005 Aug;9(4):376-93. 
                </br>
				<div class="dropdown">
					<button onclick="dropDown10()" class="dropbtn">Abstract</button>
					<div id="myDropdown10" class="dropdown-content">
						Text not available
					</div>
				</div>
				<script>function dropDown10() {
					document.getElementById("myDropdown10").classList.toggle("show");
				}</script>
                [
                <a href="./publications/Montillo-MEDIA-CardiacMotionAnalysis_in_MRI.pdf" target="_blank">pdf</a>
                | <a href="./publications/Montillo-MEDIA-CardiacMotionAnalysis_in_MRI.bib" target="_blank">bib</a>
                | doi: <a href="https://doi.org/10.1016/j.media.2005.01.003" target="_blank">10.1016/j.media.2005.01.003</a>
                | PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/15878302/" target="_blank">15878302</a>
                ]
                </br>
                </br>
                        
                Gopalakrishnan V, Montillo A, Bachelder I, inventors.
                <span class="pubtitle"> Methods and apparatus for determining the orientation of an object in an image.</span>
                U.S. issued patent #6898333. 2005 May.
                </br>
                </br>
                        
                Park K, Montillo A, Metaxas DN, Axel L**. 
                <span class="pubtitle">Volumetric Heart Modeling and Analysis. </span>
                Communications of the ACM. 2005 February; 48(2):43-48. 
                </br>
				<div class="dropdown">
					<button onclick="dropDown9()" class="dropbtn">Abstract</button>
					<div id="myDropdown9" class="dropdown-content">
						Text not available
					</div>
				</div>
				<script>function dropDown9() {
					document.getElementById("myDropdown9").classList.toggle("show");
				}</script>
                [<a href="./publications/Montillo_2005_CommACM_Volumetric_heart_modeling_and_analysis.pdf" target="_blank">pdf</a>				
                | <a href="./publications/Park_Volumetric_Heart_Modeling_and_Analysis.bib" target="_blank">bib</a>
                | doi: <a href="https://doi.org/10.1145/1042091.1042118" target="_blank">10.1145/1042091.1042118</a>
                | PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31662583" target="_blank">31662583</a>
                | <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6818726" target="_blank">PMC6818726</a>				
                ]
                </br>
                </br>
                        
                Gopalakrishnan V, Montillo A, Bachelder I, inventors.
                <span class="pubtitle">Methods and apparatuses for generating a model of an object from an image of the object.</span>
                U.S. issued patent #6813377. 2004 November.
                </br>
                </br>
                        
                Manglik T, Axel L, Pai VM, Kim D, Dugal P, Montillo A, Zhen Q**. 
                <span class="pubtitle">Use of Bandpass Gabor Filters for Enhancing Blood-Myocardium Contrast and Filling-in tags in tagged MR Images.</span>
                International Society of Magnetic Resonance In Medicine; 2004 May; c2004.
                </br>
				<div class="dropdown">
					<button onclick="dropDown8()" class="dropbtn">Abstract</button>
					<div id="myDropdown8" class="dropdown-content">
						Text not available
					</div>
				</div>
				<script>function dropDown8() {
					document.getElementById("myDropdown8").classList.toggle("show");
				}</script>
                [<a href="./publications/Montillo-ISMRM-FilterDesignForEnahancingContrast.pdf" target="_blank">pdf</a>
                ]
                </br>
                </br>
                        
                Montillo A**, Metaxas D, Axel L. 
                <span class="pubtitle">Extracting tissue deformation using Gabor filter banks.</span>
                Medical Imaging: Physiology, Function, and Structure from Medical Images (SPIE). 2004 April; 1:1-9.
                </br>
				<div class="dropdown">
					<button onclick="dropDown7()" class="dropbtn">Abstract</button>
					<div id="myDropdown7" class="dropdown-content">
						Text not available
					</div>
				</div>
				<script>function dropDown7() {
					document.getElementById("myDropdown7").classList.toggle("show");
				}</script>
                [<a href="./publications/Montillo-MedicalImagingConf-DenseMotionTrackingThroughFilterDesign.pdf" target="_blank">pdf</a>
                | <a href="./publications/Montillo-MedicalImagingConf-DenseMotionTrackingThroughFilterDesign.bib" target="_blank">bib</a>
                | doi: <a href="https://doi.org/10.1117/12.536860" target="_blank">10.1117/12.536860</a>
                | PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31824125" target="_blank">31824125</a>
                | <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6902438" target="_blank">PMC6902438</a>	
                ]
                </br>
                </br>
                        
                Montillo A, Bachelder I, inventors**. 
                <span class="pubtitle">Methods and apparatuses for identifying regions of similar texture in an image.</span>
                U.S. issued patent #6647132. 2003 November.
                </br>
                </br>
                        
                Montillo A**, Metaxas DN, Axel L. 
                <span class="pubtitle">Automated deformable model-based segmentation of the left and right ventricles in tagged cardiac MRI.</span>
                Medical Image Computing and Computer-Assisted Intervention. 2003 October; 1:507-515. 
                </br>
				<div class="dropdown">
					<button onclick="dropDown6()" class="dropbtn">Abstract</button>
					<div id="myDropdown6" class="dropdown-content">
						Text not available
					</div>
				</div>
				<script>function dropDown6() {
					document.getElementById("myDropdown6").classList.toggle("show");
				}</script>
                [<a href="./publications/Montillo-MICCAI-FeatureIntegrationForCardiacSegmentation.pdf" target="_blank">pdf</a>
                | <a href="./publications/Montillo-MICCAI-FeatureIntegrationForCardiacSegmentation.bib" target="_blank">bib</a>
                | doi: <a href="https://doi.org/10.1007/978-3-540-39899-8_63" target="_blank">10.1007/978-3-540-39899-8_63</a>
                | PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31663082" target="_blank">31663082</a>
                | <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6818716" target="_blank">PMC6818716</a>					
                ]
                </br>
                </br>
                        
                Qian Z, Montillo A, Metaxas D, Axel L**. 
                <span class="pubtitle">Segmenting cardiac MRI tagging lines using Gabor filter banks.</span>
                IEEE Engineering in Medicine and Biology Society. 2003 September; 1:630-633. 
                </br>
				<div class="dropdown">
					<button onclick="dropDown5()" class="dropbtn">Abstract</button>
					<div id="myDropdown5" class="dropdown-content">
						Text not available
					</div>
				</div>
				<script>function dropDown5() {
					document.getElementById("myDropdown5").classList.toggle("show");
				}</script>
                [<a href="./publications/Qian_2003_EMBS_SegmentingCardiacMRITaggingLinesUsingGaborFilterBanks.pdf" target="_blank">pdf</a>
                | <a href="./publications/Qian_2003_EMBS_SegmentingCardiacMRITaggingLinesUsingGaborFilterBanks.bib" target="_blank">bib</a>
                | doi: <a href="https://doi.org/10.1109/IEMBS.2003.1279834" target="_blank">10.1109/IEMBS.2003.1279834</a>
                ]
                </br>
                </br>
                        
                Montillo A**, Axel L, Metaxas D. 
                <span class="pubtitle"> Automated Correction of Background Intensity Variation and Image Scale Standardization in 4D Cardiac SPAMM-MRI.</span>
                International Society of Magnetic Resonance In Medicine; 2003 July; c2003. 
                </br>
				<div class="dropdown">
					<button onclick="dropDown4()" class="dropbtn">Abstract</button>
					<div id="myDropdown4" class="dropdown-content">
						Text not available
					</div>
				</div>
				<script>function dropDown4() {
					document.getElementById("myDropdown4").classList.toggle("show");
				}</script>
                [<a href="./publications/Montillo-ISMRM-IntensityCorrectionAndStandardization.pdf" target="_blank">pdf</a>
                | <a href="./publications/Montillo-ISMRM-IntensityCorrectionAndStandardization.bib" target="_blank">bib</a>				
                ]
                </br>
                </br>
                        
                Montillo A**, Udupa J, Axel L, Metaxas D. 
                <span class="pubtitle"> Interaction between noise suppression and inhomogeneity correction in MRI.</span>
                Medical Imaging: Image Processing (SPIE). 2003 May; 1:1-12.
                </br>
				<div class="dropdown">
					<button onclick="dropDown3()" class="dropbtn">Abstract</button>
					<div id="myDropdown3" class="dropdown-content">
						Text not available
					</div>
				</div>
				<script>function dropDown3() {
					document.getElementById("myDropdown3").classList.toggle("show");
				}</script>
                [<a href="./publications/Montillo-MedicalImagingConf-InteractionBtwnFilteringAndCorrection.pdf" target="_blank">pdf</a>
                | <a href="./publications/Montillo-MedicalImagingConf-InteractionBtwnFilteringAndCorrection.bib" target="_blank">bib</a>
                | doi: <a href="https://doi.org/10.1117/12.483555" target="_blank">10.1117/12.483555</a>
                | PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31745377" target="_blank">31745377</a>
                | <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6863362" target="_blank">PMC6863362</a>
                ]
                </br>
                </br>
                        
                Montillo A, Bachelder I, Marrion CC, inventors. 
                <span class="pubtitle">Methods and apparatuses for measuring an extent of a group of objects within an image.</span>
                U.S. issued patent #6571006. 2003 February.
                </br>
                </br>
                
                Montillo A, Bachelder I, Marrion CC, inventors.
                <span class="pubtitle">Methods and apparatuses for refining a geometric description of an object having a plurality of extensions.</span>
                U.S. issued patent #6526165. 2003 February.
                </br>
                </br>

                Montillo A**, Metaxas DN, Axel L. 
                <span class="pubtitle">Automated segmentation of the left and right ventricles in 4D cardiac SPAMM images.</span>
                Medical Image Computing and Computer-Assisted Intervention. 2002 September; 1:620-633.
                </br>
				<div class="dropdown">
					<button onclick="dropDown2()" class="dropbtn">Abstract</button>
					<div id="myDropdown2" class="dropdown-content">
						Text not available
					</div>
				</div>
				<script>function dropDown2() {
					document.getElementById("myDropdown2").classList.toggle("show");
				}</script>
                [<a href="./publications/Montillo_2002_MICCAI_AutomatedSegmentationOfLeftAndRightVentriclesIn4DCardiacMRI.pdf" target="_blank">pdf</a>	
                | <a href="./publications/Montillo_2002_MICCAI_AutomatedSegmentationOfLeftAndRightVentriclesIn4DCardiacMRI.bib" target="_blank">bib</a>				
                | doi: <a href="https://doi.org/10.1007/3-540-45786-0_77" target="_blank">10.1007/3-540-45786-0_77</a>
                | PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31737869" target="_blank">31737869</a>
                | <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6857637" target="_blank">PMC6857637</a>
                ]
                </br>
                </br>

                Fischl B, Salat DH, Busa E, Albert M, Dieterich M, Haselgrove C, van der Kouwe A, Killiany R, Kennedy D, Klaveness S, Montillo A, Makris N, Rosen B, Dale AM**. 
                <span class="pubtitle"> Whole brain segmentation: automated labeling of neuroanatomical structures in the human brain.</span>
                Neuron. 2002 Jan 31;33(3):341-55.
                </br>
				<div class="dropdown">
					<button onclick="dropDown1()" class="dropbtn">Abstract</button>
					<div id="myDropdown1" class="dropdown-content">
						Text not available
					</div>
				</div>
				<script>function dropDown1() {
					document.getElementById("myDropdown1").classList.toggle("show");
				}</script>
                [<a href="./publications/Montillo-Neuron-LearningWholeBrainSegmentation.pdf" target="_blank">pdf</a>
                | <a href="./publications/Montillo-Neuron-LearningWholeBrainSegmentation.bib" target="_blank">bib</a>
                | doi: <a href="https://doi.org/10.1016/s0896-6273(02)00569-x" target="_blank">10.1016/s0896-6273(02)00569-x</a>
                | PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/11832223/" target="_blank">11832223</a>
                ]
                </br>
                </br>
                
                <b>Copyright Notice:</b> The materials are presented here may only be used for research purposes. Copyright and all rights therein are retained by authors or by other copyright holders. In most cases, these works may not be reposted or distributed without the explicit permission of the copyright holder.

              
              </div>
            </div>
          </div>
      </div>
	  <br>
    </div>
  </section>
  <!-- /Section: publications -->

 
   <!-- Section: Teaching 
    Deleted these lines ... to make the column wider as the other sections 
    <div class="heading-about">
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-lg-offset-2">
-->                
  <section id="Teaching" class="home-section text-center">
  <div class="container">
    <div class="wow fadeInDown" data-wow-delay="0.2s">
      <div class="team boxed-grey">
          <div class="inner">		
            <div class="section-heading">
                <h2>Teaching</h2>

                <h3>Curriculum development and instruction</h3>
                <p class="subtitle" align="justify", style="padding:0px; margin-bottom: 30px;">
                  Since joining the university, I have both contributed to existing courses and developed brand-new curricula. Here’s a summary. 
                  
                  <span style="display: block; margin-top: 10px;"><strong>Machine Learning Theory and Methods</strong> This course begins with the foundations of statistical learning theory, teaches model training, optimization, and regularization, (un)supervised learning, and progresses through empirical and structural risk minimization, clustering, neural networks, and survival analysis, and concludes with transfer learning, explainable AI/ML, and causal discovery and inference. 
                  </span>
                  
                  <span style="display: block; margin-top: 10px;"><strong>Advanced Deep Learning</strong> This course covers a broad array of practical architectures in deep learning, beginning with deep neural networks for regression, classification, and segmentation in image and sequence data (e.g., convolutional and recurrent neural networks). It progresses to graph neural networks, fair and trustworthy learning, contrastive learning, hyperparameter optimization, and generative modeling, including GANs, autoencoders, and diffusion models. The course concludes with transformers, foundation models, and methods for parameter efficient fine tuning.  
                  </span>
                  
                  <span style="display: block; margin-top: 10px;"><strong>Biomedical Informatics and Biostatistics</strong> This course spans all core aspects of biomedical informatics and biostatistics. Topics taught include fundamental descriptive statistics, probability theory, hypothesis testing, ANOVA, correlation/regression for high dimensional data, confidence intervals, experiment design, multiple comparisons correction, resampling methods, and Bayesian Decision theory. Hands-on labs and problem sessions are interleaved with didactic lectures throughout the course.
                  </span>
                  
                  <span style="display: block; margin-top: 10px;"><strong>Software Engineering for Research</strong>  This graduate level course covers the best programming practices for producing maintainable research code. This includes code review, software version control, fundamentals of object-oriented code design and implementation, debugging techniques, and experiment acceleration via distributed CPU and GPU hardware. All topics include hands-on labs illustrating generative AI examples (e.g., VAE models, GANs, and hybrid models, and their hyperparameter optimization) using TensorFlow and PyTorch.  
                  </span>

                  <span style="display: block; margin-top: 10px;"><strong>Causality Journal Club</strong>  I lead this cross-campus club where we discuss the latest statistical and machine learning-driven causal analysis literature, including causal discovery, causal inference, and causal deep learning. 
                  </span>

                </p>

                <h3>Mentoring methodology</h3>
                <p class="subtitle" align="justify", style="padding:0px; margin-bottom: 30px;">
                  <span style="display: block; margin-top: 10px;">I have the privilege of advising trainees of all levels, including doctoral, MD/PhD students, and master’s and undergraduate students, and postdoctoral fellows. Several of these are co-advised with colleagues in Neurology, Neuroscience, and Radiology. I have supervised master’s theses and served on doctoral committees and qualifying exam committees (BME, Computer Science, Biomedical informatics, Physics, and Electrical Engineering). I have closely mentored many of these students and have co-authored publications with several. <br>
                  </span>

                  <span style="display: block; margin-top: 10px;">
                    <strong>Results:</strong>  Students I have mentored have gone on to prestigious jobs in companies like Apple Inc., Texas Instruments, Capital One, and Intuitive Surgical, in government agencies (NIH), and to graduate programs/postdoc positions at GA Tech, the University of Washington, UCLA, UCSF, and the University of Pittsburgh, and have received prestigious fellowships (e.g., NIH F31 and the Turing Scholar Award). 
                  </span>

                  <span style="display: block; margin-top: 10px;">
                    <strong>Goals</strong> As a mentor, I emphasize several goals, including but not limited to student-centered 1:1 mentoring and  promoting honest, and vibrant scientific community citizenship.
                  </span>

                </p> 

                <h3>Diversification strategy and community outreach</h3>
                <p class="subtitle" align="justify", style="padding:0px">
                  As an active member of the scientific community, I aim to attain the following objectives. 
                  
                  <span style="display: block; margin-top: 10px;"><strong>Promote diversity at the university, department, and lab levels</strong>   Creating pathways to success for students from all backgrounds fundamentally improves research impact. To increase diversity and inclusion in STEAM fields, I aim to provide mentorship, educational resources, and research opportunities to groups that have traditionally been underrepresented, including women, racial and ethnic minorities, and individuals from economically disadvantaged backgrounds. 
                  </span>
                
                  <span style="display: block; margin-top: 10px;"><strong>K-12 outreach  </strong>  I aim to spark curiosity, encourage critical thinking, and help K-12 students see themselves as future scientists, engineers, or innovators. 
                  </span>
                  
                  <span style="display: block; margin-top: 10px;"><strong>Scientific community service</strong>  It is my pleasure to support the next generation of scientists through the scientific community. 
                  </span>
                  
                </p>
        </div> 
      </div>
    </div>
  </div>
  </div>
</section>

<!---  TEMPLATE FOR A STANDARD WIDTH SECTION
<section id="XXXXXXXXXXXX" class="home-section text-center">
  <div class="container">
    <div class="wow fadeInDown" data-wow-delay="0.2s">
      <div class="team boxed-grey">
          <div class="inner">		
            <div class="section-heading">
              <h2>Template XXXX section</h2>
        </div>
      </div>
    </div>
  </div>
  </div>
</section>
-->

<section id="code" class="home-section text-center">
  <div class="container">
    <div class="wow fadeInDown" data-wow-delay="0.2s">
      <div class="team boxed-grey">
          <div class="inner">		
            <div class="section-heading">
              <h2>Code Repositories</h2>
                <p align="justify">
                  We embrace open-source development and are pleased to support and contribute to the community. Codes and other resources for our publications and research efforts can be found on github through the following link:
                  <a href="https://github.com/DeepLearningForPrecisionHealthLab?tab=repositories" target="_blank">https://github.com/DeepLearningForPrecisionHealthLab</a>
                  <br>
                </p>    
            </div> 
          </div>
        </div>
      </div>
  </div>
</section>

  <!-- Section: positions_available -->
  <!-- <section id="GeneralPositionInformation" class="home-section text-center"> -->
  <!--AAM: Not centered -->
  <section id="GeneralPositionInformation" class="home-section">    
          <!-- <div class="heading-about"> -->
        <div class="container">
                <!--    <div class="row"> 
                <div class="col-lg-8 col-lg-offset-2"> -->
            <div class="wow fadeInDown" data-wow-delay="0.4s">
              <div class="team boxed-grey">
                <div class="section-heading">
                  <h2 class="text-center">Positions Available</h2>

                  <div class="wow fadeInLeft" data-wow-delay="0.2s">
                    <div class="team boxed-grey">
                      <div class="inner">
                        <p align="justify">
                          <span style="display: block; margin-top: 10px;">The Montillo Lab (www.montillolab.org ) in the Departments of <a href="https://www.utsouthwestern.edu/departments/bioinformatics/" target="_blank">Bioinformatics</a> & <a href="https://www.utsouthwestern.edu/departments/biomedical-engineering/" target="_blank">Biomedical Engineering</a> at the University of Texas Southwestern in Dallas, TX is looking for full-time postdocs and research scientists to develop novel machine learning (ML) approaches for analyzing medical images, clinical, multi-omic, and speech data. 
                          </span>
        
                          <span style="display: block; margin-top: 10px;">Our lab's primary focus is on developing the <strong>theory</strong> and <strong>application</strong> of ML and causal modeling to guide prognosis and treatment decisions and to elucidate treatment mechanisms for applications in neurological disorders and oncology. We develop the <strong>theory of ML</strong> by improving how ML models learn. Existing models merely quantify predictor-target correlations and fail to quantify causal relationships. These models do not handle aleatoric and epistemic uncertainty and don’t provide statistically meaningful covariate significance. Using our experience developing new deep learning (DL) frameworks that enable any neural network to handle sample clustering from repeat-measure (non-iid) data, we aim to develop approaches integrating ideas from causal discovery with Bayesian DL.  In our <strong>clinical applications</strong>, for example in Parkinson’s Disease (PD), when standard drugs fail to provide adequate relief, deep brain stimulation (DBS) surgery can be restorative; however, there is no tool to identify who will respond or how it works. Based on our success in developing causal ML measures that predict PD trajectory, we aim to develop further models predictive of outcomes by fusing neurologists’ knowledge with probabilistic, interpretable deep learning.
                          </span> 
        
                          <span style="display: block; margin-top: 10px;">With cutting-edge computational infrastructure, access to leading neuropathophysiology and oncology experts, and an unparalleled trove of medical images, multi-omic data, and speech samples, our machine learning lab in the BME and bioinformatics departments of a leading academic medical center is poised for success in these research endeavors. What we need now are <strong>brilliant postdocs</strong> and a <strong>research scientist</strong> who are eager to innovate, think beyond traditional models, and explore bold new directions in biomedical research.
                          </span> 
        
                          <span style="display: block; margin-top: 10px;">Through close collaborations with neurologists, psychiatrists, surgeons, and neuroscientists, our lab offers truly interdisciplinary training: you will work on problems at the cutting edge of machine learning and pathophysiology.  We are a dynamic and forward-thinking lab situated at the forefront of two rapidly growing departments committed to an entrepreneurial approach to research, with a flexible work culture and competitive compensation. Additionally, our university provides <a href="https://portal.biohpc.swmed.edu/" target="_blank">world-class computational resources</a> and <a href="https://www.utsouthwestern.edu/departments/airc/" target="_blank">research-dedicated high field imaging</a> so that your efforts are focused solely on scientific innovation.
                          </span> 
        
                          <p style="font-size: 16px;">To learn more about and apply to our positions, use the POSITIONS AVAILABLE menu (above) to navigate to the appropriate subsection.</p>
                          
        
          
        
        
        
                          <p style="font-size: 12px; font-style: italic;">
                            UT Southwestern Medical Center is committed to an educational and working environment that provides equal opportunity to all members of the University community.  As an equal opportunity employer, UT Southwestern prohibits unlawful discrimination, including discrimination on the basis of race, color, religion, national origin, sex, sexual orientation, gender identity, gender expression, age, disability, genetic information, citizenship status, or veteran status.  To learn more, please visit this <a href="https://jobs.utsouthwestern.edu/why-work-here/diversity-inclusion" target="_blank">link</a>.
                          </p>
                
        
        
                        </p>
                          <!--<h3>Title?</h3>-->
                          <!-- 
                          <p align="justify">
                          The laboratory of Albert Montillo in the Bioinformatics Department at the UT Southwestern Medical Center is an interactive and collaborative team conducting cutting-edge research to advance the theory and application of machine learning for medical image analysis. We address unmet clinical needs by forming predictive models that make diagnoses and prognoses more precise and advance neuroscience by furthering the understanding of mechanisms in disease and intervention. Medical image analysis software the lab has developed include machine learning-based methods for labeling structures throughout the brain (parcellation), versions of which are used worldwide and FDA approved. The lab has built deep learning methods to label networks in resting state fMRI and detect artifacts in MEG. The lab has pioneered deep learning decision forests that increase prediction accuracy while reducing prediction time and outcome prediction methods using structural and functional connectomics. Building off these capabilities, we plan to develop novel modeling and outcome prediction tools for mental & neurodevelopmental disorders, and neurodegenerative diseases.
                          <br>
                          <br>
                          
                          The lab is co-located within the Bioinformatics Department on UT Southwestern’s south campus and embedded in the Radiology Department on north campus. We are an integral part of the Advanced Imaging Research Center, and work closely with research groups within Neuroscience, Neurology, Psychiatry, Radiation Oncology, and Surgery. Lab members have access to extensive computational resources, including the >6,800-core cluster with >8 Petabyte of storage available through UTSW’s high-performance infrastructure ( BioHPC  ). Members have access to multiple research-dedicated scanners (such as 7T and 3T MRI) and the opportunity to work on a range of image analysis, machine learning and modeling projects on interdisciplinary teams, and participate in all aspects of method development and data analysis with collaborators.
                          <br>
                          <br>
                          <i>UT Southwestern Medical Center is an Affirmative Action/Equal Opportunity Employer. Women, minorities, veterans and individuals with disabilities are encouraged to apply.</i>
        
        
                          </p>
                        -->
                        <section id="PostdoctoralFellowshipPositions"></section>
                        <h3 class="text-center">Postdoctoral Fellowship Positions</h3>
                        
                        <p align="justify" style="margin-top: 5px;  margin-bottom: 5px;">
                        Use the links below to read about and apply to our open postdoctoral fellowship positions:
                      
                        <ol style="font-size: 16px; margin-top: 5px;">
                          <li><a href="#PostdocExplainableCausalML">Explainable, causal machine learning</a></li>
                          <li><a href="#PostdocImageAnalysis">Neuroimage and medical image analysis using foundation models</a></li>
                          <li><a href="#PostdocImageGuidedCancerSurgery">Foundation models for image-guided cancer surgery</a></li>
                          <li><a href="#PostdocComputationalLinguistics">Computational linguistics for speech impairment characterization</a></li>                    
                        </ol>
                      </p>
        
                       <!-------------------------------------------------------------------------------------------------------------->    
                       <section id="PostdocExplainableCausalML"></section>
                            <h4>Explainable, causal machine learning for biomedicine</h4>
                            <p align="justify">
                              <h5>Job responsibilities</h5>
                              The central goal of this position is to develop new machine learning frameworks to overcome the limitations of current models. Some of these limitations include that users do not know when to trust the models since they don’t generally output a true probabilistic confidence and that models don’t account for epistemic and aleatoric uncertainty, nor biases in the dataset. In addition, models merely identify predictor-target correlations, rather than causal relationships. This position entails devising new Bayesian deep learning (DL) frameworks that provide statistically meaningful models that alleviate these limitations, while increasing performance and interpretability. Additionally, we will encode knowledge of pathophysiological processes to guide Bayesian causal discovery and deep learning inference, to attain a human + AI intelligence integration that is explainable and offers the greatest capacity to answer interventional and counterfactual queries. 
                              </p>
        
                            <h5>Requirements</h5>
                            <ul style="font-size: 16px;">
                              <li>A PhD or MD/PhD in biomedical informatics, computer science, biomedical or electrical engineering, statistics, physics, or any related field providing a firm computational/analytical background.</li>
                              <li>A track record of publishing high-quality research papers in any of these fields.</li>
                              <li>Strong expertise and hands-on experience innovating new machine learning frameworks or individual novel methods.</li>
                              <li>Strong programming ability in python, R, C/C++, or another programming language used in data science.</li>                      
                            </ul>
                            
                            <p align="justify" style="margin-bottom: 20px;">
                            Previous experience in explainable AI, causal inference/discovery, Bayesian neural networks, or probabilistic machine learning,  is advantageous, but not mandatory.  Advanced probability and statistics are also strengths for this position, particularly when combined with a commitment to mastering machine learning. 
                            </p>
        
                            <h5>Apply</h5>
                            <p align="justify">The postdoctoral fellowship position is available immediately and we will accept applications until the position is filled; early application is strongly recommended. To apply, please send (1) a detailed curriculum vitae with publication list, (2) the names and contact information of three references, (3) and PDFs of your two most significant publications or preprints using this link:  
                                <a href="mailto:albert.montillo@utsouthwestern.edu?subject=Application Materials for Postdoctoral Fellowship">
                                  Albert A. Montillo, Ph.D. (albert.montillo@utsouthwestern.edu).
                                </a>
                            </p>
        
                       <!-------------------------------------------------------------------------------------------------------------->    
                       <section id="PostdocImageAnalysis"></section>
                            <h4>Neuroimage and medical image analysis using foundation models</h4>
        
                            <h5>Job responsibilities</h5>
                            <p align="justify">
                            A central objective of this position is to develop novel deep learning models to predict diagnoses and outcomes from patient data including imaging, such as multicontrast MRI (fMRI, diffusion MRI, MEG/EEG, PET/SPECT) and corresponding genomic, metabolic and clinical data. <br>
                            By helping to discover image-based biomarkers, including advanced brain connectivity measures, and differentially expressed metabolic markers and genes, you will help improve early and accurate disease diagnosis, and develop tools to predict treatment outcomes in mental & neurodevelopmental disorders and neurodegenerative diseases. <br>
                            Your methods will also be used to optimize non-invasive brain stimulation therapies.<br>
                            </p>
        
                            <h5>Requirements</h5>
                            <ul style="font-size: 16px;">
                              <li>A PhD or MD/PhD in biomedical informatics, computer science, biomedical or electrical engineering, statistics, physics, or any related field providing a firm computational/analytical background.</li>
                              <li>A track record of publishing high-quality research papers in any of these fields.</li>
                              <li>Strong expertise and hands-on experience processing medical image data using machine learning.</li>
                              <li>Strong programming ability in python, R, C/C++, or another programming language used in data science.</li>
                            </ul>
                          
                            <p align="justify" style="margin-bottom: 20px;">
                            Previous experience in neuroimage analysis (image formats and preprocessing pipelines), and explainable AI methods is advantageous, but not mandatory. Outstanding candidates with a strong neuroscience or radiology background may also be considered if they have exhibited a commitment to mastering machine learning.
                            </p>  
        
                            <h5>Apply</h5>
                            <p align="justify">The postdoctoral fellowship position is available immediately and we will accept applications until the position is filled; early application is strongly recommended. To apply, please send (1) a detailed curriculum vitae with publication list, (2) the names and contact information of three references, (3) and PDFs of your two most significant publications or preprints using this link:  
                                <a href="mailto:albert.montillo@utsouthwestern.edu?subject=Application Materials for Postdoctoral Fellowship">
                                  Albert A. Montillo, Ph.D. (albert.montillo@utsouthwestern.edu).
                                </a>
                            </p>
        
                           
        
                        <!-------------------------------------------------------------------------------------------------------------->    
                        <section id="PostdocImageGuidedCancerSurgery"></section>
                            <h4>Foundation models for image-guided cancer surgery</h4>
                            <p align="justify">
                              <h5>Job responsibilities</h5>
                              A central goal of this position is to improve outcomes in endoscopy-guided cancer surgery, working closely with our surgeons in the Otolaryngology - Head & Neck surgery department. The complexity of soft-tissue endoscopy video has meant that the analysis of this rich source of information using traditional machine learning is inadequate to guide surgery and improve outcomes. We are well-positioned to change the status quo by developing performant DL-based models and segmentation methods. We aim to do this by (1) exploiting a successful pan-cancer contrast agent (dye) developed at UTSW as grounding information and (2) integrating expert surgeon knowledge, foundation models, and our large endoscopy database. 
                              </p>
        
                            <h5>Requirements</h5>
                            <ul style="font-size: 16px;">
                              <li>A PhD or MD/PhD in biomedical informatics, computer science, biomedical or electrical engineering, statistics, physics, or any related field providing a firm computational/analytical background.</li>
                              <li>A track record of publishing high-quality research papers in any of these fields.</li>
                              <li>Strong expertise and hands-on experience processing image and/or video data.</li>
                              <li>Strong programming ability in python, R, C/C++, or another programming language used in data science.</li>
                            </ul>
                            
                            <p align="justify" style="margin-bottom: 20px;">
                            Previous experience in segmentation, endoscopy analysis, and foundation models is advantageous, but not mandatory. Outstanding candidates with a strong oncology or radiology background may also be considered if they have exhibited a commitment to mastering machine learning.
                            </p>                    
        
                            <h5>Apply</h5>
                            <p align="justify">The postdoctoral fellowship position is available immediately and we will accept applications until the position is filled; early application is strongly recommended. To apply, please send (1) a detailed curriculum vitae with publication list, (2) the names and contact information of three references, (3) and PDFs of your two most significant publications or preprints using this link:  
                                <a href="mailto:albert.montillo@utsouthwestern.edu?subject=Application Materials for Postdoctoral Fellowship">
                                  Albert A. Montillo, Ph.D. (albert.montillo@utsouthwestern.edu).
                                </a>
                            </p>                     
                        <!-------------------------------------------------------------------------------------------------------------->    
                        <section id="PostdocComputationalLinguistics"></section>
                            <h4>Computational linguistics for speech impairment characterization</h4>
                            <p align="justify">
                              We are seeking a highly motivated and skilled Postdoctoral Fellow to join the lab of Dr. Albert Montillo at the University of Texas Southwestern Departments of Bioinformatics and BME. This position offers an exciting opportunity to contribute to cutting-edge research in the development of diagnostic tools using Large Language Models (LLM). The successful candidate will play a pivotal role in advancing our understanding of LLM applications in neurological disorders such as Alzheimer’s.
                              </p>
        
                            <h5>Job responsibilities</h5>
                            <ul style="font-size: 16px; margin-bottom: 20px;">
                              <li>Conduct research and development activities using state-of-the-art Large Language Models (LLM) for processing speech in a clinical environment. Orchestrate LLMs running locally and remotely.</li>
                              <li>Collaborate with a multidisciplinary team of researchers to design and implement novel algorithms and models for the analysis of clearly and unclearly spoken text.</li>
                              <li>Analyze large-scale datasets, extract relevant biomarkers, and develop innovative approaches to improve the accuracy and efficiency of diagnostic information from speech.</li>
                              <li>Evaluate algorithm performance using rigorous experiment design and benchmarks.</li>
                              <li>Publish research findings in high-impact journals and present at scientific conferences and seminars.</li>
                              <li>Assist in mentoring junior researchers.</li>
                              <li>Develop grant writing skills.</li>
                            </ul>
        
                            <h5>Requirements</h5>
                            <ul style="font-size: 16px;">
                              <li>A PhD or MD/PhD in biomedical informatics, computer science, biomedical or electrical engineering, statistics, physics, or any related field providing a firm computational/analytical background.</li>
                              <li>A track record of publishing high-quality research papers in any of these fields.</li>
                              <li>Strong expertise and hands-on experience in using LLMs for text processing.</li>
                              <li>Strong programming ability in python, R, C/C++, or another programming language used in data science.</li>
                            </ul>
                            
                            <p align="justify" style="margin-bottom: 20px;">
                            Previous experience in speech analysis, computational linguistics, and audio/voice analysis is highly advantageous, but not mandatory. Experience in speech impairment is desirable. Outstanding candidates with a strong neuroscience, neuropsychology, or cognitive psychology background may also be considered if they have exhibited a commitment to mastering machine learning.
                            </p>
        
                            <h5>Apply</h5>
                            <p align="justify">The postdoctoral fellowship position is available immediately and we will accept applications until the position is filled; early application is strongly recommended. To apply, please send (1) a detailed curriculum vitae with publication list, (2) the names and contact information of three references, (3) and PDFs of your two most significant publications or preprints using this link:  
                              <a href="mailto:albert.montillo@utsouthwestern.edu?subject=Application Materials for Postdoctoral Fellowship">
                                Albert A. Montillo, Ph.D. (albert.montillo@utsouthwestern.edu).
                                <br>  <!-- these br's are MANDATORY to allow the mailto link above to be clickable. Must have this for the last position in each section  -->
                                <br>
                              </a>
                            </p>         

                        <!-------------------------------------------------------------------------------------------------------------->                             
                        <section id="ResearchScientistPositions"></section>
                            <h3 class="text-center">Research Scientist Positions</h3>
                            <p align="justify" style="margin-top: 5px;  margin-bottom: 5px;">
                              Use the links below to read about and apply to our open research scientist positions:
                            
                              <ol style="font-size: 16px; margin-top: 5px;">
                                <li><a href="#ResScientistBiomedicalDataAnalysis">Machine learning for biomedical data analysis, foundation models and explainable AI</a></li>                      
                              </ol>
                            </p>
              
                            <!----------->
                            <section id="ResScientistBiomedicalDataAnalysis"></section>
                            <h4>Machine learning for biomedical data analysis, foundation models, and explainable AI</h4>
                            <p align="justify">
                              Our lab’s focus is on developing the theory and application of deep learning (DL) and causal modeling to elucidate treatment mechanisms, and to guide prognosis and treatment decisions with applications in neurological disorders and oncology. With cutting-edge computational infrastructure, access to leading experts in neurology, neuroscience, and cancer surgery, and an unparalleled trove of medical images and multi-omic data, our machine learning lab in the BME and bioinformatics departments of a leading university and academic medical center is poised for success in these research endeavors. What we need now are motivated research scientists who are eager to apply their skills, think beyond traditional approaches, and develop bold new applications in biomedical research.
                              </p>
            
                            <h5>Job responsibilities</h5>
                            <ul style="font-size: 16px; margin-bottom: 20px;">
                              <li>Construction of machine learning models for biomedical data analysis.</li>
                              <li>Development and implementation of methods for explainable AI revealing intricacies about what our models have learned.</li>
                              <li>Neuroimage and medical image analysis pipeline development.</li>
                            </ul>
            
                            <p align="justify" style="margin-bottom: 20px;">
                            It is expected that the  research scientist will work closely with postdoctoral research fellows and the PI, implementing solutions for our clinical and basic science collaborators. Our clinical collaborations entail developing tools to help physicians select the best treatment for conditions related to mental health, neurodegeneration, and neurodevelopmental disorders. In our basic science collaborations, we are identifying new causal biomarkers of disease pathophysiology.
                            </p>
            
                            <h5>Requirements</h5>
                            <ul style="font-size: 16px;">
                              <li>A master’s or PhD in computer science, biomedical or electrical engineering, statistics, physics, or any related field providing a firm computational/analytical background.</li>
                              <li>Publications demonstrating the application of leading methods and/or algorithmic innovation.</li>
                              <li>Strong programming ability and experience with machine learning.</li>
                              <li>Software maintenance with soruce control (e.g., git), documentation, containerization, and efficient builds (e.g., cmake).</li>
                            </ul>
            
                            <p align="justify" style="margin-bottom: 20px;">
                              Previous experience in image analysis (e.g. MRI, endoscopy), PEFT for FMs, explainable AI, causal discovery/ inference is advantageous, but not mandatory.  Candidates with a strong neuroscience, oncology, or radiology background may be considered if they have exhibited a commitment to mastering ML.
                            </p>
            
                            <h5>Apply</h5>
            
                            <p align="justify">
                              This research scientist position is available immediately and we will accept applications until the position is filled; early application is strongly recommended. To apply, please send (1) your resume or CV including a list of publications, (2) transcript of college courses completed if available (unofficial is acceptable), (3) links to code repositories you have authored, and (4) contact information for three references using this link:  
                              <a href="mailto:albert.montillo@utsouthwestern.edu?subject=Research Scientist Position application materials">
                                Albert A. Montillo, Ph.D. (albert.montillo@utsouthwestern.edu).
                                <br>  <!-- these br's are MANDATORY to allow the mailto link above to be clickable. Must have this for the last position in each section -->
                                <br>
                              </a>
                            </p>          

                        <section id="PhDStudentResearchAssistantPositions"></section>
                            <h3 class="text-center">PhD Student Research Assistant Positions</h3>
                            <p align="justify">Current students (Ph.D. students at UT Southwestern, University of Texas Dallas (UTD), University of Texas Arlington (UTA), Southern Methodist University (SMU), and  <a href="https://www.utsouthwestern.edu/education/medical-school/academics/combined-degrees/mstp/" target="_blank">MSTP</a> MD/Ph.D. students) interested in joining our team, should arrange a meeting by reaching out via this link 
                              <a href="mailto:albert.montillo@utsouthwestern.edu?subject=Student/Research Assistant application materials">
                                Albert A. Montillo, Ph.D. (albert.montillo@utsouthwestern.edu).
                              </a>                      
                            The research experience in our lab provides a great opportunity to supplement your background in computer science, engineering, statistics, physics or neuroscience with robust training in scientific algorithm development and computational modeling while conducting cutting-edge research to advance the theory and application of machine learning for medical image analysis.
                            </br>
                            </br>
                            Prospective students should mention my name (Albert Montillo) on their application and need to <a href="https://www.utsouthwestern.edu/education/graduate-school/application-and-admissions/basic-sciences.html" target="_blank">apply for UTSW graduate school admission</a> before the university’s FIXED December 1st deadline, and preferably by November 1st. Be sure to explicitly indicate your interest in my lab in your application. For prospective Ph.D. students, the Ph.D. program in Biomedical Engineering, and in particular the <a href="https://www.utsouthwestern.edu/education/graduate-school/programs/phd-degrees/biomedical-engineering/biomedical-and-molecular-imaging.html" target="_blank">Imaging Track</a>, is one often pursued by students in our lab. Other suitable tracks include Medical Physics, Molecular Biophysics, and Computational Biology. Computer Science and Engineering (BME/EE) programs at UTD, UTA, and SMU are also suitable programs for our lab. For M.D./Ph.D. applicants, the MSTP admission deadline is November 1st.
                            </p align="justify">                            

                      </div>
                    </div>
                  </div>


                </div>
              </div>
            </div>
        </div>
</section>
<!-- /Section: positions_available -->


  
  <!-- Section: Gallery -->
    <div class="modal fade" id="image-gallery" tabindex="-1" role="dialog lg" aria-labelledby="myModalLabel" aria-hidden="true">
        <div class="modal-dialog">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal">&times;</button>
                    <h3 class="modal-title">GALLERY</h3>
                </div>
                <div class="modal-body">
                    <img id="image-gallery-image" class="img-responsive" src="">
                    <p style="padding:2px;"></p>
                    <div class="col-md-12 text-justify" id="image-gallery-caption">
                        This text will be overwritten by jQuery
                    </div>
                </div>
                <div class="modal-footer">
                    <div>
                    <button type="button" class="btn prev" id="show-previous-image">Previous</button>
                    <button type="button" id="show-next-image" class="btn next">Next</button>
                    </div>
                </div>
            </div>
        </div>
    </div> 
 

  <!-- Section: news -->
  <section id="news" class="home-section text-center bg-gray">
    <div class="heading-about">
      <div class="container">
        <div class="row">
          <div class="col-xs-8 col-xs-offset-2">
            <div class="wow fadeInDown" data-wow-delay="0.4s">
              <div class="section-heading">
                <h2>News</h2>
                <i class="fa fa-2x fa-angle-down"></i>

              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    <div class="container">
      <div class="row">
        <div class="col-xs-2 col-xs-offset-5">
          <hr class="marginbot-50">
        </div>
      </div>
	  <div class="row">
          <div class="wow fadeInLeft" data-wow-delay="0.2s">
            <div class="team boxed-grey">
              <div class="inner">

        <!--  TEMPLATE
        <h3 style="margin-bottom: 5px;">xxxx</h3>
        <p style="margin-top: 5px;  margin-bottom: 20px;">
          xxxx
        </p>
        -->       

        <h3 style="margin-bottom: 5px;">July 2025</h3>
        <p style="margin-top: 5px;  margin-bottom: 20px;">
          Welcome Usitha to the lab!
        </p>  


        <h3 style="margin-bottom: 5px;">June 2025</h3>
        <p style="margin-top: 5px;  margin-bottom: 20px;">
          Welcome Khushi to the lab!
        </p>  

        <h3 style="margin-bottom: 5px;">May 2025</h3>
        <p style="margin-top: 5px;  margin-bottom: 20px;">
          Our paper is accepted at the American Neurology Association's annual meeting. Congratulations Brandon!<br>
          Aixa presents our batch effects modeling and visualization framework for scRNA-seq at the Great Lakes Bioinformatics Conference in Minneapolis, MN. Well done!
        </p>  

        <h3 style="margin-bottom: 5px;">Spring 2025</h3>
        <p style="margin-top: 5px;  margin-bottom: 20px;">
          Albert, Aixa, Austin, and Son develop and teach our core course on SWE for computational/AI research. 
        </p>  

        <h3 style="margin-bottom: 5px;">Feb 2025</h3>
        <p style="margin-top: 5px;  margin-bottom: 20px;">
          Our PLOS-ONE paper is published. Congratulations Kevin and our iternational team!
        </p>        

        <h3 style="margin-bottom: 5px;">Jan 2025</h3>
        <p style="margin-top: 5px;  margin-bottom: 20px;">
          Austin passes BME Exam 2. Congratulations Austin!
        </p>        


        <h3 style="margin-bottom: 5px;">December 2024</h3>
        <p style="margin-top: 5px;  margin-bottom: 20px;">
          Albert attends NeurIPS 2024.
        </p>        
        
        <h3 style="margin-bottom: 5px;">November 2024</h3>
        <p style="margin-top: 5px;  margin-bottom: 20px;">
          Our breast cancer prognostics paper is featured in this NVIDIA 
          <a href="https://developer.nvidia.com/blog/?p=91133&preview=1&_ppp=6550126fe6" target="_blank">news article.</a>
        </p>        

        <h3 style="margin-bottom: 5px;">October 2024</h3>
        <p style="margin-top: 5px;  margin-bottom: 20px;">
          Aixa wins a travel award for the Best Bioinformatics Scientific Presentation. Way to go, Aixa!!<br>
          Albert, Aixa, and Ameer instruct scientists, students and postdocs in advanced deep learning.
        </p>        
        

        <h3 style="margin-bottom: 5px;">September 2024</h3>
        <p style="margin-top: 5px;  margin-bottom: 20px;">
          Youngest member of our lab is born, Khang An Nguyen. Congrats to Son & Thuong!<br>
          Aixa unconditionally passes qualifying exam 2, dissertation proposal. Nice job Aixa!
        </p>                

        <h3 style="margin-bottom: 5px;">May 2024</h3>
        <p style="margin-top: 5px;  margin-bottom: 20px;">
          A CBIIT news article featuring our Breast Cancer prognostics machine learning model is live at this 
          <a href="https://datascience.cancer.gov/news-events/news/machine-learning-blends-imaging-and-clinical-data-refine-breast-cancer-care" target="_blank">link</a><br>
          Albert serves as a grant reviewer on an NSF panel and on an NIH study section.
        </p>


        <h3 style="margin-bottom: 5px;">April 2024</h3>
        <p style="margin-top: 5px;  margin-bottom: 20px;">
          Our breast cancer research on: Machine Learning Prediction of Lymph Node Metastasis in Breast Cancer: Performance of a Multi-institutional MRI-based 4D Convolutional Neural Network, appears in the journal, Radiology:Imaging Cancer and is accessible via this  
          <a href="https://pubs.rsna.org/doi/10.1148/rycan.230107" target="_blank">link</a>
        </p>        

        <h3 style="margin-bottom: 5px;">March 2024</h3>
        <p style="margin-top: 5px;  margin-bottom: 20px;">
          Albert is promoted to Associate Professor with Tenure.
        </p>

        <h3 style="margin-bottom: 5px;">February 2024</h3>
        <p style="margin-top: 5px;  margin-bottom: 20px;">
          Our method for the Longitudinal prognosis of Parkinson’s outcomes using causal connectivity appears in the journal NeuroImage:Clinical and is accessible via this <a href="https://doi.org/10.1016/j.nicl.2024.103571" target="_blank">link</a>
        </p>

        <h3 style="margin-bottom: 5px;">December 2023</h3>
        <p style="margin-top: 5px;  margin-bottom: 20px;">
            Our paper on machine learning for improving the reproducibility of functional and causal connectivity from functional MRI is accepted into the Journal of Neural Engineering. Congratulations Cooper!
        </p>      

        <h3 style="margin-bottom: 5px;">August 2023</h3>
        <p style="margin-top: 5px;  margin-bottom: 20px;">
          Dr. Montillo teaches scientific programming with Python in our bootcamp to incoming PhD students. 
        </p>  

        <h3 style="margin-bottom: 5px;">June 2023</h3>
        <p style="margin-top: 5px;  margin-bottom: 20px;">
          Dr. Montillo gives an invited talk at Oxford University in the UK.  Albert serves as a grant reviewer on NIH study section.<br>
          Adam Wang joins the lab. Welcome Adam!
        </p>          

        <h3 style="margin-bottom: 5px;">May 2023</h3>
        <p style="margin-top: 5px;  margin-bottom: 20px;">
          Dr. Montillo gives an invited talk at NYU in NYC, NY.  Albert, Son and Austin teach SW engineering for Research to incoming PhD students.<br>
          Dr. Montillo attends Royal Society Mtg, London, UK.<br>
        </p>  

        <h3 style="margin-bottom: 5px;">March 2023</h3>
        <p style="margin-top: 5px;  margin-bottom: 20px;">
          More progress on our Parkinson’s Imaging study. Way to go team!
        </p>    

        <h3 style="margin-bottom: 5px;">February 2023</h3>
        <p style="margin-top: 5px;  margin-bottom: 20px;">
          Our paper on Mixed Effects Deep Learning is accepted into IEEE TPAMI. Congratulations Kevin!<br>  
          Dr Montillo gives an invited talk at SMU.  Dr Montillo teaches Biomedical Informatics and Biostatistics this semester. 
        </p>  

        <h3 style="margin-bottom: 5px;">January 2023</h3>
        <p style="margin-top: 5px;  margin-bottom: 20px;">
          Alex joins PCCI as a research scientist. Congratulations!  Montillo lab is awarded an R01 grant from NIGMS for the next 5 years. 
        </p>  

        <h3 style="margin-bottom: 5px;">December 2022</h3>
        <p style="margin-top: 5px;  margin-bottom: 20px;">
          Alex successfully defends. Way to go Alex.<br>
          Austin joins the lab. Welcome Austin!
        </p>          

        <h3 style="margin-bottom: 5px;">November 2022</h3>
        <p style="margin-top: 5px;  margin-bottom: 20px;">
          Dr Montillo gives a seminar to the Neurology dept, UTSW and an invited talk at the Bioengineering Dept at UTD.<br>
          Cooper gives an invited presentation to NIH NINDS. Nice job Cooper!
        </p>            

        <h3 style="margin-bottom: 5px;">August 2022</h3>
        <p style="margin-top: 5px;  margin-bottom: 20px;">
          Alex's work on machine learning for glaucoma diagnosis is published in Clinical Ophthalmology. Great job Alex!<br>
          Dr. Montillo teaches mathematical modeling with python in the Programming Bootcamp at UTSW along with TAs: Aixa and Alex.
        </p>          

        <h3 style="margin-bottom: 5px;">June 2022</h3>
        <p style="margin-top: 5px;  margin-bottom: 20px;">
          Cooper and Kevin successfully defend their PhD theses. Congratulations!<br>
          Summer lab pool party at the Montillo's residence. Fun in the sun celebrating our many successes this year!  
        </p>    
        
        <h3 style="margin-bottom: 5px;">May 2022</h3>
        <p style="margin-top: 5px;  margin-bottom: 20px;">
          Dr. Montillo gives an invited talk on MEG artifact suppression via spatiotemporal deep learning at the ASNR conference.<br>
          Krishna's paper on brain segmentation via deep learning is accepted into this year's OHBM conference.<br> 
          Dr. Montillo teaches module 2 (Object Oriented Programming) in the Bioinformatics Software Engineering course
        </p>          

        <h3 style="margin-bottom: 5px;">April 2022</h3>
        <p style="margin-top: 5px;  margin-bottom: 20px;">
          PhD student, Aixa X. Andrade joins the lab. Welcome Aixa!<br>
          Albert prepares a new course on Architectures and Applications of Deep Learning with a focus on GANs and VAEs. 
        </p>            

        <h3 style="margin-bottom: 5px;">March 2022</h3>
        <p style="margin-top: 5px;  margin-bottom: 20px;">
          Welcome to rotation students Austin Marckx and Conor McFadden! 
        </p>          

        <h3 style="margin-bottom: 5px;">February 2022</h3>
        <p style="margin-top: 5px;  margin-bottom: 20px;">
          Kevins's manuscript is featured in multiple press releases at <a href="https://www.utsouthwestern.edu/newsroom/articles/year-2021/new-imaging-biomarkers.html" target="_blank">UTSW</a>, <a href="https://www.forbes.com/sites/victoriaforster/2021/11/22/scientists-identify-way-to-predict-response-to-antidepressants/?sh=4303ed1049a8" target="_blank">Forbes</a>, and <a href="https://www.sciencedaily.com/releases/2021/11/211109135012.htm" target="_blank">Science Daily</a>. Awesome, Kevin!<br>
          Karel's manuscript defining metabolites predictive of Alzheimer’s Disease in blood plasma and donated brain tissue was accepted into the Journal of Alzheimer’s Disease. Nice, Karel!
        </p>    

        <h3 style="margin-bottom: 5px;">January 2022</h3>
        <p style="margin-top: 5px;  margin-bottom: 20px;">
          Vyom's manuscript on the pitfalls and recommended strategies and metrics to suppress fMRI motion artifacts is accepted into Neuroinformatics. Excellent work, Vyom!<br>
          Cooper's manuscript detailing the reproducible neuroimaging features that enable the diagnosis of Autism Spectrum Disorder with machine learning is accepted into the journal Scientific Reports. Nice job Cooper.
        </p>    

        <h3>November 2021</h3>
        Alex’s manuscript on automated removal of artifact from magnetoencephalography is published in NeuroImage. Awesome job Alex!
              </p>
              </br>
        <h3>September 2021</h3>
        Kevin Nguyen’s manuscript on the prediction of Antidepressant outcomes for Major Depressive Disorder patients from fMRI is published in Biological Psychiatry. Well done Kevin!
              </p>
              </br>
        <h3>August 2021</h3>
              </br>
        Albert teaches Python Programming Bootcamp to incoming PhD students at UTSW.
              </p>
              </br>
			  
        <h3>March 2021</h3>
        Congratulations to former undergraduate student Yenho Chen who has been admitted to the Machine Learning Ph.D. program at Georgia Tech with the President’s Fellowship award.<br>
        Congratulations to former high school student Meyer Zinn who was admitted to the Computer Science BS program at the University of Texas Austin with the Turing Scholarship award.
              </p>        
              </br>

        <h3>February 2021</h3>
        Kevin Nguyen’s manuscript on Parkinson’s disease prognostics from fMRI is published in Parkinsonism and Related Disorders. Nice job Kevin!
              </p>
              </br>

        <h3>January 2021</h3>
        Welcome to undergraduate Atef Ali, who has joined the lab as part of the UTSW Bioinformatics Gap Year program! Also welcome to rotation student Mahak Virlley!
              </p>
              </br>

        <h3>September 2020</h3>
        Son Nguyen gives a talk at MICCAI on predicting breast cancer metastases to the axillary lymph nodes. Well done Son!
              </p>
              </br>

			  <h3>August 2020</h3>
			  Group outing: team Montillo takes to the Katy trail for a morning bike ride. Fun!
              </p>
              </br>
			  
			  <h3>July 2020</h3>
			  Team Montillo hosts several codefests exchanging best ML implementation practices.
              </p>
              </br>
			  
        <h3>June 2020</h3>
			  Vyom graduates and is accepted into the MD/PhD program at the University of Washington. Great news!
              </p>
              </br>
			  
			  <h3>May 2020</h3>
			  Son Nguyen's breast cancer prognostics full-length peer reviewed paper is accepted into premier conference, MICCAI. Awesome!
              </p>
              </br>
			  
			  <h3>April 2020</h3>
			  Cooper reveals features important for deep learning model to diagnose Autism at ISBI. 
			  Vyom presents an omnibus model for improved motion suppression in fMRI. Excellent work!
              </p>
              </br>
			  
			  <h3>March 2020</h3>
			  Vyom presents prediction of individual's rate of Parkinson's progression at ICASSP from biomechanics. Well done.
              </p>
              </br>
			  
			  <h3>February 2020</h3>
			  Kevin Nguyen presents first ever data augmentation approach for 4D fMRI which improves prediction performance at SPIE Medical Imaging. Nice job Kevin!
              </p>
              </br>
			  
			  <h3>January 2020</h3>
              </br>
			  Kevin and Albert present methods for Major Depression Disorder treatment response prediction at UTSW.
              </p>
              </br>
			  
			  <h3>November 2019</h3>
              Welcome Postdoctoral Fellow, Son Nam Nguyen!<br>
			  Albert chairs the session on Artificial Intelligence in Radiology at the annual ASFNR meeting in San Francisco, CA.
              </p>
              </br>
			  
        <h3>September 2019</h3>
        NIH F31 fellowship awarded to Cooper. Congratulations Cooper!
        </p>
        </br>
			  
			  <h3>June 2019</h3>
	          Albert attends ICML and CVPR in Los Angeles
			  </p>
              </br>
			  
			  <h3>June 2019</h3>
	          Yenho Chen receives Postbaccalaureate Intramural Research Training Award and starts a research scientist position at NIH's Center for Multimodal Neuroimaging within Dr Pereira's Machine Learning Team. Way to go Yenho!
			  </p>
              </br>
              
			  <h3>May 2019</h3>
              Albert gives invited talk on Machine Learning to radiologists at the American Society of Neuroradiology (ASNR) in Boston, MA 			  
              </p>
              </br>

			  <h3>April 2019</h3>
	          Multiple F30 and F31 fellowships submitted. Way to go students!! <br>
              Cooper presents his research on Autism diagnosis and Kevin’s research on Major Depression Disorder at ISBI in Italy.<br>
              Wedding bells for Alex. Congrats Alex!!<br>
			  </p>
              </br>

			  <h3>March 2019</h3>
	          Albert teaches deep learning in the UTSW Bioinformatics nanocourse, Machine Learning. <br>
              It’s a boy! Baby Anthony born to Albert and Andrea. Wohoo!!
			  </p>
              </br>

              <h3>February 2019</h3>
	          Alex Treacher presents on Liver Fibrosity diagnosis at SPIE Medical Imaging. Go Alex!
			  </p>
              </br>
              
              <h3>January  2019</h3>
	          Welcome Green Fellow student Vyom Raval!
			  </p>
              </br>

			  <h3>December 2018</h3>
			  <p class="subtitle">New website goes live! Thank you for visiting!</br>
	          Albert gives invited conference talk at Brain Informatics conference.</br>
			  </p>
              </br>

			  <h3>November 2018</h3>
			  <p class="subtitle">Bioinformatics Dept Hackathon 2018 is a super success; congrats Alex for winning an award!</p>
              </br>

			  <h3>October 2018</h3>
			  <p class="subtitle">Welcome new MSTP graduate student Cooper!</br>
			  Welcome rotation student Paul!</p>
              </br>

			  <h3>July 2018</h3>
			  <p class="subtitle">Welcome new MSTP graduate student Kevin!</p>
              </br>

			  <h3>May 2018</h3>
			  <p class="subtitle">Welcome new graduate student Alex!</p>
              </br>
			  
			  <h3>April 2018</h3>
			  <p class="subtitle">Albert gives invited talk, Deep learning for artifact detection in MEG, at the 2018 International Workshop on Interactive and Spatial Computing (IWISC).</p>
              </br>
			  <h3>March 2018</h3>
			  <p class="subtitle">Albert joins program committee of the SPIE Medical Imaging conference.</p>
              </br>
			  <h3>February 2018 </h3>
			  <p class="subtitle">Behrouz and Gowtham deliver oral presentations at SPIE Medical Imaging conference in Houston, TX.</br>
				A team of bioinformatics researchers (Drs. Montillo, Rajaram and Cobanoglu) develop and teach a new nanocourse, Machine Learning I, to researchers (grad students, postdocs, faculty) from across the UTSW. Highly positive reviews! Plans underway for subsequent offerings.</br>
				Welcome to our new scientific programmer Danni!</p>
              </br>
			  <h3>January 2018</h3>
			  <p class="subtitle">Albert gives invited talk, Deep learning: a new tool for analyzing Big Neuroimaging Datasets at the jointly (UTD, UTSW) sponsored symposium, Neuroimaging is a team sport.</p>
              </br>
			  <h3>December 2017 </h3>
			  <p class="subtitle">Albert receives appointment in the newly formed Bioinformatics Department at UTSW</br>
			  Albert trains researchers in neuroimage analysis with SPM.</br></p>
              </br>
			  <h3>November 2017 </h3>
			  <p class="subtitle">Albert is interviewed for research contributions in machine learning for radiology at RSNA.</p>
              </br>
			  <h3>September 2017</h3>
			  <p class="subtitle">2 papers presented at the International conference, Medical Image Computing and Computer Assisted Intervention (MICCAI) including Convolutional Neural Networks for artifact detection in MEG, and deep neural networks for quantifying the association between type-2 diabetes management and brain perfusion measured via ASL MRI.</p>
              </br>
			  <h3>August 2017 </h3>
			  <p class="subtitle">2 abstracts accepted to American Society for Functional Neuroradiology (ASFNR). Congratulations Behrouz and Gowtham!</p>
              </br>
			  <h3>July 2017</h3>
			  <p class="subtitle">2 papers presented at Pattern Recognition for Neuro Imaging (PRNI) on 3D convolutional neural networks for resting state network labeling for rs-fMRI and deep convolutional neural networks for MEG cardiac artifact detection.</br>1 paper presented at Human Brain Mapping conference on machine learning that uses resting state fMRI to accurately predict head impact exposure in youths playing a single season of football.</p>
              </br>
			  <h3>May 2017</h3>
			  <p class="subtitle">
			  Albert joins the Research Committee of American Society of Neuroradiology.</br>
			  Albert teaches Mathematics for Medicine to medical students at UTSW including topics of Bayesian Decision Theory and Deep Learning.
			  </p></br>
			  <h3>April 2017 </h3>
			  <p class="subtitle">
			  Afarin Famili successfully defends master’s thesis using machine learning to detect functional connectivity changes in epilepsy & diabetes. Congrats Afarin!</br>
			  Albert gives invited conference talk: Machine Learning in functional Neuroimaging at the American Society of Neuroradiology in Los Angeles.</br>
			  4 papers presented at UTSW Radiology Research Day by Prabhat Garg, Gowtham Murugesan, Afarin Famili!</br>
			  Gowtham Murugesan presents 2 papers at IEEE International Symposium on Biomedical Imaging (ISBI) in Melbourne, Australia</br>
			  </p></br>
			  <h3>March 2017</h3>
			  <p class="subtitle">
			  Abstract accepted to Organization for Human Brain Mapping (OHBM) conference</br>
			  </p></br>
			  <h3>February 2017</h3>
			  <p class="subtitle">
			  Two papers Accepted to IEEE International Symposium on Biomedical Imaging (ISBI) Meeting Conference!</br>
			  Albert attends annual mtg of American clinical MEG society (ACMEGS).
			  </p></br>
			  <h3>January 2017</h3>
			  <p class="subtitle">
			  Welcome to our new postdoc, Behrouz and research scientist, Anand to the lab!</br>
			  </p>
              </br>
			  <h3>December 2016</h3>
			  <p class="subtitle">Welcome aboard new trainee, Gowtham!</p>
              </br>
			  <h3>Sept 2016</h3>
			  <p class="subtitle">Welcome aboard graduate student, Afarin to the lab!</p>
              </br>
			  <h3>June 2016</h3>
			  <p class="subtitle">King Foundation grant awarded to Drs. Montillo and Moore.</p>
              </br>
			  <h3>May 2016</h3>
			  <p class="subtitle">Albert gives invited conference talk at American Society of Neuroradiology (ASNR) in Washington DC:  Machine Learning for Neuroimaging.</p>
              </br>
			  <h3>February 2016</h3>
			  <p class="subtitle">Albert gives seminar talks to Mathematics Dept at UT Dallas and Statistics Dept at Southern Methodist University.</p>
              </br>
			  <h3>November 2015</h3>
			  <p class="subtitle">Albert attends MEG training at McGill.</p>
              </br>
              </div>
            </div>
          </div>
      </div>
	  <br>
    </div>
  </section>
  <!-- /Section: news -->
 
 
 
  
  <section id="gallery" class="home-section text-center bg-gray">
    <div class="heading-about">
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-lg-offset-2">
            <div class="wow fadeInDown" data-wow-delay="0.4s">
              <div class="section-heading">
                <h2>Gallery</h2>
                <i class="fa fa-2x fa-angle-down"></i>

              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    <div class="container">
        <div class="row">
            <div class="col-lg-2 col-lg-offset-5">
                <hr class="marginbot-50">
            </div>
        </div>

      <div class="row">
          <div class="col-sm-12 col-md-6 ">
              <div class="wow fadeInLeft" data-wow-delay="0.3s">        
              <div class="team Gallery-img">
                  <div class="inner">
                      <label>Summer fun, at our very own Pie Tap pizzeria in the design district! </label>
                      <a class="thumbnail img-responsive" href="#" data-image-id="" 
                      data-toggle="modal" data-title="" data-caption="Gathering of subset of our group, July 2024 [Aixa, Son, Josh, Albert ; away are: Austin, Krishna, Brandon]"
                      data-image="img/funPics/Lunch_July_2024.png" data-target="#image-gallery">
                          <img class="Thumbnail img-responsive " src="img/funPics/Luncheon_20250618.png" alt="">
                          
                      </a>
                      <p style="padding:5px;"></p>
                  </div>
              </div>
              </div> 
        </div>

      <div class="row">
          <div class="col-sm-12 col-md-6 ">
              <div class="wow fadeInLeft" data-wow-delay="0.3s">        
              <div class="team Gallery-img">
                  <div class="inner">
                      <label>Celebrating new trainees in the lab. Welcome Khushi! </label>
                      <a class="thumbnail img-responsive" href="#" data-image-id="" 
                      data-toggle="modal" data-title="" data-caption="Gathering of subset of our group, July 2024 [Aixa, Son, Josh, Albert ; away are: Austin, Krishna, Brandon]"
                      data-image="img/funPics/Lunch_July_2024.png" data-target="#image-gallery">
                          <img class="Thumbnail img-responsive " src="img/funPics/Luncheon_20250604.png" alt="">
                          
                      </a>
                      <p style="padding:5px;"></p>
                  </div>
              </div>
              </div> 
        </div>

      <div class="row">
          <div class="col-sm-12 col-md-6 ">
              <div class="wow fadeInLeft" data-wow-delay="0.3s">        
              <div class="team Gallery-img">
                  <div class="inner">
                      <label>Celebrating the work leading to multiple papers in review and under revision! </label>
                      <a class="thumbnail img-responsive" href="#" data-image-id="" 
                      data-toggle="modal" data-title="" data-caption="Alumni Kevin got married!  Congratulations "
                      data-image="img/funPics/Kevin_wedding.png" data-target="#image-gallery">
                          <img class="Thumbnail img-responsive " src="img/funPics/Celebration_20250228.png" alt="">
                          
                      </a>
                      <p style="padding:5px;"></p>
                  </div>
              </div>
              </div> 
      </div>

      <div class="row">
          <div class="col-sm-12 col-md-6 ">
              <div class="wow fadeInLeft" data-wow-delay="0.3s">        
              <div class="team Gallery-img">
                  <div class="inner">
                      <label>Gathering of subset of our group, July 2024 [Aixa, Son, Josh, Albert ; away are: Austin, Krishna, Brandon] </label>
                      <a class="thumbnail img-responsive" href="#" data-image-id="" 
                      data-toggle="modal" data-title="" data-caption="Gathering of subset of our group, July 2024 [Aixa, Son, Josh, Albert ; away are: Austin, Krishna, Brandon]"
                      data-image="img/funPics/Lunch_July_2024.png" data-target="#image-gallery">
                          <img class="Thumbnail img-responsive " src="img/funPics/Lunch_July_2024.png" alt="">
                          
                      </a>
                      <p style="padding:5px;"></p>
                  </div>
              </div>
              </div> 
        </div>

      <div class="row">
          <div class="col-sm-12 col-md-6 ">
              <div class="wow fadeInLeft" data-wow-delay="0.3s">        
              <div class="team Gallery-img">
                  <div class="inner">
                      <label>Alumni Kevin got married!  Congratulations </label>
                      <a class="thumbnail img-responsive" href="#" data-image-id="" 
                      data-toggle="modal" data-title="" data-caption="Alumni Kevin got married!  Congratulations "
                      data-image="img/funPics/Kevin_wedding.png" data-target="#image-gallery">
                          <img class="Thumbnail img-responsive " src="img/funPics/Kevin_wedding.png" alt="">
                          
                      </a>
                      <p style="padding:5px;"></p>
                  </div>
              </div>
              </div> 
        </div>

      <div class="row">
          <div class="col-sm-12 col-md-6 ">
              <div class="wow fadeInLeft" data-wow-delay="0.3s">        
              <div class="team Gallery-img">
                  <div class="inner">
                      <label>Dr Montillo sparks interest in research among high school students from across Dallas, TX as part of the STARS program. Lots of connections made!</label>
                      <a class="thumbnail img-responsive" href="#" data-image-id="" 
                      data-toggle="modal" data-title="" data-caption="Dr Montillo sparks interest in research among high school students from across Dallas, TX as part of the STARS program. Great turnout!!" 
                      data-image="img/funPics/Albert_present_STARS_2024.png" data-target="#image-gallery">
                          <img class="Thumbnail img-responsive " src="img/funPics/Albert_present_STARS_2024.png" alt="">
                          
                      </a>
                      <p style="padding:5px;"></p>
                  </div>
              </div>
              </div> 
        </div>

      <div class="row">
          <div class="col-sm-12 col-md-6 ">
              <div class="wow fadeInLeft" data-wow-delay="0.3s">        
              <div class="team Gallery-img">
                  <div class="inner">
                      <label>Full Solar Eclipse  on April 8 2024</label>
                      <a class="thumbnail img-responsive" href="#" data-image-id="" 
                      data-toggle="modal" data-title="" data-caption="Full Solar Eclipse  on April 8 2024" 
                      data-image="img/funPics/Eclipse_April_8_2024_b.png" data-target="#image-gallery">
                          <img class="Thumbnail img-responsive " src="img/funPics/Eclipse_April_8_2024_b.png" alt="">
                          
                      </a>
                      <p style="padding:5px;"></p>
                  </div>
              </div>
              </div> 
        </div>

      <div class="row">
          <div class="col-sm-12 col-md-6 ">
              <div class="wow fadeInLeft" data-wow-delay="0.3s">        
              <div class="team Gallery-img">
                  <div class="inner">
                      <label>Full Solar Eclipse  on April 8 2024</label>
                      <a class="thumbnail img-responsive" href="#" data-image-id="" 
                      data-toggle="modal" data-title="" data-caption="Full Solar Eclipse  on April 8 2024" 
                      data-image="img/funPics/Eclipse_April_8_2024.png" data-target="#image-gallery">
                          <img class="Thumbnail img-responsive " src="img/funPics/Eclipse_April_8_2024.png" alt="">
                          
                      </a>
                      <p style="padding:5px;"></p>
                  </div>
              </div>
              </div> 
        </div>

      <div class="row">
          <div class="col-sm-12 col-md-6 ">
              <div class="wow fadeInLeft" data-wow-delay="0.3s">				
              <div class="team Gallery-img">
                  <div class="inner">
                      <label>Pool party at Montillo Residence. June 2022</label>
                      <a class="thumbnail img-responsive" href="#" data-image-id="" 
                      data-toggle="modal" data-title="" data-caption="Pool party at Montillo Residence" 
                      data-image="img/funPics/PoolPartyJune2022_1.jpg" data-target="#image-gallery">
                          <img class="Thumbnail img-responsive " src="img/funPics/PoolPartyJune2022_1.jpg" alt="">
                          
                      </a>
                      <p style="padding:5px;"></p>
                  </div>
              </div>
              </div> 
        </div>

        <div class="row">
          <div class="col-sm-12 col-md-6 ">
              <div class="wow fadeInLeft" data-wow-delay="0.3s">				
              <div class="team Gallery-img">
                  <div class="inner">
                      <label>Pool party at Montillo Residence. June 2022</label>
                      <a class="thumbnail img-responsive" href="#" data-image-id="" 
                      data-toggle="modal" data-title="" data-caption="Pool party at Montillo Residence" 
                      data-image="img/funPics/PoolPartyJune2022_1.jpg" data-target="#image-gallery">
                          <img class="Thumbnail img-responsive " src="img/funPics/PoolPartyJune2022_2.jpg" alt="", data-rotate="90">
                      </a>
                      <p style="padding:5px;"></p>
                  </div>
              </div>
              </div>
          </div> 

      <div class="row">
          <div class="col-sm-12 col-md-6 ">
              <div class="wow fadeInLeft" data-wow-delay="0.3s">				
              <div class="team Gallery-img">
                  <div class="inner">
                      <label> Basketball outing at UTSW Student Center. June 2022</label>
                      <a class="thumbnail img-responsive" href="#" data-image-id="" 
                      data-toggle="modal" data-title="" data-caption="Basketball at UTSW Student Center" 
                      data-image="img/funPics/Basket_June2022.jpg" data-target="#image-gallery">
                          <img class="Thumbnail img-responsive " src="img/funPics/Basket_June2022.jpg" alt="">
                          
                      </a>
                      <p style="padding:5px;"></p>
                  </div>
              </div>
              </div> 
        </div>
        <div class="row">
          <div class="col-sm-12 col-md-6 ">
              <div class="wow fadeInLeft" data-wow-delay="0.3s">				
              <div class="team Gallery-img">
                  <div class="inner">
                      <label> Luncheon at Rodeo Goat. June 2022</label>
                      <a class="thumbnail img-responsive" href="#" data-image-id="" 
                      data-toggle="modal" data-title="" data-caption="Luncheon at Rodeo Goat" 
                      data-image="img/funPics/Luncheon_RodeoGoat_June2022.jpg" data-target="#image-gallery">
                          <img class="Thumbnail img-responsive " src="img/funPics/Luncheon_RodeoGoat_June2022.jpg" alt="", data-rotate="90">
                      </a>
                      <p style="padding:5px;"></p>
                  </div>
              </div>
              </div>
        </div>        
        <div class="row">
            <div class="col-sm-12 col-md-6 ">
                <div class="wow fadeInLeft" data-wow-delay="0.3s">				
                <div class="team Gallery-img">
                    <div class="inner">
                        <label> Racing at the Dallas Karting Complex. Oct 2019</label>
                        <a class="thumbnail img-responsive" href="#" data-image-id="" 
                        data-toggle="modal" data-title="" data-caption="Student Poster at SPIE 2019" 
                        data-image="img/funPics/LineupDallasKarting.jpg" data-target="#image-gallery">
                            <img class="Thumbnail img-responsive " src="img/funPics/LineupDallasKarting.jpg" alt="", data-rotate="90">
                        </a>
                        <p style="padding:5px;"></p>
                    </div>
                </div>
                </div>
            </div>
            <div class="col-sm-12 col-md-6 ">
                <div class="wow fadeInLeft" data-wow-delay="0.3s">				
                <div class="team Gallery-img">
                    <div class="inner">
                        <label> Start your engines!  Fine skills on display. Oct 2019</label>
                        <a class="thumbnail img-responsive" href="#" data-image-id="" 
                        data-toggle="modal" data-title="" data-caption="Luncheon at Fire Side Pies" 
                        data-image="img/funPics/StartingLineDallasKarting.jpg" data-target="#image-gallery">
                            <img class="Thumbnail img-responsive " src="img/funPics/StartingLineDallasKarting.jpg" alt="">
                        </a>
                        <p style="padding:5px;"></p>
                    </div>
                </div>
                </div>
            </div>			
        </div>        
        
        <div class="row">
            <div class="col-sm-12 col-md-6 ">
                <div class="wow fadeInLeft" data-wow-delay="0.3s">				
                <div class="team Gallery-img">
                    <div class="inner">
                        <label> Summer outing on the main UTSW plaza, July 2019</label>
                        <a class="thumbnail img-responsive" href="#" data-image-id="" 
                        data-toggle="modal" data-title="" data-caption="Luncheon at Fire Side Pies" 
                        data-image="img/funPics/IMG_9118.jpg" data-target="#image-gallery">
                            <img class="Thumbnail img-responsive " src="img/funPics/IMG_9118.jpg" alt="">
                        </a>
                        <p style="padding:5px;"></p>
                    </div>
                </div>
                </div>
            </div>
            <div class="col-sm-12 col-md-6 ">
                <div class="wow fadeInLeft" data-wow-delay="0.3s">				
                <div class="team Gallery-img">
                    <div class="inner">
                        <label> Luncheon at the Velvet Taco, August 2019</label>
                        <a class="thumbnail img-responsive" href="#" data-image-id="" 
                        data-toggle="modal" data-title="" data-caption="Student Poster at SPIE 2019" 
                        data-image="img/funPics/Luncheon_VelvetTaco_Aug2019cropped.jpg" data-target="#image-gallery">
                            <img class="Thumbnail img-responsive " src="img/funPics/Luncheon_VelvetTaco_Aug2019cropped.jpg" alt="", data-rotate="90">
                        </a>
                        <p style="padding:5px;"></p>
                    </div>
                </div>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-sm-12 col-md-6 ">
                <div class="wow fadeInLeft" data-wow-delay="0.3s">				
                <div class="team Gallery-img">
                    <div class="inner">
                        <label> Luncheon at Fireside Pies in Dallas </label>
                        <a class="thumbnail img-responsive" href="#" data-image-id="" 
                        data-toggle="modal" data-title="" data-caption="Luncheon at Fire Side Pies" 
                        data-image="img/funPics/FireSide_Luncheon_2019.jpeg" data-target="#image-gallery">
                            <img class="Thumbnail img-responsive " src="img/funPics/FireSide_Luncheon_2019.jpeg" alt="">
                        </a>
                        <p style="padding:5px;"></p>
                    </div>
                </div>
                </div>
            </div>
            <div class="col-sm-12 col-md-6 ">
                <div class="wow fadeInLeft" data-wow-delay="0.3s">				
                <div class="team Gallery-img">
                    <div class="inner">
                        <label> Alex Treacher presenting at SPIE 2019 </label>
                        <a class="thumbnail img-responsive" href="#" data-image-id="" 
                        data-toggle="modal" data-title="" data-caption="Student Poster at SPIE 2019" 
                        data-image="img/funPics/Alex_SPIE2019_Presentation_2_crop.jpg" data-target="#image-gallery">
                            <img class="Thumbnail img-responsive " src="img/funPics/Alex_SPIE2019_Presentation_2_crop.jpg" alt="", data-rotate="90">
                        </a>
                        <p style="padding:5px;"></p>
                    </div>
                </div>
                </div>
            </div>
        </div>
        <div class="row"> 
            <div class="col-sm-12 col-md-6 ">
                <div class="wow fadeInLeft" data-wow-delay="0.3s">				
                <div class="team Gallery-img">
                    <div class="inner">
                        <label> Bioinformatics Hackathon, November 2018 </label>
                        <a class="thumbnail img-responsive" href="#" data-image-id="" 
                        data-toggle="modal" data-title="" data-caption="Hackathon, November 2018" 
                        data-image="img/funPics/Hackathon_2018.jpg" data-target="#image-gallery">
                            <img class="Thumbnail img-responsive " src="img/funPics/Hackathon_2018.jpg" alt="">
                        </a>
                        <p style="padding:5px;"></p>
                    </div>
                </div>
                </div>
            </div>
            <div class="col-sm-12 col-md-6 ">
                <div class="wow fadeInLeft" data-wow-delay="0.3s">				
                <div class="team Gallery-img">
                    <div class="inner">
                        <label> Lunch outing cellebrating end of semester successes, May 2018 </label>
                        <a class="thumbnail img-responsive" href="#" data-image-id="" 
                        data-toggle="modal" data-title="" data-caption="Lunch outing cellebrating end of semester successes, May 2018" 
                        data-image="img/funPics/Outing_2018.jpg" data-target="#image-gallery">
                            <img class="Thumbnail img-responsive " src="img/funPics/Outing_2018.jpg" alt="">
                        </a>
                        <p style="padding:5px;"></p>
                    </div>
                </div>
                </div>
            </div>
        </div>
        <div class="row">
            <div class="col-sm-12 col-md-6">
                <div class="wow fadeInLeft" data-wow-delay="0.3s">				
                <div class="team Gallery-img">
                    <div class="inner">
                        <label> Lunch outing with trainees, March 2017 </label>
                        <a class="thumbnail img-responsive" href="#" data-image-id="" 
                        data-toggle="modal" data-title="" data-caption="Lunch outing with trainees, March 2017" 
                        data-image="img/funPics/LunchCellebration_2017.jpg" data-target="#image-gallery">
                            <img class="Thumbnail img-responsive " src="img/funPics/LunchCellebration_2017.jpg" alt="">
                        </a>
                        <p style="padding:5px;"></p>
                    </div>
                </div>
                </div>
            </div>
            <div class="col-sm-12 col-md-6">
                <div class="wow fadeInLeft" data-wow-delay="0.3s">				
                <div class="team Gallery-img">
                    <div class="inner">
                        <label> Group gathering and outing with trainees, 2016 </label>
                        <a class="thumbnail img-responsive" href="#" data-image-id="" 
                        data-toggle="modal" data-title="" data-caption="Group gathering and outing with trainees, 2016" 
                        data-image="img/funPics/Outing_2016.jpg" data-target="#image-gallery">
                            <img class="Thumbnail img-responsive " src="img/funPics/Outing_2016.jpg" alt="">
                        </a>
                        <p style="padding:5px;"></p>
                    </div>
                </div>
                </div>
            </div>
        </div>
    </div>	
  </section>  
  <!-- /Section: Gallery -->  
  

  <!-- Section: contact -->
  <section id="contact" class="home-section text-center">
    <div class="heading-contact">
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-lg-offset-2">
            <div class="wow fadeInDown" data-wow-delay="0.4s">
              <div class="section-heading">
                <h2>Get in touch</h2>
                <i class="fa fa-2x fa-angle-down"></i>

              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    <div class="container">
        <div class="col-lg-12 widget-contact">
            <h5>Deep Learning for Precision Health lab (Montillo Lab)</h5>
            <address>
                  <strong>Physcial mail:</strong><br>    
                  <strong>Department of Bioinformatics</strong><br>
                  <strong>Department of Biomedical Engineering</strong><br>
                  <strong>UT Southwestern Medical Center</strong><br>
                  5323 Harry Hines Blvd.
                  <br>J9.130b 
                  Dallas, TX  75390-9365<br>
                  
            </address>
            <address>
              <strong>For most correspondence, email:</strong>
              <p align="justify"><a href="mailto:Albert.Montillo@utsouthwestern.edu">Albert.Montillo@utsouthwestern.edu </a></p> <br>

              <strong>Alternative</strong>, contact <strong>Erica Garza</strong>, our lab administrator. <p align="justify"><a href="mailto:Erica.Garza@utsouthwestern.edu">Erica.Garza@utsouthwestern.edu </a><br>
              <abbr title="Phone">     Ph: </abbr>(214) 648-3998<br> 

            </address>	
            <p align="justify">As we serve both the Bioinformatics and Biomedical Engineering Departments, we have locations on both the south campus in the J building (J9), and by appointment, on the east campus in the BME building (EA4).</p>
            <p align="justify">The Department of Bioinformatics is located in the J building at 5323 Harry Hines Blvd., Dallas, Texas. For visitors driving here, from Harry Hines Blvd., turn southwest onto Sen. Kay Bailey Hutchison Drive. Take the first right onto a drive that leads to Lot 7, Visitor Parking. See Erica Garza during your visit for a parking pass. From Visitor Parking, cross the street to the Donald Seldin Plaza. Walk across the plaza to the right, go down the steps and walk past the koi fish pond, across the next courtyard, in between the archway formed by the G and J buildings. At the right side under the archway, enter the J building and take the elevator to the 9th floor. Exit the elevators and then turn left to find the Department of Bioinformatics entrance consisting of a double glass doorway. Our offices are halfway down on the right and a team member can escort you to your meeting.</p>
            <p align="justify">UT Southwestern has <a class="link" href="http://www.utsouthwestern.edu/about-us/maps-and-directions/parking/index.html" target="_blank">full information on parking. </a></p>
            <p align="justify">We are accessible by <a class="link" href="http://www.utswmedicine.org/hospitals-clinics/maps-directions/transit.html" target="_blank"> public transportation.</a></p>
            <p align="justify">We are an 8 minute walk from the Southwestern Medical District/Parkland Station on the DART green and orange rail lines and 5 min walk from the Medical/Market Station on the Trinity Railway Express.</p>
        </div>
    </div>
  </section>
  <!-- /Section: contact -->
 
  
 <footer>
    <div class="container">
      <div class="row">
        <div class="col-md-12 col-lg-12">
          <div class="wow shake" data-wow-delay="0.4s">
            <div class="page-scroll marginbot-30">
              <a href="#intro" id="totop" class="btn btn-circle">
							<i class="fa fa-angle-double-up animated"></i>
						</a>
            </div>
          </div>
			<p>&copy; Deep Learning for Precision Health Laboratory. All rights reserved. 2024.</p> 
			<p>This website reflects only the views of the author and is not a publication of UT Southwestern, which bears no responsibility for its content.</p>          
        </div>
      </div>
    </div>
  </footer>

  <!-- Core JavaScript Files -->
  <script src="js/jquery.min.js"></script>
  <script src="js/bootstrap.min.js"></script>
  <script src="js/jquery.easing.min.js"></script>
  <script src="js/jquery.scrollTo.js"></script>
  <script src="js/wow.min.js"></script>
  <!-- Custom Theme JavaScript -->
  <script src="js/custom.js"></script>
  <script src="contactform/contactform.js"></script>
  <script src="js/custom.js"></script>
  <script>
	/* When the user clicks on the button,
	toggle between hiding and showing the dropdown content */


	// Close the dropdown menu if the user clicks outside of it
	window.onclick = function(event) {
	  if (!event.target.matches('.dropbtn')) {
		var dropdowns = document.getElementsByClassName("dropdown-content");
		var i;
		for (i = 0; i < dropdowns.length; i++) {
		  var openDropdown = dropdowns[i];
		  if (openDropdown.classList.contains('show')) {
			openDropdown.classList.remove('show');
		  }
		}
	  }
	} 
    
    $(document).ready(function(){

        loadGallery(true, 'a.thumbnail');

        //This function disables buttons when needed
        function disableButtons(counter_max, counter_current){
            $('#show-previous-image, #show-next-image').show();
            if(counter_max == counter_current){
                $('#show-next-image').hide();
            } else if (counter_current == 1){
                $('#show-previous-image').hide();
            }
        }

        /**
         *
         * @param setIDs        Sets IDs when DOM is loaded. If using a PHP counter, set to false.
         * @param setClickAttr  Sets the attribute for the click handler.
         */

        function loadGallery(setIDs, setClickAttr){
            var current_image,
                selector,
                counter = 0;

            $('#show-next-image, #show-previous-image').click(function(){
                if($(this).attr('id') == 'show-previous-image'){
                    current_image--;
                } else {
                    current_image++;
                }

                selector = $('[data-image-id="' + current_image + '"]');
                updateGallery(selector);
            });

            function updateGallery(selector) {
                var $sel = selector;
                current_image = $sel.data('image-id');
                $('#image-gallery-caption').text($sel.data('caption'));
                $('#image-gallery-title').text($sel.data('title'));
                $('#image-gallery-image').attr('src', $sel.data('image'));
                disableButtons(counter, $sel.data('image-id'));
            }

            if(setIDs == true){
                $('[data-image-id]').each(function(){
                    counter++;
                    $(this).attr('data-image-id',counter);
                });
            }
            $(setClickAttr).on('click',function(){
                updateGallery($(this));
            });
        }
		
    });
	

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener("click", function(e) {
          e.preventDefault();
          const targetId = this.getAttribute("href");
          const targetElement = document.querySelector(targetId);

          if (targetElement) {
              // Calculate the offset from the top of the document to the target element
              const yOffset = 0; // Adjust this based on the height of your fixed navbar
              const y = targetElement.getBoundingClientRect().top + window.pageYOffset + yOffset;

              // Scroll to the calculated position with smooth behavior
              window.scrollTo({ top: y, behavior: "smooth" });
          }
      });
  });

  </script>

</body>

</html>
