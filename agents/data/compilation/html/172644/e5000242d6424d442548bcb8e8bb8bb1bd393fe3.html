<!DOCTYPE html>
<html>

<head>
    <title>Research-Wayne AI Research</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="Wayne State AI Research and Education Core Group" />
    <script type="application/x-javascript">
        addEventListener("load", function () {
            setTimeout(hideURLbar, 0);
        }, false);

        function hideURLbar() {
            window.scrollTo(0, 0);
        }
    </script>
    <!-- Favicon -->
    <link rel="shortcut icon" type="image/icon" href="images/wsu-ico.png" />
    <!-- bootstrap-css -->
    <!-- <link href="css/bootstrap.css" rel='stylesheet' type='text/css' /> -->
    <link href="css/bootstrap.min.css" rel='stylesheet' type='text/css' />
    <!-- <link href="css/bootstrap-grid.css" rel='stylesheet' type='text/css' /> -->
    <!-- //bootstrap-css -->
    <!-- css -->
    <link href="css/style.css" rel='stylesheet' type='text/css' />
    <link href="css/font-awesome.min.css" rel='stylesheet' type='text/css' />
    <!-- //css -->
    <!-- fonts -->
    <link
        href='http://fonts.useso.com/css?family=Open+Sans:400,300,300italic,400italic,600,600italic,700,700italic,800,800italic'
        rel='stylesheet' type='text/css'>
    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link href="https://fonts.googleapis.com/css2?family=Oswald:wght@500&display=swap" rel="stylesheet">
    <!-- //fonts -->
    <!-- js -->
    <script src="js/jquery-1.11.1.min.js"></script>
    <script src="js/modernizr.custom.js"></script>
    <!-- <script src="js/bootstrap.js"></script> -->
    <script src="js/bootstrap.min.js"></script>
    <script src="js/wow.min.js"></script>
    <!-- //js -->
    <!-- start-smoth-scrolling-->
    <script type="text/javascript">
        jQuery(document).ready(function ($) {
            $(".scroll").click(function (event) {
                event.preventDefault();

                $('html,body').animate({
                    scrollTop: $(this.hash).offset().top
                }, 1000);
            });
        });
    </script>
    <!--//end-smoth-scrolling-->
</head>

<body>
    <div class="top-nav">
        <nav class="navbar navbar-default">
            <div>
                <div class="navbar-header">
                    <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
                        data-target="#bs-example-navbar-collapse-1">
                        <span class="sr-only">Toggle navigation</span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                    <div class="logo">
                        <a href="index.html"><img src="images/AI.png" alt=""></a>
                    </div>
                </div>
                <!-- Collect the nav links, forms, and other content for toggling -->
                <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                    <ul class="nav navbar-nav navbar-center">
                        <li><a href="index.html">HOME</a></li>
                        <li><a href="about.html">ABOUT</a></li>
                        <li><a href="research.html" class="active">RESEARCH</a></li>
                        <li><a href="education.html">EDUCATION</a></li>
                        <li><a href="outreach.html">OUTREACH</a></li>
                        <!-- <li><a href="https://bulletins.wayne.edu/graduate/college-engineering/computer-science/computer-science-ms/#requirementstext">EDUCATION</a></li> -->
                        <!-- <li><a href="#" class="dropdown-toggle hvr-bounce-to-bottom" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">EDUCATION<span class="caret"></span></a>
                            <ul class="dropdown-menu">
                                <li><a class="hvr-bounce-to-bottom" href="education.html">Education1</a></li>
                                <li class="dropdown-submenu">
                                    <a href="#" class="dropdown-toggle" data-toggle="dropdown-submenu" role="button" aria-haspopup="true" aria-expanded="false">Education2<span class="caret"></span></a>
                                    <ul class="dropdown-menu">
                                        <li><a tabindex="-1" href="education.html">Education4</a></li>
                                        <li><a href="education.html">Education5</a></li>
                                        <li><a href="education.html">Education6</a></li>
                                    </ul>
                                </li>
                                <li><a class="hvr-bounce-to-bottom" href="education.html">Education3</a></li>
                            </ul>
                        </li> -->
                        <!-- <li><a href="events.html">EVENTS</a></li> -->
                    </ul>
                    <div class="clearfix"> </div>
                </div>
            </div>
        </nav>
    </div>
    <!-- script-for sticky-nav -->
    <script>
        $(document).ready(function () {
            var navoffeset = $(".top-nav").offset().top;
            $(window).scroll(function () {
                var scrollpos = $(window).scrollTop();
                if (scrollpos > navoffeset) {
                    $(".top-nav").addClass("fixed");
                } else {
                    $(".top-nav").removeClass("fixed");
                }
            });

        });
    </script>
    <!-- /script-for sticky-nav -->
    <!--navigation-->

    <div class="about-info">
        <h2>Research</h2>
    </div>
    <!--start-work-->

    <!-- services -->
    <div id="services" class="services" style="background-color:#fff">
        <div class="container">
            <div class="services-grids">
                <div class="col-md-4 services-grid">
                    <div class="services-icon">
                        <span class="glyphicon glyphicon-asterisk glyphicon-eye-open" aria-hidden="true"></span>
                    </div>
                    <h4>Computer Vision</h4>
                </div>
                <div class="col-md-4 services-grid">
                    <div class="services-icon">
                        <span class="glyphicon glyphicon-asterisk glyphicon glyphicon-bullhorn"
                            aria-hidden="true"></span>
                    </div>
                    <h4>Natural Language Processing</h4>
                </div>
                <div class="col-md-4 services-grid">
                    <div class="services-icon">
                        <span class="glyphicon glyphicon-asterisk glyphicon-lock" aria-hidden="true"></span>
                    </div>
                    <h4>Cybersecurity</h4>
                </div>
                <div class="clearfix"> </div>
            </div>
        </div>
        <div class="container">
            <div class="services-grids">
                <div class="col-md-4 services-grid">
                    <div class="services-icon">
                        <span class="glyphicon glyphicon-asterisk glyphicon-road" aria-hidden="true"></span>
                    </div>
                    <h4>Transportation</h4>
                </div>
                <div class="col-md-4 services-grid">
                    <div class="services-icon">
                        <span class="glyphicon glyphicon-asterisk glyphicon-plus" aria-hidden="true"></span>
                    </div>
                    <h4>Healthcare</h4>
                </div>
                <div class="col-md-4 services-grid">
                    <div class="services-icon">
                        <span class="glyphicon glyphicon-asterisk glyphicon-cog" aria-hidden="true"></span>
                    </div>
                    <h4>Intelligent Reality</h4>
                </div>
                <div class="clearfix"> </div>
            </div>
        </div>
        <!-- //container -->
    </div>
    <!-- services -->
    <div class="details">
        <div style="background-color:#fff;">
            <div class="details-info container">
                <div class="details-left col-lg-4 col-sm-6">
                    <img class="media-object" src="images/nsf_real_time_computing.jpg" alt="...">
                    <a href="https://nsf.gov/awardsearch/showAward?AWD_ID=2140346&HistoricalAwards=false" class="read" target="_blank">Learn More</a>
                </div>
                <div class="details-right col-lg-8 col-sm-6">
                    <h3 class="media-heading">AI for Edge Computing</h3>
                    <br>
                    <div id="abc" class="details-text">
                        <p>
                            <b>Project title: </b>Enabling Real-time, Scalable and Secure Collaborative Intelligence on the Edge
                        </p>
                        <p>
                            <b>Investigators: </b>Zheng Dong, Weisong Shi
                        </p>
                        <p>
                            <b>Abstract: </b> With the proliferation of embedded systems, multicore computing devices enable the recent trend of moving 
                            computation from the centralized cloud to distributed edge platforms. This trend yields new products and services across smart 
                            infrastructures in smart cities. However, as real-time workloads are executed at the edge computing platforms, the performance 
                            bottleneck is transferred from the edge-cloud communication to on-chip communication. The system’s real-time performance faces 
                            new system-architectural challenges for the Network-On-Chip (NoC), which are scalability and security. These challenges are 
                            hinged with dynamic data distributions across different users. This project aims to design a real-time and scalable NoC for 
                            implementing real-time collaborative learning algorithms. The key strategy is to orchestrate a system-architecture and algorithm 
                            co-design to explore the new design space on the edge computing platform.
                        </p>
                        <p>
                            To cope with the research challenges, a comprehensive architecture will be developed to address these multifaceted problems 
                            through a hardware and software co-design, which consists of three key thrusts: (i) designing an interconnect, which will eliminate 
                            non-predictability barrier on the NoC; (ii) establishing a scalable virtualized transaction environment for the collaborative learning 
                            system to guarantee that all the real-time transaction tasks can complete at the right time; (iii) implementing a real-time and secure 
                            multi-target tracking system on the edge platform in light of the newly proposed architecture. The proposed research will be evaluated 
                            using the physical platform Equinox, with indoor and outdoor studies beyond simulation.
                        </p>
                        <p>    
                            This research will open a new dimension of research and educational opportunities. In particular, the success of the project 
                            will provide a hardware/software package that can enhance the real-time collaborative computing on the edge. The resulted 
                            interconnect and Equinox are ready-to-use platforms that will allow experts/researchers to easily examine their research 
                            designs regarding collaborative learning and real-time edge computing, thereby sealing the gap between different research 
                            fields. Educational efforts will be devoted to (i) curriculum design for the undergraduate and graduate program, (ii) summer 
                            camp development for middle and high school students, and teachers, (iii) broadening participation in computing and engineering, 
                            at the Wayne State University.
                        </p>
                
            
                    </div>

                </div>

            </div>
        </div>

        <div class="details-info container">
            <div class="details-right col-lg-8 col-sm-6">
                <h3 class="media-heading">AI for Mobility</h3>
                <br>
                <div class="details-text">
                    <p>
                        <b>Project title: </b> SCC-CIVIC-PG Track A: Leveraging AI-assist Microtransit to Ameliorate
                        Spatiotemporal Mismatch between Housing and Employment
                    </p>
                    <p>
                        <b>Investigators: </b>Dongxiao Zhu, Weisong Shi, Daniel Grosu, Marco Brocanelli, and Michael Bray
                    </p>
                    <p>
                        <b>Abstract: </b>Persons with disabilities (PWD) have historically faced significant employment 
                        challenges mainly due to lack of transportation to employment-related Points of Interest (ePOIs) 
                        such as work, education, and training locations. Paratransit services that provide door-to-door 
                        and curb-to-curb services could alleviate the first/last mile problem. However, they often 
                        require submitting pick-up requests a few days to a few weeks in advance, which is not flexible 
                        enough to handle more urgent requests to arrive at ePOIs on time. A main reason for such temporal 
                        lags is the lack of accessible technology that helps make complex yet prompt decisions for the 
                        determination of pick-up/drop-off location, routing, scheduling, and re-routing. This project 
                        promotes disability inclusion in workplaces by enhancing the availability and reliability of 
                        paratransit services. Specifically, our vision is to deliver an open-source human-centered 
                        Artificial Intelligence (AI) technology that aids microtransit services to determine when and 
                        where to pick up/drop off PWD, and incorporates near real-time routing algorithms to serve more 
                        urgent PWD requests between residential and ePOI-rich regions.
                    </p>
                    <p>
                        This project will be built on the already established strong collaboration among several 
                        organizations operating in the Metro Detroit Area, including paratransit service providers, 
                        disability research institutions, workforce development institutions, outreach communication 
                        services, and Wayne State University. Specifically, in this project we plan to: (1) Organize 
                        outreach activities, focus groups, and workshops to involve more organizations, have a convergent 
                        stakeholder discussion to better understand their needs, how best to provide near real-time 
                        paratransit services to meet identified needs, and identify data and ePOIs for testing; (2) Study 
                        inflow and outflow of paratransit service demand across regions and accessibility for PWD in the 
                        identified service area; (3) Create measurement tools for success of our prototype for each 
                        stakeholder type (user, service provider, employers). The data and measurement tools generated 
                        by this project will shape the development and design of the proposed technology.
                    </p>
                </div>

            </div>
            <div class="details-left col-lg-4 col-sm-6">
                <img class="media-object" src="images/33.jpg" alt="...">
                <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2235225&HistoricalAwards=false" class="read"
                    target="_blank">Learn More</a>
            </div>
        </div>
        <div style="background-color:#fff;">
            <div class="details-info container">
                <div class="details-left col-lg-4 col-sm-6">
                    <img class="media-object" src="images/32.png" alt="...">
                    <a href="https://taggs.hhs.gov/Detail/AwardDetail?arg_AwardNum=R21NR020388&arg_ProgOfficeCode=136"
                        class="read" target="_blank">Learn More</a>
                </div>
                <div class="details-right col-lg-8 col-sm-6">
                    <h3 class="media-heading">AI for Healthcare</h3>
                    <br>
                    <div class="details-text">
                        <p>
                            <b>Project title: </b>Neural Conversational Agent for Automated Weight Loss Counseling
                        </p>
                        <p>
                            <b>Investigators: </b>Alexander Kotov, April Idalski Carcone, and Elizabeth Towner
                        </p>
                        <p>
                            <b>Abstract: </b>Obesity is one of the most important medical and public health problems in 
                            the United States. According to recent nationally representative studies, every third adult 
                            in the U.S. is obese. Motivational Interviewing (MI), a client-centered and directive approach 
                            to behavior change counseling, has been widely adapted for treating obesity. Despite the 
                            evidence presented in published meta-reviews that suggests that MI is effective at activating 
                            behavioral changes, anthropometric changes are less significant. At the same time, there 
                            are several access barriers to this type of behavioral health care, such as shortage of human 
                            counselors in certain geographical areas, long wait times, cost, and fear of judgment. 
                            Recent advances in deep learning have allowed artificial intelligence (AI) methods to expand 
                            into the areas of health care that were previously thought to be the exclusive province of 
                            human experts, such as clinical diagnostics.
                        </p>
                        <p>
                            Behavioral health and MI, however, are the areas of medicine that have not yet substantially 
                            benefitted from modern AI technologies, such as neural conversational agents. To address this 
                            limitation, the proposed project aims to test the feasibility and usability of using neural 
                            conversational agents for automated behavioral counseling with a focus on weight loss. 
                            Specifically, we build on recent advances in deep learning, such as conversational agents, 
                            neural attention, transformers, supervised policy learning, variational autoencoders and 
                            adversarial training, and aim to develop and validate Neural Agent for Obesity Motivational 
                            Interviewing (NAOMI), a mobile device (smartphone or tablet) application to conduct automated 
                            MI counseling focused on weight loss. NAOMI is based on a novel neural architecture, which 
                            consists of neural networks that can be independently and collectively trained using the 
                            proposed multi-stage procedure to learn communication behaviors, which should be strategically 
                            utilized during different stages of an MI counseling session depending on the observed 
                            interactions and generate responses that are grounded in session context and reflect patient’s language.
                        </p>
                            We will recruit 40 obese adults, who will interact with NAOMI and provide their feedback through 
                            semi-structured qualitative interviews. We plan on conducting at most 4 iterative development 
                            cycles of NAOMI with 10 patients participating in each cycle. We will conduct a mixed-methods 
                            sub-study after each development cycle. Quantitative evaluation of NAOMI’s MI counseling skills 
                            will be conducted based on the transcripts of participants’ interactions by a coder trained in 
                            using the MI Treatment Integrity (MITI) coding system, a standard instrument for assessing MI 
                            fidelity. Qualitative interviews with the participants will be analyzed using Framework Matrix Analysis. 
                            The methods and techniques proposed in this project can be adapted to other types of psychotherapeutic 
                            interventions besides MI and to other conditions besides obesity.
                        <p>

                        </p>
                    </div>

                </div>

            </div>
        </div>


        <div class="details-info container">
            <div class="details-right col-lg-8 col-sm-6">
                <h3 class="media-heading">AI for Biomedical Informatics</h3>
                <br>
                <div class="details-text">
                    <p>
                        <b>Project title: </b>Severity Predictors Integrating salivary Transcriptomics and proteomics
                        with Multi neural network Intelligence in SARS-CoV2 infection in Children (SPITS MISC)
                    </p>
                    <p>
                        <b>Investigators: </b>Dongxiao Zhu
                    </p>
                    <p>
                        <b>Abstract: </b>Children have been disproportionately less impacted by the Corona Virus Disease
                        2019 (COVID-19) caused by the Severe Acute Respiratory Syndrome Corona Virus 2 (SAR-CoV-2)
                        compared to adults. However, severe illnesses
                        including Multisystem Inflammatory Syndrome (MIS-C) and respiratory failure have occurred in a
                        small proportion of children with SARS-CoV-2 infection. Nearly 80% of children with MIS-C are
                        critically ill with a 2-4% mortality rate.
                        Currently there are no modalities to characterize the spectrum of disease severity and predict
                        which child with SARS-CoV-2 exposure will likely develop severe illness including MIS-C. Thus
                        there is an urgent need to develop a diagnostic
                        modality to distinguish the varying phenotypes of disease and risk stratify disease. The
                        epigenetic changes in microRNA (miRNA) profiles that occur due to an infection can impact
                        disease severity by altering immune response and
                        cytokine regulation which may be detected in body fluids including saliva. Our long-term goal is
                        to improve outcomes of children with SARS-CoV-2 by early identification and treatment of those
                        at risk for severe illness. Our central
                        hypothesis is that a model that integrates salivary biomarkers with social and clinical
                        determinants of health will predict disease severity in children with SARS-CoV-2 infection. The
                        central hypothesis will be pursued through
                        phased four specific aims. The first two aims will be pursued during the R61 phase and include:
                        1) Define and compare the salivary molecular host response in children with varying phenotypes
                        (severe and non severe) SARS-CoV-2 infections
                        and 2) Develop and validate a sensitive and specific model to predict severe SARS-CoV-2 illness
                        in children. During the R33 phase we will pursue the following two aims: 3) Develop a portable,
                        rapid device that quantifies salivary
                        miRNAs with comparable accuracy to predicate technology (qRT-PCR), and 4) Develop an artificial
                        intelligence (AI) assisted cloud and mobile system for early recognition of severe SARS-CoV-2
                        infection in children. We will pursue
                        the above aims using an innovative combination of salivaomics and bioinformatics, analytic
                        techniques of AI and clinical informatics. The proposed research is significant because
                        development of a sensitive model to risk stratify
                        disease is expected to improve outcomes of children with severe SARS-CoV-2 infection via early
                        recognition and timely intervention. The proximate expected outcome of this proposal is better
                        understanding of the epigenetic regulation
                        of host immune response to the viral infection which we expect to lead to personalized therapy
                        in the future. The results will have a positive impact immediately as it will lead to the
                        creation of patient profiles based on individual
                        risk factors which can enable early identification of severe disease and appropriate resource
                        allocation during the pandemic.
                    </p>
                </div>

            </div>
            <div class="details-left col-lg-4 col-sm-6">
                <img class="media-object" src="images/34.jpg" alt="...">
                <a href="https://projectreporter.nih.gov/project_info_details.cfm?aid=10273618&icde=53205904"
                    class="read" target="_blank">Learn More</a>
            </div>
        </div>


        <div style="background-color:#fff;">
            <div class="details-info container">
                <div class="details-left col-lg-4 col-sm-6">
                    <img class="media-object" src="images/35.png" alt="...">
                    <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2311245"
                        class="read" target="_blank">Learn More</a>
                </div>
                <div class="details-right col-lg-8 col-sm-6">
                    <h3 class="media-heading">AI for Medical Imaging</h3>
                    <br>
                    <div class="details-text">
                        <p>
                            <b>Project title: </b>Elements: MVP: Open-Source AI-Powered MicroVessel Processor for Next-Generation Vascular Imaging Data
                        </p>
                        <p>
                            <b>Investigators: </b>Zichun Zhong, Jing Hua
                        </p>
                        <p>
                            <b>Abstract: </b>Effectively acquiring and processing complicated microstructures and their morphology become increasingly 
                        important in scientific and engineering discoveries. A growing body of evidence in animal and human studies shows that 
                        micro-cerebrovascular abnormalities are the real source of many neurologic disorders and vascular diseases. Therefore, there 
                        is an urgent need for better detection and understanding of vascular characteristics in vivo at the micro-level. However, 
                        the existing techniques and software solutions are developed based on general-scale medical images for processing macro-level 
                        organs and tissues, not applicable to the challenging next-generation vascular imaging data and micro-level vasculature. 
                        Furthermore, they are difficult to be customized to specific scientific microvascular imaging applications for domain developers. 
                        The overall objective of this project is to design and develop a rigorous, scalable, intelligent, and comprehensive data and 
                        software infrastructure, MicroVessel Processor (MVP), which supports and sustains advancements of understanding and analyzing 
                        the complicated 3D microvascular networks, provides services to a large community, and fosters continuous innovation in the 
                        multidisciplinary domains.
                        <br>
                        This project integrates new paradigm of data-driven 3D microvascular discovery - generate new knowledge and understanding 
                        and accelerate discovery and innovation via the advanced software cyberinfrastructure, along with use-case driven functional 
                        applications and evaluations. The capabilities of the newly developed AI-based high-fidelity 3D image enhancement, 3D 
                        geometric segmentation / extraction, reconstruction, and analytics techniques are integrated in the MVP system as the core 
                        modules in the software infrastructure. The MVP database including a large number of subjects with varying anatomical shapes, 
                        morphological features, and different data modalities is collected and constructed as the infrastructure (i.e., knowledgebase), 
                        which provides the knowledge for 3D microvascular networks tracking and analysis. The MVP system is designed and built based 
                        on an open-source and drag-drop real-time application system, in order to reduce both human labors and computation costs, 
                        accelerate the speed and efficiency of re-development and extensibility. This unique framework supports a wide adoption in 
                        microvasculature analytics in biomedical engineering, big-data neuroscience, and AI-based clinical diagnosis.
                    </div>

                </div>
            </div>
        </div>

        <div class="details-info container">
            <div class="details-right col-lg-8 col-sm-6">
                <h3 class="media-heading">AI for Public Safety</h3>
                <br>
                <div class="details-text">
                    <p>
                        <b>Project title: </b>DeepWave, an AI acoustic analysis technology that can deliver sound
                        element separation and audio enhancement in real time
                    </p>
                    <p>
                        <b>Investigators: </b>Ming Dong
                    </p>
                </div>
            </div>
            <div class="details-left col-lg-4 col-sm-6">
                <img class="media-object" src="images/36.jpg" alt="...">
                <a href="https://research.wayne.edu/news/mtrac-innovation-hub-for-advanced-computing-awards-270000-to-wayne-state-university-artificial-intelligence-ai-projects-40904"
                    class="read" target="_blank">Learn More</a>
            </div>
        </div>
    </div>

    <!-- funding opportunities -->
    <div class="about-bottom">
        <div class="container">
            <h3>AI-related funding opportunities</h3>
            <div class="about-bottom-grids">
                <div class="col-md-6 about-bottom-left">
                    <h4>National Science Foundation </h4>
                    <div class="funding-list funding-text">
                        <ul>
                            <li><a href="https://www.nsf.gov/cise/ai.jsp">AI program overview</a></li>
                            <li><a href="https://www.nsf.gov/pubs/2021/nsf21535/nsf21535.htm">Smart and Connected
                                    Community (SCC)</a></li>
                            <li><a href="https://www.nsf.gov/pubs/2021/nsf21530/nsf21530.htm">Smart and Connected Health
                                    (SCH)</a></li>
                            <li><a href="https://www.nsf.gov/pubs/2021/nsf21500/nsf21500.htm">Secure and Trustworthy
                                    Cyberspace (SaTC)</a></li>
                            <li><a href="https://www.nsf.gov/eng/futureofwork.jsp">Future of Work at the
                                    Human-Technology Frontier (FW-HTF)</a></li>
                            <li><a href="https://www.nsf.gov/cise/harnessingdata/">Harnessing the Data Revolution
                                    (HDR)</a></li>
                            <li><a href="https://www.nsf.gov/news/news_summ.jsp?cntn_id=127138">New Dear Colleague
                                    Letters</a></li>
                            <li><a href="https://www.nsf.gov/funding/pgm_summ.jsp?pims_id=505873">Mathematical and
                                    Scientific Foundations of Deep Learning (SCALE MoDL)</a></li>
                            <li><a href="https://www.nsf.gov/pubs/2021/nsf21572/nsf21572.htm">NSF Convergence
                                    Accelerator Phases I and II for the 2021 Cohort</a></li>
                        </ul>
                    </div>
                </div>
                <div class="col-md-6 about-bottom-left about-bottom-right">
                    <h4>National Institute of Health</h4>
                    <div class="funding-list funding-text">
                        <ul>
                            <li><a href="https://allofus.nih.gov/">All of US program </a></li>
                            <li><a href="https://allofus.nih.gov/funding-and-program-partners/funding-opportunities">Nutrition
                                    for Precision Health</a></li>
                            <li><a href="https://www.nibib.nih.gov/research-funding/machine-learning?v=tab3">Artificial
                                    Intelligence, Machine Learning, and Deep Learning</a></li>
                            <li><a href="https://www.nlm.nih.gov/ep/Grants.html ">NLM biomedical informatics</a></li>
                        </ul>
                    </div>
                </div>
                <div class="col-md-6 about-bottom-left" style="margin-top: 3em;">
                    <h4>AI research resources</h4>
                    <div class="funding-list funding-text">
                        <ul>
                            <li><a href="doc/Facilities - Wayne Artificial Intelligence.docx">Facilities for proposal
                                    writing</a></li>
                        </ul>
                    </div>
                </div>
                <div class="clearfix"> </div>
            </div>
        </div>
    </div>


    <div style="padding-top: 3em;">
        <div class="container">
            <div class="services-info">
                <h3>Selected <span>AI publication</span></h3>
            </div>
            <div style="margin-top:3em;">
                <div class="col-lg-3 col-md-3 " style="margin-top:2em;">
                    <ul class="nav nav-tabs nav-stacked paper">
                        <li class="active">
                            <a href="#GeneralAI" data-toggle="tab">
                                <h4>General AI/Machine Learning</h4>
                            </a>
                        </li>
                        <li>
                            <a href="#ComputerVision" data-toggle="tab">
                                <h4>Computer Vision & Visualization</h4>
                            </a>
                        </li>
                        <li>
                            <a href="#InformationRetrieval" data-toggle="tab">
                                <h4>Information Retrieval</h4>
                            </a>
                        </li>
                    </ul>
                </div>
                <div class="col-lg-9 col-md-9 tab-content paperlist">
                    <div class="tab-pane active paperlink" id="GeneralAI">
                        <ul>
                            <li>
                                <a href="https://www.ijcai.org/proceedings/2021/0396.pdf">
                                    Deng Pan, Xin Li, Dongxiao Zhu: Explaining Deep Neural Network Models with
                                    Adversarial Gradient Integration. IJCAI 2021: 2876-2883.
                                </a>
                            </li>
                            <li>
                                <a href="https://arxiv.org/pdf/2012.07688.pdf">
                                    Xin Li, Xiangrui Li, Deng Pan, Dongxiao Zhu: Improving Adversarial Robustness via
                                    Probabilistically Compact Loss with Logit Constraints. AAAI 2021: 8482-8490.
                                </a>
                            </li>
                            <li>
                                <a href="https://arxiv.org/pdf/2011.13495.pdf">
                                    Baorui Ma, Zhizhong Han, Yu-Shen Liu, Matthias Zwicker: Neural-Pull: Learning Signed
                                    Distance Functions from Point Clouds by Learning to Pull Space onto Surfaces. ICML
                                    2021.
                                </a>
                            </li>
                            <li>
                                <a href="https://www.ijcai.org/Proceedings/2020/0373.pdf">
                                    Deng Pan, Xiangrui Li, Xin Li, Dongxiao Zhu: Explainable Recommendation via
                                    Interpretable Feature Mapping and Evaluation of Explainability. IJCAI 2020:
                                    2690-2696.
                                </a>
                            </li>
                            <li>
                                <a href="https://ojs.aaai.org//index.php/AAAI/article/view/5907">
                                    Xiangrui Li, Xin Li, Deng Pan, Dongxiao Zhu: On the Learning Property of Logistic
                                    and Softmax Losses for Deep Neural Networks. AAAI 2020: 4739-4746.
                                </a>
                            </li>
                            <li>
                                <a href="http://proceedings.mlr.press/v119/han20b/han20b.pdf">
                                    Zhizhong Han, Chao Chen, Yu-Shen Liu, Matthias Zwicker: DRWR: A Differentiable
                                    Renderer without Rendering for Unsupervised 3D Structure Learning from Silhouette
                                    Images. ICML 2020: 3994-4005.
                                </a>
                            </li>
                        </ul>
                    </div>
                    <div class="tab-pane paperlink" id="ComputerVision">
                        <ul>
                            <li>
                                <a href="https://arxiv.org/pdf/2108.03746.pdf">
                                    Chao, Chen, Zhizhong Han, Yu-Shen Liu, and Matthias Zwicker: Unsupervised Learning
                                    of Fine Structure Generation for 3D Point Clouds by 2D Projection Matching. ICCV
                                    (2021).
                                </a>
                            </li>

                            <li>
                                <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9222053">
                                    Yifan Wang, Guoli Yan, Haikuan Zhu, Sagar Buch, Ying Wang, Ewart Mark Haacke, Jing
                                    Hua, Zichun Zhong: VC-Net: Deep Volume-Composition Networks for Segmentation and
                                    Visualization
                                    of Highly Sparse and Noisy Image Data. IEEE Trans. Vis. Comput. Graph. 27(2):
                                    1301-1311 (2021).
                                </a>
                            </li>
                            <li>
                                <a href="https://arxiv.org/pdf/2003.05559.pdf">
                                    Zhizhong Han, Guanhui Qiao, Yu-Shen Liu, Matthias Zwicker: SeqXY2SeqZ: Structure
                                    Learning for 3D Shapes by Sequentially Predicting 1D Occupancy Segments from 2D
                                    Coordinates. ECCV (24) 2020: 607-625.
                                </a>
                            </li>
                            <li>
                                <a href="http://zzhong.eng.wayne.edu/_resources/pdfs/DeepOrganNet_TVCG2019.pdf">
                                    Yifan Wang, Zichun Zhong, Jing Hua: DeepOrganNet: On-the-Fly Reconstruction and
                                    Visualization of 3D / 4D Lung Models from Single-View Projections by Deep
                                    Deformation Network. IEEE Trans. Vis. Comput. Graph. 26(1): 960-970 (2020).
                                </a>
                            </li>
                            <li>
                                <a href="https://zichunzhong.github.io/papers/Eigen_TVCG2019.pdf">
                                    Hajar Hamidian, Zichun Zhong, Farshad Fotouhi, Jing Hua:Surface Registration with
                                    Eigenvalues and Eigenvectors. IEEE Trans. Vis. Comput. Graph. 26(11): 3327-3339
                                    (2020).
                                </a>
                            </li>
                            <li>
                                <a href="https://zichunzhong.github.io/papers/A-CNN_CVPR2019.pdf">
                                    Artem Komarichev, Zichun Zhong, Jing Hua, "A-CNN: Annularly Convolutional Neural
                                    Networks on Point Clouds," IEEE Conference on Computer Vision and Pattern
                                    Recognition (CVPR), Long Beach, CA, June 2019.
                                </a>
                            </li>
                            <li>
                                <a href="https://par.nsf.gov/servlets/purl/10127082">
                                    Chen, S., Zhang, C., & Dong, M. (2018). Coupled end-to-end transfer learning with
                                    generalized fisher information. In Proceedings of the IEEE Conference on Computer
                                    Vision and Pattern Recognition (pp. 4329-4338).
                                </a>
                            </li>
                            <li>
                                <a
                                    href="https://openaccess.thecvf.com/content_ICCV_2017/papers/Xu_Directionally_Convolutional_Networks_ICCV_2017_paper.pdf">
                                    Haotian Xu, Ming Dong, Zichun Zhong, "Directionally Convolutional Networks for 3D
                                    Shape Segmentation," IEEE International Conference on Computer Vision (ICCV), pp.
                                    2698 - 2707, Venice, Italy, October 2017.
                                </a>
                            </li>
                            <li>
                                <a href="https://ieeexplore.ieee.org/document/7539296">
                                    Jiaxi Hu, Hajar Hamidian, Zichun Zhong, Jing Hua: Visualizing Shape Deformations
                                    with Variation of Geometric Spectrum. IEEE Trans. Vis. Comput. Graph. 23(1): 721-730
                                    (2017)
                                </a>
                            </li>
                        </ul>
                    </div>
                    <div class="tab-pane paperlink" id="InformationRetrieval">
                        <li>
                            <a href="https://dl.acm.org/doi/pdf/10.1145/3447548.3467112">
                                Guang Wang, Zhou Qin, Shuai Wang, Huijun Sun, Zheng Dong, Desheng Zhang: Record: Joint
                                Real-Time Repositioning and Charging for Electric Carsharing with Dynamic Deadlines. KDD
                                2021: 3660-3669.
                            </a>
                        </li>

                        <li>
                            <a href="https://edgar.meij.pro/wp-content/papercite-data/pdf/sigir-2018-dietz-tut.pdf">
                                Laura Dietz, Alexander Kotov, Edgar Meij: Utilizing Knowledge Graphs for Text-Centric
                                Information Retrieval. SIGIR 2018: 1387-1390
                            </a>
                        </li>
                        <li>
                            <a href="http://webpages.eng.wayne.edu/~fn6418/docs/nikolaev-sigir16.pdf">
                                Fedor Nikolaev*, Alexander Kotov* and Nikita Zhiltsov, "Parameterized Fielded Term
                                Dependence Models for Ad-hoc Entity Retrieval from Knowledge Graphs", In Proceedings of
                                the 39th Annual International ACM SIGIR Conference on Research and Development in
                                Information Retrieval (SIGIR'16), pages 435-444
                            </a>
                        </li>
                        <li>
                            <a href="http://webpages.eng.wayne.edu/~fn6418/docs/zhiltsov-sigir15.pdf">
                                Nikita Zhiltsov, Alexander Kotov and Fedor Nikolaev, "Fielded Sequential Dependence
                                Model for Ad-Hoc Entity Retrieval in the Web of Data", In Proceedings of the 38th Annual
                                International ACM SIGIR Conference on Research and Development in Information Retrieval
                                (SIGIR'15), pages 253-262
                            </a>
                        </li>
                        <li>
                            <a href="http://webpages.eng.wayne.edu/~fn6418/docs/yang-sigir15.pdf">
                                Zaihan Yang, Alexander Kotov, Aravind Mohan and Shiyong Lu, "Parametric and
                                Non-parametric User-aware Sentiment Topic Models", In Proceedings of the 38th Annual
                                International ACM SIGIR Conference on Research and Development in Information Retrieval
                                (SIGIR'15), pages 413-422
                            </a>
                        </li>
                    </div>
                </div>
                <script>
                    $('#myTab a').click(function (e) {
                        e.preventDefault();
                        $(this).tab('show');
                    });
                </script>
            </div>

        </div>
    </div>
    <!-- new-bottom -->
    <div class="new-bottom">
        <div class="container">
            <div class="new-bottom-info">
                <h3>
                    Our faculty consistently publish in top AI venues tracked by <a
                        href="http://csrankings.org/#/index?all&us" style="font-style: italic;">csrankings.org <i
                            class="fa fa-external-link" aria-hidden="true"></i></a>

                </h3>
            </div>
        </div>
    </div>
    <!-- //new-bottom -->

    <!-- footer -->
    <div class="footer">
        <!-- container -->
        <div class="container">
            <div class="footer-grids">
                <div class="col-sm-4 footer-grid">
                    <div class="footer-grid-info">
                        <h3>Navigation</h3>
                    </div>
                    <div class="footer-grid-list">
                        <ul>
                            <li><a href="about.html">About</a></li>
                            <li><a href="research.html">Research</a></li>
                            <li><a href="education.html">Education</a></li>
                            <li><a href="outreach.html">Outreach</a></li>
                        </ul>
                    </div>
                </div>
                <div class="col-sm-4 footer-grid">
                    <div class="footer-grid-info">
                        <h3>Research</h3>
                    </div>
                    <div class="footer-grid-list">
                        <ul>
                            <li><a href="research.html">Cyber Physical Systems</a></li>
                            <li><a href="research.html">Health Engineering and Informatics</a></li>
                            <li><a href="research.html">Transportation and Mobility</a></li>
                            <li><a href="research.html">Smart and Connected Communities</a></li>
                            <li><a href="research.html">Education and Workforce Training</a></li>
                        </ul>
                    </div>
                </div>
                <div class="col-sm-4 footer-grid">
                    <div class="footer-grid-info">
                        <h3>Contact Us</h3>
                    </div>
                    <div class="footer-grid-list">
                        <h4>Address</h4>
                        <p>5057 Woodward, Suite 3010
                            <span>Detroit, MI, 48202</span>
                        </p>
                        <h4>Contact Us</h4>
                        <p>Telephone : +1 313-577-2477
                            <span>FAX : +1 313-577-6868</span> E-mail : <a
                                href="mailto:ai.research@wayne.edu">ai.research@wayne.edu</a>
                        </p>
                    </div>
                </div>
                <div class="clearfix"> </div>
            </div>
        </div>
        <!-- container -->
    </div>
    <!-- //footer -->
    <!-- copyright -->
    <div class="copyright">
        <!-- container -->
        <div class="container">
            <p>Copyright &copy; 2024.Wayne State University AI Group All rights reserved.</p>
        </div>
        <!-- /container -->
    </div>
    <!-- //copyright -->
</body>

</html>