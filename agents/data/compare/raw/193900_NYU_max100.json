[
  {
    "query": "site:nyu.edu New York University generative AI policy",
    "title": "AI Guidance & Governance",
    "url": "https://www.nyu.edu/life/information-technology/artificial-intelligence-at-nyu/governance.html",
    "text": "AI Guidance & Governance\n\n# AI Guidance & Governance\n\n--\n\n## A Cross-University Team to Guide the Use of AI at NYU\n\nThe AI Leadership Council (AILC) is a standing committee that guides NYU’s strategy, acquisition, development, and implementation of AI tools and services on the university’s behalf. The AILC works with schools and units to understand their needs and to advise or redirect proposed work based on utility, cost, opportunity, and risk considerations.\n\n--\n\n### Core Goals\n\n- Inform leadership and the broader university community about findings and conclusions\n- Follow developments in the field and study new capabilities\n- Help manage legal constraints and ethical risks from use of AI\n- Avoid wasting NYU’s time or money on developing or procuring ineffective or duplicative uses\n- Direct schools and units towards effective and cost effective uses of AI\n- Understand, and coordinate where needed, NYU's larger-scale investments in AI\n\n--\n\n### AI Leadership Council Structure\n\nMembership is drawn from the Offices of the President and Provost, Information Technology, and Global Enrollment Management and Student Success. The group consults widely with members of the Administrative Management Council (AMC), Instructional Technologists Committee (ITC), Committee on Technology Enhanced Education (TEE), and the offices of the EVP, Dean of Libraries, and all relevant Trustee groups. The group reports on the state and possible trajectories of AI to the President, Provost, and EVP twice a year.\n\n#### AI Leadership Council Members:\n\n- Nina Gray, Associate Vice Provost for Research, Provost\n- Hongyi Wen, Assistant Professor of Computer Science Faculty of Engineering and Computer Science, NYU SH\n- Theodore Lee, Chief Information Officer (CIO) and Special Advisor to the COO for Strategic Initiatives, NYU\n- April Hathcock, Associate Dean for Open Knowledge and Faculty Affairs, Libraries\n- Don Welch, Vice President, Information Technology and Global Chief Information Officer, IT\n- MJ Knoll-Finn, Senior Vice President for Global Enrollment, Student Success, and Strategic Positioning, GEMSS\n- Andrea Hernandez, AI Governance and Strategy Director, President’s Office\n- Kristie Patten, Counselor to the President, President’s Office\n- Jennifer Sparrow, Associate Vice President, Research and Instructional Technology and Chief Academic Technology Officer, IT\n- Clay Shirky, Vice Provost for AI and Technology in Education, Provost\n\nFor any questions please contact: [AILC@nyu.edu].\n\n--\n\nBack to top\n\n---\n\n#### IT Support\n\nNYU IT Service Desk is available 24x7. Please email if not urgent.\n\n[NYU Support Center] \n\n[Support & Request Form] \n\n[Global Contact Info] \n\n[NYU IT Feedback] \n\n[IT Service Status] \n\n[Report a Cybersecurity Issue] \n\n[Student Technology Centers]",
    "length": 2787,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University generative AI policy",
    "title": "Statement on Generative AI - College of Arts & Science - NYU",
    "url": "https://cas.nyu.edu/ewp/about/statement-on-generative-ai.html",
    "text": "(This policy statement was drafted in July-November 2025 by Jenni Quilter, and in partnership with EWP's Generative AI Working Group, EWP's Directors, Assistant ...",
    "length": 164,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University generative AI policy",
    "title": "Generative AI Guidelines for NYU Communicators",
    "url": "https://www.nyu.edu/employees/resources-and-services/media-and-communications/nyu-brand-guidelines/creating-messaging-and-visual-assets/best-practices/generative-ai-guidelines-for-nyu-communicators.html",
    "text": "Generative AI Guidelines for NYU Communicators\n\n# Generative AI Guidelines for NYU Communicators\n\n--\n\nNYU is a world-renowned research institution, and as such, we approach the subject of artificial intelligence (AI) with genuine curiosity. While AI is already incorporated into many communications tools and presents positive opportunities for our community, it is a developing technology that also comes with unique challenges. Using generative AI for marketing communications on NYU’s behalf requires a firm understanding of its use cases and limitations, knowledge of the ethical considerations involved, and most importantly—human oversight.\n\nThe following guidelines are to help NYU communicators leverage generative AI as a tool for effective content generation. Here, the word ‘content’ is used in a broad sense: text, graphics, photography, videos, music, etc. These guidelines do not apply to educational and classroom settings and should not be construed as official NYU policy.\n\nPlease note that because AI technology is advancing quickly, this is a living document that will be updated as best practices evolve.\n\n---\n\n--\n\n### Guiding Principles\n\nGenerative AI tools are “trained on” existing content, and, in response to user input, synthesize new material. Generative AI tools are statistical models that generate responses based on patterns in their training content. Generative AI does not understand the concept of “truth” and, as such, has demonstrated that it can have biases and “hallucinate” i.e. make up facts, and pull information from source data without regard for citations or intellectual property rights. It does not engage with moral or ethical considerations, cannot think critically, and is not a replacement for human imagination or discernment. For these reasons, it is important that NYU communicators stick to these guiding principles when using generative AI tools:\n\n--\n\n#### Human-Centered Activity\n\nGenerative AI tools are just that: tools. They should assist—not replace—the people who make content. The breadth of your communications should never be turned over to AI, but it can support your process. AI is no substitute for the creativity, empathy, and attention to detail practiced by NYU communications professionals, but it can be used to enhance our work.\n\n--\n\n#### Review Everything\n\nWe are ultimately accountable for the content we create. Generative AI tools are statistical models and cannot be regarded as an authority on any topic. Their output is influenced by existing material, and this material can be biased, without context, out-of-date, and incorrect. Generative AI also does not fact-check or reliably take copyright or other intellectual property rights into account. You can, however, ask for citations in your prompts, which we recommend. Regardless of citations, it is critical to review and edit any outputs produced by AI to eliminate bias, fact-check content, and avoid plagiarism.\n\n--\n\n#### Protect Data and Privacy\n\nSome generative AI tools may store what you input and use it in future output(s), and this information also may not be encrypted. Do not input any information that is personal or confidential (yours, NYU’s, or anyone else’s), as this may be in violation of university policy as well as state or federal privacy laws such as FERPA (Family Education Rights and Privacy Act). Some examples of protected information include names, demographic information, birthdays, original ideas and code, etc.\n\nAdditionally, do not input licensed, copyrighted, or proprietary content such as NYU logos or wordmarks.\n\n--\n\n#### Be Transparent\n\nBe forthright when you are using AI-generated content. If you have used AI to meaningfully change an image or other content, consider a citation to that effect, referencing the specific tool you used (e.g. ChatGPT, Open AI, etc.).\n\n---\n\n--\n\n### When to Use AI\n\nAI tools can be especially helpful with tasks like creative brainstorming, taking notes, refining ideas, generating code, formatting text, and editing images. It can also help synthesize information, take first passes at editing content (e.g. to match AP or Chicago styles), or improve SEO. Still, AI tools should never be used as the final source for facts or editing. Instead, they can help save time on routine tasks and provide a jumping-off point for creative ideation. Following are some examples of acceptable and unacceptable ways to incorporate generative AI into content creation and communications.\n\n--\n\n#### Examples of Acceptable Use\n\n--\n\nBrainstorming or creating mood boards:\n\n--\n\nGenerative AI tools can create first draft images or compile pictures and images to use as inspiration.\n\n--\n\nResearch and synthesis:\n\n--\n\nGenerative AI tools can create summaries for quick overviews of new topics. This research must be verified by humans, and is not a substitute for scholarly research. For example, you could use generative AI to quickly summarize news articles about a current event, which could help you decide what to explore in more depth.\n\n--\n\nSearch Engine Optimization (SEO):\n\n--\n\nGenerative AI tools can help you conduct keyword research, report on readability, optimize headlines and subheads, and structure information for better navigability, etc.\n\n--\n\nEditorial help:\n\n--\n\nYou can have generative AI tools take a first pass at editing your content to match Chicago style, AP style, etc. But be aware that it may not be using the most up-to-date versions of these manuals and your content will still need to be read by a person. Generative AI tools can also make suggestions for shortening your content, looking for repeated words or ideas or suggesting more efficient language. All final editorial reviews should be conducted with human oversight before publication: see the NYU [Editorial Guide] for best practices.\n\n--\n\nNote-taking and transcription:\n\n--\n\nGenerative AI tools can help you take notes and transcribe interviews or meetings to save time. The results are imperfect and should not be assumed to be a verbatim transcript. AI-generated transcripts should be carefully reviewed before they are shared for anything more than your personal use and reference.\n\n--\n\nEditing images:\n\n--\n\nGenerative AI can help you augment or enhance an image, like retouching an existing image, cleaning up a grainy image, or expanding an image (e.g. adding extra sky to the top of a photograph to adjust the aspect ratio). People, places, and other characteristic elements that tell the NYU story should not be generated by AI for the reasons stated above. Adhere to existing best practices for photo editing and stay true to the goal of presenting factual information.\n\n--\n\nCreating abstract imagery:\n\n--\n\nGenerative AI can be used to create images (not photographs) that are not intended to be interpreted as portraying reality. After you have created the image, use a web image search tool to make sure it has not been plagiarized from another source. Be transparent and credit the image as AI-generated.\n\n--\n\nCoding:\n\n--\n\nGenerative AI tools can help draft or check basic code used on websites.\n\n--\n\n#### Examples of Unacceptable Use\n\n--\n\nCreating photographs or photorealistic images:\n\n--\n\nNYU communications should not use photographs or photorealistic images that have been created entirely by AI, especially if they have human subjects or identifiable university content. AI can be used to edit real images but not to create images. See “Additional Considerations When Creating Photography, Video, and Audio” below for more guidelines\n\n--\n\nTranslation:\n\n--\n\nGenerative AI tools are not yet accurate enough to rely on for translation.\n\n--\n\nCaptions:\n\n--\n\nAI-generated captions may not be accurate or meet our digital accessibility requirements.\n\n--\n\nSensitive, urgent, or private content:\n\n--\n\nCommunications that are sensitive, urgent, or require protected or personal information should not be created using generative AI tools. They should be created by professionals who are authorities on the subject matter, aware of the clarity and empathy these communications require, and mindful of protecting personal information.\n\n--\n\nAuthored content:\n\n--\n\nAny content with a byline should be the original work of the author.\n\n---\n\n--\n\n### Additional Considerations When Creating Photography, Video, and Audio\n\nExercise caution when using AI tools. For example, using an AI voice-over tool for a training video is acceptable, but using AI to generate the voices of any NYU community member or guest, be it a specific individual or a generic one, is misleading. If an AI script or narration is used, it should be reviewed carefully and disclosed.\n\nAI should not be used to create sound bites or quotes by people who speak in videos. Inputting a real person’s voice into an AI tool endangers that person’s privacy and can be a security risk. This is because the recorded voice of a real person can be used to generate unlimited audio files that recreate the sound of the actual person’s voice saying anything and not just what the person said in the recording.\n\nAI-generated music may be appropriate in videos but can very easily infringe on copyrighted material, even if the AI tool uses only a portion of the material. The same is true of photography and art. Consider other human-generated resources first, including royalty-free music.\n\nAs stated above, use generative AI to help brainstorm or enhance but not to create the final product.\n\nAlways carefully review AI-generated work. Since AI tools pull from numerous sources, consider whether the AI-generated work is reasonably similar to existing work.\n\n--\n\n### Other Considerations\n\nIt is important to know that search engines like Google can detect AI-generated content. While this will not necessarily harm your web page’s search rankings at this time, search engine companies constantly change their algorithms, and experts offer conflicting information about whether AI-generated content will or will not be favored. What has been constant",
    "length": 9989,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University generative AI policy",
    "title": "Generative AI Tools for Academic Research - Generative AI Tools for Academic Research - Research Guides at New York University",
    "url": "https://guides.nyu.edu/ai-tools",
    "text": "Generative AI Tools for Academic Research - Generative AI Tools for Academic Research - Research Guides at New York University Skip to Main Content\n\nSearch\n\n# Generative AI Tools for Academic Research\n\nSupport for critical approaches to GenAI tools for academic research.\n\n## Welcome\n\nThis guide is intended to support researchers as they navigate the emergent landscape of generative artificial intelligence (GenAI) applications that are marketed to students and educators as effective tools for academic research. Resources are mentioned here for informational purposes only; their inclusion is not an endorsement or recommendation of their use by NYU or NYU Libraries. We encourage you to think critically about each tool that you use including how it was created, what it does, how you use it, and how it interacts with the rest of your research materials and processes.\n\nGenAI tools are not a substitute for learning the fundamentals of conducting research. As you start your project, take a look at our related research guides for help with your research process, including:\n\n- [Academic Integrity for Students at NYU Policy] \n- [Plagarism (Plagiarism and How to Avoid It)] \n- [Proper citation (Citation Style Guide)] \n- [How to organize your sources (Zotero)] \n- [How to craft a research question (First-Year Writing Seminar)] \n\n## Generative AI for Academic Research in Practice\n\nAcademic research is the exploration, evaluation, collection, organization, analysis, and synthesis of sources and materials in support of a scholarly argument.\n\nSome GenAI tools can be useful for tasks such as brainstorming, for discovering new terms and unexpected connections between ideas, and writing code, but every output generated by AI must be independently verified. Verification may require different skills depending on the output e.g. evaluating the accuracy of statements, running code without errors, identifying positive or negative bias, or confirming that a citation or cited source really exists, et al..\n\nAny use and/or the transparency of use of GenAI tools must align with the guidelines set forth by your institution and instructors or evaluators.\n\n## Generative AI Tools and Academic Integrity\n\nAs with all tools and resources, be sure to follow the policies that your institution has put in place to maintain academic integrity.\n\nIf you are a part of the NYU community, [Teaching with Generative AI] provides guidelines that highlight important considerations when it comes to:\n\n- Academic Integrity and AI\n- AI Citation and Acknowledgement\n- Exploring AI\n\nFor more information on Generative AI and academic integrity for academic research see our [Research Guide: Generative AI and Academic Integrity].\n\n## Generative AI Tools: Independent Reviews and Evaluations\n\n[ITHAKA S+R Generative AI Product Tracker] \n\nThe Generative AI Product Tracker is a project of [ITHAKA S+R], a non-profit organization, and documents products that are marketed specifically towards post-secondary faculty and students. Each tool has a short description, key features, comments, and known limitations. The GenAI tool tracker is updated frequently.This list is for informational purposes only and tools listed in this document are not recommended or endorsed by NYU Libraries.\n\n[MIT AI Risk Repository] \n\nMIT maintains a repository of AI risks drawn from a deep-dive into the AI risk literature. The listing includes a “causal taxonomy” for AI risks; a \"domain taxonomy\" for AI risks; and an \"AI Risk Database\" that captures and describes risks extracted from 65 existing frameworks and classifications of AI risk.\n\n[Stanford HAI: Stanford University Human-Centered Artificial Intelligence] \n\nThe Center maintains a [Foundation Model Transparency Index]. Reports, data, individual model ratings, and more are available for free.\n\n## Additional Resources & Foundational Literature on Generative Artificial Intelligence\n\n[A People's Guide to AI: A workbook by Mini Onuoha and Mother Cyborg, published by Allied Media Projects.] \n\nA basic workbook and introduction for foundational GenAi concepts created by the non-profit Allied Media Projects.\n\n[Generative AI Primer: An Accessible overview of Generative AI topics and tools, published by the non-profit Centre for AI (UK).] \n\nAn introduction and overview to Generative AI tools and concepts.\n\n[Models All the Way Down: An introduction and investigation in AI training data sets by Knowing Machines.] \n\nA research project from the non-profit organization Knowing Machines tracing the histories, practices, and politics of how machine learning systems are trained to interpret the world.\n\n[On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? Bender, Emily M. ; Gebru, Timnit ; McMillan-Major, Angelina ; Shmitchell, Shmargaret Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 2021, p.610-62] \n\nA seminal article on the nature of AI and Large Language Models (LLMs)\n\n[He, Ran; Cao, Jie; Tan, Tieniu (2025). \"Generative Artificial Intelligence: A Historical Perspective\". National Science Review.] \n\nA general review of current generative AI applications and a discussion of challenges and potential research directions in GAI technologies.\n\n- [Print Page] \n- URL: https://guides.nyu.edu/ai-tools\n- Last Updated: Dec 2, 2025 5:09 PM\n\n[Author Log-in] \n\n[Report a problem] \n\n[Accessibility]",
    "length": 5382,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University generative AI policy",
    "title": "Teaching with Generative AI",
    "url": "https://www.nyu.edu/faculty/teaching-and-learning-resources/teaching-with-generative-tools.html",
    "text": "# Teaching with Generative AI\n\nStudents and faculty report growing use of generative AI—tools that produce human-like writing (e.g ChatGPT), images (e.g. MidJourney), code (e.g. Microsoft Co-Pilot) and the like. The flexibility of these tools mean that there is no current default for acceptable vs. unacceptable use of these tools in coursework, and student adoption is moving faster than faculty adaptation. Many students are using AI without clear directions from their instructors about which uses are acceptable.\n\n**Faculty should explain to students what is and is not allowed** around AI use in their classes. (We know some faculty believe students are not using AI in their classes. If this is you, we assure you you are wrong.) The Provost’s Office recommends that faculty adopt the following three principles for student use of AI:\n\n1. When a student uses these tools, they should acknowledge that use\n2. The student is responsible for the content and accuracy of any work they submit, however created\n3. Students only learn from productive effort, and should understand how misuse or overuse of AI threatens that effort\n\nIn order to help students understand these things, we recommend that instructors:\n\n- [Explain your AI policy in your syllabus], and discuss the reasons you adopted it in class\n- Be specific about Dos and Don’ts—“Do acknowledge and describe any AI use”, or “Don’t use any AI for anything other than suggesting topics and sources”\n- Explain the [limitations of generative AI].\n- Remember that students generally want to learn, and explain to them what they can learn from doing the work, not just the potential punishments for cheating\n\nAdditional details can be found in the [AI FAQ] and in [Adapting Assignments to AI].\n\n### Academic Integrity and Generative AI\n\nWith AI being integrated into a wide range of student work, there is no longer any obvious line dividing acceptable from unacceptable use. Using AI to generate ideas, our outlines, or drafts to be edited might be allowed (or even required) for an assignment or it might be forbidden. There is no way for a student to know which it is without guidance.\n\nToo often, academic integrity is presented as a list of behaviors to avoid. We need to present academic integrity as a positive virtue, a description of the conditions necessary for students to learn. The best long-term strategy is to design courses to have more, lower-stakes assessments that offer rapid feedback and an opportunity to make incremental progress on an assignment. Even with course designed around those principles, however, there may be students who use AI in ways that violate faculty requirements.\n\nDetecting and adjudicating inappropriate use of generative AI is harder than detecting simple cut and pasting from public sources. Every student now has no-cost access to a service that can answer a question or write an essay for them; the familiar paid essay writing services are now effectively ubiquitous and free. Intervening when an instructor suspects AI misuse relies far more on the instructor’s judgment about the student’s capabilities than when the source material exists online or in a database.\n\nIf an instructor suspects a student of an academic integrity violation:\n\n- Document reasons for believing the writing is not the student’s own. Possible evidence includes:\n - **Internal Patterns:** Grammatical perfection, consistent but bland style, sudden changes in style or tone, vague or unsubstantiated claims, spurious or incorrect references, and list structures masquerading as development of an idea.\n - **External Patterns:** Writing does not match a student's previous work  (particularly work produced in class), lack of rough drafts or evidence of editing, footnotes or references not related to the body of the text, footnotes or references pointing to work that does not exist.\n- Ask the student if they used generative AI on the assignment in inappropriate or unacknowledged ways, given the evidence. One possible response if they say Yes (and if it is in line with your school’s policies) is to require them to redo the work, providing evidence of editing\n- If they deny using these tools but you continue to suspect that they used them, involve your school administration.\n\nWhile there are a number of products that purport to positively identify AI-generated writing, they have high error rates, especially for students for whom English is an additional language. NYU does not license or endorse use of any of these tools.\n\n* * *\n\n#### A Curated List of AI Resources\n\n- [nyu.edu/ai] \n - [Private Generative AI Pilot] \n- Office of the Provost:\n - [NYU Teaching and Learning with AI]  (web page)\n - [Adapting Writing Assignments to Generative AI]  (Google Doc)\n - [Generative AI Primer]   (Google Slides)\n - [Hands-On with ChatGPT]  (Google Slides)\n - [(Re)designing Assignments & Assessments]  (Google Slides)\n- NYU Schools\n - Abu Dhabi's Hilary Ballon Center for Teaching and Learning: [Teaching with Generative AI]  (NYU Stream)\n - Arts and Science [Getting Started with Generative AI for Instructors]  (Brightspace course open to all NYU Instructors.)\n - Steinhardt\n\n\n - [AI: Creating Prompts with AI]  (web page)\n - [AI: Class Policies]  (web page)\n - [AI: Tips for Writing Assignments]  (web page)\n - [Stern]  (website)\n - Tisch:\n - [Game Center AI Policy]  (web page)\n- NYU Libraries\n - [Evaluating and Acknowledging AI-Generated Text]  (Slides)\n - [Understanding ChatGPT and the Concept of AI Language Generators]  (website)\n - [Machines and Society (NYU Shanghai Library)]  (website)\n\n[⌃ back to top]",
    "length": 5601,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University generative AI policy",
    "title": "Generative AI Updates – Live Syllabus and Faculty Development Resources – A&S Office of Teaching Excellence and Innovation",
    "url": "https://wp.nyu.edu/fas-edtech/2024/01/generative-ai-updates-live-syllabus-and-faculty-development-resources/",
    "text": "Generative AI Updates – Live Syllabus and Faculty Development Resources – A&S Office of Teaching Excellence and Innovation\n\nAs we begin another semester and set expectations with our students, it’s important to include our expectations for generative AI use in our syllabi and initial course discussions. Your approach is dependent upon your context, including your discipline, course, student cohort, or the learning outcomes you have set for a particular assignment. For some, generative AI use may be helpful for the brainstorming phase of writing but not be appropriate again until the final draft of written work through the use of tools like grammar checkers. For others, generative AI use may be embedded into the learning process to facilitate critical digital literacy skills. Whatever your approach, clear communication with students about your expectations and your justification for your generative AI use policies should be on your beginning of the semester agenda.\n\nWe know this task is daunting, especially as generative AI technologies continue to improve and their use becomes more widespread. There are a number of resources available to you as you determine what generative AI use policies are appropriate for each of your assignments and courses.\n\nThe following guides provide a wealth of information to inform your course design process.\n\n- [Instructor Generative AI Guide] \n- [Library Generative AI Citation Guide] \n- [Faculty: AI and Coursework at NYU — Frequently Asked Questions] \n\nIf you’d like to learn more of the generative AI basics on your own, you may also be interested in checking out our asynchronous [Getting Started with Generative AI Course on Brightspace]. We will be publishing a second set of units in that course focused on Prompt Engineering soon, so keep an eye out for more opportunities to explore generative AI capabilities and limitations.\n\nFinally, our team is here to support you as you develop a generative AI use policy that fits your context. Contact our team at fas-edtech-group@nyu.edu or use the [Liaison Finder] to find your department’s educational technology specialist to set up a consultation.",
    "length": 2154,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University generative AI policy",
    "title": "Research Guides: Machines and Society: Generative AI for Research and Creative Use",
    "url": "https://guides.nyu.edu/data/llm-research-creative-use",
    "text": "[Skip to Main Content] \n\n[![Banner]] \n\nSearch this GuideSearch\n\n# Machines and Society\n\nA growing guide on the latest in data-driven research and emerging technologies at the intersection of society, information and technology.\n\n- [Home] \n- [Large Language Models] \n - [What Large Language Models Are] \n - [Technical Overview] \n - [Bias] \n- [Generative AI for Research and Creative Use] \n\n - [Introduction] \n\n - [Overview of ChatGPT] \n - [Generative AI for Data-driven Research] \n - [Generative AI for Application Development] \n - [Generative AI for Visual Design] \n - [Generative AI in Campus Life] \n- [Emerging AI Tools for Teaching and Learning] \n - [Chatbot Quickstarts] \n - [Image Generation Tools] \n - [Setting Up Local Generative AI Tools] \n - [Suggestions for Teaching and Learning] \n - [Citing Generative AI] \n- [Technology and Society] \n - [Copyright, Authorship, and Governance] \n - [Business and Industry] \n- [Computational Social Research] \n - [The Field of Computational Social Science] \n - [Web Mining for Digital Disease Surveillance] \n - [Data Collection with Crowdsourcing Technology] \n\n## Introduction\n\nThis guide provides summaries, examples, and resources of how to use generative AI for scholarly and creative purposes in academic settings. The guide uses ChatGPT as an example to illustrate how AI assistants could be applied in data-driven research, application development, visual design, and solving problems and enhancing productivity in one's life and work.\n\nThis section covers the following topics\n\n- [Overview of ChatGPT] \n- [Generative AI for Data-driven Research] \n- [Generative AI for Application Development] \n- [Generative AI for Visual Design] \n- [Generative AI in Campus Life] \n\n- [<< **Previous:** Bias] \n- [**Next:** Overview of ChatGPT >>] \n\n[Accessibility (opens\\\nin new window)]",
    "length": 1821,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University generative AI policy",
    "title": "Generative AI – A&S Office of Teaching Excellence and Innovation",
    "url": "https://wp.nyu.edu/fas-edtech/category/generative-ai/",
    "text": "[![]] \n\n[Skip to content] \n\nAs Generative AI continues to present a challenge for traditional teaching and learning practices, many faculty are expressing curiosity about alternative grading, a term that includes several forms of assessment (such as contract grading or standards-based grading) where course grades are determined by students’ effort over time rather than by their performance on individual assessments. \\[…\\]\n\nDo you want to see for yourself the most common ways your students are using generative AI—to summarize assigned texts, to edit or translate their written work, and to generate ideas for assignments? Do you want to test out generative AI’s capabilities and think critically about its potential uses and shortcomings with colleagues? Our office \\[…\\]\n\nThe pilot Jterm Foundations of Research Computing (FORC) mini-camp, aka Flash FORC, was a resounding success! More than 40 graduate students gathered in Bobst Library on January 16, 2025 to explore the potential of Generative AI as a research tool. The FORC program is a joint offering of NYU Data Services (NYU Libraries and IT), \\[…\\]\n\nNYU Data Services (NYU Libraries and IT), the Graduate School of Arts & Science Master’s College, and the Arts & Sciences Office of Teaching Excellence and Innovation are excited to launch a new extension of the Foundations of Research Computing (FORC) Camp training opportunity for graduate students! Given the strong interest in data skills development \\[…\\]\n\nWhile the landscape of teaching in higher education is always changing, the disruption brought on by the availability of Generative AI can leave many instructors feeling overwhelmed and unsure of where to start. For those of you who missed it, the Office of the Provost offered a series of Generative AI workshops in August of \\[…\\]\n\nAs we begin another semester and set expectations with our students, it’s important to include our expectations for generative AI use in our syllabi and initial course discussions. Your approach is dependent upon your context, including your discipline, course, student cohort, or the learning outcomes you have set for a particular assignment. For some, generative \\[…\\]\n\nGenerative AI continues to fill headlines and occupy conference agendas and, although the landscape of education continuously evolves, the impact of generative AI seems to be causing a particular shock for institutions.  In an effort to provide faculty with the foundational knowledge they need to begin exploring the limitations and possibilities of such tools in \\[…\\]\n\nWe had a great time hosting our watch party for NYU’s Teaching & Learning with Generative AI Virtual Conference! The LaGuardia Student Technology Center graciously hosted our event and the set-up was perfect. Cozy chairs surrounding a big screen fully equipped to join Zoom meetings and conferences. We even had our own camera set-up so \\[…\\]\n\nWidespread access to generative AI tools necessitates revisiting assignments to make them at the very least less vulnerable to breaches of academic integrity, but also to find opportunities to transform them into vehicles for promoting better understanding and critical use of these tools by students. Two things are certain: There is no silver bullet response. \\[…\\]\n\nAs another academic year approaches, we would be hard pressed to find an instructor who hasn’t at least heard of ChatGPT or other Generative AI tools. The widespread availability and use of this technology has caused quite a stir, leading many in the field of Higher Education to reconsider what it means to evaluate student \\[…\\]",
    "length": 3600,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University generative AI policy",
    "title": "Frequently Asked Questions About Teaching and AI",
    "url": "https://www.nyu.edu/faculty/teaching-and-learning-resources/teaching-with-generative-tools/frequently-asked-questions.html",
    "text": "Frequently Asked Questions About Teaching and AI\nMenu[Skip to All NYU Navigation] [Skip to Main Content] \n[NYU] \nSearchSearch SiteAll NYU\n[NYU Home] \n[Login toNYU Home] \nAll NYU\n[NYU] \nSearch Site\n# Frequently Asked Questions About Teaching and AI\n#### **[Generative AI] **\n**[What is generative AI? How can I experiment with it?] \n[How can I experiment with generative AI?] \n[What are some limitations of generative AI use?] \n[What is NYU's policy about student AI use in coursework?] \n[What risks of learning loss can generative AI create?] **\n#### **[Recommendations for Faculty Use of AI] **\n**[What recommendations apply to faculty use of AI?] \n[What are the recommendations around data use?\n] [How should I communicate my preferences for AI use to my students?] \n[When and how can I get access to NYU’s private generative AI service?] **\n#### **[Generative AI Ethics and Responsible Use] **\n[**Academic Integrity and Generative AI\n**] **[What uses of AI constitute cheating?] \n[How should faculty respond to suspected cases of cheating with AI?] \n[Why doesn't NYU license an AI detector?] **\n#### **[Additional Office of the Provost Resources around Generative AI at NYU] **\n**[Conversations at NYU about AI] **\n### **Generative AI\n**\n**What is generative AI? How can I experiment with it?**\nGenerative AI is a label for tools such as ChatGPT,[Gemini],[NotebookLM], or Midjourney, and describes AI services that generate novel responses to prompting by a user. These services create output as a response to prompting by the user, based on training on billions of examples of text, images, code, etc.\nThough there are many types of generative AI, the “large language models” like[Gemini] from Google, ChatGPT from OpenAI; LLaMa from Meta; or Claude from Anthropic, have the widest range of uses in academic settings. These models can generate relevant responses to many kinds of prompts, meaning they can be used—and are being used—in some way or another in most classes. The opportunity is that students use them to explore ideas and test their knowledge. The threat is that students use the tools to opt out of the effort needed for them to learn.\n**How can I experiment with generative AI?**\nNYU now offers access and support for both Google’s[Gemini] and[NotebookLM] to faculty, staff, and students. Learn more about these tools in this[fact sheet] from NYU IT.\nThere are many kinds of generative tools, for creating text, audio, images, video, and code. More recently, more tools are multimodal, producing combined output —text and images, web pages and code —that increase the complexity of what is possible.\nText-generating tools are the most widely used at NYU, and their most notable feature is producing surprisingly competent written responses to relatively complex questions.\nIf you would like to try it, below are sample prompts you can input into[Google’s Gemini].\n* Can you quiz me on the nature of aliphatic compounds?\n* What are some critical tradeoffs in the design and deployment of public transportation in American cities?\n* Can you write a python script that calculates the Fibonacci sequence to the 50th place?\n* Can you write an outline, with opening and closing paragraphs, comparing the work of Mark Rothko and Willem de Kooning?\nIt is possible to use more complex prompts with these tools, by including the role you are asking the model to play (which generally improves the answers), and the question you want a response to. Here are three sample prompts you can use with large language models:\n1. You are a professor of biology, teaching an introductory course. Please write a description of meiosis vs. mitosis, highlighting similarities and differences in the two processes.\n2. You are an art historian of Chinese ceramics. Please describe the technical and aesthetic changes in ceramic production from the Shang Dynasty to the Warring States period.\n3. You are a screenwriter pitching a film. Please write three loglines for science fiction movies where one of the protagonists is not human.\nTrying one or more of these prompts, modifying them, or creating your own will demonstrate the basic capabilities of text-generating tools. It will be especially valuable if you try these tools with material from your own courses. You can also try[image generation],[voice generation],[code generation],[research support], and so on.\nArts and Science has developed a Brightspace course open to all NYU instructors,[Getting Started with Generative AI for Instructors], that provides more in-depth experience with these tools.\n**What are some limitations of generative AI use?**\n* **Random responses**\nRandomness is built in. You'll get a different answer every time even when you use the same prompt.\n* **Trained for plausibility, not accuracy**\nGenerative AI is designed to produce plausible instances (i.e., to make things up). “Hallucination” describes the inclusion of incorrect or invented information in responses to user prompting.\n* **Bias**\n* Generative AI tools are trained from a wide range of sources, so output may follow bias absorbed from those sources. Bias can also take the form of a lack of coverage of particular disciplines, languages, regions, and so on.\n* Generative AI tools have typically been trained on data that tends towards stereotypical answers—“Doctors are men whereas nurses are women” kinds of biases that extend to many circumstances. All users of these tools should be aware that these biases exist and should use their judgment in using or editing the output.\n* **Digital Divide\n**Access is not equitable. There are gaps between who has access and who doesn’t, largely as a result of differences in tools between free and paid tiers of access, and between students who can afford more expensive computers and phones that have AI capabilities built-in, vs. those using cheaper models.\n* **Intellectual Property and Copyright Issues\n**These models are often trained on copyrighted materials, though it is not yet clear whether such training violates copyright law.\n**What is NYU’s policy about student AI use in coursework?**\n1. The instructor approves.\n2. The student abides by any requirements or limitations the instructor may have.\n3. The use does not violate[NYU’s Academic Integrity Policy], which forbids “submitting work (papers, homework assignments, computer programs, experimental results, artwork, etc.) that was created by another, substantially or in whole, as one's own.”\nGenerative AI is a new arrival in the academic environment and can be used in a wide variety of ways. Because of this novelty and flexibility, there are few standard approaches to its use beyond an institution-wide restriction on taking credit for AI output without acknowledging its use. Most policies will be set by the schools or by individual faculty members. Check with your school or department to see if there are local policies.\n**What risks of learning loss can generative AI create?**\n**Using AI can*feel*like learning**. Though much of the public conversation on AI use has focused on cheating, the bigger risk is students using AI because they think it is helping them learn when it is instead replacing the experiences students are meant to learn from. Learning requires effort, and not understanding something can make people feel dumb. Getting an answer from AI quickly and easily is a shortcut that doesn’t feel like one. It is easy to believe that generating an answer or plausible response is the same as creating one.\nOne significant risk is automation bias, which is to say**students may place undue trust in the output**of generative AI tools. These tools have been trained to produce written output that sounds confident and plausible, leading many people to believe that the output is also accurate. Interestingly, failure rates seem to be higher for answers produced in highly structured formats, like journal citations or legal case identifiers. In those cases, large language models can produce references in perfect MLA style to papers that do not exist.\nRelatedly, students should understand that AI tools are**not authoritative sources**. While their output should be acknowledged, they should never be cited as evidence. No matter what tools are used, the student is ultimately responsible for the contents of any work they submit.\n**AI output is opaque without chain-of-thought prompting or tools**, reducing students’ understanding of the process. There is no way for a student (or anyone) to know how an answer was constructed or how a change to a prompt will change the answer without chain-of-thought prompting or tools. There is also no way to produce the same answer in the future, even with an identical prompt. This can limit students’ comprehension of the material.\n### **Recommendations for Faculty Use of AI**\n**\nWhat recommendations apply to faculty use of AI?**\nMost decisions about classroom conduct are left to individual instructors, and faculty use of AI in the design and running of their courses is no exception. Faculty at NYU are experimenting with AI tools to make suggestions or provide feedback on syllabi, assignment prompts, and test questions. However, there are both restrictions and recommendations about such use:\n* The[humans-in-the-loop] principle, meaning that an AI’s operations and output should be subjected to human review before use, is a good one for both faculty and student work.\n* If you use these tools to help develop class materials —explainers, banks of test questions, assignment statements —you should be as alert to the risk of plausible sounding but incorrect suggestions as you expect your students to be.\n* If you use",
    "length": 9650,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University generative AI policy",
    "title": "Generative AI Tools for Academic Research",
    "url": "https://guides.nyu.edu/ai-tools/discovery",
    "text": "For Discovery - Generative AI Tools for Academic Research - Research Guides at New York University[Skip to Main Content] \n[![NYU Libraries logo.]] \nSearch this GuideSearch\n# Generative AI Tools for Academic Research\nSupport for critical approaches to GenAI tools for academic research.\n* [Generative AI Tools for Academic Research] \n* [For Discovery] \n* [AI Tools for Discovery] \n* [GenAI-enhanced Search Tools] \n* [Chatbots] \n* [Personalized Knowledge Management and Research Organization Tools] \n* [Google Gemini and NotebookLM at NYU] \n* [Citation Chasing and Visualization] \n* [Evaluating AI Tools for Discovery] \n* [Additional Resources] \n* [For Transcription] \n* [For Translation] \n## Related Research Guides\n* [Generative AI and Large Language Models (LLMs)] \n* [Citation Style Guide] \n* [Citation Style Guide: Citing and evaluating AI-Generated text] \n* [Plagiarism and How to Avoid It] \n* [Generative AI and Academic Integrity] \n* [Images and AI in Academic Research] \n* [Media and Misinformation] \n* [AI and Qualitative Research] \n## Subject Librarian\n[\n![] \nRoberta Muñoz\n] \n[Email Me] \n## Subject Librarian\n[\n![] \nCarol Choi\n] \n[Email Me] \n**Subjects:**[Public Policy & Administration],[Urban Planning] \n## Guide Contributors\n* Joshua Eisenstat\n* [Alla Roylance] \n* [Lia Warner] \n## AI Tools for Discovery\nGenAI tools are marketed to perform a number of tasks as part of the academic research workflow including brainstorming, search, summarizing, coding, and more. Evaluating their usefulness starts with an understanding of the tools themselves - how they&rsquo;&rsquo;re built and work - as well as careful validation and human oversight to ensure currency, reliability, authority, purpose (point of view/bias), and truthfulness in conjunction with the time it takes to verify outputs.\n**All search tools that use Generative AI can return misinformation, including fake facts and fabricated citations.**\nBelow is a brief overview of the types of tools/tasks currently available.\n## GenAI-enhanced Search Tools\nThis type of feature has been added to tools you are already familiar with:\n* **Search engines/sites**like Google.com and DuckDuckGo &ldquo;&ldquo;crawl&rdquo;&rdquo; the internet, index pages and match your search terms to priorities such as relevance and currency. Now, the results may also provide an AI-generated summary.\nAI summaries do not appear with every search. These AI features are a separate function powered by large language models and other tools (e.g. Google AI Overview uses Google&rsquo;s Gemini LLM, and is &ldquo;supplemented with aspects of the company&rsquo;s Search system, like the[Knowledge Graph] &rdquo;&rdquo; according to this[May 16, 2024 article in Wired by Reece Rogers]).\n* **Some Library databases**now include generative AI features including search/keyword suggestions, article summaries, suggestions for research questions, and related resources (e.g.[Statista Research AI Assistant],[JSTOR]). These tools use commercial LLMs as underlying infrastructure and use retrieval-augmented generation (RAG) trained on the database&rsquo;&rsquo;s corpus in order to focus the outputs; this allows AI-generated responses to cite sources from within the database only, or to generateoutputs that are relevant to the subject domain of the platform. These features may still generate lies, misinformation, or be misleading and even harmful. Outputs must always be independently verified and evaluated.\nNYU Libraries provides access to approximately 1,500 databases. AI features in these resources are evolving rapidly and we are evaluating them as they develop. If you are unsure about whether a specific NYU Libraries database uses AI or about how this will affect your research process,[contact a librarian].\n**Note:[ProQuest&rsquo;s AI Research Assistant] was evaluated by NYU librarians in December 2024 and was found to be unsuitable for inclusion in NYU Libraries databases. The tool will be re-evaluated and re-considered at a future date.**\n## Chatbots\nChatbots are sometimes referred to as &quot;&quot;answer engines&quot;&quot; (as opposed to search engines). Chatbots generate a synthesized response (output) to a user query (input) based on a probabilistic and statistical algorithm. The responses appear as conversational summaries. Some chatbots have conversational memory and can build and follow-up on questions and queries.\nChatbots can:\n* Have their own platform (e.g. ChatGPT, Claude, Microsoft CoPilot, Perplexity), which can be multi-modal - offering different Gen AI tools on the same platform.\n* Be an add-on/extension (e.g.[Perplexity Chrome extension])\n* Be a feature within a library resource (e.g. Statista Research AI Assistant)\nSome of these tools generate outputs with hyperlinks to sources/citations to help users verify information. Please note that it is still possible for the outputs to include misinformation. Many of these tools do not cite scholarly, academic sources. The number of sources may be limited. The accuracy and relevance of sources must be verified and evaluated.\n## Personalized Knowledge Management and Research Organization Tools\nDigital AI Notebooks and Research Organization tools allow users to upload and query documents that can range from PDFs of articles, bibliographies, citations, links, personal notes, and paper drafts written by the user (e.g.[Elicit],[ChatGPT],[Google NotebookLM]). The tool then provides summaries, suggests connections between the uploaded materials, and/or allows users to generate inputs that &ldquo;query&rdquo; the materials in the form of a chat exchange similar to the tools described above.\nThese tools use RAG AI and results are subject to the same risk of false, synthetic information and confabulations as AI generated tools.\n**Note: Exercise caution when uploading material into these tools as there are privacy and legal concerns to consider.**\n**The materials you upload may include content that should remain private and/or may be subject to restrictive licensing agreements. For instance, PDFs of articles retrieved via NYU Libraries&rsquo; resources are for non-commercial, academic purposes only; some companies reserve the right to add uploaded material to their training data or use for other commercial purposes and/or outputs generated may violate licensed use. It is the responsibility of each user to carefully review the terms of services and related policies.**\n## Google Gemini and NotebookLM at NYU\nAs of February 2025, NYU provides access to Google Gemini and Google NotebookLM to current students, faculty, and staff. The latest information on the NYU instances of these tools including data privacy settings and how to access them can be found via[NYU Generative AI (GenAI) Services].\nConsider both[the note above regarding data privacy and restrictions on uploading NYU library resources] along with the rubric below when integrating these tools into your research workflow.\n## Citation Chasing and Visualization\nCitation chasing is the process of using an article that you have in-hand as a starting point then tracking down other sources connected to that work as you create a literature review (e.g.[Elicit],[Research Rabbit],[Inciteful]). Connections are made via citations (i.e. a paper is cited in or cites a connected paper), shared authors, shared subject matter, etc. Some tools generate a visualization that maps these connections.\n## Evaluating AI Tools for Discovery\nMany researchers select a tool based on what is commonly used by peers in a department or field. As a researcher, it is your responsibility to investigate tools independently. In addition to identifying your own research or accessibility requirements, there are a number of other things to consider.\nThe table below provide a rubric for evaluating AI tools for discovery.|**Criteria**|**Considerations**|\nAccuracy and Verification|GenAI tools are based on statistical probability and predicting text,**not retrieving information**. GenAI has been proven to create responses with false summaries and/or imaginary citations and sources that do not exist. The reliability and authenticity of every piece of information must be independently verified regardless of the GenAI tool(s) you are using.|\nSources/Training Data|\nAre the training data sources transparent? Have the sources and data been ethically sourced?\nWhat are the sources of information the tool draws on or what is the training data (these can be different)? Are the subjects and disciplines relevant to your search included?\nDoes the tool provide verifiable citations in the form of links to information sources? Does it use scholarly databases? Peer-reviewed material? The open web?\n**Note: Confabulations occur even in tools that draw data from verified scholarly datasets or databases.**|\nPrivacy and Data Collection|\nIs the tool cloud-based or run locally on your device? How is data transfer and privacy managed for either?\nHow will your inputs (queries, uploaded files, etc.) be used? Are chatbot conversations, research queries, and personal data**protected**? Will your data be used to train the tool? Are your search queries**archived**or**preserved**, or will they be lost if you stop subscribing to the tool?\n|\nLicensing|Do you have permission to provide your inputs/files to the platform/tool? (seeUpload and Query Documents in the above table)|\nAccess and Equity|\nDoes it cost money to use this tool? If so, how much and how much are you willing/able to pay? Are there different tiers with different fees? Is the tool easy or",
    "length": 9547,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University generative AI policy",
    "title": "NYU Launches Generative AI Resources for Instructors and Researchers",
    "url": "https://www.nyu.edu/research/navigating-research-technology/stories/nyu-launches-resources-for-instructors-exploring-generative-ai.html",
    "text": "NYU Launches Generative AI Resources for Instructors and Researchers\n[![New York University homepage]![New York University homepage]] \nSearch Box\nSearch\nSearch\nAll NYU\nClose\n[] \n[Login to NYU Home] \nGlobal Locations\n* * [New York] \n* [Abu Dhabi] \n* [Shanghai] \n* * [Accra] \n* [Berlin] \n* [Buenos Aires] \n* [Florence] \n* [London] \n* [Los Angeles] \n* [Madrid] \n* [Paris] \n* [Prague] \n* [Sydney] \n* [Tel Aviv] \n* [Tulsa] \n* [Washington DC] \nSchools\n* [Arts and Science] \n* [College of Arts and Science] \n* [Graduate School of Arts and Science] \n* [Liberal Studies] \n* [College of Dentistry] \n* [Courant Institute of Mathematical Sciences] \n* [Gallatin School of Individualized Study] \n* [Grossman School of Medicine] \n* [Institute for the Study of the Ancient World] \n* [Institute of Fine Arts] \n* [Leonard N. Stern School of Business] \n* [Long Island School of Medicine] \n* [Robert F. Wagner Graduate School\nof Public Service] \n* [Rory Meyers College of Nursing] \n* [School of Global Public Health] \n* [School of Law] \n* [School of Professional Studies] \n* [Silver School of Social Work] \n* [Steinhardt School of Culture,\nEducation, and Human Development] \n* [Tandon School of Engineering] \n* [Tisch School of the Arts] \nMenu[Skip to All NYU Navigation] [Skip to Main Content] \n[NYU] \nSearchSearch SiteAll NYU\n[NYU Home] \n[Login toNYU Home] \nAll NYU\n[NYU] \nSearch Site\n# NYU Launches Generative AI Resources for Instructors and Researchers\n## Site includes glossary, resources, and Generative AI pilot\nNYU has been active for many years in areas of artificial intelligence (AI) and machine learning for experimentation and research. The rise in attention to the technology and potential impact of AI and the increase in publicly available AI tools has made discussion around AI a robust topic of conversation in higher education.\nTo help NYU instructors and researchers navigate the fast-evolving AI landscape, NYU Information Technology, in collaboration with the Office of the Provost, has launched a new web resource.[Artificial Intelligence at NYU] contains information to aid the NYU community in making informed decisions about the role AI could play in teaching, learning, research, and work. The new side includes:\n* **[Artificial Intelligence at NYU] info hub**: introduces key AI questions and providing a glossary of terms and links to AI resources at NYU.\n* **[NYU Community Generative AI Tools] **: a guide to the most popular public AI tools, including ChatGPT, Bard, and Bing Chat.\nIf you have any remaining questions or concerns about the use of generative AI for NYU academic or research purposes, or would like to add an AI-related NYU resource to this list, please email[genai-support@nyu.edu].\n**November 2, 2023\n**Keith Allison\n[###### More Research &amp; Instructional Technology Stories\n]",
    "length": 2809,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University generative AI policy",
    "title": "Steinhardt AI Hub",
    "url": "https://steinhardt.nyu.edu/faculty-and-staff/academic-affairs/steinhardt-ai-hub",
    "text": "[Skip to main content] \n\n## Search NYU Steinhardt\n\nSearch\n\nClose Search\n\n# Steinhardt AI Hub\n\n## Artificial Intelligence at NYU Steinhardt\n\nThe Office of Academic Affairs and the Office of Digital Innovation and Learning at NYU Steinhardt are dedicated to supporting the exploration of AI in the college classroom. We provide comprehensive resources and guidance for faculty, students, and staff to enhance teaching, learning, and working with AI technologies.\n\n## [Getting Started with Generative AI] \n\nAI is transforming education by providing new ways to support teaching and learning. This page serves as a starting point for understanding how AI can be integrated into your teaching practice.\n\n[Read More] \n\n## [Academic Integrity and Syllabus Support in the Age of Generative AI] \n\nCreating clear policies around AI use is essential to maintaining academic integrity and setting student expectations. These policies outline how AI tools can be used and ensure students understand the implications of AI in academic work.\n\n[Read More] \n\n## [Enhancing Teaching and Learning with Generative AI] \n\nThis collection offers resources, tools, and best practices to support Steinhardt faculty in integrating AI into their courses, enhancing teaching effectiveness, and fostering student engagement.\n\n[Read More] \n\n## Watch the Recordings! Steinhardt AI Workshop Series\n\n**Thank you for joining our 2024 AI Workshop Series!** Throughout the series, we delved into how AI can be integrated into education and professional practice. Our sessions covered various topics, including using AI for student writing, enhancing feedback, differentiating instruction with GPTs, applying AI in research and clinical simulations, overcoming creative blocks, and exploring AI in music creation.\n\nIf you missed any of our workshops, don’t worry—you can still access the recordings and presentation materials to further explore and apply AI in your academic and workplace environments!\n\n[View the Recordings and Resources] \n\n## AIAI Board\n\nAs part of our ongoing commitment to fostering innovation and excellence in the field of artificial intelligence (AI) at Steinhardt, we are excited to introduce the establishment of the Steinhardt AI Advisory and Insights (AIAI) Board. This board brings together a diverse group of individuals (faculty, students, and administrators) to provide guidance, offer ideas, and address concerns related to AI within our academic community.\n\nThe faculty who make up the AIAI Board possess a keen interest in AI and are capable of articulating departmental concerns and ideas effectively.\n\n### Key Responsibilities of AIAI Board Members:\n\n- Provide guidance on AI-related projects and initiatives.\n- Foster interdisciplinary collaboration and communication on AI matters.\n- Act as a conduit for conveying concerns and ideas from their respective departments.\n- Participate in discussions to shape the university and school’s approach to AI education and research.\n\n### 2024-2025 Board Members\n\n- **Anne Washington,** Applied Statistics and Humanities\n- **Carolyn Strom,** Teaching & Learning\n- **Ed Kang,** Media, Culture, & Communications\n- **Emilie Ricco,** Steinhardt Student Affairs\n- **Ethan Balk,** Nutrition & Food Studies\n- **Greg Gao,** Physical Therapy\n- **Jennifer Astuto,** Applied Psychology\n- **Kelsey Cook,** Digital Innvoation and Learning\n- **Kevin McCoy,** Art & Art Professions\n- **Lorena Llosa,** Academic Affairs\n- **Panayotis Mavromatis,** Music and Performing Arts Professions\n- **Sinead Harrington,** Occupational Therapy\n- **Sonakshi Gupta,** USG Representative\n- **Tara McAllister,** Communicative Sciences and Disorders\n- **Vinny Nelson,** GSO representative\n- **Xavier Ochoa,** Administration, Leadership, & Technology\n- **Office of Digital Innovation & Learning,** NYU Steinhardt",
    "length": 3820,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University generative AI policy",
    "title": "NYU Generative AI (GenAI) Services",
    "url": "https://www.nyu.edu/life/information-technology/artificial-intelligence-at-nyu/generative-ai-services.html",
    "text": "# NYU Generative AI (GenAI) Services\n\n## NYU’s GenAI Services\n\nNYU provides access to and support for several generative AI (GenAI) services. Select a service to learn more below and check back to this page periodically for new information.\n\n[**Google Gemini**] \n\n[**Google NotebookLM**] \n\n[**NYU Private GenAI Service (Pilot)**] \n\n## Guidance on the Use of GenAI at NYU\n\n[Teaching with Generative AI] \n\n[Student Learning with Generative AI] \n\n[Academic Integrity for Students at NYU] \n\n## About Google Gemini\n\nGoogle Gemini is a GenAI chatbot that can be used to create new content, streamline repetitive tasks, assist with communications, and more. Currently, Gemini is part of NYU Google Workspace Services but used as a standalone tool and not integrated directly into NYU Google apps such as Email and Docs. Gemini is available at [gemini.google.com] or via the Google App Launcher menu at the top right of most Google apps.\n\n### About Data Privacy in Gemini\n\nWhen you’re logged into Gemini with your NYU NetID account, Gemini never trains its AI model on your data. While it will save your past queries and Gemini's results, they are only available to you, and you can delete them at any time, ensuring your data remains private to you. Explore the resources in the section below if you’d like to better understand the terms of service, which have been vetted by NYU’s Office of Global Counsel.\n\nMore About Data Privacy in Gemini\n\nGemini is a “ [Core Service] ” under NYU’s Google Workspace for Education agreement, and its use is covered by both the [Terms of Use for NYU Google Workspace Services]  and the [Google Workspace for Education Terms of Service]. Its use is not subject to Google data mining, AI model training, or advertising.\n\nYou should use Gemini as you would NYU Google Drive/Email with regard to Data Privacy & Security Classification. Refer to the [Electronic Data and System Risk Classification Policy] to determine your data risk classification.\n\n### Who Uses Gemini?\n\nNYU faculty, staff, and students who want to use a generative AI chatbot to create content, streamline repetitive tasks, assist with communications, and more.\n\n### Locations Offered\n\nAll NYU locations\n\n### How to Request This Service\n\nGemini is automatically available to all eligible NYU community members by logging in with their NYU NetID and password at [gemini.google.com]  or via the Google App Launcher menu at the top right of most Google apps.\n\n### Support Resources\n\n##### **NYU Support**\n\n- [Google Gemini and NotebookLM AI Fact Sheet] \n- [Artificial Intelligence at NYU]  (general AI resources for the NYU community)\n- [NYU Google Services Support] \n\n##### **Google Support**\n\n- [Gemini FAQ] \n- [30+ ways to use Gemini in education]  (Google Slides)\n\n### Support and Request Form\n\n- [Submit a Gemini question in the NYU Support Center] \n\n## About Google NotebookLM\n\nNotebookLM is a personalized research assistant. You can upload various file types to the tool, ask questions about those files, receive answers with cited sources, and produce outputs such as summaries, briefing docs, timelines, FAQs, study guides, and audio overviews. Currently, NotebookLM is part of NYU Google Workspace Services but used as a standalone tool and not integrated directly into NYU Google apps such as Email and Docs. NotebookLM is available at [notebooklm.google.com].\n\n### About Data Privacy in NotebookLM\n\nWhen you’re logged into NotebookLM with your NYU NetID account, NotebookLM never trains its AI model on your data. While it will save your past queries and NotebookLM's results, they are only available to you, and you can delete them at any time, ensuring your data remains private to you. Explore the resources in the section below if you’d like to better understand the terms of service, which have been vetted by NYU’s Office of Global Counsel.\n\nMore About Data Privacy in NotebookLM\n\nNotebookLM is an “ [Additional Service] ” under NYU’s Google Workspace for Education agreement, and its use operates under the [Google Terms of Service]  and the [Google Privacy Policy]. Uploads, queries and the tool’s responses will not be reviewed by humans or used to train AI models.\n\nYou should use NotebookLM as you would NYU Google Drive/Email with regard to Data Privacy & Security Classification. Refer to the [Electronic Data and System Risk Classification Policy]  to determine your data risk classification.\n\n### Who Uses NotebookLM?\n\nNYU faculty, staff, and students who want to use an AI-powered collaborator to gain personalized insights into source files they upload, refine and organize their ideas, and produce content including audio and text summaries, FAQs, and more.\n\n### Locations Offered\n\nAll NYU locations except NYU Shanghai. NotebookLM is currently unavailable from NYU Shanghai as China is not yet a [Google-supported region].\n\n### How to Request This Service\n\nNotebookLM is automatically available to all eligible NYU community members by logging in with their NYU NetID and password at [notebooklm.google].\n\n### Support Resources\n\n##### **NYU Support**\n\n- [Google Gemini and NotebookLM AI Fact Sheet] \n- [Teaching with Generative AI] \n- [Student Learning with Generative AI] \n- [Artificial Intelligence at NYU]  (general AI resources for the NYU community)\n- [NYU Google Services Support] \n\n##### **Google Support**\n\n- [NotebookLM Help] \n\n### Support and Request Form\n\n- [Submit a NotebookLM question in the NYU Support Center] \n\n## About the NYU Private GenAI Service (Pilot)\n\nThe NYU Private GenAI service is free to use but [requires University approval]. Any information entered into the NYU Private GenAI model is governed by [NYU’s data privacy policy].\n\n### Who Uses the NYU Private GenAI Service?\n\nNYU researchers who have a clear use case related to research that can’t be achieved using Google Gemini and/or NotebookLM (see above).\n\n### Locations Offered\n\nAll NYU locations\n\n### How to Request This Service\n\nResearchers interested in this service should [**complete this request form**]. Once a request is submitted, project participants are notified by email within seven business days regarding next steps. The response may include additional questions to help scope out the project, approval access to tools, a requirement to sign a data use agreement, and other relevant items to best understand the project requirements.\n\n### Support and Request Forms\n\n- To request **access** to the NYU Private GenAI Service, [complete this request form].\n- To ask a **question** about about the NYU Private GenAI Service, [submit this support form in the NYU Support Center]  or email [genai-support@nyu.edu]",
    "length": 6630,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University generative AI policy",
    "title": "Machines and Society",
    "url": "https://guides.nyu.edu/data/ai-governance",
    "text": "Copyright, Authorship, and Governance - Machines and Society - Research Guides at New York University Skip to Main Content\n\nSearch\n\n# Machines and Society\n\nA growing guide on the latest in data-driven research and emerging technologies at the intersection of society, information and technology.\n\n## Copyright Considerations\n\nIntellectual property law across the globe is reckoning with the implications of generative AI for creators of copyrighted works and the artists, programmers, and scholars who would use those works for generative AI outputs. There are many questions implicated, including the copyrightability, authorship and ownership of generative AI outputs; the merits of a fair use defense when using copyrighted works to train AI tools; and what regulations, if any, should be imposed in response to this dramatic shift in technology and society. At this time, there is [not a clear answer] for many of these questions.\n\n## Ownership and Copyrightability of Generative AI Outputs\n\nMost copyright regimes have certain requirements that must be satisfied before protecting a work under copyright, patent, trademark, or other forms of intellectual property law. These requirements may be based on the subject matter of the output; the originality and creativity vested in the work; or a standard of fixation. (In fact, if a prompt given to a generative AI tool satisfies these requirements, it may be eligible for copyright protection itself, even if the resulting output is not).\n\nThese requirements can be found in the text of [§102] of the US Copyright Act (17 USC) and in Chapter I of the [Copyright Law of the People’s Republic of China] (中华人民共和国著作权法)\n\nBeyond this, most copyright regimes have requirements with regards to the authorship of a work in question before conferring copyright protection to a work.\n\n## “AI-generated” versus “AI-assisted” Outputs\n\nThe answer to questions about ownership and authorship of AI works under patent, trademark, and copyright laws will vary across jurisdictions and whether the work is “AI-generated” or “AI-assisted”. The World Intellectual Property Organization (WIPO) Secretariat offers definitions in paragraph 12 of the Revised Statement on Intellectual Property Policy and Artificial Intelligence ([WIPO/IP/AI/2/GE/20/1 Rev.]):\n\n“AI-generated” and “generated autonomously by AI” are terms that are used interchangeably and refer to the generation of an output by AI without human intervention. In this scenario, AI can change its behavior during operation to respond to unanticipated information or events. This is to be distinguished from “AI-assisted” outputs that are generated with material human intervention and/or direction.\n\nWhen considering if your AI-generated or AI-assisted output is copyrightable, expert legal advice should be sought.\n\nIn the United States, authors of a copyrighted work must be human: the 9th Court of Appeals affirmed in [Naruto v. David Slater et al.] (2016) that non-human animals lack statutory standing for protection under the Copyright Act, and the US Copyright Office has refused to register AI-generated works produced autonomously without human involvement. However, in [Copyright Registration Guidance for Works Containing AI-Generated Material], the Office distinguishes between works that “are the result of “mechanical reproduction” instead of an author’s “own original mental conception, to which [the author] gave visible form.” (Quoting Burrow-Giles v. Sarony).\n\nThe question of protecting AI-generated works has already arisen in the context of Chinese copyright law, as well. The Cyberspace Administration of China (CAC, 国家互联网信息办公室) is [drafting measures] for the management and regulation of generative AI systems, [open for public comment until 10 May 2023].\n\nIn 2019, the Nanshan District People’s Court in Shenzhen drew a distinction between “AI-generated” and “AI-assisted” outputs in [Shenzhen Tencent v. Shanghai Yingxun] (you can read the full text of the court’s decision [here], though you’ll need to register with a phone number first). The Court granted copyright protection to the works in question, determining that the content generated were written works (a copyrightable subject matter) and that the creative team was sufficiently involved in the input, selection, arrangement, and other intellectual activities that the works were original and creative enough to be ultimately the product of human authorship.\n\n## Fair Use and Exclusive Rights\n\nWhen using emerging tools for generative AI projects, researchers, artists, programmers, and others should consider the expertise of legal counsel in guiding their use of training data ethically, as well as protecting the outputs of those tools.\n\nAlthough scraping content to create datasets may often be considered an example of \"fair use\" in US copyright law, that does not mean that all generative AI projects will fall within the ambit of this exception. Claiming a fair use defense for any generative AI project will need to be assessed on the facts of that specific instance using the [four-factor test].\n\nData and materials used to train generative AI tools may themselves be copyrighted and protected by both property and personality (or \"moral\") rights. In recent years, owners of copyrighted works have demonstrated a willingness to challenge the unauthorized use of their intellectual properties.\n\nIn 2021 the estate of artist Pablo Picasso invoked the author’s [moral right to disclose a work] to demand that his works not be used without permission for generative AI artworks.\n\nIn 2023, multiple lawsuits were brought against unauthorized uses of artworks for training generative AI tools and producing new visual works. In the United Kingdom, [Getty Images] filed a complaint against Stability AI with the High Court of Justice in London. Getty argues that they offer licenses for uses such as these, and that when Stability AI ignored these viable licensing options Getty’s copyright was infringed. In the United States, a class action lawsuit was filed on behalf of three artists against Stability AI and others. Counsel for the plaintiffs does not mince words, likening Stability AI to “a par­a­site that, if allowed to pro­lif­er­ate, will cause irrepara­ble harm to artists, now and in the future.” You can view the complaint & exhibits from the plaintiffs [here]. Thus, it is not clear-cut that using existing copyrighted works to train generative AI tools will be covered by a fair use (or similar) defense.\n\n## Contact and Support\n\nFor Research Support Contact Caitlin MacKenzie Mannion Head of Reference & Instruction Services and Librarian for the Arts & Humanities Email: shanghai.librarian@nyu.edu Book an appointment: https://nyu-shanghai.libcal.com/appointments/CMKM\n\nThe library is unable to provide legal advice or guidance. If you have specific questions about your project’s compliance with local IP Law, please seek official legal counsel.\n\nNYU Shanghai community members may also contact the University’s office of Legal Compliance.\n\n- [Print Page] \n- URL: https://guides.nyu.edu/data\n- Last Updated: Aug 28, 2025 1:28 AM\n\n[Author Log-in] \n\n[Report a problem] \n\nSubjects: [Data Science], [Multidisciplinary], [Social Sciences], [Technology] \n\nTags: [artificial intelligence], [computational research], [computing], [data], [information technology] \n\n[Accessibility]",
    "length": 7375,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University generative AI policy",
    "title": "University Policies and Guidelines",
    "url": "https://www.nyu.edu/about/policies-guidelines-compliance/policies-and-guidelines.html",
    "text": "University Policies and Guidelines\n\n# University Policies and Guidelines\n\n--\n\nNYU's University Policies and Guidelines database serves as a central repository for current University Policies. Its primary objectives are to standardize policy format, eliminate redundancies, and enhance organization, accessibility, search, and navigation functions for users. University Policies and Guidelines are categorized and listed in menus below, with some appearing in multiple categories.\n\n--\n\n### Policy Assistance\n\nUniversity Policies and Guidelines are an integral element of [NYU’s Global Ethics and Compliance Program]. The Office of Ethics and Compliance manages the publication and archiving of administrative policies and guidelines to help NYU employees and community members understand the laws, regulations, policies, and procedures that guide informed decision-making. Contact [policies@nyu.edu] for questions and assistance.\n\nWhile the database provides a comprehensive repository of University Policies, it is not exhaustive. For additional assistance with locating policies, developing, final review and approval of new or revised University Policies and Guidelines, and posting approved University Policies and Guidelines in the database, visit the University [Policy Review and Approval Process] page or contact [NYU Ethics and Compliance] at [policies@nyu.edu] to learn about the University Policy Program, or for additional assistance and questions.\n\n--\n\n## New and Revised Policies and Guidelines\n\nNew and Revised University Policies and Guidelines recently approved and published in the University Policies and Guidelines database are featured below along with links to the relevant new or revised Policy or Guideline page.\n\n### New Policies\n\n[Unified Policy Regarding Credentials Integrity in Undergraduate Admissions] - December 17, 2025\n\n[NYU Digital Accessibility Policy] - November 14, 2025\n\n[Data Risk Classification Policy] - August 1, 2025\n\n[Global Information Security Policy] - August 1, 2025\n\n[New York University Policy on Hazing] - June 23, 2025\n\n[Enterprise Information Management (EIM) Policy] - June 1, 2025\n\n[Prenatal Leave Policy and Procedures] - January 1, 2025\n\n### Revised Policies\n\n[Retention and Disposal of Records Policy] - October 22, 2025\n\n[Code of Ethical Conduct] - June 3, 2025\n\n[Compliance Complaint Policy] - June 3, 2025\n\n[Conflicts of Interest Policy for Trustees, Officers, and Senior Administrators] - June 3, 2025\n\n[Identity Theft Prevention Program] - June 3, 2025\n\n[IT Scheduled Maintenance Guidelines] - February 4, 2025\n\n### Policy Search\n\nKeyword Category Select COVID-19 Financial Affairs Governance and Legal Academic Affairs and Faculty Human Resources Research University Guides and Manuals Student Services Information Technology Operations and Safety Effective Date Range\n\nDate From\n\nDate To\n\nSubmit\n\n###### NYU Global Ethics and Compliance Program",
    "length": 2909,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University AI policy academic integrity",
    "title": "Academic Integrity and Syllabus Support in the Age of Generative AI",
    "url": "https://steinhardt.nyu.edu/faculty-and-staff/academic-affairs/steinhardt-ai-hub/academic-integrity-and-syllabus-support-age",
    "text": "Academic Integrity and Syllabus Support | NYU Steinhardt[Skip to main content] \n[![Steinhardt School of Culture, Education, and Human Development]] \nSearch\nOpen Main MenuClose Main Menu\n## Search NYU Steinhardt\nSearch\nClose Search\n![NYU building with University flag] \n# Academic Integrity and Syllabus Support in the Age of Generative AI\nCreating clear policies around AI use is essential to maintaining academic integrity and setting student expectations. These policies should outline when and how AI tools like ChatGPT, Perplexity.ai, or Grammarly can be used and ensure students understand the ethical implications of AI in academic work.\nIf you’re interested,[check out this AI Chatbot we created] that can provide you with sample syllabus statements based on your unique course information and preferences.\n## Considerations for AI Policy Creation\n### Permitted Use Cases\nClearly define what AI tools can be used for in your course (e.g., brainstorming, idea generation, or drafting) and where they are prohibited (e.g., completing graded assignments without supervision).\n**Example Policy Statement:***\"Students may use AI tools like ChatGPT for initial idea generation and draft creation, but final submissions must reflect the student's original thoughts and revisions.\"*\n### Prohibited Use Cases\nEstablish boundaries for AI use to prevent academic misconduct, such as using AI to generate full essays or solutions to homework problems.\n**Example Policy Statement:***\"Using AI tools to generate any work is considered plagiarism and will result in disciplinary action.\"*\n### Ethical AI Use\nInclude guidelines on ethical AI usage, including proper attribution when AI-generated content is used in assignments.\n**Example Policy Statement:***\"Any AI-generated content used in assignments must be properly attributed. Failure to disclose AI assistance may result in plagiarism charges.\"*\n## AI Syllabus Statement Templates\nTo help streamline the process of adding AI policies to your syllabus, here are templates and examples that can be adapted for your course. These templates ensure students are fully informed about when AI can be used and how to properly acknowledge AI-generated content. Remember that you can establish different AI policies for each assignment, depending on how you want the tools to be used (or not used). Just make sure to clearly communicate this decision to your students.\n### General AI Use Template\n* \"AI tools, such as ChatGPT or Grammarly, may be used for brainstorming or refining ideas, but all work submitted must be your own. If AI assistance is used in drafting, please include a note explaining how the tool was used.\"\n* \"AI tools, such as DALL-E or MidJourney, may be used for brainstorming or idea generation in art projects, but the student must create and refine all final artwork. If AI tools are used in any part of the creative process, students must disclose their role and provide a written reflection or recorded demonstration about how AI contributed to their creative decisions.\"\n* \"AI tools, such as AIVA or Amper Music, may be used for generating initial musical ideas or experimenting with different styles. However, students are required to modify and develop their compositions independently. Any AI-generated musical elements must be disclosed, and students must provide a written reflection on how they used AI in their compositional process.\"\n### AI in Writing and Research Assignments\n* \"Students may use AI tools to help with research, but all final written content must be original. Cite all sources, including AI-generated suggestions, where appropriate.\"\n* \"AI tools can be used to assist in music analysis or transcription tasks, such as identifying chord progressions or analyzing harmonic structures. However, students must critically evaluate AI output and include their own insights. AI tools must not be used to bypass critical analysis and understanding.\"\n### AI in Group Projects\n* \"In group work, AI can be used as a collaborative tool for idea generation or outlining, but students must document the specific AI tool used and how it contributed to the project.\"\n* \"AI tools can be used to assist in collaborative art projects for idea generation or visual research. However, the final artwork must be original and primarily created by students. All AI-generated concepts or visuals must be properly credited and documented in the project submission.\"\n### Templates for Reflecting on AI Use in Art &amp; Music\n* \"If AI tools are used during the creative process, students must include a 1-2 page reflection outlining how the AI contributed to their project, the specific tools used, and how they adapted or refined the AI-generated content to fit their vision.\n* If art or music-based, “The reflection should also address the ethical implications of using AI in creative arts.\"\n## Engaging Students in AI Policy Discussions\nTo foster a better understanding of AI’s role in education, engage students early in conversations about how AI should be used in academic work. These discussions can help students grasp the ethical responsibilities and critical thinking skills required to effectively and responsibly use AI.\n[] \n* [### Classroom Discussions\n] \n* [### Reflection Assignments\n] [] \nStart the semester with an open discussion on using AI tools, including the ethical implications and expectations for proper use.\n#### Discussion Prompts\n\"How do you think AI will impact your learning experience? What are the potential risks and benefits?\"\n“How do you think AI should be used in our classroom? How can we establish agreed-upon norms for AI usage?”\n[**Discussion Guide**(NetID Login Required)] \nAssign students a reflection on how AI may assist them in their work and the importance of critical thinking beyond relying on AI-generated responses.\n#### Example Assignments\n\"Write a reflection on how you used AI for your project and explain how it influenced your thinking process.\"\n“Reflect on how relying on AI may have influenced your problem-solving approach and identify any gaps in understanding that could arise from over-reliance on AI-generated outputs.”\n## Privacy and Data Security Considerations\nWhen using AI tools, it’s essential to consider privacy and data security. Do not share work containing student identifiers with any third-party services—no student names or other unique identifiers like NetID or N-numbers. Sharing such identifiers with services like ChatGPT or Google Gemini violates the Federal Educational Records Privacy Act (FERPA), which mandates careful handling of student records and restricts their disclosure to third parties. Sharing data that identifies students with tools that NYU has not licensed will never be FERPA-compliant, as FERPA requires the institution to have a specific sort of business relationship. ([NYU’s Academic Integrity for Students at NYU].)\n## Addressing Academic Integrity Concerns\nWith the rise of AI tools like ChatGPT and other generative AI applications, concerns about academic integrity have become increasingly relevant. As AI becomes more integrated into the educational experience here at NYU Steinhardt, both faculty and students must navigate the fine line between appropriate use and academic dishonesty. Clear guidelines are necessary to help students understand when and how AI can be used responsibly.\nIf you suspect a violation, follow NYU Steinhardt’s policy on[reporting an academic integrity violation].\nKey strategies to address academic integrity concerns include:\n* **Establishing Clear AI Use Policies:**Instructors must create explicit policies outlining when AI tools can be used and what constitutes misuse. For example, using AI for initial drafts may be allowed, but passing off fully AI-generated work as one's own without modification or attribution is not.\n* **Promoting Critical Thinking:**Instead of banning AI, educators should focus on teaching students to use AI as a learning tool while encouraging them to critically evaluate AI-generated content. As AI is reshaping how work is done across industries, it’s essential for educators to adapt and incorporate these changes into their teaching practices, helping students navigate and responsibly engage with AI technologies.\n* **Ethical AI Use:**Educators should emphasize ethical practices, such as proper attribution for AI assistance and transparency about the use of AI in assignments.\n* **Define Plagiarism with AI:**Clarify what constitutes plagiarism when AI tools are involved, such as submitting AI-generated work as your own or failing to attribute AI contributions.### Example\n\"Submitting AI-generated content without proper attribution is considered academic dishonesty and will be subject to disciplinary action.\"\n## Assessments and AI in Academic Integrity\nIntegrating AI considerations into assessments is crucial for maintaining academic integrity and aligning AI use with course objectives. Here are key elements to consider:\n* **Assessment Design**: Design assignments that encourage original thought and critical analysis, minimizing opportunities for academic misconduct. For instance, open-ended questions, reflective responses, and analysis-based projects can make it harder for students to rely solely on AI-generated content.\n* **Clear Guidelines for AI in Assessments**: Specify when and how students can use AI assessment tools. For example, “AI tools can be used for initial research and brainstorming, but the final submission should be your original work.” If AI is prohibited for certain tasks (e.g., producing written essays or solving complex problems), clearly outline this.\n* **Reflective Assessment on AI Use**: Include assignments where students reflect on their use of AI in completing tasks. This can help students critically assess AI’s impact on their learning and ensure that AI is a supplement, not a replacement",
    "length": 9884,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University AI policy academic integrity",
    "title": "Academic Integrity for Students at NYU",
    "url": "https://www.nyu.edu/about/policies-guidelines-compliance/policies-and-guidelines/academic-integrity-for-students-at-nyu.html",
    "text": "Academic Integrity for Students at NYU\nMenu[Skip to All NYU Navigation] [Skip to Main Content] \n[NYU] \nSearchSearch SiteAll NYU\n[NYU Home] \n[Login toNYU Home] \nAll NYU\n[NYU] \nSearch Site\nPolicy# Academic Integrity for Students at NYU\n## Policy Contents\n* [STATEMENT OF POLICY] \n* [To Whom the Policy Applies] \n* [POLICY AND PROCEDURES] \n* [Notes] \n## STATEMENT OF POLICY\n[top] \nThis policy sets forth core principles and standards with respect to academic integrity for students at New York University. Each school at New York University may establish its own detailed supplemental guidelines for academic integrity, consistent with its own culture, and consistent with the University-wide general guidelines described in this document.\n## To Whom the Policy Applies\n[top] \nThis policy applies to all students at NYU.\n## POLICY AND PROCEDURES\n[top] \nAt NYU, a commitment to excellence, fairness, honesty, and respect within and outside the classroom is essential to maintaining the integrity of our community. By accepting membership in this community, students take responsibility for demonstrating these values in their own conduct and for recognizing and supporting these values in others. In turn, these values will create a campus climate that encourages the free exchange of ideas, promotes scholarly excellence through active and creative thought, and allows community members to achieve and be recognized for achieving their highest potential.\nIn pursuing these goals, NYU expects and requires its students to adhere to the highest standards of scholarship, research and academic conduct. Essential to the process of teaching and learning is the periodic assessment of students' academic progress through measures such as papers, examinations, presentations, and other projects. Academic dishonesty compromises the validity of these assessments as well as the relationship of trust within the community.  Students who engage in such behavior will be subject to review and the possible imposition of penalties in accordance with the standards, practices, and procedures of NYU and its colleges and schools. Violations may result in failure on a particular assignment, failure in a course, suspension or expulsion from the University, or other penalties.\nFaculty are expected to guide students in understanding other people's ideas, in developing and clarifying their own thinking, and in using and conscientiously acknowledging resources - an increasingly complex endeavor given the current environment of widely available and continually emerging technologies that can produce text, images, code, video and the like. In addition, students come to NYU from diverse educational contexts and may have understandings regarding academic expectations that differ from those at NYU. NYU values and respects all academic traditions; however, while at NYU, students are expected to adhere to the norms and standards of academic integrity espoused by the NYU community and will be assessed in accordance with these standards. Students should ask their professors for guidance regarding these standards, including where instructor permission might override these definitions, as well as style guide preferences for citation or acknowledgement of sources for assignments in their courses.\nFollowing are examples of behaviors that compromise the academic and intellectual community of NYU. The list is not exhaustive.  Students should consult the websites and guidelines of their individual schools for an extended list of examples and for further clarification.\n1. Plagiarism: Plagiarism is a form of fraud. It involves presenting work without adequate acknowledgement of its source (e.g., another person, your own earlier work, an AI tool, etc.), as though it were one’s own current work. We all stand on the shoulders of others, and we must give credit to the creators of the works that we incorporate into products that we call our own.  Some examples of plagiarism:\n·a sequence of words incorporated without quotation marks\n·an unacknowledged passage paraphrased from another's work\n·the use of ideas or materials from another source as  though it were one’s own\n2. Cheating: deceiving a faculty member or other individual who assess student performance into believing that one’s mastery of a subject or discipline is greater than it is by a range of dishonest methods, including but not limited to:\n·bringing or accessing unauthorized materials during an examination (e.g., notes, books, or other information accessed via cell phones, computers, other technology or any other means)\n·providing assistance to acts of academic misconduct/dishonesty (e.g., sharing copies of exams via cell phones, computers, other technology or any other means, allowing others to copy answers on an exam)\n·submitting the same or substantially similar work in multiple courses, either in the same semester or in a different semester, without the express approval of all  instructors\n·submitting work (papers, homework assignments, computer programs, experimental results, artwork, etc.) that was created by another, substantially or in whole, as one's own\n· submitting answers on an exam that were obtained from the work of another source; or providing answers or assistance to others during an exam\n·submitting evaluations of group members’ work for an assigned group project which misrepresent the work that was performed by another group member\n·altering or forging academic documents, including but not limited to admissions materials, academic records, grade reports, add/drop forms, course registration forms, etc.\n3. Participating in any adverse action against an individual for making a good faith report of prohibited conduct or for participating in any academic integrity proceeding under this policy or the academic policies set forth by the student's NYU School, department, or division.\n4. Any behavior that violates the academic policies set forth by the student’s NYU School, department, or division.\n###### Notes\n[top] \n1. Dates of official enactment and amendments: Aug 1, 2011\n2. History: enacted August 1, 2011, updated May 24, 2024; Last Updated August 25, 2025\n3. Cross References: N/A\n## About This Policy\nEffective DateAug 25, 2025SupersedesMay 24, 2024Issuing AuthorityProvostResponsible OfficerVice Provost for Undergraduate Academic Affairs\nDefinitions\nNone\nRelated Policies\nSchool Policies as found in the[New York University Bulletins]",
    "length": 6445,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University AI policy academic integrity",
    "title": "Academic Integrity",
    "url": "https://cas.nyu.edu/academic-integrity.html",
    "text": "Academic Integrity\n\n# Academic Integrity\n\nAs you begin your College career—attending classes, participating in extracurricular activities, performing community service, and thinking about where your academic and career interests lie—it is important to reflect on your role and responsibilities within an academic community.\n\nI. A COMMUNITY OF THE MIND\n\nNew York University is a community of scholars who value free and open inquiry. Our work depends on honest assessment of ideas and their sources; and we expect all members of our community to maintain the highest integrity in their academic work. As scholars committed to the critical evaluation of ideas, free of personal prejudice, we also have an obligation to one other to create an educational atmosphere of mutual trust and respect in which differences of opinion can be subjected to deliberate and reasonable examination without animus. Because of the central importance of these values to our intellectual life together, students who fail to maintain them will be subject to disciplinary sanction, which may include dismissal from the University.\n\nII. SOME GUIDELINES\n\nAcademic honesty means that the work you submit — in whatever form — is original. Obviously, bringing answers into an examination or copying all or part of a paper straight from a book, the Internet, or a fellow student is a violation of this principle. But there are other forms of cheating or plagiarizing which are just as serious — for example, presenting an oral report drawn without attribution from other sources (oral or written), writing a paragraph which, despite being in different words, expresses someone else’s idea without a reference to the source of the idea, or submitting essentially the same paper in two different courses (unless both instructors have given their permission in advance). Receiving help on a take-home examination or quiz is also cheating — and so is giving that help — unless expressly permitted by the instructor (as in collaborative projects). While all this looks like a lot to remember, all you need to do is to give credit where it is due, take credit only for your original ideas, and ask your instructor or advisor when in doubt.\n\nAcademic Disciplinary offenses include but are not limited to:\n\n- destruction, theft, or unauthorized use of laboratory data, or research materials.\n- cheating, plagiarism, falsification of data or sources, forgery of academic documents in attempt to defraud;\n\nThe following penalties may be imposed by the faculty for disciplinary infractions:\n\n- Dismissal\n- Suspension\n- Disciplinary Probation\n- Warning\n\nComplete statements of the policies and procedures for adjudicating academic disciplinary complaints concerning students in the College are available from the Office of the Associate Dean for Students and on the website of the College of Arts and Science.\n\nIII. RULES AND PROCEDURES\n\nGeneral Principles\n\n1. In cases of academic misconduct, evaluation of the student’s academic performance is distinguished from disciplinary adjudication of the offense. The question of what grade the student’s work should earn is distinct from that about whether a disciplinary sanction should also be imposed. When a student is found to have engaged in academic misconduct, the instructor may reduce the student’s grade for the assignment or for the course as a whole; however, such a determination is an academic judgment made by the instructor in accord with the expectations of the department or program offering the course and is not a form of disciplinary sanction. The question of whether a disciplinary sanction should also be imposed is separate from this academic determination, as specified in the procedures described herein.\n2. Student academic misconduct includes plagiarism, cheating, and possession of or use of any prohibited notes, reference resources, or data processing or other devices in any class or examination; and forgery of academic documents in attempt to defraud.\n\nAcademic Misconduct—Academic Review\n\n1. The decision of the department or program on the student’s appeal is final.\n2. For incidents of academic misconduct, the student’s appeal of the grade reduction is limited to departmental review conducted by the Director of Undergraduate Studies and/or the Department Chair, as specified in the CAS policy for grade appeals. The review will be limited to the question of whether the reduction in grade was made fairly and in keeping with the expectations of the department or program.\n3. In order to better educate the student about the CAS standards for academic integrity, the faculty member and/or the Director of Undergraduate Studies should meet with the student to discuss the nature of the offense and the action taken. This responsibility of the faculty should not be delegated to recitation or laboratory instructors or other course assistants.\n4. Should the faculty member judge the violation substantial and well supported by the evidence, he or she may, with the assent of the Director of Undergraduate Studies (or, if the Director of Undergraduate Studies is the instructor, with the chair or another academic director in the department or program, or if the department or program should be too small, in an ad hoc consultation with a chair or academic director of another department or program from the same academic division) reduce the student’s grade or assign the student a failing grade for the assignment in question or for the course as a whole. This grade reduction only reflects the student’s failure creditably to complete the academic requirements in question and is not a disciplinary sanction. The grade reduction should be proportional to the size and weight of the incident of academic misconduct among all requirements for the course and appropriate to the level at which the course is offered.\n5. When it is believed that violations of academic integrity may have occurred it is within the discretion of the faculty member to address the matter informally with the student should the infraction be judged insubstantial or should the evidence be inconclusive. In such cases the faculty member may determine that no grade reduction is warranted.\n\nAcademic Misconduct—Reporting and Disciplinary Referral\n\n1. In all instances in which there has been a finding that a non-CAS student committed a substantial violation of academic integrity standards of CAS or of any of its departments or programs, the Director of Undergraduate Studies will proceed in accord with the procedures under (a) and (b), except that notice will be made instead to the Dean of Students of the student’s school.\n2. If this is the student’s second or further incident of academic misconduct, the Associate Dean for Students will meet with the student, discuss the evidence of academic misconduct, and provide the student an opportunity to respond. The student will be informed of his or her right to accept or reject a resolution by the Associate Dean. After considering all relevant information, the Associate Dean may offer the student terms upon which CAS is willing to resolve the matter, which may include imposition of a disciplinary sanction. Where the student and the Associate Dean agree to terms in writing, a binding consensual resolution will exist between the student and CAS. Where the Associate Dean is unable to resolve the complaint by consensual resolution, the matter will be referred to the Committee on Student Discipline.\n3. If this is the student’s first incident of academic misconduct, the Associate Dean for Students will send the student a warning letter indicating that a suspension or a more severe penalty may result from a second academic integrity offense of any kind.\n4. The Director of Undergraduate Studies will also within seven (7) calendar days inform the CAS Associate Dean for Students in writing and/or via email of the student’s violation, forward to the dean the evidence of the violation, and send a copy of the correspondence to the faculty member and to the Department Chair or Program Director.\n5. In all instances in which there has been a finding that a CAS student committed a substantial violation of academic integrity standards of CAS or of any of its departments or programs, the Director of Undergraduate Studies will inform the student within seven (7) calendar days in writing and/or via email of any action taken and send copies of this letter to the CAS Associate Dean for Students, the faculty member, and the Department Chair or Program Director. The letter will include the nature of the violation, any resulting reduction in grade, and notice of the student’s right to appeal. A copy of the correspondence and the evidence of the violation shall be kept in a confidential file maintained by the Director of Undergraduate Studies.\n\nNon-academic Behavioral Misconduct\n\n1. All students are expected to abide by the expectation set forth in the [University-wise Student Conduct Policy]. Effective August 12, 2018, allegations of non-academic misconduct against a student of the College of Arts and Science shall be addressed pursuant to the [NYU Student Conduct Procedures] administered by the Office of Student Conduct and Community Standards under the authority of the Senior Vice President of Student Affairs. Complaints of student behavioral misconduct should be made to the CAS Associate Dean for Students. When such a complaint is recieved, the Associate Dean will notify the University Office of Student Conduct.",
    "length": 9510,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University AI policy academic integrity",
    "title": "CDS Academic Integrity Statement and Policy - NYU Center for Data Science",
    "url": "https://cds.nyu.edu/academics/academic-integrity-statement-policy/",
    "text": "[Skip to content] \n\nSearch for:\n\nAll students, faculty, instructional staff, administrators, and individuals involved in the Center for Data Science must follow the academic integrity policies listed below. Academic integrity is a shared responsibility; therefore, all must make a serious commitment to academic integrity. The consequences of violating academic integrity are serious for those involved and for the Center as a whole. Particularly,\n\n- Faculty must define, communicate, and enforce academic integrity and collaboration policies for their courses.\n- Instructional staff must be alert for signs of academic integrity violations and report possible violations to the instructor.\n- Students are expected to adhere to all academic integrity policies. This includes communicating with other students in any way and/or use of any materials or technology not explicitly allowed by the instructor.\n\n[Academic Integrity for Students at NYU] \\| [GSAS Statement on Academic Integrity] \n\n## **Procedures and Policies**\n\nIf an instructor suspects academic dishonesty, the instructor should contact the Director of Graduate Studies and the Director of Academic and Student Affairs. The Director of Academic and Student Affairs will then contact the student and meet with him or her to discuss the incident.\n\nIf an academic integrity violation is determined, penalties are set by the Director of Graduate Studies. Penalties for violations of the academic integrity policy are serious and swift. These penalties include failing the relevant course, having their case referred to GSAS, and termination from the program. All and any of these penalties may be enacted for a first offense.\n\n### [NYU Center for Data Science] \n\n× Close Panel",
    "length": 1734,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University AI policy academic integrity",
    "title": "GenAI & Academic Integrity",
    "url": "https://sites.google.com/stern.nyu.edu/teaching-learning-gen-ai/academic-integrity",
    "text": "You can find NYU's official policy on the use of generative AI, plus more here. How should I discuss the use of AI and academic integrity with my students?",
    "length": 155,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University AI policy academic integrity",
    "title": "",
    "url": "https://www.nyu.edu/content/dam/nyu/provost/documents/Academic-Integrity-Policy-Memo.pdf",
    "text": "Office of the Provost\nElmer Holmes Bobst Library\n70 Washington Square South, Room 1221\nNew York, New York 10012-1091\nTelephone: 212 998 3077\nFacsimile: 212 995 3190\ndavid.mclaughlin@nyu.edu\nDavid W. McLaughlin Provost\nMEMORANDUM\nTo: All Deans and Directors\nUniversity Leadership Team\nFrom: David W. McLaughlin, Provost\nRe: University Policy on Academic Integrity for Students at NYU\nDate: August 15, 2011\nI write to bring your attention to the newly developed University-wide policy on Academic\nIntegrity for Students at NYU. This is the first University-wide statement of its kind,\nalthough the Schools have their own policies regarding expectations of academic integrity\namong students. The new policy is a general statement of NYU’s standards regarding\nacademic integrity and is applicable to all students at all NYU schools. The individual\nschool policies further address issues in academic integrity and school-based processes.\nThis policy is the product of the diligent work of many dedicated faculty and administrators\nacross the University. In 2009, I charged the Executive Committee of the Faculty Senators\nCouncil (FSC) with the task of reporting on best practices in assessment in higher\neducation. The recommendations of the Task Force on Best Practices in Student\nPerformance Assessment, chaired by Professor Carol Shoshkes Reiss, then a member of\nthe FSC Executive Committee, were submitted to the University-wide Assessment Council.\nThe Assessment Council, assembled by Vice Provost for Academic Affairs, Jane Tylus,\nand comprised of faculty and administrators from across the University, formulated the\npolicy on Academic Integrity for Students at NYU over the course of this past academic\nyear in consultation with deans, General Counsel, and others.\nThe policy is posted online at:\nwww.nyu.edu/about/policies-guidelines-compliance/policies-and-guidelines/academic\u0002integrity-for-students-at-nyu.html School policies can be accessed by clicking on the\n“Related Policies” link.\nPlease distribute this document as appropriate within your units. In particular, I am asking\nthe Deans and Directors to share this document widely within the Schools, and to ensure\nthat School faculties are aware of the policy. If you have questions about the policy,\nplease contact Michaela Rome, Assistant Vice Provost for Assessment, at\nMichaela.Rome@nyu.edu.",
    "length": 2355,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University AI policy academic integrity",
    "title": "EWP Statement on Academic Integrity",
    "url": "https://cas.nyu.edu/ewp/faq/statement-on-academic-integrity.html",
    "text": "- [Skip to Main] \n\n# EWP Statement on Academic Integrity\n\nAt NYU, you are expected to write in conversation with other thinkers, honoring their words and ideas just as professional scholars do. In our class, you will learn strategies for representing, analyzing and citing the work of others. But ultimately, you are responsible for your academic integrity and for avoiding plagiarism. According to the [College of Arts and Science Honor Code], it is a violation of the integrity of the academic community to “represent the words, works, or ideas of others as \\[your\\] own.” Plagiarism can include using:\n\n-  a phrase, sentence, or passage copied or paraphrased from another writer's work without quotation marks and citation;\n- facts, ideas, or written text gathered or downloaded from the Internet without attribution;\n- a purchased paper or \"research\" from a peer, company or online service;\n- your own writing recycled from a current or previous course;\n- writing that is ghost-written by someone else, like a family member or tutor;\n- text generated or translated by an Artificial Intelligence writing assistance tool and presented as your own.\n\nPlagiarism is a serious academic offense. Final drafts with instances of plagiarism will be downgraded or marked with an F and may result in failure of the course. Further, all cases of plagiarism in EWP courses must be reported to the Director of the Expository Writing Program and the Dean of your college. Disciplinary consequences will range from a warning, to suspension, to expulsion from the university.\n\n### What is Academic Integrity? (and other FAQs)\n\n#### _What is Academic Integrity?_\n\nAcademic integrity, at its most basic level, is being honest, responsible, and clear about where a source’s idea begins and ends, and what your unique response to that idea is. Whether deliberate or accidental, if you are not honest or clear in this manner, you have committed plagiarism, and your doing so may result in your essay being penalized or even your failure of the course.\n\nSee [here] for more on CAS’s and NYU’s policy on Academic Integrity.\n\nWhy this emphasis on who owns ideas? The University can be understood as a vast set of conversations on a wide range of subjects. This conversation cannot advance if you simply repeat someone else’s idea as if it were your own. If everyone did this we would get nowhere. The basic move in academic discourse is learning to distinguish your thinking from that of others. (There’s even a book whose title sums up the whole game we are playing: [They Say, I Say] by Gerald Graff and Cathy Birkenstein.)\n\n#### FAQs:\n\n_**I’ve never written a college paper before, and I’m worried I’ll do it wrong and/or say something stupid. Is it okay if I get help from my parent/sibling/smart friend to help me craft my paper?**_\n\nWhen we’re new to something, it’s natural to seek out tutors to guide us. The Writing Center ( [https://cas.nyu.edu/content/nyu-as/cas/ewp/writing-center.html]) can help you train in three key skills:\n\n1. Active reading. This is the ability to isolate intriguing quotes and ideas in a source and make connections to other sources and ideas.\n\n2. How to foster _your own curiosity_ of those quotes and ideas. This means generating questions you are genuinely invested in ( _What does this quote really mean? Can I explain this complex concept back to myself and others? What happens if I place Idea X against or in conversation with Idea Y?_)\n\n3. How to craft thoughtful, coherent arguments that answer those questions in ways that only you could produce.\n\n\nIf you recruit a friend or family member to help you with such work, there is a danger that they will unintentionally do too much of the active reading/questioning/responding work that is for  you. There is a fine line between helpful collaboration and excessive help, and consultants in the Writing Center will know how to assist you without crossing that line.\n\n_**I wrote something I’m proud of in another class/back in high school. Can I re-use it?**_\n\nWe write to forge new insights for ourselves and our audiences, and so recycling previously-written essays (in their entirety or large sections from them) undermines the purpose of writing in a new situation. It’s normal to revisit work you felt was exploring fertile territory, but discuss with your professor (or a Writing Center consultant) how to develop new ideas from your old writing.\n\n_**I don’t want to plagiarize, but I’m embarrassed that I still don’t fully understand what it means to represent and cite sources ethically, honestly, and responsibly.**_\n\nMany students (and even expert, professional writers!) are unclear about what constitutes plagiarism; intellectual property is not an easy issue to grasp. If in doubt, simply ask your professor. Additionally, Writing Center consultants can clarify the difference between plagiarizing another writer’s idea and borrowing a cited idea in order to respond to it and develop your own line of thought.\n\n_**Is it plagiarism if I change the words/phrasing from a source?**_\n\nIf the core idea came from a source other than you, no amount of re-phrasing the language of that idea makes it yours, so you must cite where you got the idea. If you don’t, this is “patchwriting”--a common form of plagiarism.\n\nSee here for more on “patchwriting”: [https://www.merriam-webster.com/words-at-play/words-were-watching-patchwriting] \n\n_**Is it plagiarism to put an uncited idea in my own writing if I think that idea is common knowledge?**_\n\nThis is tricky. As a newcomer to the university, don’t assume you know what is or isn’t “common knowledge” in the same way that an expert in the field might. Remember that you are writing for a community of diverse readers, and their frames of reference could be very different from yours. Even if you think it is obvious you are alluding to a lyric from a famous pop song, anticipate your reader may not know it, and note the source. When in doubt, cite it.\n\nSee here for more on “common knowledge”: [https://integrity.mit.edu/handbook/citing-your-sources/what-common-knowledge] \n\n_**I put the author’s words in quotes, so I’m done, right?**_\n\nNot quite. Citation is about more than acknowledging that an idea isn’t yours. It also helps your fellow scholars track down the sources that you found helpful. If all you do is put quotes around borrowed words, how could your reader ever find out more about your source if they get curious about it? When looking over your work, ask yourself the following: (1) Will your reader be able to identify where each quote comes from--what writer or source? (2) Does each quoted source have a full companion entry in the Works Cited List? (3) Could your reader track down the exact source using the Works Cited list as their guide?\n\n_**I found a great idea/quote in my notes, but I didn’t keep track of the source. Can I still use it?**_\n\nAs many new scholars learn the hard way, the answer is no. Develop a habit of recording quotes with their author/title. Maybe snap a photo of the book cover/article link/etc., along with the quote. Whenever you use a sourceless idea or quote in your writing, that’s plagiarism.\n\n_**There are so many different citation styles (APA, Chicago, MLA, etc.) Can I use whichever I want?**_\n\nEach subject will have specific requirements. Ask your professor, but all EWP courses  require MLA.\n\n_**What happens if I plagiarize?**_\n\nYour professor will meet with you to discuss the language in question. If the plagiarism is extensive you may fail the course; if it’s less extensive you may be asked to re-write the paper and be marked down. All instances of plagiarism must be reported to the Director of the Expository Writing Program and to the Dean of your college.\n\n**_As long as smart ideas get on the page, why does it matter whether or not they are mine?_**\n\nThis question cuts to the core of why we have a university in the first place: to develop more thoughtful, rigorous, creative minds and more accountable individuals who will help us to solve problems in our world. There will always be pressure on us to cut corners or to be dishonest for short term gains. But the truth is that every time we pretend to understand something we don’t, or impersonate a wiser voice, or steal a unique viewpoint, we weaken ourselves. Every act of plagiarism (this includes using paper mills or hiring a ghost-writer) confirms to you that you cannot succeed on your own. Plagiarism corrodes your sense of personal power and ability.\n\nConversely, following scholarly protocol (such as clearly representing your sources) encourages you to develop your own ideas, find your own intellectual voice, and actively join the conversation. Our community gains when that happens because we need your fresh ideas for the future and not just the old ideas we already have.",
    "length": 8841,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University AI policy academic integrity",
    "title": "Academic Integrity",
    "url": "https://as.nyu.edu/departments/cns/UndergraduateProgram/AcademicIntegrity.html",
    "text": "Academic Integrity \n* [Skip to Main] \n* [About Us] \n* [About Us] \n* [Facilities and Resources] \n* [Affiliated Programs and Centers] \n* [Careers] \n* [Contact Us] \n* [Community and Outreach] \n* [People] \n* [Core Faculty] \n* [Other Faculty] \n* [Administration] \n* [Doctoral Program] \n* [Undergraduate Program] \n* [Postdoctoral Program] \n* [News &amp; Events] \n* [Event Calendar] \n* [Event Descriptions] \n* [News] \n* [CNS Video Archive] \n* [Internal Resources] \n# Academic Integrity\n**CNS Policy on Academic Integrity**\nCNS students must adhere to NYU’s principles of[academic integrity], and the[CAS Honor Code].\nAcademic integrity means that all of the work that you submit is original.\nViolations of academic integrity include:\n* Cheating on exams, quizzes, or other graded assignments\n* [Plagiarism]: appropriating the ideas, words, and images of others\n* Fabrication or falsification of data\nConsequences of a single violation of the principles of academic integrity are a grade of F on\nthe scored assignment or examination, and a formal report to the Dean’s Office. The grade of F\nmust be factored into the course’s final grade.\nIn cases of serious violation(s) of these standards, the department will seek dismissal of the\nstudent from the university.",
    "length": 1254,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University AI policy academic integrity",
    "title": "Who Should Decide AI's Future? A Public Conversation on Governing Frontier Technology | NYU School of Global Public Health",
    "url": "https://publichealth.nyu.edu/events-news/events/2026/02/07/who-should-decide-ais-future-public-conversation-governing-frontier",
    "text": "Who Should Decide AI's Future? A Public Conversation on Governing Frontier Technology | NYU School of Global Public Health\n\n# Who Should Decide AI's Future? A Public Conversation on Governing Frontier Technology\n\n4:30-6pm\n\nNYU School of Law, Greenberg Lounge, 40 Washington Sq S, New York, NY 10012\n\nAdd to Calendar\n\n- [iCal / MS Outlook] \n- [Office.com] \n- [Outlook.com] \n- [Yahoo!] \n- [Google] \n\nAs artificial intelligence reshapes everything from healthcare to democracy, one question grows more urgent: who gets to set the rules?\n\n​Join us for a vital public discussion on AI governance featuring perspectives from philosophy, law, industry, policy, and civil society.\n\n​Welcome Address by Philip S. Goldberg, U.S. Ambassador (Ret), NYU Distinguished Ambassador-in-Residence\n\nModerated by S. Matthew Liao (NYU - Director of the Center for Bioethics, Arthur Zitrin Professor of Bioethics)​This conversation brings together:\n\n- Brad Carson (Americans for Responsible Innovation) – President\n- Victoria Nash (Oxford Internet Institute) – Senior Policy Fellow\n- Rorry Daniels (Asia Society Policy Institute) – Managing Director\n- Kenji Yoshino (NYU Law / Meta Oversight Board) – Chief Justice Earl Warren Professor of Constitutional Law\n- ​Seb Krier (Google DeepMind) – Frontier Policy Lead\n- Kwame Anthony Appiah (NYU / The Ethicist, NYTimes) – Professor of Philosophy and Law\n\nWhy This Matters NowAI systems are advancing faster than our ability to govern them. How do we balance innovation with accountability? What can we learn from regulating other technologies? And what role should the public play in decisions that will shape society for generations? This panel bridges the gap between expert deliberation and public understanding, offering accessible insights into one of our era's most consequential challenges.\n\nPart of the NYU-KAIST Summit on Building Governance Infrastructure for Frontier AI, this event is supported by the Korea Foundation, the NYU-KAIST Global Innovation and Research Institute, and the NYU Center for Bioethics.\n\n[RSVP] \n\nAcademic Department\n\nBioethics",
    "length": 2086,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University AI policy academic integrity",
    "title": "AI, Misinformation, and Policy Seminar Series",
    "url": "https://cds.nyu.edu/ai-misinformation-and-policy-seminar-series/",
    "text": "AI, Misinformation, and Policy Seminar Series | NYU CDS\n\nOn this page: Series Overview • Key Focus Areas • Organizers • Attendance Information\n\nMisinformation has been the focus of significant public attention following a spate of volatile civic events including elections and national referendums that surfaced the prevalence of influence operations. The AI, Misinformation, and Policy (AMPol) Seminar Series provides a platform for researchers and practitioners to share insights on combating misinformation through the ethical use of technology and effective governance.\n\n## Series Overview\n\nLaunched in March 2023, this seminar series brings together “doers” rather than just “thinkers,” showcasing applied work in the fields of AI, misinformation, and policy. By fostering dialogue between researchers, policymakers, and industry leaders, the series aims to develop more effective strategies for addressing the challenges created by global misinformation.\n\n### Key Focus Areas\n\nThe seminar covers a wide range of topics, including but not limited to:\n\n1. Psychosocial Analysis\n2. Algorithmic Auditing\n3. Recommender Systems\n4. Transparency and Ethics\n5. Reinforcement Learning\n6. Multiagent Systems\n7. Agent-based Models\n8. Natural Language Processing\n9. Causal Effects and Interventions\n10. Online Toxicity\n11. Hate Speech\n12. Fake News\n13. Social Network Analysis\n14. Generative Models\n\nThis seminar is a space to introduce beginners to research in these fields. It will provide a platform to continue the conversation with a cross-functional community to foster nuanced discussions on how to address the challenges created by global misinformation through the ethical use of technology and effective governance.\n\n## Organizers\n\nThe AI, Misinformation, and Policy (AMPol) Seminar is organized by [Swapneel Mehta] (CDS PhD alumnus and current Postdoctoral Associate at Boston University and MIT) and [Megan Brown] (CSMAP Sr. Research Engineer).\n\n## Attendance Information\n\nWhile we had in-person events in the past year, all seminars are at present held virtual-only unless otherwise specified.",
    "length": 2100,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University AI policy academic integrity",
    "title": "Academic Integrity Policy",
    "url": "https://tisch.nyu.edu/student-affairs/important-resources/academic-integrity-policy",
    "text": "Academic Integrity PolicyAcademic Integrity Policy\n[Skip to Navigation] [skip to main content] \n[Student Affairs] \n# Academic Integrity Policy\nPlease see the Tisch Policy on Academic Integrity in the NYU Tisch Bulletin:\n[NYU Tisch Bulletin] \n[New York University] \nEqual Opportunity and Non-Discrimination at NYU - New York University is committed to maintaining an environment that encourages and fosters respect for individual values and appropriate conduct among all persons. In all University spaces physical and digital programming, activities, and events are carried out in accordance with applicable law as well as University policy, which includes but is not limited to its[Non-Discrimination and Anti-Harassment Policy].",
    "length": 729,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University AI policy academic integrity",
    "title": "AI Judgment Rule(s) | Compliance and Enforcement",
    "url": "https://wp.nyu.edu/compliance_enforcement/2024/12/10/ai-judgment-rules/",
    "text": "AI Judgment Rule(s) | Compliance and Enforcement\n\nby [Katja Langenbucher] \n\nPhoto courtesy of author\n\nIn an upcoming [paper], I explore whether the use of AI to enhance decision-making brings about radical change for legal doctrine or, by contrast, is just another new tool. The essay submits that we must rethink the law’s implicit assumption that (and how) humans make the decisions that corporate law regulates. If there is movement in implicit assumptions about how people make decisions, legal rules need review.\n\nDecision-making is the cornerstone of corporate life and of keen interest to a variety of scholarly disciplines. They range from rational-actor theories over behavioral approaches to neuro-economics and psychology. The law has its own theories on decision-making. Many are normative and specify decision procedures and outcomes. In addition, the law rests on implicit theories of decision-making: A legal rule will look different if, for instance, it assumes either that decision-making follows optimal choice patterns or that heuristics and biases guide human decisions.\n\nA unifying assumption of the law’s implicit theories has been that they regulate human behavior. With the rise of artificial intelligence (AI) to support and augment human decision-making, this assumption does not necessarily hold.\n\nThe paper focuses on decision-making by board members. This provides an especially interesting example because corporate law has laid out explicit expectations for how board members must go about decision-making. The law requires board members to own their decisions. At the same time, the law trusts corporate boards to take disinterested, and well-informed decisions. Directors are encouraged to delegate decisions, they can, sometimes must, seek information and expert support. Technical support tools have been a part of this process, encompassing pocket calculators, excel spread sheets, or more sophisticated machines. The same goes for human support. Boards regularly hear employees, officers, or outside experts to inform their decisions and corporate law has been confident that board members can affirm ownership of a decision that technical support tools or humans have contributed to.\n\nSo far, corporate law rules on business judgments, on other decisions, and on owning information that was furnished from non-board members all have human decision-makers in mind. An implicit assumption is that board members can cognitively follow when experts present their findings or, alternatively, ask for an explanation. Does this implicit assumption translate seamlessly to integrating an AI?\n\nOne way of looking at it is to conceptualize AI as a technical support tool. It is still the board, one might claim, that takes decisions even if it follows what the AI suggests.\n\nAnother way of looking at it is to analogize an AI to a human expert informing the board. Again, one might stress, the board, not the AI, takes the final decision, even if the board as a rule follows the AI’s recommendation.\n\nInstead, yet another way of looking at it is to stress dissimilarities between AI, traditional technical support tools, and human experts. This essay goes down that route. It submits that reflection and review are core elements of how corporate law has conceptualized board decision-making. The essay moves on to suggest that with increasing complexity of an AI, especially of the black-box variety, processing its input by humans looks fundamentally different than dealing with traditional support tools or with experts. The difference, I suggest, is the way in which an AI ‘malfunctions’ and ‘errs’. There is no conversation, even if large language models might make you think so. There is very little understanding of how the AI produces its results. With a black-box AI, board members do not get information on relevant variables nor on their weights. Depending on data and model, it will be hard or impossible to estimate the probability that the AI’s prediction is biased, not well enough suited to the corporation’s situation, or altogether wrong. Critical dialogue among humans has little equivalent because an AI ‘reasons’ differently from a human expert. Humans, when faced with a prediction task, tend to formulate a hypothesis against the background of their real-world understanding. By contrast, an AI approaches this task as a challenge of inductive inferences from data. Even if researchers can employ an AI to generate a variety of causal hypotheses, it still performs a theory-blind, data-driven search. A deeper reason for this conundrum is the difference between how a human and an AI ‘explain’. When confronted with a human expert, the board member would ask for a causal explanation. For an AI to provide that, we would need to model and infer causality from data. However, an AI mostly gives counterfactual clues, but does not provide a theoretical, conceptual explanation a human expert would expect to hear.\n\nEncoding knowledge, building hypotheses-based explanations, and causality are just three examples to show how an AI ‘reasons’ and ‘explains’ differently from a human person. They suggest that building a board decision on an AI’s prediction resembles neither the use of a traditional technical support tool nor a dialogue with a human expert.\n\nAgainst that background, the essay concludes that ownership of a board decision must be reviewed because cognitive reflection, critical dialogue, and review look different from what human decision-makers are used to. For corporate law, this implies the need to rethink implicit assumptions about how board members make decisions. Enhanced duties for boards that consult outside experts do not adequately capture what is different about an AI that augments board decisions, especially of the black box variety. At the same time, tightly regulating the use of AI would deprive boards of a powerful tool. Arguably, the law, first, needs another implicit theory on decision-making to, then, review and adapt its normative framework.\n\n[Katja Langenbucher] is a Professor at Goethe University’s House of Finance, Frankfurt. This post first appeared in the [Oxford Business Law Blog]. This post is based on a [pape] r by the author published in the University of Chicago Law Review.\n\nThe views, opinions and positions expressed within all posts are those of the author(s) alone and do not represent those of the Program on Corporate Compliance and Enforcement (PCCE) or of the New York University School of Law. PCCE makes no representations as to the accuracy, completeness and validity or any statements made on this site and will not be liable any errors, omissions or representations. The copyright of this content belongs to the author(s) and any liability with regards to infringement of intellectual property rights remains with the author(s).\n\n### Share this post:\n\n[X (Twitter)] [Facebook] [LinkedIn] [Email] [Reddit]",
    "length": 6925,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University ChatGPT policy students",
    "title": "Dear all, This is an advisory update on use of ChatGPT in ...",
    "url": "https://www.nyu.edu/content/dam/nyu/provost/documents/Chat%20GPT%20email.pdf",
    "text": "This is the first full semester where students have access to ChatGPT . The. Provost's office is hearing from faculty about students generating essays, test. 1 page",
    "length": 164,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University ChatGPT policy students",
    "title": "Ethics Handbook for Students - NYU Journalism",
    "url": "https://journalism.nyu.edu/about-us/resources/ethics-handbook-for-students/",
    "text": "[Skip to content] \n\n[NYU Arts & Science] \n\n# Ethics Handbook for Students\n\n_NYU Journalism Handbook for Students:_\n\n_Ethics, Law and Good Practice_\n\nThe handbook was written by Prof. Adam Penenberg, and is available in two versions:\n\n[Read the Handbook Online] \n\n[Download PDF] \n\n## Ethics Pledge\n\n[Ethics Pledge PDF] \n\nAs a New York University journalism student, you are part of a community of scholars at a university recognized for its research. A scholar’s mission is to push forward the boundaries of knowledge; a journalist’s mission is to serve the public by seeking out and reporting the facts as accurately as possible. Good journalists and scholars share a commitment to the same principle: integrity in their work.\n\nBy signing this ethics pledge, you agree to maintain the highest standards of honesty and foster ethical behavior at all times. Anyone who fails to uphold these ethical standards has committed a serious violation of this agreement. Penalties can range from an F on an assignment to a failing grade in a course to expulsion, depending on the nature of the breach and the outcome of any inquiries held in accordance with NYU’s policies and procedures.\n\nExamples of such activities can include (but are not limited to):\n\n**Plagiarism:** Attempting to pass off someone else’s words or ideas as your own without proper attribution or acknowledgment. In both journalism and academia, this is akin to theft. Examples: Copying in whole or in part a published article or another student’s paper, borrowing language or concepts, lifting quotes or failing to use quotation marks where appropriate. **This includes the unauthorized use of generative AI tools such as ChatGPT without the express permission of your instructor. See “Guidance on the Ethical Uses of Generative AI Tools in Journalism”.**\n\n**Fabrication:** Making up information, faking anecdotes or sources, falsifying quotes, creating fictitious sources, citing non-existent articles, or fudging data.\n\n**Multiple submission:** Recycling assignments from one class for use in another, or submitting assignments to one class that were derived from research in another without prior approval from all professors involved.\n\n**Cheating:** Using or attempting to use unauthorized assistance, material, or study aids in examinations or other academic exercises. Examples: Using study resources not expressly approved by the instructor, working with another student or students on a take-home exam without prior approval, tampering with grades, purchasing a paper written by someone else or paying someone to write an assignment for you.\n\nIn addition, if asked you will submit notes and source lists to your professor without delay.\n\n—–\n\n**Guidance on the Ethical Uses of Generative AI Tools in Journalism Arthur L. Carter Journalism Institute at New York University**\n\nThe rise of advanced generative AI models, such as ChatGPT, DALL·E and similar technologies, presents a paradigm shift in how we gather, analyze and disseminate information. While these tools hold immense potential, they also present ethical challenges that can harm the integrity of journalistic work. In recognition of these challenges, the faculty of the Journalism Institute at New York University have created this addendum to the Institute’s Ethics Pledge.\n\n**1\\. Transparency and Attribution**\n\na. When using generative AI to produce or augment content, journalists must disclose its use to their audience. This transparency is crucial for maintaining trust in journalism.\n\nb. Generative tools should never be used to invent quotations or fabricate statements.\n\nc. All generated content should be clearly labeled as “Generated by \\[AI model name\\]” or similar, to ensure readers understand the source.\n\n**2\\. Verification and Fact-Checking**\n\na. AI models can not be considered credible sources. Students must remain skeptical of information provided by AI and should always fact-check against bonafide credible sources before publishing.\n\nb. Generative AI can provide a starting point or supplement to a story but should not be the ultimate source of information, especially on contentious issues.\n\n**3\\. Avoiding Deepfakes and Misrepresentation**\n\na. Use of generative models like DALL·E to create images or multimedia content must be done responsibly. It’s unethical to use these tools to produce misleading or false representations.\n\nb. Deepfakes or AI-generated visuals that could mislead or confuse the audience must be clearly labeled.\n\n**4\\. Editorial Independence**\n\na. Journalists must maintain editorial control and independence. While AI can, in certain circumstances, suggest content or ideas, final decisions must be made by human judgment.\n\nb. Journalists should be aware of and remain critical of any potential biases in AI-generated content.\n\n**5\\. Respect for Human Dignity**\n\na. AI tools should not be used in ways that could demean, stereotype, or harm individuals or communities.\n\nb. Care should be taken to avoid amplifying biases present in AI tools, and they should not be used to perpetuate stereotypes or misinformation.\n\n**6\\. Experimentation and Feedback**\n\na. The Institute encourages experimental uses of AI in journalism, however, we all must balance innovation with responsibility.\n\nb. Feedback loops should be established to report and rectify any issues or ethical concerns related to the use of AI.\n\nIn embracing the future of journalism, it’s essential to uphold the core values that have always defined this profession: truth, accuracy, fairness, and responsibility. This addendum to the ethics pledge aims to integrate the transformative capabilities of generative AI tools while ensuring that these principles remain at the heart of our journalistic endeavors.\n\n**NOTE:** Graduate and undergraduate pledges should be returned to the designated boxes in the 6th floor reception area. **The final grade for a student registered in a journalism course will not be submitted to the Registrar unless a signed pledge is on file in the Institute.**\n\n[Career Resources] \n\n- [Equipment Resources & Information] \n- [Guidelines & Policies at 20 Cooper Square] \n- [Ethics Handbook for Students] \n- [Faculty Resources] \n\n[Open in New Tab] [Close Popup] \n\n[Previous Item] [Next Item]",
    "length": 6258,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University ChatGPT policy students",
    "title": "[PDF] Dear all, This is an advisory update on use of ChatGPT in the ... - NYU",
    "url": "https://www.nyu.edu/content/dam/nyu/provost/documents/Chat%2520GPT%2520email.pdf",
    "text": "There is currently no way to reliably prove ChatGPT use after the fact, and we expect detection tools to remain largely ineffective (claims from vendors like.",
    "length": 158,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University ChatGPT policy students",
    "title": "Compliance and Enforcement",
    "url": "https://wp.nyu.edu/compliance_enforcement/2023/02/10/does-your-company-need-a-chatgpt-policy-probably/",
    "text": "Does Your Company Need a ChatGPT Policy? Probably. | Compliance and Enforcement\n[Skip to content] \n# [Compliance and Enforcement] \n## [![Compliance and Enforcement]] \n# Does Your Company Need a ChatGPT Policy? Probably.\nby**[Megan Bannigan] **,**[Avi Gesser] **,**[Henry Lebowitz] **,**[Anna Gressel] **,**[Michael R. Roberts] **,**[Melissa Muse] **,**[Benjamin Leb] **,**[Jarrett Lewis] **,**[Lex Gaillard] **, and**[ChatGPT] **\n![Photos of the authors] \nTop row left to right: Megan Bannigan, Avi Gesser, Henry Lebowitz, and Anna Gressel\nBottom row left to right: Michael R. Roberts, Melissa Muse, Benjamin Leb, and Jarrett Lewis\nChatGPT is an AI language model developed by OpenAI that was released to the public in November 2022 and already has millions of users. While most people were initially using the publicly available version of ChatGPT for personal tasks (e.g., generating recipes, poems, workout routines, etc.) many have started to use it for work-related projects. In this Debevoise Data Blog post, we discuss how people are using ChatGPT at their jobs, what are the associated risks, and what policies companies should consider implementing to reduce those risks.\n**How Employees Are Using ChatGPT at Work**\nDozens of articles have been written about how ChatGPT will replace certain jobs. But, at least for now, it appears that ChatGPT is not replacing workers, but rather, increasing their productivity. Here are some examples:\n* **Fact Checking**:Employees are using ChatGPT in the same way that they might use Google or Wikipedia to check facts in documents that they are either producing or reviewing.\n* **First Drafts**: ChatGPT can generate drafts of speeches, memos, cover letters, and routine emails. When asked to write this blog post, ChatGPT came up with several helpful suggestions, including “Employees using ChatGPT must undergo training to understand the tool’s capabilities and limitations, as well as the best practices for using it in the workplace.”\n* **Editing Documents**: Because it is a language model that was trained on millions of documents, ChatGPT is very good at editing text. Employees are taking poorly worded paragraphs and having ChatGPT fix grammatical errors, provide more clarity, and generally increase readability.\n* **Generating Ideas**: ChatGPT is surprisingly good at generating lists. For our upcoming**[webcast on the role of ChatGPT in the legal profession] **, ChatGPT came up with questions about maintaining privilege, checking for accuracy, and disclosing the role of ChatGPT to clients and courts.\n* **Coding**: Two of the most common uses for ChatGPT at work are generating new code and checking existing code, with many programmers saying that ChatGPT has made them much more efficient and productive.\n**Risks of Using ChatGPT at Work**\n* **Quality Control Risks**: As impressive as it is, ChatGPT can produce inaccurate results. When drafting sections of a legal brief, it sometimes cites to cases that are irrelevant or do not exist. Because it is a language model, it often struggles with computational tasks and can give incorrect results when asked to solve basic algebra problems. OpenAI is well aware of these limitations. Indeed, ChatGPT itself often issues warnings that it might generate incorrect information. It also has gaps in its knowledge about world events that occurred after 2021. These risks may be lower when the person reviewing ChatGPT’s outputs can easily spot and correct these kinds of errors. But if the reviewer is not able to easily identify what is wrong with (or missing from) ChatGPT’s response, or there is no person reviewing it at all, then the quality control risks increase. How significant these risks are depends on the use case. For example, the risk is lower when it is summarizing news stories on a particular topic for internal awareness, than it would be for generating essential code for the core operations of the company’s information systems.\n* **Contractual Risks**: There are two primary sources of contractual risks associated with the use of ChatGPT for work. First, there may be restrictions on the company’s ability to share customers’ or clients’ confidential information with third parties, including with OpenAI through ChatGPT. Second, the sharing of certain client data with ChatGPT may also violate contractual provisions with those clients regarding the purposes for which their data can be used. In conducting this analysis, companies should keep in mind that the usage rights for ChatGPT are set out in multiple documents, including the**[Terms of Use] **,[**Sharing &amp; Publication Policy**],**[Content Policy] **, and**[Usage Policies] **, which provide that OpenAI may use content provided to ChatGPT to develop and improve its functionality. It is also important to note that many employees sign up for ChatGPT in their personal capacity, and therefore it is not entirely clear to whom these terms apply.\n* **Privacy Risks**: Similar to some of the contractual risks, sharing personal information about customers, clients, or employees with OpenAI through ChatGPT can create privacy risks. According to the**[ChatGPT FAQ] **, OpenAI may use ChatGPT conversations for training purposes and to improve its systems. Depending on the nature of the personal information being shared with ChatGPT, companies may have obligations to update privacy policies, provide notices to customers, obtain their consent, and/or provide them with opt-out rights, etc. These obligations may stem from U.S. state or federal privacy law, and companies should consider the evolving interpretation of**[automated decision-making] **, profiling, and other related concepts under the**[2023 state privacy laws] **. Uses of ChatGPT that involve personal data also raise questions about how companies—and in turn OpenAI—might approach deletion rights or requests to remove data from their ChatGPT-generated workstreams or the model itself.\n* **Consumer Protection Risks**: If consumers are not aware that they are interacting with ChatGPT (as opposed to a human customer service representative), or they receive a document from a company that was generated by ChatGPT without that being clearly disclosed, there is risk of claims of unfair or deceptive practices under state or federal law (aside from the obvious reputational risks). Depending on the circumstances, clients may be upset if they paid for content that they later learn was generated by ChatGPT but was not identified as such.\n* **Intellectual Property Risks**: The use of ChatGPT raises several complex IP issues. First, to the extent that employees use ChatGPT to generate software code or other content, that content may not be protectable by copyright in many jurisdictions since it was not authored by a human being. That is currently the position of the United States Copyright Office, although the requirement for human authorship is under challenge in recently filed litigation. Second, there is risk that ChatGPT and any content it produces may be deemed a derivative work of copyrighted materials used to train the model. If that view prevails, software code, marketing materials, and other content generated by ChatGPT may be found infringing, particularly if such content looks substantially similar to the copyrighted training data. In addition, to the extent that employees submit confidential code, financial data, or other trade secrets and confidential information into ChatGPT for analysis, there is a risk that other users of ChatGPT may be able to pull that same data out, thereby compromising its confidentiality and potentially supporting an argument that such data was not the subject of reasonable steps to preserve its confidential status. Finally, if software submitted to ChatGPT includes open source, it is worth considering whether such submission could be deemed to constitute a distribution that may trigger possible open source license obligations.\n* **Vendor Risks**: Many of the risks described above also apply to company data that is provided to or received from vendors. For example, should contracts with vendors specify that information provided by the vendor to the company cannot be generated by ChatGPT without prior consent? Should contracts also specify that confidential company data cannot be entered into ChatGPT?\n**Ways to Reduce ChatGPT Risks**\nGiven these legal, commercial, and reputational risks, some companies have started to train their employees on the proper use of ChatGPT and draft policies on the use of ChatGPT for work. Training should alert employees to the reality that ChatGPT is not perfect and results from a query to ChatGPT should still be verified using traditional means. The policies surrounding ChatGPT tend to divide ChatGPT uses into three categories: (1) uses that are prohibited (e.g., using ChatGPT to check for mistakes in confidential company or client documents, or sensitive company code); (2) uses that are permitted with authorization from some designated authority (e.g., generating code, so long as it is carefully reviewed by an expert before being implemented); and (3) uses that are generally permitted without any prior authorization (e.g., creating purely administrative internal information such as generating ideas for icebreakers for new hires). In addition, companies are taking steps to reduce the risks associated with the use of ChatGPT, including the following:\n* **Risk Rating**: Creating a set of criteria for assessing whether a particular ChatGPT use is low, medium, or high risk (e.g., will confidential company or client information be shared with ChatGPT, will the output be shared with clients, etc.).\n* **Inventory**: Requiring that all uses of ChatGPT for work be reported to a team that keeps track of",
    "length": 9786,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University ChatGPT policy students",
    "title": "Machines and Society",
    "url": "https://guides.nyu.edu/data/chatgpt",
    "text": "Overview of ChatGPT - Machines and Society - Research Guides at New York University Skip to Main Content\n\nSearch\n\n# Machines and Society\n\nA growing guide on the latest in data-driven research and emerging technologies at the intersection of society, information and technology.\n\nThis page is not currently available due to visibility settings.\n\n- [Print Page] \n- URL: https://guides.nyu.edu/data\n- Last Updated: Aug 28, 2025 1:28 AM\n\n[Author Log-in] \n\n[Report a problem] \n\nSubjects: [Data Science], [Multidisciplinary], [Social Sciences], [Technology] \n\nTags: [artificial intelligence], [computational research], [computing], [data], [information technology] \n\n[Accessibility]",
    "length": 676,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University ChatGPT policy students",
    "title": "Machines and Society",
    "url": "https://guides.nyu.edu/data/chatgpt-developer",
    "text": "Generative AI for Application Development - Machines and Society - Research Guides at New York University[Skip to Main Content] \n[![Banner]] \nSearch this GuideSearch\n# Machines and Society\nA growing guide on the latest in data-driven research and emerging technologies at the intersection of society, information and technology.\n* [Home] \n* [Large Language Models] \n* [What Large Language Models Are] \n* [Using Large Language Models] \n* [Technical Overview] \n* [Bias] \n* [Generative AI for Research and Creative Use] \n* [Generative AI for Data-driven Research] \n* [Generative AI for Application Development] \n* [Introduction] \n* [Assistive Usage: Accelerating the Development Process] \n* [Application Backend: Enhancing Functionality via API] \n* [Specialized Applications: Refining ChatGPT] \n* [Privacy Concerns: Safeguarding User Data] \n* [Contact] \n* [Generative AI for Visual Design] \n* [Generative AI in Literature Searching] \n* [Emerging AI Tools for Teaching and Learning] \n* [Generative AI Quickstarts] \n* [Setting Up Local Generative AI Tools] \n* [Suggestions for Teaching and Learning] \n* [Citing Generative AI] \n* [Technology and Society] \n* [Copyright, Authorship, and Governance] \n* [Business and Industry] \n* [Computational Social Research] \n* [The Field of Computational Social Science] \n* [Web Mining for Digital Disease Surveillance] \n* [Data Collection with Crowdsourcing Technology] \n## Introduction\nDevelopers can leverage ChatGPT&#39;s potential in various capacities, enhancing their work across multiple aspects of application development. Two vital areas when using ChatGPT is particularly beneficial include assistive usage and application backend. You should also be careful about privacy concerns while using ChatGPT.\n## Assistive Usage: Accelerating the Development Process\nChatGPT can significantly aid developers in writing code and expediting the development process. By providing context-aware suggestions, it can help:\n* **Generate Code Snippets:**Developers can input a brief description of the desired functionality, and ChatGPT can generate relevant code snippets in multiple programming languages, saving time and effort.\n* **Debugging:**ChatGPT can assist in identifying common coding issues, offering suggestions to fix errors and improve code quality.\n* **Documentation:**Developers can utilize ChatGPT to create clear and concise documentation, ensuring that their code is easily understandable by other team members.\n* **Translation:**Developers can use ChatGPT to translate their interface to different languages without needing to import/export any data.\nBelow, you can find a list of specialized ChatGPT instances to assist your coding.\n|Product|Description|Website|\nGitHub Copilot|GitHub Copilot is an AI-powered code completion tool developed by Microsoft and OpenAI that suggests code snippets and blocks to developers in real-time.|[https://github.com/features/copilot] |\nGitHub Copilot X|Supercharged Copilot capable of assisting you with CLI commands, documentation, issues and more.|[https://github.com/features/preview/copilot-x] |\n## Application Backend: Enhancing Functionality via API\nChatGPT can be integrated to many applications as a backend via the OpenAI API. It is versatile in handling numerous tasks such as NLP, machine translation, classification, and content generation. The possibilities of utilization are only limited by imagination.\nAn illustrative presentation of the emerging application stack for ChatGPT integrated applications can be viewed[here].\n[![application stack for ChatGPT integrated applications]] \nChatGPT acts as the core of the application, harmonizing with various components that facilitate interaction within different parts of the stack.\nAdditionally, in the course of application development, consider utilizing the following libraries to bolster functionality:\n1. [LlamaIndex] \n* Offers data connectors.\n* Structures data efficiently.\n* Facilitates advanced retrieval/query interface over data.\n* Promotes easy integrations.\n* [LangChain] \n* Integrates LLMs with varied computational sources for enriched functionalities.\n* Demonstrates application versatility in chatbots, agents, and question-answering systems.\n* Provides detailed documentation and examples, aiding developers in crafting powerful applications.\nReview and compare these libraries based on your specific requirements during the development process.\n## Specialized Applications: Refining ChatGPT\nVarious methodologies are available to tailor ChatGPT to meet the specific needs of your application. Here are four imperative techniques:\n1. [Fine-tuning] \n* Yields results of superior quality compared to prompting.\n* Facilitates training on a more substantial number of examples than possible in a prompt.\n* Promotes token savings due to more concise prompts.\n* Ensures lower latency in requests.\n* [Guidance] \n* Structures outputs for enhanced syntactical accuracy and coherence.\n* [Representation Engineering (RepE)] \n* Augments the transparency of Large Language Models (LLMs), focusing on broad-level representations.\n* Addresses issues such as truthfulness and memorization inherent in large language models.\n* [Retrieval-Augmented Generation] \n* Combines the retrieval of external documents with text generation capacities.\n* Elevates the richness and relevance of the content generated by augmenting it with retrieved information.\nThese refinements are crucial for optimizing the performance and output of ChatGPT in various applications.\n## Privacy Concerns: Safeguarding User Data\nUsing ChatGPT through its API or proxies can lead to privacy concerns since OpenAI or proxy providers store all the data. To address these issues and ensure user data protection, developers should ensure:\n* **Encryption:**Implement end-to-end encryption for data transmission between ChatGPT and the application, safeguarding sensitive information.\n* **Data Retention:**Establish strict data retention policies and practices, which dictate the duration and circumstances in which user data is stored or deleted.\n* **Transparency:**Inform users about the usage of ChatGPT and the potential privacy implications, allowing them to provide informed consent.\n* **Anonymization:**Anonymize user data by removing personally identifiable information (PII) before processing it through ChatGPT, minimizing the risks of unintended data exposure.\n* **Proxy Usage:**Avoid using any services that offer ChatGPT through a proxy if possible. It is very easy for proxies to collect information, which could result in unintended data exposure.\n## Contact\nUtku Ege Tuluk\nSenior Associate of Emerging Technologies\nuet200@nyu.edu\n* [&lt;&lt;**Previous:**Generative AI for Data-driven Research] \n* [**Next:**Generative AI for Visual Design &gt;&gt;] \n* Last Updated:Aug 28, 2025 1:28 AM\n* URL:https://guides.nyu.edu/data\n* [**Print Page] \n[Author Log-in] \n[Report a problem] \nSubjects:[Data Science],[Multidisciplinary],[Social Sciences],[Technology] \nTags:[artificial intelligence],[computational research],[computing],[data],[information technology] \n[****] \n[Accessibility(opens\nin new window)]",
    "length": 7125,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University ChatGPT policy students",
    "title": "ChatGPT | Compliance and Enforcement",
    "url": "https://wp.nyu.edu/compliance_enforcement/tag/chatgpt/",
    "text": "Feb 10, 2023 · Does Your Company Need a ChatGPT Policy? Probably. ChatGPT is an AI language model developed by OpenAI that was released to the public in ...",
    "length": 156,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University provost generative AI guidance",
    "title": "NYU Office of the Provost Generative AI Workshop: (Re)Designing Assignments and (Re)thinking Assessment for Learning in the Age of GenAI",
    "url": "https://nexus.sps.nyu.edu/post/nyu-office-of-the-provost-generative-ai-workshop-re-designing-assignments-and-re-thinking-assessm",
    "text": "-- NYU Office of the Provost Generative AI Workshop: (Re)Designing Assignments and (Re)thinking Assessment for Learning in the Age of GenAI\n\ntop of page\n\nRecently, the NYU Office of the Provost offered a morning of [Generative AI Workshops].\n\nI attended “(Re)Designing Assignments and (Re)thinking Assessment for Learning in the Age of GenAI.”\n\n## Approaches\n\nOf multiple topics covered during the training, I appreciated how [Associate Vice Provost DeAngela Duff] framed two approaches for professors to consider when it comes to student assignment or assessment completion: Human-First vs. AI-First.\n\nHuman-First AI Use: In this approach, students first independently brainstorm, research, and draft. Then, they ask AI to help refine, iterate, and even innovate. By the end, students ensure they have vetted all outputs for accuracy and quality. Associate Vice Provost Duff shared that as a professor, she favors this approach, calling it the “human sandwich”: Human generation - AI editing - Human finalizing.\n\n[To] me, this approach empowers and preserves human creativity and critical\n\nthinking skills—even confidence—through productive struggle (Lee et al., 2025). AI is\n\nemployed as an assistant or editor for humans to ultimately vet and finalize outputs,\n\nrather than the other way around.\n\nAI-First AI Use: This approach acknowledges that many students are already using generative AI to create first drafts of written assignments, presentations, and more. After this step, human-intervention is then paramount to evaluate accuracy, prompt and edit, and revise before finalizing: AI generation - Human editing and iterating with AI - Human finalizing.\n\nI appreciate that the latter approach helps realign habits away from students using AI only to complete assignments for them, which is a common concern expressed by professors today.\n\nEach approach offers positives and challenges, including ethical questions, for professors to explore. There is no right answer; it depends on the professor and content area.\n\n## AI Policies & Student Choice\n\nNYU provides [guidelines and considerations for generative AI], but Associate Vice Provost Duff emphasized that it’s up to professors how students should be using AI in their assignments and assessments. Professors might come up with a blanket syllabus statement, and/or create guidelines for acceptable AI use in different assignments.\n\n[The guidelines] also note that instructors are fully responsible for any use of AI in their courses, including the design of assessments, the grading of student work, the writing of feedback, and the protection of student privacy and information. Faculty use of GenAI to develop course materials and/or student feedback should always be disclosed to students.\n\nDuff also cautioned professors not to assume that all students use, or even want to use, AI in their assignments. For example, Dartmouth professor, Scott Anthony, felt surprised by his [Gen Z students’ fear and anxiety] of having their humanity and critical thinking skills replaced by artificial intelligence (Lichtenberg, 2025). For this reason, professors might create [classroom AI policies collaboratively] (NYU login required) with students to include their views on how they can/will use AI in their coursework.\n\n## GenAI Learning Strategies\n\nRather than only share restrictions of AI use, this workshop offered positively-framed strategies for effective, responsible completion of assignments with AI. For example:\n\nMeta-reflections: Have students continuously reflect and capture notes on the process of completing an assignment, not just the output.\n\nBrainstorm with AI: Have students prompt AI for options rather than one answer.\n\nCompare and Contrast: Have students compare and pull from several prompts or several AI tools before choosing.\n\nConfirm Ownership: Emphasize that your students are responsible for everything, including accuracy, in an assignment.\n\n## Assessment Strategies\n\nTo ensure student accountability for learning, Associate Vice Provost Duff shared the following direct assessment strategies:\n\nLive Demonstrations\n\nOral Defenses\n\nPost-Presentation Q+A\n\nPeer Review\n\nTraditional Written Exams\n\nProcess Portfolios\n\nGoogle Doc Written Assignments (Version History)\n\nMeta-Reflections (e.g. Reflective Journaling on AI Use)\n\nand more!\n\n## My Meta-Reflection: Process for Writing this Blog\n\nAlthough I strongly prefer a “Human-First/Human-Mostly\" approach to GenAI, I decided to test an AI-First approach to write this blog post. This section models a process reflection that professors might consider integrating into student assignment submissions.\n\nFirst, I uploaded my general notes, resources, and ideas from the NYU GenAI workshop into Google Gemini, and prompted it to come up with a first draft.*\n\nThough it captured the content of some of my ideas, the level and quality of writing felt generic and uninspiring to me. What I found after a couple of iterative prompts to help shape it is that I deeply enjoy the craft of writing—ever since childhood—as a way to integrate my learning from my mind and my notes into my own voice and finally into words. The process is important to me, and it makes me feel inspired and happy.\n\nBy experimenting with an AI-First approach, I also reconfirmed for myself that although I’ve learned to be a careful editor from 20+ years of experience, I do not love editing. It’s tedious.\n\nTherefore, given the poor quality of the initial drafts from generative AI, I concluded that I still value a Human-First—well, Human-Only or Human-Mostly—approach when it comes to writing and creative work.\n\nHow I did use generative AI as my assistant in my Human-Mostly approach:\n\nFormatting APA references, which I vetted and finalized in this publication.\n\nA quick check of grammar, especially when a colleague isn’t available for a peer-proofread. (I still prefer the latter. After all, it is human beings - you! - who are my audience, so having a second pair of human eyes helps.) :)\n\nFor more information and resources, check out the (Re)designing Assignments and (Re)thinking Assessments workshop [slide deck] (NYU login required).\n\nReferences\n\n*Google. (2026). Gemini [Large language model]. [https://gemini.google.com] \n\nLee, H.-P. (Hank), Sarkar, A., Tankelevitch, L., Drosos, I., Rintel, S., Banks, R., & Wilson, N. (2025). The impact of generative AI on critical thinking: Self-reported reductions in cognitive effort and confidence effects from a survey of knowledge workers (Tech. Rep.). Microsoft Research. In Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems (CHI ’25). [https://doi.org/10.1145/3706598.3713778] \n\nLichtenberg, N. (2025, December 20). ‘They’ll lose their humanity’: Dartmouth professor says he’s surprised just how scared his Gen Z students are of AI. Fortune. [https://fortune.com/2025/12/20/does-ai-make-you-dumb-dartmouth-professor-says-gen-z-scared] \n\n## *Appendix: Gemini-Generated Blog\n\nHeader image credit: NYU Office of the Provost GenAI Workshop, 2026\n\nbottom of page",
    "length": 7043,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University provost generative AI guidance",
    "title": "Adapting Assignments to Generative AI",
    "url": "https://www.nyu.edu/faculty/teaching-and-learning-resources/teaching-with-generative-tools/adapting-assignments-to-generative-AI.html",
    "text": "Adapting Assignments to Generative AI\n\n# Adapting Assignments to Generative AI\n\n--\n\nWhile there are many individual strategies faculty can adopt for assignments, they can be broadly grouped into three categories:\n\n- Forbidding: Students are told they should not use generative AI\n- Avoiding: Assignments are (re)designed so that generative AI is less relevant\n- Integrating: Students are allowed or required to use generative AI, so long as that use stays within guidelines and is acknowledged\n\nNote that as adoption of AI continues to grow, strategies of avoiding and forbidding are becoming less effective, as students can use AI in most assignments in most classes.\n\n### 1. Integrating Use of Generative AI\n\nIntegrating use of generative AI involves giving students explicit permission to use the tool in a course or on an assignment, but in approved ways. The list of possible ways these tools can be integrated into coursework is large and growing: a [list of strategies collected by UNESCO] on page 9 runs to nearly a dozen items.\n\nThe advantage of integrating these tools is that it will encourage students to discuss their use in the context of the class. The disadvantage is that understanding student use will require new effort by the instructor. Involving students in this way will also make them more like co-designers of the assignments, which has both advantages (more engagement) and disadvantages (less predictability.)\n\nSample statement for syllabus: Use of Gemini and related tools is allowed in this class, but only in ways noted in the assignments. (Taking credit for work you did not create is a violation of NYU’s Academic Integrity policy.) As with all assignments, learning from the work is your responsibility. You must use the tools in a way that involves effort you learn from.\n\nFor every assignment, you should also describe:\n\n- Be prepared to discuss your work in class or in conversation with me\n- What you learned from the work\n- Which tools and techniques you used and for which parts of the assignment\n\nWhere an instructor decides to design assignments that integrate generative AI, they should consider one or more of the following strategies:\n\n- Design multi-step assignments that invite student deliberation, analysis, critique, and decision during the creation process\n- Highlight the student’s responsibility for the accuracy of any work they submit, and the need to verify any references or claims in the text\n- Share examples of effective uses of the tool for brainstorming and iterating the output, rather than just copying and pasting the results of a single query\n\n### 2. Avoiding Use of Generative AI\n\nMaking generative AI less relevant means designing an assignment to require the kind of work where humans still significantly outperform machines.\n\nThe advantage of avoiding use of these tools is that assignments will be designed to require student effort. The disadvantage is that these assignments will be a moving target, as things the tools cannot do well this semester may become possible next semester, requiring regular review of their effectiveness. Strategies that worked in 2023, like asking for integrated text and images, are no longer effective for students using contemporary AIs.\n\nSample statement for syllabus:\n\nThough you are welcome to use generative AI tools to brainstorm in the early phases of an assignment, you are expected to produce the assignments themselves on your own. (Taking credit for work you did not create is a violation of NYU’s Academic Integrity policy.) The assignments have been designed around tasks or outputs the tools do not perform well, and your work will be graded down, perhaps substantially, if it fails to meet those expectations regardless of how it was created.\n\nWhere an instructor decides to design assignments that make use of generative AI less relevant, they should consider one or more of the following strategies:\n\n- Design assignments that require oral presentation or in-class discussion\n- Design assignments tightly tied to specific course readings or concepts\n- Design assignments that require integration of discussions in class\n- Ask for specific references or quotes from material studied in class\n- Design assignments with greater emphasis on process — iterative work, submission of rough drafts, preserving edit history\n- Collect early student thoughts about an assignment in class, to get a sense of how they work unaided\n\n### 3. Advising Against Use of Generative AI\n\nPersuading students not to use these tools for some or all assignments will require explaining that the things you want them to learn from the assignment require that they do the work themselves. It also asks students to self-police, as there is no regular way to detect use of these tools. Note that this strategy works less well than it did in 2023, as a majority of students have now adopted these tools.\n\nThe advantage of asking students not to use these tools is that this strategy can preserve some of the design of individual assignments or a whole course. The disadvantage is that while you can recommend against use of these tools, you cannot prevent their use. Given the relative difficulty in detecting use of these tools, academic integrity cases can be harder to adjudicate, because most evidence is circumstantial.\n\nSample statement for syllabus: You will only learn from these assignments if you do the work yourself. You should not use Gemini or other AI tools as a shortcut or substitute for drafting and editing work in this class. Taking credit for work you do not do is a violation of NYU’s Academic Integrity policy.\n\nAdvising against use of generative AI is compatible with designing assignments to avoid use of generative AI. Faculty may want to consider using elements of both strategies, instructing students not to use these tools and designing assignments that cannot easily be completed by these tools.",
    "length": 5915,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University provost generative AI guidance",
    "title": "Still wondering about Generative AI? Here are some NYU Resources",
    "url": "https://wp.nyu.edu/fas-edtech/2024/10/still-wondering-about-generative-ai-here-are-some-nyu-resources/",
    "text": "Oct 7, 2024 · For those of you who missed it, the Office of the Provost offered a series of Generative AI workshops in August of 2024 to address the many ...",
    "length": 157,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University provost generative AI guidance",
    "title": "AI and Technology in Education",
    "url": "https://www.nyu.edu/about/leadership-university-administration/office-of-the-president/office-of-the-provost/ai-and-technology-in-education.html",
    "text": "Organization Chart\n\n# AI and Technology in Education\n\nClay Shirky\n,\nVice Provost\n\nClay Shirky is Vice Provost for AI and Technology in Education. In this role, he designs, develops, and enhances all academic aspects of technology-based teaching and learning, University-wide; oversees the development of NYU’s instructional technology strategy, working with deans, faculty, NYU IT, and other university offices; maintains an inventory of online education offerings; and helps schools use educational technology to recruit new students, help existing students learn and progress, and generate costs savings or new revenues. He chairs the University’s Future of Technology-Enhanced Education Committee.\n\n[Usability Lab] \n\n## Head of Unit\n\n[Clay Shirky] \n\nVice Provost for AI and Technology in Education\n\n[clay.shirky@nyu.edu] \n\n## Key People\n\n### In AI and Technology in Education\n\n[De Angela Duff] \n\nAssociate Vice Provost\n\n[deangela.duff@nyu.edu] \n\n[Claire Menegus] \n\nDirector, NYU Usability Lab\n\n[cm3884@nyu.edu]",
    "length": 1013,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University provost generative AI guidance",
    "title": "",
    "url": "https://www.nyu.edu/about/leadership-university-administration/office-of-the-president/office-of-the-provost/clay-shirky.html",
    "text": "# Clay Shirky\n\n## Vice Provost for AI and Technology in Education\n\n[clay.shirky@nyu.edu] \n\n![] \n\nClay Shirky is Vice Provost for AI and Technology in Education. In this role, he designs, develops, and enhances all academic aspects of technology-based teaching and learning, University-wide; oversees the development of NYU’s instructional technology strategy, working with deans, faculty, NYU IT, and other university offices; maintains an inventory of online education offerings; and helps schools use educational technology to recruit new students, help existing students learn and progress, and generate costs savings or new revenues. He chairs the University’s Future of Technology-Enhanced Education Committee.\n\nShirky is Associate Professor at the Arthur L. Carter Center of Journalism in FAS and Associate Arts Professor in Tisch School of the Arts’ Interactive Telecommunications Program. From 2014 to 2017, he served as Chief Information Officer at NYU Shanghai. Before joining NYU’s full-time faculty in fall 2004, he was a partner at an international investment company, and was the original Professor of New Media at Hunter College, where he helped design its MFA in Integrated Media Arts program. Currently, Shirky is a faculty associate at Harvard University’s Berkman Center for Internet and Society, and was the 2010 Edward R. Murrow Visiting Lecturer at Harvard's Joan Shorenstein Center on the Press, Politics, and Public Policy.\n\nShirky holds a B.A. in Fine Art from Yale University. A leading voice on the social and economic impact of internet technologies, he is the author of _Little Rice: Smartphones, Xiaomi, and the Chinese Dream_ (2015), _Cognitive Surplus: Creativity and Generosity in a Connected Age_ (2010), and _Here Comes Everybody: The Power of Organizing Without Organizations_ (2008). In 2010, he was named one of Foreign Policy’s “Top 100 Global Thinkers.” He has had regular columns in _Business 2.0_ and _FEED_, among other publications, and his writings have appeared in _The New York Times_, the _Wall Street Journal_, _Harvard Business Review_, _Wired_, _Computerworld_, and _Foreign Affairs_.\n\n**Assistant:** Le'Shelle Brotherton\n\n[lb1204@nyu.edu] \n\n* * *\n\n## Key People\n\n### In Office of the Provost\n\n[![] \\\nDiana L. (Karafin) Arpino] \n\nVice Provost for Academic Program Review and Doctoral Affairs\n\n[dk96@nyu.edu] \n\n[![] \\\nStacie Grossman Bloom] \n\nChief Research Officer, Vice Provost & Vice Chancellor for Global Research and Innovation\n\n[blooms03@nyu.edu] \n\n[![] \\\nEliot Borenstein] \n\nVice Chancellor and Vice Provost for Global Programs\n\n[eb7@nyu.edu] \n\n[![] \\\nElise Cappella] \n\nVice Provost for University-wide Initiatives and Graduate Education\n\n[ec79@nyu.edu] \n\n[![] \\\nKristen Day] \n\nVice Provost\n\n[kday@nyu.edu] \n\n[![] \\\nJoseph Juliano] \n\nVice Provost for Planning and Academic Operations\n\n[joe.juliano@nyu.edu] \n\n[![] \\\nMJ Knoll-Finn] \n\nSenior Vice President for Global Enrollment Management and Student Success\n\n[mjknollfinn@nyu.edu] \n\n[![] \\\nCharlton McIlwain] \n\nVice Provost for Faculty Engagement, Pathways & Public Interest Technology\n\n[charlton.mcilwain@nyu.edu] \n\n[![] \\\nKaren Nercessian] \n\nAssociate Vice Provost for Strategy and Implementation\n\n[karen.nercessian@nyu.edu] \n\n[![] \\\nRyan Poynter] \n\nAssociate Vice Provost for Academic Affairs and Chief of Staff\n\n[ryan.poynter@nyu.edu] \n\n[![] \\\nClay Shirky] \n\nVice Provost for AI and Technology in Education\n\n[clay.shirky@nyu.edu] \n\n[![] \\\nMark Siegal] \n\nVice Provost for Undergraduate Education\n\n[mark.siegal@nyu.edu]",
    "length": 3528,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University provost generative AI guidance",
    "title": "Getting Started with Generative AI",
    "url": "https://steinhardt.nyu.edu/faculty-and-staff/academic-affairs/steinhardt-ai-hub/getting-started-generative-ai",
    "text": "Getting Started with Generative AI | NYU Steinhardt[Skip to main content] \n[![Steinhardt School of Culture, Education, and Human Development]] \nSearch\nOpen Main MenuClose Main Menu\n## Search NYU Steinhardt\nSearch\nClose Search\n![Computer] \n# Getting Started with Generative AI\n**AI is transforming education by providing new ways to support teaching and learning**. Instructors can use AI to personalize learning experiences, streamline administrative tasks, and enhance student engagement. This page serves as a starting point for understanding how AI can be integrated into your teaching practice.\n## Teaching with Generative AI\nExplore NYU&#039;s comprehensive FAQ page on teaching with generative AI tools. This resource provides valuable insights and answers to common questions about effectively integrating AI in your classroom, addressing topics like ethical use, academic integrity, and practical applications.\n[Access the FAQ page to get started] \n## **AI Literacy Basics**\nA few essential terms:\n### Artificial Intelligence (AI)\nA branch of computer science focused on creating systems that can perform tasks that would typically require human intelligence, like recognizing patterns, learning from experience, or understanding language. AI has been around for decades. It is utilized in autocorrect, Google Maps, search and recommendation algorithms, and banking, like e-payments, just to name a few.\n### Machine Learning (ML)\nA subset of AI that enables systems to learn and improve from experience.\n### Generative AI (“Gen AI”)\nAI that creates content, such as text or images, based on prompts (e.g., ChatGPT).\n### Large Language Model (LLM)\nA type of generative AI model trained on vast text data to understand and generate human-like language. LLMs, like GPT (Generative Pre-trained Transformer), power many modern AI text tools, like ChatGPT.\n### Prompt\nThe input or question given to a generative AI tool, like ChatGPT, to generate responses. The effectiveness of AI-generated results often depends on the clarity and specificity of the prompt.[Check out this deep dive into Prompt Engineering].\n### Chatbot\nA chatbot is a program that is designed to communicate with people through text or voice commands in a way that mimics human-to-human conversation. When you are engaging with a chatbot, you are not talking to a human.\n### Natural Language Processing (NLP)\nThe umbrella term for any machine’s ability to perform conversational tasks, such as recognizing what is said to it, understanding the intended meaning, and responding intelligibly.\n### Tokens\nTokens are the basic units of text or code that an LLM AI uses to process and generate language. Tokens can be characters, words, subwords, or other segments of text or code, depending on the chosen tokenization method or scheme. Tokens are assigned numerical values or identifiers, and are arranged in sequences or vectors, and are fed into or outputted from the model. Tokens are the building blocks of language for the model.\n## **Guidelines for AI Use and Academic Integrity**\n### Permitted and Prohibited Use Cases\nClearly outline where AI tools are allowed and restricted in your course. For example, AI might be used for brainstorming or initial drafts but should not be used to complete graded assignments independently. Establish boundaries to prevent academic misconduct, ensuring students understand when AI use crosses into prohibited territory, such as generating full essays or solutions.**Note: You may include multiple policy statements in your syllabus to specify when AI tools are permitted or prohibited, depending on the assignment or activity.**\n### Ethical AI Use\nEncourage ethical AI usage, including proper attribution when AI tools contribute to an assignment. Highlight that AI is a*supplement*, not a*substitute*for original work.\n### Sample Policy Statements\n* *General Use*: \"Students may use Generative AI tools for brainstorming, but final submissions should reflect their own work.\"\n* *Prohibited Use*: \"Using Generative AI tools to generate full assignments is considered plagiarism.\"\n* *Attribution*: \"Any AI-generated content used must be acknowledged; failure to disclose may lead to academic consequences.\"### Engaging Students in Ethical AI Use\nConsider starting the semester with discussions on AI’s role in learning, including ethical considerations, to build awareness and foster critical thinking about technology's role in academic work.\n[**For more information about Syllabus and Academic Integrity Support with Generative AI, visit our FAQ.**]",
    "length": 4562,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University provost generative AI guidance",
    "title": "Generative AI - Generative AI and Large Language Models (LLMs) - Research Guides at New York University",
    "url": "https://guides.nyu.edu/chatgpt",
    "text": "Generative AI - Generative AI and Large Language Models (LLMs) - Research Guides at New York University Skip to Main Content\n\nSearch\n\n# Generative AI and Large Language Models (LLMs)\n\nUnderstanding LLMs (e.g., ChatGPT) and the concept, use, and ethics of Generative AI tools and platforms.\n\n## Generative AI Primer\n\n### What is generative AI?\n\nGenerative AI (GAI) is a type of artificial intelligence that can generate text, images, videos, and other content in response to a user prompt, based on its training data.\n\nThis guide focuses on text-based AI generators. For information on image and video AI generators, see the [Machines and Society] guide.\n\n### Text-based generative AI: LLMs\n\nLarge language model (LLMs) are the foundation of GAI. LLMs are trained on vast amounts of text to understand existing content and generate original content. They function as chatbots, responding to user prompts by processing natural language in a conversational, human-like way. They can perform a variety of language-based tasks, like generating, summarizing, and translating text.\n\n#### What are some of the LLMs out there?\n\n[ChatGPT]: (OpenAI) Has free and fee-based options\n\n[Copilot:] (Microsoft) Free\n\n[Gemini]: (Google) Free to anyone with a Google account\n\n[Llama2]: (Meta) Free for download\n\n### What types of things can ChatGPT and other LLMs do?\n\nWhen asked what it is capable of doing, this is one way ChatGPT has answered:\n\n- Part-of-speech tagging: I can identify the part of speech (noun, verb, adjective, etc.) of each word in a given sentence.\n- Named entity recognition: I can identify and extract named entities such as people, places, and organizations from text.\n- Sentiment analysis: I can analyze text to determine the overall sentiment or emotion expressed within it.\n- Conversational AI: This refers to my ability to engage in natural language conversations with humans, responding to prompts and questions in a conversational manner.\n- Text translation: I can translate text from one language to another, with varying levels of accuracy depending on the language pairs.\n- Summarization: I can summarize longer pieces of text into shorter summaries while retaining the main ideas and important details.\n- Question-answering: I can answer questions by identifying the most relevant information from my training data and generating an appropriate response.\n- Text completion: This involves predicting and generating the most likely words or phrases to complete a given sentence or paragraph based on context.\n- Text generation: This refers to my ability to generate new text based on a given prompt or topic. I can use my understanding of language and my training data to produce sentences, paragraphs, or even longer pieces of text.\n\n(ChatGPT, personal communication, March 14, 2023)\n\n### How do LLMs work, for example ChatGPT?\n\nWhat is behind ChatGPT's mystique? This is one way that ChatGPT has responded to the question of how it works:\n\nChatGPT is a language model that utilizes a range of concepts, architectures, processes, and data inputs to perform its tasks. Here are some of the key elements that enable ChatGPT to work:\n\nLarge language model: ChatGPT is a large language model that is designed to process and generate large amounts of natural language text. It is trained on massive amounts of text data, including books, articles, websites, the Common Crawl, Wikipedia, and other sources. These datasets provide the foundational knowledge that ChatGPT draws on when processing input text and generating responses.\n\nArtificial Neural Networks (ANNs): ANNs are mathematical models that simulate the way that the human brain processes information. They are used extensively in ChatGPT to process input text and generate responses.\n\nNatural Language Processing (NLP): This is the use of computational techniques to analyze and understand human language. ChatGPT uses NLP to process input text and generate responses.\n\nTransformer architecture: The transformer architecture is a type of neural network that is used in GPT models. It enables ChatGPT to process input text and generate responses in a way that is both efficient and effective.\n\nGenerative Pre-trained Transformer (GPT): ChatGPT is based on GPT, a type of deep learning model specifically designed for natural language processing. GPT is trained on vast amounts of text data to learn the patterns and structures of language, enabling it to generate human-like responses to input prompts.\n\nTransfer learning: ChatGPT is trained on a vast corpus of text data that covers a wide range of topics and styles. Transfer learning enables ChatGPT to transfer knowledge learned in one domain to another related domain, allowing it to generate responses to a diverse range of input prompts.\n\nReinforcement learning: ChatGPT uses reinforcement learning to improve its performance over time. This involves training it on a dataset of prompts and human-generated responses, and then adjusting its behavior based on feedback from humans.\n\nAttention mechanism: The attention mechanism is a component of the transformer architecture that allows ChatGPT to focus on specific parts of the input text when generating a response. This helps it to generate more accurate and relevant responses.\n\nOverall, ChatGPT utilizes a complex combination of technologies and processes to analyze and understand human language, enabling it to generate responses that are similar to those produced by humans.\n\n(ChatGPT, personal communication, March 14, 2023)\n\n## ChatGPT Q&A Examples\n\n### Example 1\n\nUser question: Can you provide a diverse list of the best books of the 20th century?\n\nChatGPT answer: The 20th century produced an incredible amount of great literature across a wide range of genres and styles. Here are some of the best books of the 20th century, in no particular order, that represent a diverse range of voices and perspectives:\n\n1. \"The Diary of Anne Frank\" by Anne Frank\n2. \"The Lord of the Rings\" by J.R.R. Tolkien\n3. \"Brave New World\" by Aldous Huxley\n4. \"The Handmaid's Tale\" by Margaret Atwood\n5. \"The Sun Also Rises\" by Ernest Hemingway\n6. \"The Color Purple\" by Alice Walker\n7. \"A Passage to India\" by E.M. Forster\n8. \"Things Fall Apart\" by Chinua Achebe\n9. \"The Bell Jar\" by Sylvia Plath\n10. \"Slaughterhouse-Five\" by Kurt Vonnegut\n11. \"Their Eyes Were Watching God\" by Zora Neale Hurston\n12. \"The Grapes of Wrath\" by John Steinbeck\n13. \"The Sound and the Fury\" by William Faulkner\n14. \"The Catcher in the Rye\" by J.D. Salinger\n15. \"Invisible Man\" by Ralph Ellison\n16. \"The Great Gatsby\" by F. Scott Fitzgerald\n17. \"Beloved\" by Toni Morrison\n18. \"One Hundred Years of Solitude\" by Gabriel Garcia Marquez\n19. \"1984\" by George Orwell\n20. \"To Kill a Mockingbird\" by Harper Lee\n\nThis is by no means an exhaustive list, but it includes some of the most influential and widely-read books of the 20th century.\n\n(ChatGPT, personal communication, March 14, 2023)\n\n---\n\n### Example 2\n\nUser question: What is the most efficient cardio-vascular exercise?\n\nChatGPT answer: There is no single \"most efficient\" cardio-vascular exercise as different exercises offer different benefits and are suited for different individuals and fitness goals. However, some cardio exercises are generally considered more effective than others for improving cardiovascular fitness and burning calories.\n\nHere are a few examples of popular cardio exercises that are generally considered effective:\n\n1. High-Intensity Interval Training (HIIT): HIIT workouts involve short bursts of high-intensity exercise followed by periods of rest. These workouts can be very effective for improving cardiovascular fitness and burning calories in a short amount of time.\n2. Swimming: Swimming is a low-impact exercise that works your whole body and can improve cardiovascular fitness. It's also a great option for people with joint problems or injuries.\n3. Cycling: Cycling is a low-impact exercise that can be done indoors or outdoors. It's a great way to work your legs and get your heart rate up, and can be adjusted to suit different fitness levels.\n4. Running: Running is a great way to get your heart rate up and improve your cardiovascular fitness. It also burns a significant number of calories per minute and can be done indoors or outdoors.\n\nUltimately, the most efficient cardio exercise for you will depend on your individual fitness level, goals, and preferences. It's important to choose an exercise that you enjoy and can stick to in the long term, as consistency is key to seeing results.\n\n(ChatGPT, personal communication, March 13, 2023)\n\n---\n\n### Example 3\n\nUser question: What should I make for dinner tonight?\n\nChatGPT answer: I'm happy to help you come up with some ideas for dinner tonight! Here are a few suggestions based on different dietary preferences and ingredients you might have on hand:\n\n- Baked salmon with a side of steamed green beans and quinoa. You could season the salmon with lemon, garlic, and herbs for added flavor.\n- Black bean tacos with avocado, salsa, and a side of brown rice. You could also add some grilled vegetables, such as onions and bell peppers, for extra flavor.\n- Spaghetti with tomato sauce and sautéed vegetables, such as zucchini, mushrooms, and bell peppers. You could also add some ground turkey or lentils to the sauce for protein.\n- Grilled chicken or tofu with a side of roasted vegetables, such as broccoli, carrots, and sweet potatoes.\n\n(ChatGPT, personal communication, March 13, 2023)\n\n- [Print Page] \n- URL: https://guides.nyu.edu/chatgpt\n- Last Updated: Oct 7, 2025 1:49 PM\n\n[Author Log-in] \n\n[Report a problem] \n\n[Accessibility]",
    "length": 9630,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University teaching and learning generative AI guidance",
    "title": "Enhancing Teaching and Learning with Generative AI",
    "url": "https://steinhardt.nyu.edu/faculty-and-staff/academic-affairs/steinhardt-ai-hub/enhancing-teaching-and-learning-generative-ai",
    "text": "Enhancing Teaching and Learning with Generative AI | NYU Steinhardt[Skip to main content] \n[![Steinhardt School of Culture, Education, and Human Development]] \nSearch\nOpen Main MenuClose Main Menu\n## Search NYU Steinhardt\nSearch\nClose Search\n![NYU classroom] \n# Enhancing Teaching and Learning with Generative AI\n## Integrating AI into the Classroom\nThis guide is designed for educators seeking to integrate AI into their teaching practices. It offers actionable strategies, practical resources, and detailed examples to help enrich student learning with AI tools. AI can enhance personalized learning, automate routine tasks, and boost student engagement, but aligning its use with clear learning objectives and ethical guidelines is essential for effective implementation.\n### Best Practices for AI Integration\n#### Define Clear Objectives for AI Use\n**Purpose-driven AI integration:**Before using AI, clarify the goals it will support. Define how AI can enhance learning outcomes, such as personalized feedback, content creation, or research assistance.\n**Example:**Use AI to brainstorm project topics. Explicitly tell students when they should stop utilizing generative AI for this project.\n#### Maintain Transparency with Students\n**Explain AI’s role in the classroom:**Be transparent with students about how AI will be used and explain its capabilities and limitations. This promotes ethical use and helps students understand AI’s strengths and weaknesses.\n**Example:**Introduce students to AI tools like ChatGPT by explaining how it generates responses and the importance of critically evaluating AI-generated content. Create an introductory assignment that requires students to use ChatGPT to generate written work. Ask that students critically evaluate the output and submit that for grading and large &amp; small group reflection.\n#### Encourage the Ethical Use of AI\n**Teach responsible AI use:**Develop guidelines around AI usage, such as proper attribution of AI-generated content and the ethical considerations of using AI for assignments.\n**Example:**Incorporate early discussions on academic integrity, plagiarism, and the appropriate use of AI for research and writing assistance.\n#### Use AI to Foster Critical Thinking\n**Complement, don’t replace:**AI should be used to complement learning, not as a substitute for critical thinking and problem-solving. Encourage students to critically assess AI-generated suggestions or solutions.\n**Example:**Have students use AI tools for brainstorming or drafting, but require them to analyze and refine the output with their own insights. Require students to reflect on these exercises using in-class discussions or asynchronous online discussions utilizing NYU Brightspace.\n#### Personalize Learning Experiences\n**Leverage AI for adaptive learning:**Use AI-powered tools to tailor instruction based on individual student needs, providing personalized learning experiences that adapt to student progress.\n**Example:**Create personalized study plans for your different learning styles. Try imputing your activity or assignment into chatGPT and asking it to provide you with ideas on how to adjust the assignment for learners with anxiety or depression or for students who might be new to the subject matter and need more scaffolding.\n#### Integrate AI with Collaborative Learning\n**Facilitate group projects with AI:**Use AI to enhance collaboration by allowing students to engage in AI-driven group discussions, idea generation, and content refinement.\n**Example:**Students can use AI to collectively generate project ideas or feedback, fostering peer learning and critical evaluation of AI outputs. Ask students to assess the AI output for bias and misinformation.\n#### Continuously Assess and Adjust AI Use\n**Monitor effectiveness:**Regularly assess the impact of AI on student learning outcomes. Be prepared to adjust its use based on feedback and learning progress.\n**Example:**Conduct regular check-ins with students to gauge how AI aids their learning and where it may need adjustment or further guidance. You can facilitate this through a reflective discussion, anonymous feedback via Google Forms, or anonymous discussions on NYU Brightspace.\n#### Create Clear Policies\n**Develop AI usage policies:**Set clear policies on how AI can and cannot be used in coursework. Include these guidelines in the syllabus and ensure students understand the expectations.\n**Example:**Clearly state that AI-generated text must be cited or only used in specific parts of an assignment (e.g., brainstorming).\n#### Offer Training and Support\n**Provide AI tool training:**Ensure students are adequately trained in using AI tools. Offer tutorials or resources to help everyone use AI effectively and ethically. Don’t assume that just because your learners are younger, they’re comfortable with AI!\n**Example:**Request that the*Digitial Innovation and Learning*Team host an AI workshop at the start of the semester to familiarize students with the AI tools they’ll be using in class.\n#### Address AI’s Limitations\n**Be mindful of AI’s weaknesses:**Educate students about AI’s limitations, such as potential biases, factual inaccuracies, or lack of contextual understanding, and how these can impact output quality.\n**Example:**Have students cross-check AI-generated research content with primary sources to verify accuracy. Additionally, have students intentionally examine the output for*bias*and share the findings with the larger audience.\n## Sample Classroom Activities\nThese lesson plans are designed to support critical thinking, creativity, and engagement through the thoughtful use of AI. Whether you're new to AI or looking to enhance your existing lessons, these plans offer practical ways to bring AI into various subjects, helping students develop digital literacy and navigate AI's role in education. Explore ready-to-use templates and ideas for fostering interactive, AI-supported learning experiences.\n### Ctrl+Alt+Debate: AI-Powered Argumentation and Debate Strategies\n**Best for:**Undergraduate &amp; Graduate\n**Activity Type:**Discussion &amp; Critical Thinking\n**Description:**Students use AI to generate arguments for or against a topic and then engage in a structured debate. This activity helps students analyze AI-generated reasoning, refine arguments, and improve their debate skills.\n**Lesson Plan Steps:**\n1. Assign students a debate topic related to the course material.\n2. Have students use an AI tool (like ChatGPT or Gemini) to generate arguments for both sides.\n3. Pair students and assign them positions (pro/con).\n4. Students refine AI-generated responses with evidence from course readings.\n5. Conduct live debates in class.\n**Materials Needed:**\n1. Access to an AI chatbot\n2. Course readings\n3. Debate rubric\n**Prep Time:**15-20 minutes\n**Activity Duration:**30-45 minutes\n[Activity Lesson Plan] \n### AI Writes, You Refine: A Storytelling Activity\n**Best for:**Undergraduate\n**Activity Type:**Creative Writing &amp; AI Interaction\n**Description:**Students generate AI-assisted short stories by remixing different styles, perspectives, or time periods. This activity encourages creativity, genre analysis, and critical evaluation of AI-generated content while reinforcing course concepts.\n**Lesson Plan Steps:**\n1. Provide students with a historical event, concept, or case study from the course.\n2. Have them prompt an AI to rewrite the event in a specific genre (e.g., sci-fi, dystopian, detective).\n3. Students revise and add their own analysis.\n4. Share and discuss how AI changes the narrative perspective.\n**Materials Needed:**\n1. AI text generator (ChatGPT, Gemini, etc.)\n2. Course materials for context\n**Prep Time:**10 minutes\n**Activity Duration:**45-60 minutes\n[Activity Lesson Plan] \n### Spot the Bot: AI Research Challenge\n**Best for:**Graduate &amp; Upper-Level Undergraduate\n**Activity Type:**Critical Thinking\n**Description:**Students analyze AI-generated fake research papers to identify biases and inaccuracies.\n**Lesson Plan Steps:**\n1. Provide AI-generated \"fake\" research papers with errors.\n2. Students analyze papers for logical inconsistencies, bias, or misrepresented sources.\n3. Discuss AI's role in academic integrity and research credibility.\n**Materials Needed:**\n1. AI-generated research excerpts\n2. Fact-checking resources\n**Prep Time:**20 minutes\n**Activity Duration:**45-60 minutes\n[Activity Lesson Plan] \n### AI-Powered Podcast Host\n**Best for:**Undergraduate\n**Activity Type:**Media &amp; Communication\n**Description:**Students create a short podcast episode using AI-generated scripts and then refine them.\n**Lesson Plan Steps:**\n1. Assign students a course-related topic.\n2. Have them generate a script with a generative AI software.\n3. Students revise for accuracy and engagement.\n4. Record and share their podcast episodes and reflect on the work of AI in podcasting.\n**Materials Needed:**\n1. AI chatbot\n2. Recording software (iphone,Anchor, Audacity, etc.)\n**Prep Time:**20-30 minutes\n**Activity Duration:**60-90 minutes\n[Activity Lesson Plan] \n### AI-Powered Exam Question Generator\n**Best for:**Undergraduate &amp; Graduate\n**Activity Type:**Study &amp; Review\n**Description:**Students use AI to generate potential exam questions and critique their quality.\n**Lesson Plan Steps:**\n1. Assign students key topics or themes to review.\n2. Have them generate exam questions using AI.\n3. Students refine and critique AI-generated questions.\n4. Submit the best ones for peer review or instructor use.\n**Materials Needed:**\n1. AI chatbot\n2. Access to course themes and materials\n**Prep Time:**10 minutes\n**Activity Duration:**30-45 minutes\n[Activity Lesson Plan] \n### AI-Powered Ethical Dilemmas –Human vs. AI Decision-Making\n**Best for:**Undergraduate &amp; Graduate\n**Activity Type:**Ethics &amp; Decision-Making\n**Description:**Students engage with AI-generated ethical dilemmas related to course themes.",
    "length": 9919,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University teaching and learning generative AI guidance",
    "title": "Teaching and Learning with Generative AI",
    "url": "https://stern.nyu.edu/portal-partners/faculty-staff/learning-science-lab/teaching-technologies/teaching-and-learning-generative-ai",
    "text": "[Skip to main content] \n\nOpen Menu\n\nSearch the NYU Stern SiteSearch\n\nSearch the NYU Stern SiteSearch\n\n# [Learning Science Lab] \\| Teaching and Learning with Generative AI\n\n# Teaching and Learning with Generative AI\n\nThe past few months have shown a significant increase in the popularity of generative AI (GenAI) tools - like ChatGPT - in and outside of the classroom. Here at the Learning Science Lab, we understand that drastic technological advances can feel overwhelming. However, we believe change can also be a great opportunity to innovate and educate one another.\n\n[**Explore our Generative AI resource**] \n\n## Brush up on new techniques and technologies.\n\nOur workshops are a great place to learn new skills and enhance your teaching.\n\n[Save Your Spot] \n\n### Questions? We're available weekdays, 9am-5pm to respond to email queries.\n\n[learning.science@stern.nyu.edu]",
    "length": 875,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University teaching and learning generative AI guidance",
    "title": "Student Learning with Generative AI - NYU",
    "url": "https://www.nyu.edu/faculty/teaching-and-learning-resources/Student-Learning-with-Generative-AI.html",
    "text": "Below are some general principles to consider when using generative AI in your studies. Follow Your Instructor's Guidance For Each Course.",
    "length": 138,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  }
]