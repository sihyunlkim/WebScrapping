[
  {
    "query": "site:nyu.edu New York University generative AI policy",
    "title": "AI Guidance & Governance",
    "url": "https://www.nyu.edu/life/information-technology/artificial-intelligence-at-nyu/governance.html",
    "text": "AI Guidance & Governance\n\n# AI Guidance & Governance\n\n--\n\n## A Cross-University Team to Guide the Use of AI at NYU\n\nThe AI Leadership Council (AILC) is a standing committee that guides NYU’s strategy, acquisition, development, and implementation of AI tools and services on the university’s behalf. The AILC works with schools and units to understand their needs and to advise or redirect proposed work based on utility, cost, opportunity, and risk considerations.\n\n--\n\n### Core Goals\n\n- Inform leadership and the broader university community about findings and conclusions\n- Follow developments in the field and study new capabilities\n- Help manage legal constraints and ethical risks from use of AI\n- Avoid wasting NYU’s time or money on developing or procuring ineffective or duplicative uses\n- Direct schools and units towards effective and cost effective uses of AI\n- Understand, and coordinate where needed, NYU's larger-scale investments in AI\n\n--\n\n### AI Leadership Council Structure\n\nMembership is drawn from the Offices of the President and Provost, Information Technology, and Global Enrollment Management and Student Success. The group consults widely with members of the Administrative Management Council (AMC), Instructional Technologists Committee (ITC), Committee on Technology Enhanced Education (TEE), and the offices of the EVP, Dean of Libraries, and all relevant Trustee groups. The group reports on the state and possible trajectories of AI to the President, Provost, and EVP twice a year.\n\n#### AI Leadership Council Members:\n\n- Nina Gray, Associate Vice Provost for Research, Provost\n- Hongyi Wen, Assistant Professor of Computer Science Faculty of Engineering and Computer Science, NYU SH\n- Theodore Lee, Chief Information Officer (CIO) and Special Advisor to the COO for Strategic Initiatives, NYU\n- April Hathcock, Associate Dean for Open Knowledge and Faculty Affairs, Libraries\n- Don Welch, Vice President, Information Technology and Global Chief Information Officer, IT\n- MJ Knoll-Finn, Senior Vice President for Global Enrollment, Student Success, and Strategic Positioning, GEMSS\n- Andrea Hernandez, AI Governance and Strategy Director, President’s Office\n- Kristie Patten, Counselor to the President, President’s Office\n- Jennifer Sparrow, Associate Vice President, Research and Instructional Technology and Chief Academic Technology Officer, IT\n- Clay Shirky, Vice Provost for AI and Technology in Education, Provost\n\nFor any questions please contact: [AILC@nyu.edu].\n\n--\n\nBack to top\n\n---\n\n#### IT Support\n\nNYU IT Service Desk is available 24x7. Please email if not urgent.\n\n[NYU Support Center] \n\n[Support & Request Form] \n\n[Global Contact Info] \n\n[NYU IT Feedback] \n\n[IT Service Status] \n\n[Report a Cybersecurity Issue] \n\n[Student Technology Centers]",
    "length": 2787,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University generative AI policy",
    "title": "NYU Generative AI (GenAI) Services",
    "url": "https://www.nyu.edu/life/information-technology/artificial-intelligence-at-nyu/generative-ai-services.html",
    "text": "# NYU Generative AI (GenAI) Services\n\n## NYU’s GenAI Services\n\nNYU provides access to and support for several generative AI (GenAI) services. Select a service to learn more below and check back to this page periodically for new information.\n\n[**Google Gemini**] \n\n[**Google NotebookLM**] \n\n[**NYU Private GenAI Service (Pilot)**] \n\n## Guidance on the Use of GenAI at NYU\n\n[Teaching with Generative AI] \n\n[Student Learning with Generative AI] \n\n[Academic Integrity for Students at NYU] \n\n## About Google Gemini\n\nGoogle Gemini is a GenAI chatbot that can be used to create new content, streamline repetitive tasks, assist with communications, and more. Currently, Gemini is part of NYU Google Workspace Services but used as a standalone tool and not integrated directly into NYU Google apps such as Email and Docs. Gemini is available at [gemini.google.com] or via the Google App Launcher menu at the top right of most Google apps.\n\n### About Data Privacy in Gemini\n\nWhen you’re logged into Gemini with your NYU NetID account, Gemini never trains its AI model on your data. While it will save your past queries and Gemini's results, they are only available to you, and you can delete them at any time, ensuring your data remains private to you. Explore the resources in the section below if you’d like to better understand the terms of service, which have been vetted by NYU’s Office of Global Counsel.\n\nMore About Data Privacy in Gemini\n\nGemini is a “ [Core Service] ” under NYU’s Google Workspace for Education agreement, and its use is covered by both the [Terms of Use for NYU Google Workspace Services]  and the [Google Workspace for Education Terms of Service]. Its use is not subject to Google data mining, AI model training, or advertising.\n\nYou should use Gemini as you would NYU Google Drive/Email with regard to Data Privacy & Security Classification. Refer to the [Electronic Data and System Risk Classification Policy] to determine your data risk classification.\n\n### Who Uses Gemini?\n\nNYU faculty, staff, and students who want to use a generative AI chatbot to create content, streamline repetitive tasks, assist with communications, and more.\n\n### Locations Offered\n\nAll NYU locations\n\n### How to Request This Service\n\nGemini is automatically available to all eligible NYU community members by logging in with their NYU NetID and password at [gemini.google.com]  or via the Google App Launcher menu at the top right of most Google apps.\n\n### Support Resources\n\n##### **NYU Support**\n\n- [Google Gemini and NotebookLM AI Fact Sheet] \n- [Artificial Intelligence at NYU]  (general AI resources for the NYU community)\n- [NYU Google Services Support] \n\n##### **Google Support**\n\n- [Gemini FAQ] \n- [30+ ways to use Gemini in education]  (Google Slides)\n\n### Support and Request Form\n\n- [Submit a Gemini question in the NYU Support Center] \n\n## About Google NotebookLM\n\nNotebookLM is a personalized research assistant. You can upload various file types to the tool, ask questions about those files, receive answers with cited sources, and produce outputs such as summaries, briefing docs, timelines, FAQs, study guides, and audio overviews. Currently, NotebookLM is part of NYU Google Workspace Services but used as a standalone tool and not integrated directly into NYU Google apps such as Email and Docs. NotebookLM is available at [notebooklm.google.com].\n\n### About Data Privacy in NotebookLM\n\nWhen you’re logged into NotebookLM with your NYU NetID account, NotebookLM never trains its AI model on your data. While it will save your past queries and NotebookLM's results, they are only available to you, and you can delete them at any time, ensuring your data remains private to you. Explore the resources in the section below if you’d like to better understand the terms of service, which have been vetted by NYU’s Office of Global Counsel.\n\nMore About Data Privacy in NotebookLM\n\nNotebookLM is an “ [Additional Service] ” under NYU’s Google Workspace for Education agreement, and its use operates under the [Google Terms of Service]  and the [Google Privacy Policy]. Uploads, queries and the tool’s responses will not be reviewed by humans or used to train AI models.\n\nYou should use NotebookLM as you would NYU Google Drive/Email with regard to Data Privacy & Security Classification. Refer to the [Electronic Data and System Risk Classification Policy]  to determine your data risk classification.\n\n### Who Uses NotebookLM?\n\nNYU faculty, staff, and students who want to use an AI-powered collaborator to gain personalized insights into source files they upload, refine and organize their ideas, and produce content including audio and text summaries, FAQs, and more.\n\n### Locations Offered\n\nAll NYU locations except NYU Shanghai. NotebookLM is currently unavailable from NYU Shanghai as China is not yet a [Google-supported region].\n\n### How to Request This Service\n\nNotebookLM is automatically available to all eligible NYU community members by logging in with their NYU NetID and password at [notebooklm.google].\n\n### Support Resources\n\n##### **NYU Support**\n\n- [Google Gemini and NotebookLM AI Fact Sheet] \n- [Teaching with Generative AI] \n- [Student Learning with Generative AI] \n- [Artificial Intelligence at NYU]  (general AI resources for the NYU community)\n- [NYU Google Services Support] \n\n##### **Google Support**\n\n- [NotebookLM Help] \n\n### Support and Request Form\n\n- [Submit a NotebookLM question in the NYU Support Center] \n\n## About the NYU Private GenAI Service (Pilot)\n\nThe NYU Private GenAI service is free to use but [requires University approval]. Any information entered into the NYU Private GenAI model is governed by [NYU’s data privacy policy].\n\n### Who Uses the NYU Private GenAI Service?\n\nNYU researchers who have a clear use case related to research that can’t be achieved using Google Gemini and/or NotebookLM (see above).\n\n### Locations Offered\n\nAll NYU locations\n\n### How to Request This Service\n\nResearchers interested in this service should [**complete this request form**]. Once a request is submitted, project participants are notified by email within seven business days regarding next steps. The response may include additional questions to help scope out the project, approval access to tools, a requirement to sign a data use agreement, and other relevant items to best understand the project requirements.\n\n### Support and Request Forms\n\n- To request **access** to the NYU Private GenAI Service, [complete this request form].\n- To ask a **question** about about the NYU Private GenAI Service, [submit this support form in the NYU Support Center]  or email [genai-support@nyu.edu]",
    "length": 6630,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University generative AI policy",
    "title": "Statement on Generative AI - College of Arts & Science - NYU",
    "url": "https://cas.nyu.edu/ewp/about/statement-on-generative-ai.html",
    "text": "It can be difficult to parse the intellectual and ethical implications of using generative AI writing technologies, particularly when those technologies are ...",
    "length": 160,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University generative AI policy",
    "title": "Generative AI Guidelines for NYU Communicators",
    "url": "https://www.nyu.edu/employees/resources-and-services/media-and-communications/nyu-brand-guidelines/creating-messaging-and-visual-assets/best-practices/generative-ai-guidelines-for-nyu-communicators.html",
    "text": "Generative AI Guidelines for NYU Communicators\n\n# Generative AI Guidelines for NYU Communicators\n\n--\n\nNYU is a world-renowned research institution, and as such, we approach the subject of artificial intelligence (AI) with genuine curiosity. While AI is already incorporated into many communications tools and presents positive opportunities for our community, it is a developing technology that also comes with unique challenges. Using generative AI for marketing communications on NYU’s behalf requires a firm understanding of its use cases and limitations, knowledge of the ethical considerations involved, and most importantly—human oversight.\n\nThe following guidelines are to help NYU communicators leverage generative AI as a tool for effective content generation. Here, the word ‘content’ is used in a broad sense: text, graphics, photography, videos, music, etc. These guidelines do not apply to educational and classroom settings and should not be construed as official NYU policy.\n\nPlease note that because AI technology is advancing quickly, this is a living document that will be updated as best practices evolve.\n\n---\n\n--\n\n### Guiding Principles\n\nGenerative AI tools are “trained on” existing content, and, in response to user input, synthesize new material. Generative AI tools are statistical models that generate responses based on patterns in their training content. Generative AI does not understand the concept of “truth” and, as such, has demonstrated that it can have biases and “hallucinate” i.e. make up facts, and pull information from source data without regard for citations or intellectual property rights. It does not engage with moral or ethical considerations, cannot think critically, and is not a replacement for human imagination or discernment. For these reasons, it is important that NYU communicators stick to these guiding principles when using generative AI tools:\n\n--\n\n#### Human-Centered Activity\n\nGenerative AI tools are just that: tools. They should assist—not replace—the people who make content. The breadth of your communications should never be turned over to AI, but it can support your process. AI is no substitute for the creativity, empathy, and attention to detail practiced by NYU communications professionals, but it can be used to enhance our work.\n\n--\n\n#### Review Everything\n\nWe are ultimately accountable for the content we create. Generative AI tools are statistical models and cannot be regarded as an authority on any topic. Their output is influenced by existing material, and this material can be biased, without context, out-of-date, and incorrect. Generative AI also does not fact-check or reliably take copyright or other intellectual property rights into account. You can, however, ask for citations in your prompts, which we recommend. Regardless of citations, it is critical to review and edit any outputs produced by AI to eliminate bias, fact-check content, and avoid plagiarism.\n\n--\n\n#### Protect Data and Privacy\n\nSome generative AI tools may store what you input and use it in future output(s), and this information also may not be encrypted. Do not input any information that is personal or confidential (yours, NYU’s, or anyone else’s), as this may be in violation of university policy as well as state or federal privacy laws such as FERPA (Family Education Rights and Privacy Act). Some examples of protected information include names, demographic information, birthdays, original ideas and code, etc.\n\nAdditionally, do not input licensed, copyrighted, or proprietary content such as NYU logos or wordmarks.\n\n--\n\n#### Be Transparent\n\nBe forthright when you are using AI-generated content. If you have used AI to meaningfully change an image or other content, consider a citation to that effect, referencing the specific tool you used (e.g. ChatGPT, Open AI, etc.).\n\n---\n\n--\n\n### When to Use AI\n\nAI tools can be especially helpful with tasks like creative brainstorming, taking notes, refining ideas, generating code, formatting text, and editing images. It can also help synthesize information, take first passes at editing content (e.g. to match AP or Chicago styles), or improve SEO. Still, AI tools should never be used as the final source for facts or editing. Instead, they can help save time on routine tasks and provide a jumping-off point for creative ideation. Following are some examples of acceptable and unacceptable ways to incorporate generative AI into content creation and communications.\n\n--\n\n#### Examples of Acceptable Use\n\n--\n\nBrainstorming or creating mood boards:\n\n--\n\nGenerative AI tools can create first draft images or compile pictures and images to use as inspiration.\n\n--\n\nResearch and synthesis:\n\n--\n\nGenerative AI tools can create summaries for quick overviews of new topics. This research must be verified by humans, and is not a substitute for scholarly research. For example, you could use generative AI to quickly summarize news articles about a current event, which could help you decide what to explore in more depth.\n\n--\n\nSearch Engine Optimization (SEO):\n\n--\n\nGenerative AI tools can help you conduct keyword research, report on readability, optimize headlines and subheads, and structure information for better navigability, etc.\n\n--\n\nEditorial help:\n\n--\n\nYou can have generative AI tools take a first pass at editing your content to match Chicago style, AP style, etc. But be aware that it may not be using the most up-to-date versions of these manuals and your content will still need to be read by a person. Generative AI tools can also make suggestions for shortening your content, looking for repeated words or ideas or suggesting more efficient language. All final editorial reviews should be conducted with human oversight before publication: see the NYU [Editorial Guide] for best practices.\n\n--\n\nNote-taking and transcription:\n\n--\n\nGenerative AI tools can help you take notes and transcribe interviews or meetings to save time. The results are imperfect and should not be assumed to be a verbatim transcript. AI-generated transcripts should be carefully reviewed before they are shared for anything more than your personal use and reference.\n\n--\n\nEditing images:\n\n--\n\nGenerative AI can help you augment or enhance an image, like retouching an existing image, cleaning up a grainy image, or expanding an image (e.g. adding extra sky to the top of a photograph to adjust the aspect ratio). People, places, and other characteristic elements that tell the NYU story should not be generated by AI for the reasons stated above. Adhere to existing best practices for photo editing and stay true to the goal of presenting factual information.\n\n--\n\nCreating abstract imagery:\n\n--\n\nGenerative AI can be used to create images (not photographs) that are not intended to be interpreted as portraying reality. After you have created the image, use a web image search tool to make sure it has not been plagiarized from another source. Be transparent and credit the image as AI-generated.\n\n--\n\nCoding:\n\n--\n\nGenerative AI tools can help draft or check basic code used on websites.\n\n--\n\n#### Examples of Unacceptable Use\n\n--\n\nCreating photographs or photorealistic images:\n\n--\n\nNYU communications should not use photographs or photorealistic images that have been created entirely by AI, especially if they have human subjects or identifiable university content. AI can be used to edit real images but not to create images. See “Additional Considerations When Creating Photography, Video, and Audio” below for more guidelines\n\n--\n\nTranslation:\n\n--\n\nGenerative AI tools are not yet accurate enough to rely on for translation.\n\n--\n\nCaptions:\n\n--\n\nAI-generated captions may not be accurate or meet our digital accessibility requirements.\n\n--\n\nSensitive, urgent, or private content:\n\n--\n\nCommunications that are sensitive, urgent, or require protected or personal information should not be created using generative AI tools. They should be created by professionals who are authorities on the subject matter, aware of the clarity and empathy these communications require, and mindful of protecting personal information.\n\n--\n\nAuthored content:\n\n--\n\nAny content with a byline should be the original work of the author.\n\n---\n\n--\n\n### Additional Considerations When Creating Photography, Video, and Audio\n\nExercise caution when using AI tools. For example, using an AI voice-over tool for a training video is acceptable, but using AI to generate the voices of any NYU community member or guest, be it a specific individual or a generic one, is misleading. If an AI script or narration is used, it should be reviewed carefully and disclosed.\n\nAI should not be used to create sound bites or quotes by people who speak in videos. Inputting a real person’s voice into an AI tool endangers that person’s privacy and can be a security risk. This is because the recorded voice of a real person can be used to generate unlimited audio files that recreate the sound of the actual person’s voice saying anything and not just what the person said in the recording.\n\nAI-generated music may be appropriate in videos but can very easily infringe on copyrighted material, even if the AI tool uses only a portion of the material. The same is true of photography and art. Consider other human-generated resources first, including royalty-free music.\n\nAs stated above, use generative AI to help brainstorm or enhance but not to create the final product.\n\nAlways carefully review AI-generated work. Since AI tools pull from numerous sources, consider whether the AI-generated work is reasonably similar to existing work.\n\n--\n\n### Other Considerations\n\nIt is important to know that search engines like Google can detect AI-generated content. While this will not necessarily harm your web page’s search rankings at this time, search engine companies constantly change their algorithms, and experts offer conflicting information about whether AI-generated content will or will not be favored. What has been constant",
    "length": 9989,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University generative AI policy",
    "title": "Generative AI Tools for Academic Research - Generative AI Tools for Academic Research - Research Guides at New York University",
    "url": "https://guides.nyu.edu/ai-tools",
    "text": "Generative AI Tools for Academic Research - Generative AI Tools for Academic Research - Research Guides at New York University Skip to Main Content\n\nSearch\n\n# Generative AI Tools for Academic Research\n\nSupport for critical approaches to GenAI tools for academic research.\n\n## Welcome\n\nThis guide is intended to support researchers as they navigate the emergent landscape of generative artificial intelligence (GenAI) applications that are marketed to students and educators as effective tools for academic research. Resources are mentioned here for informational purposes only; their inclusion is not an endorsement or recommendation of their use by NYU or NYU Libraries. We encourage you to think critically about each tool that you use including how it was created, what it does, how you use it, and how it interacts with the rest of your research materials and processes.\n\nGenAI tools are not a substitute for learning the fundamentals of conducting research. As you start your project, take a look at our related research guides for help with your research process, including:\n\n- [Academic Integrity for Students at NYU Policy] \n- [Plagarism (Plagiarism and How to Avoid It)] \n- [Proper citation (Citation Style Guide)] \n- [How to organize your sources (Zotero)] \n- [How to craft a research question (First-Year Writing Seminar)] \n\n## Generative AI for Academic Research in Practice\n\nAcademic research is the exploration, evaluation, collection, organization, analysis, and synthesis of sources and materials in support of a scholarly argument.\n\nSome GenAI tools can be useful for tasks such as brainstorming, for discovering new terms and unexpected connections between ideas, and writing code, but every output generated by AI must be independently verified. Verification may require different skills depending on the output e.g. evaluating the accuracy of statements, running code without errors, identifying positive or negative bias, or confirming that a citation or cited source really exists, et al..\n\nAny use and/or the transparency of use of GenAI tools must align with the guidelines set forth by your institution and instructors or evaluators.\n\n## Generative AI Tools and Academic Integrity\n\nAs with all tools and resources, be sure to follow the policies that your institution has put in place to maintain academic integrity.\n\nIf you are a part of the NYU community, [Teaching with Generative AI] provides guidelines that highlight important considerations when it comes to:\n\n- Academic Integrity and AI\n- AI Citation and Acknowledgement\n- Exploring AI\n\nFor more information on Generative AI and academic integrity for academic research see our [Research Guide: Generative AI and Academic Integrity].\n\n## Generative AI Tools: Independent Reviews and Evaluations\n\n[ITHAKA S+R Generative AI Product Tracker] \n\nThe Generative AI Product Tracker is a project of [ITHAKA S+R], a non-profit organization, and documents products that are marketed specifically towards post-secondary faculty and students. Each tool has a short description, key features, comments, and known limitations. The GenAI tool tracker is updated frequently.This list is for informational purposes only and tools listed in this document are not recommended or endorsed by NYU Libraries.\n\n[MIT AI Risk Repository] \n\nMIT maintains a repository of AI risks drawn from a deep-dive into the AI risk literature. The listing includes a “causal taxonomy” for AI risks; a \"domain taxonomy\" for AI risks; and an \"AI Risk Database\" that captures and describes risks extracted from 65 existing frameworks and classifications of AI risk.\n\n[Stanford HAI: Stanford University Human-Centered Artificial Intelligence] \n\nThe Center maintains a [Foundation Model Transparency Index]. Reports, data, individual model ratings, and more are available for free.\n\n## Additional Resources & Foundational Literature on Generative Artificial Intelligence\n\n[A People's Guide to AI: A workbook by Mini Onuoha and Mother Cyborg, published by Allied Media Projects.] \n\nA basic workbook and introduction for foundational GenAi concepts created by the non-profit Allied Media Projects.\n\n[Generative AI Primer: An Accessible overview of Generative AI topics and tools, published by the non-profit Centre for AI (UK).] \n\nAn introduction and overview to Generative AI tools and concepts.\n\n[Models All the Way Down: An introduction and investigation in AI training data sets by Knowing Machines.] \n\nA research project from the non-profit organization Knowing Machines tracing the histories, practices, and politics of how machine learning systems are trained to interpret the world.\n\n[On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? Bender, Emily M. ; Gebru, Timnit ; McMillan-Major, Angelina ; Shmitchell, Shmargaret Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 2021, p.610-62] \n\nA seminal article on the nature of AI and Large Language Models (LLMs)\n\n[He, Ran; Cao, Jie; Tan, Tieniu (2025). \"Generative Artificial Intelligence: A Historical Perspective\". National Science Review.] \n\nA general review of current generative AI applications and a discussion of challenges and potential research directions in GAI technologies.\n\n- [Print Page] \n- URL: https://guides.nyu.edu/ai-tools\n- Last Updated: Dec 2, 2025 5:09 PM\n\n[Author Log-in] \n\n[Report a problem] \n\n[Accessibility]",
    "length": 5382,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University generative AI policy",
    "title": "Teaching with Generative AI",
    "url": "https://www.nyu.edu/faculty/teaching-and-learning-resources/teaching-with-generative-tools.html",
    "text": "# Teaching with Generative AI\n\nStudents and faculty report growing use of generative AI—tools that produce human-like writing (e.g ChatGPT), images (e.g. MidJourney), code (e.g. Microsoft Co-Pilot) and the like. The flexibility of these tools mean that there is no current default for acceptable vs. unacceptable use of these tools in coursework, and student adoption is moving faster than faculty adaptation. Many students are using AI without clear directions from their instructors about which uses are acceptable.\n\n**Faculty should explain to students what is and is not allowed** around AI use in their classes. (We know some faculty believe students are not using AI in their classes. If this is you, we assure you you are wrong.) The Provost’s Office recommends that faculty adopt the following three principles for student use of AI:\n\n1. When a student uses these tools, they should acknowledge that use\n2. The student is responsible for the content and accuracy of any work they submit, however created\n3. Students only learn from productive effort, and should understand how misuse or overuse of AI threatens that effort\n\nIn order to help students understand these things, we recommend that instructors:\n\n- [Explain your AI policy in your syllabus], and discuss the reasons you adopted it in class\n- Be specific about Dos and Don’ts—“Do acknowledge and describe any AI use”, or “Don’t use any AI for anything other than suggesting topics and sources”\n- Explain the [limitations of generative AI].\n- Remember that students generally want to learn, and explain to them what they can learn from doing the work, not just the potential punishments for cheating\n\nAdditional details can be found in the [AI FAQ] and in [Adapting Assignments to AI].\n\n### Academic Integrity and Generative AI\n\nWith AI being integrated into a wide range of student work, there is no longer any obvious line dividing acceptable from unacceptable use. Using AI to generate ideas, our outlines, or drafts to be edited might be allowed (or even required) for an assignment or it might be forbidden. There is no way for a student to know which it is without guidance.\n\nToo often, academic integrity is presented as a list of behaviors to avoid. We need to present academic integrity as a positive virtue, a description of the conditions necessary for students to learn. The best long-term strategy is to design courses to have more, lower-stakes assessments that offer rapid feedback and an opportunity to make incremental progress on an assignment. Even with course designed around those principles, however, there may be students who use AI in ways that violate faculty requirements.\n\nDetecting and adjudicating inappropriate use of generative AI is harder than detecting simple cut and pasting from public sources. Every student now has no-cost access to a service that can answer a question or write an essay for them; the familiar paid essay writing services are now effectively ubiquitous and free. Intervening when an instructor suspects AI misuse relies far more on the instructor’s judgment about the student’s capabilities than when the source material exists online or in a database.\n\nIf an instructor suspects a student of an academic integrity violation:\n\n- Document reasons for believing the writing is not the student’s own. Possible evidence includes:\n - **Internal Patterns:** Grammatical perfection, consistent but bland style, sudden changes in style or tone, vague or unsubstantiated claims, spurious or incorrect references, and list structures masquerading as development of an idea.\n - **External Patterns:** Writing does not match a student's previous work  (particularly work produced in class), lack of rough drafts or evidence of editing, footnotes or references not related to the body of the text, footnotes or references pointing to work that does not exist.\n- Ask the student if they used generative AI on the assignment in inappropriate or unacknowledged ways, given the evidence. One possible response if they say Yes (and if it is in line with your school’s policies) is to require them to redo the work, providing evidence of editing\n- If they deny using these tools but you continue to suspect that they used them, involve your school administration.\n\nWhile there are a number of products that purport to positively identify AI-generated writing, they have high error rates, especially for students for whom English is an additional language. NYU does not license or endorse use of any of these tools.\n\n* * *\n\n#### A Curated List of AI Resources\n\n- [nyu.edu/ai] \n - [Private Generative AI Pilot] \n- Office of the Provost:\n - [NYU Teaching and Learning with AI]  (web page)\n - [Adapting Writing Assignments to Generative AI]  (Google Doc)\n - [Generative AI Primer]   (Google Slides)\n - [Hands-On with ChatGPT]  (Google Slides)\n - [(Re)designing Assignments & Assessments]  (Google Slides)\n- NYU Schools\n - Abu Dhabi's Hilary Ballon Center for Teaching and Learning: [Teaching with Generative AI]  (NYU Stream)\n - Arts and Science [Getting Started with Generative AI for Instructors]  (Brightspace course open to all NYU Instructors.)\n - Steinhardt\n\n\n - [AI: Creating Prompts with AI]  (web page)\n - [AI: Class Policies]  (web page)\n - [AI: Tips for Writing Assignments]  (web page)\n - [Stern]  (website)\n - Tisch:\n - [Game Center AI Policy]  (web page)\n- NYU Libraries\n - [Evaluating and Acknowledging AI-Generated Text]  (Slides)\n - [Understanding ChatGPT and the Concept of AI Language Generators]  (website)\n - [Machines and Society (NYU Shanghai Library)]  (website)\n\n[⌃ back to top]",
    "length": 5601,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University generative AI policy",
    "title": "Generative AI – A&S Office of Teaching Excellence and Innovation",
    "url": "https://wp.nyu.edu/fas-edtech/category/generative-ai/",
    "text": "[![]] \n\n[Skip to content] \n\nAs Generative AI continues to present a challenge for traditional teaching and learning practices, many faculty are expressing curiosity about alternative grading, a term that includes several forms of assessment (such as contract grading or standards-based grading) where course grades are determined by students’ effort over time rather than by their performance on individual assessments. \\[…\\]\n\nDo you want to see for yourself the most common ways your students are using generative AI—to summarize assigned texts, to edit or translate their written work, and to generate ideas for assignments? Do you want to test out generative AI’s capabilities and think critically about its potential uses and shortcomings with colleagues? Our office \\[…\\]\n\nThe pilot Jterm Foundations of Research Computing (FORC) mini-camp, aka Flash FORC, was a resounding success! More than 40 graduate students gathered in Bobst Library on January 16, 2025 to explore the potential of Generative AI as a research tool. The FORC program is a joint offering of NYU Data Services (NYU Libraries and IT), \\[…\\]\n\nNYU Data Services (NYU Libraries and IT), the Graduate School of Arts & Science Master’s College, and the Arts & Sciences Office of Teaching Excellence and Innovation are excited to launch a new extension of the Foundations of Research Computing (FORC) Camp training opportunity for graduate students! Given the strong interest in data skills development \\[…\\]\n\nWhile the landscape of teaching in higher education is always changing, the disruption brought on by the availability of Generative AI can leave many instructors feeling overwhelmed and unsure of where to start. For those of you who missed it, the Office of the Provost offered a series of Generative AI workshops in August of \\[…\\]\n\nAs we begin another semester and set expectations with our students, it’s important to include our expectations for generative AI use in our syllabi and initial course discussions. Your approach is dependent upon your context, including your discipline, course, student cohort, or the learning outcomes you have set for a particular assignment. For some, generative \\[…\\]\n\nGenerative AI continues to fill headlines and occupy conference agendas and, although the landscape of education continuously evolves, the impact of generative AI seems to be causing a particular shock for institutions.  In an effort to provide faculty with the foundational knowledge they need to begin exploring the limitations and possibilities of such tools in \\[…\\]\n\nWe had a great time hosting our watch party for NYU’s Teaching & Learning with Generative AI Virtual Conference! The LaGuardia Student Technology Center graciously hosted our event and the set-up was perfect. Cozy chairs surrounding a big screen fully equipped to join Zoom meetings and conferences. We even had our own camera set-up so \\[…\\]\n\nWidespread access to generative AI tools necessitates revisiting assignments to make them at the very least less vulnerable to breaches of academic integrity, but also to find opportunities to transform them into vehicles for promoting better understanding and critical use of these tools by students. Two things are certain: There is no silver bullet response. \\[…\\]\n\nAs another academic year approaches, we would be hard pressed to find an instructor who hasn’t at least heard of ChatGPT or other Generative AI tools. The widespread availability and use of this technology has caused quite a stir, leading many in the field of Higher Education to reconsider what it means to evaluate student \\[…\\]",
    "length": 3600,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University generative AI policy",
    "title": "Getting Started with Generative AI",
    "url": "https://steinhardt.nyu.edu/faculty-and-staff/academic-affairs/steinhardt-ai-hub/getting-started-generative-ai",
    "text": "Getting Started with Generative AI | NYU Steinhardt[Skip to main content] \n[![Steinhardt School of Culture, Education, and Human Development]] \nSearch\nOpen Main MenuClose Main Menu\n## Search NYU Steinhardt\nSearch\nClose Search\n![Computer] \n# Getting Started with Generative AI\n**AI is transforming education by providing new ways to support teaching and learning**. Instructors can use AI to personalize learning experiences, streamline administrative tasks, and enhance student engagement. This page serves as a starting point for understanding how AI can be integrated into your teaching practice.\n## Teaching with Generative AI\nExplore NYU&#039;s comprehensive FAQ page on teaching with generative AI tools. This resource provides valuable insights and answers to common questions about effectively integrating AI in your classroom, addressing topics like ethical use, academic integrity, and practical applications.\n[Access the FAQ page to get started] \n## **AI Literacy Basics**\nA few essential terms:\n### Artificial Intelligence (AI)\nA branch of computer science focused on creating systems that can perform tasks that would typically require human intelligence, like recognizing patterns, learning from experience, or understanding language. AI has been around for decades. It is utilized in autocorrect, Google Maps, search and recommendation algorithms, and banking, like e-payments, just to name a few.\n### Machine Learning (ML)\nA subset of AI that enables systems to learn and improve from experience.\n### Generative AI (“Gen AI”)\nAI that creates content, such as text or images, based on prompts (e.g., ChatGPT).\n### Large Language Model (LLM)\nA type of generative AI model trained on vast text data to understand and generate human-like language. LLMs, like GPT (Generative Pre-trained Transformer), power many modern AI text tools, like ChatGPT.\n### Prompt\nThe input or question given to a generative AI tool, like ChatGPT, to generate responses. The effectiveness of AI-generated results often depends on the clarity and specificity of the prompt.[Check out this deep dive into Prompt Engineering].\n### Chatbot\nA chatbot is a program that is designed to communicate with people through text or voice commands in a way that mimics human-to-human conversation. When you are engaging with a chatbot, you are not talking to a human.\n### Natural Language Processing (NLP)\nThe umbrella term for any machine’s ability to perform conversational tasks, such as recognizing what is said to it, understanding the intended meaning, and responding intelligibly.\n### Tokens\nTokens are the basic units of text or code that an LLM AI uses to process and generate language. Tokens can be characters, words, subwords, or other segments of text or code, depending on the chosen tokenization method or scheme. Tokens are assigned numerical values or identifiers, and are arranged in sequences or vectors, and are fed into or outputted from the model. Tokens are the building blocks of language for the model.\n## **Guidelines for AI Use and Academic Integrity**\n### Permitted and Prohibited Use Cases\nClearly outline where AI tools are allowed and restricted in your course. For example, AI might be used for brainstorming or initial drafts but should not be used to complete graded assignments independently. Establish boundaries to prevent academic misconduct, ensuring students understand when AI use crosses into prohibited territory, such as generating full essays or solutions.**Note: You may include multiple policy statements in your syllabus to specify when AI tools are permitted or prohibited, depending on the assignment or activity.**\n### Ethical AI Use\nEncourage ethical AI usage, including proper attribution when AI tools contribute to an assignment. Highlight that AI is a*supplement*, not a*substitute*for original work.\n### Sample Policy Statements\n* *General Use*: \"Students may use Generative AI tools for brainstorming, but final submissions should reflect their own work.\"\n* *Prohibited Use*: \"Using Generative AI tools to generate full assignments is considered plagiarism.\"\n* *Attribution*: \"Any AI-generated content used must be acknowledged; failure to disclose may lead to academic consequences.\"### Engaging Students in Ethical AI Use\nConsider starting the semester with discussions on AI’s role in learning, including ethical considerations, to build awareness and foster critical thinking about technology's role in academic work.\n[**For more information about Syllabus and Academic Integrity Support with Generative AI, visit our FAQ.**]",
    "length": 4562,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University generative AI policy",
    "title": "Research Guides: Machines and Society: Generative AI for Research and Creative Use",
    "url": "https://guides.nyu.edu/data/llm-research-creative-use",
    "text": "[Skip to Main Content] \n\n[![Banner]] \n\nSearch this GuideSearch\n\n# Machines and Society\n\nA growing guide on the latest in data-driven research and emerging technologies at the intersection of society, information and technology.\n\n- [Home] \n- [Large Language Models] \n - [What Large Language Models Are] \n - [Technical Overview] \n - [Bias] \n- [Generative AI for Research and Creative Use] \n\n - [Introduction] \n\n - [Overview of ChatGPT] \n - [Generative AI for Data-driven Research] \n - [Generative AI for Application Development] \n - [Generative AI for Visual Design] \n - [Generative AI in Campus Life] \n- [Emerging AI Tools for Teaching and Learning] \n - [Chatbot Quickstarts] \n - [Image Generation Tools] \n - [Setting Up Local Generative AI Tools] \n - [Suggestions for Teaching and Learning] \n - [Citing Generative AI] \n- [Technology and Society] \n - [Copyright, Authorship, and Governance] \n - [Business and Industry] \n- [Computational Social Research] \n - [The Field of Computational Social Science] \n - [Web Mining for Digital Disease Surveillance] \n - [Data Collection with Crowdsourcing Technology] \n\n## Introduction\n\nThis guide provides summaries, examples, and resources of how to use generative AI for scholarly and creative purposes in academic settings. The guide uses ChatGPT as an example to illustrate how AI assistants could be applied in data-driven research, application development, visual design, and solving problems and enhancing productivity in one's life and work.\n\nThis section covers the following topics\n\n- [Overview of ChatGPT] \n- [Generative AI for Data-driven Research] \n- [Generative AI for Application Development] \n- [Generative AI for Visual Design] \n- [Generative AI in Campus Life] \n\n- [<< **Previous:** Bias] \n- [**Next:** Overview of ChatGPT >>] \n\n[Accessibility (opens\\\nin new window)]",
    "length": 1821,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University generative AI policy",
    "title": "Frequently Asked Questions About Teaching and AI",
    "url": "https://www.nyu.edu/faculty/teaching-and-learning-resources/teaching-with-generative-tools/frequently-asked-questions.html",
    "text": "Frequently Asked Questions About Teaching and AI\nMenu[Skip to All NYU Navigation] [Skip to Main Content] \n[NYU] \nSearchSearch SiteAll NYU\n[NYU Home] \n[Login toNYU Home] \nAll NYU\n[NYU] \nSearch Site\n# Frequently Asked Questions About Teaching and AI\n#### **[Generative AI] **\n**[What is generative AI? How can I experiment with it?] \n[How can I experiment with generative AI?] \n[What are some limitations of generative AI use?] \n[What is NYU's policy about student AI use in coursework?] \n[What risks of learning loss can generative AI create?] **\n#### **[Recommendations for Faculty Use of AI] **\n**[What recommendations apply to faculty use of AI?] \n[What are the recommendations around data use?\n] [How should I communicate my preferences for AI use to my students?] \n[When and how can I get access to NYU’s private generative AI service?] **\n#### **[Generative AI Ethics and Responsible Use] **\n[**Academic Integrity and Generative AI\n**] **[What uses of AI constitute cheating?] \n[How should faculty respond to suspected cases of cheating with AI?] \n[Why doesn't NYU license an AI detector?] **\n#### **[Additional Office of the Provost Resources around Generative AI at NYU] **\n**[Conversations at NYU about AI] **\n### **Generative AI\n**\n**What is generative AI? How can I experiment with it?**\nGenerative AI is a label for tools such as ChatGPT,[Gemini],[NotebookLM], or Midjourney, and describes AI services that generate novel responses to prompting by a user. These services create output as a response to prompting by the user, based on training on billions of examples of text, images, code, etc.\nThough there are many types of generative AI, the “large language models” like[Gemini] from Google, ChatGPT from OpenAI; LLaMa from Meta; or Claude from Anthropic, have the widest range of uses in academic settings. These models can generate relevant responses to many kinds of prompts, meaning they can be used—and are being used—in some way or another in most classes. The opportunity is that students use them to explore ideas and test their knowledge. The threat is that students use the tools to opt out of the effort needed for them to learn.\n**How can I experiment with generative AI?**\nNYU now offers access and support for both Google’s[Gemini] and[NotebookLM] to faculty, staff, and students. Learn more about these tools in this[fact sheet] from NYU IT.\nThere are many kinds of generative tools, for creating text, audio, images, video, and code. More recently, more tools are multimodal, producing combined output —text and images, web pages and code —that increase the complexity of what is possible.\nText-generating tools are the most widely used at NYU, and their most notable feature is producing surprisingly competent written responses to relatively complex questions.\nIf you would like to try it, below are sample prompts you can input into[Google’s Gemini].\n* Can you quiz me on the nature of aliphatic compounds?\n* What are some critical tradeoffs in the design and deployment of public transportation in American cities?\n* Can you write a python script that calculates the Fibonacci sequence to the 50th place?\n* Can you write an outline, with opening and closing paragraphs, comparing the work of Mark Rothko and Willem de Kooning?\nIt is possible to use more complex prompts with these tools, by including the role you are asking the model to play (which generally improves the answers), and the question you want a response to. Here are three sample prompts you can use with large language models:\n1. You are a professor of biology, teaching an introductory course. Please write a description of meiosis vs. mitosis, highlighting similarities and differences in the two processes.\n2. You are an art historian of Chinese ceramics. Please describe the technical and aesthetic changes in ceramic production from the Shang Dynasty to the Warring States period.\n3. You are a screenwriter pitching a film. Please write three loglines for science fiction movies where one of the protagonists is not human.\nTrying one or more of these prompts, modifying them, or creating your own will demonstrate the basic capabilities of text-generating tools. It will be especially valuable if you try these tools with material from your own courses. You can also try[image generation],[voice generation],[code generation],[research support], and so on.\nArts and Science has developed a Brightspace course open to all NYU instructors,[Getting Started with Generative AI for Instructors], that provides more in-depth experience with these tools.\n**What are some limitations of generative AI use?**\n* **Random responses**\nRandomness is built in. You'll get a different answer every time even when you use the same prompt.\n* **Trained for plausibility, not accuracy**\nGenerative AI is designed to produce plausible instances (i.e., to make things up). “Hallucination” describes the inclusion of incorrect or invented information in responses to user prompting.\n* **Bias**\n* Generative AI tools are trained from a wide range of sources, so output may follow bias absorbed from those sources. Bias can also take the form of a lack of coverage of particular disciplines, languages, regions, and so on.\n* Generative AI tools have typically been trained on data that tends towards stereotypical answers—“Doctors are men whereas nurses are women” kinds of biases that extend to many circumstances. All users of these tools should be aware that these biases exist and should use their judgment in using or editing the output.\n* **Digital Divide\n**Access is not equitable. There are gaps between who has access and who doesn’t, largely as a result of differences in tools between free and paid tiers of access, and between students who can afford more expensive computers and phones that have AI capabilities built-in, vs. those using cheaper models.\n* **Intellectual Property and Copyright Issues\n**These models are often trained on copyrighted materials, though it is not yet clear whether such training violates copyright law.\n**What is NYU’s policy about student AI use in coursework?**\n1. The instructor approves.\n2. The student abides by any requirements or limitations the instructor may have.\n3. The use does not violate[NYU’s Academic Integrity Policy], which forbids “submitting work (papers, homework assignments, computer programs, experimental results, artwork, etc.) that was created by another, substantially or in whole, as one's own.”\nGenerative AI is a new arrival in the academic environment and can be used in a wide variety of ways. Because of this novelty and flexibility, there are few standard approaches to its use beyond an institution-wide restriction on taking credit for AI output without acknowledging its use. Most policies will be set by the schools or by individual faculty members. Check with your school or department to see if there are local policies.\n**What risks of learning loss can generative AI create?**\n**Using AI can*feel*like learning**. Though much of the public conversation on AI use has focused on cheating, the bigger risk is students using AI because they think it is helping them learn when it is instead replacing the experiences students are meant to learn from. Learning requires effort, and not understanding something can make people feel dumb. Getting an answer from AI quickly and easily is a shortcut that doesn’t feel like one. It is easy to believe that generating an answer or plausible response is the same as creating one.\nOne significant risk is automation bias, which is to say**students may place undue trust in the output**of generative AI tools. These tools have been trained to produce written output that sounds confident and plausible, leading many people to believe that the output is also accurate. Interestingly, failure rates seem to be higher for answers produced in highly structured formats, like journal citations or legal case identifiers. In those cases, large language models can produce references in perfect MLA style to papers that do not exist.\nRelatedly, students should understand that AI tools are**not authoritative sources**. While their output should be acknowledged, they should never be cited as evidence. No matter what tools are used, the student is ultimately responsible for the contents of any work they submit.\n**AI output is opaque without chain-of-thought prompting or tools**, reducing students’ understanding of the process. There is no way for a student (or anyone) to know how an answer was constructed or how a change to a prompt will change the answer without chain-of-thought prompting or tools. There is also no way to produce the same answer in the future, even with an identical prompt. This can limit students’ comprehension of the material.\n### **Recommendations for Faculty Use of AI**\n**\nWhat recommendations apply to faculty use of AI?**\nMost decisions about classroom conduct are left to individual instructors, and faculty use of AI in the design and running of their courses is no exception. Faculty at NYU are experimenting with AI tools to make suggestions or provide feedback on syllabi, assignment prompts, and test questions. However, there are both restrictions and recommendations about such use:\n* The[humans-in-the-loop] principle, meaning that an AI’s operations and output should be subjected to human review before use, is a good one for both faculty and student work.\n* If you use these tools to help develop class materials —explainers, banks of test questions, assignment statements —you should be as alert to the risk of plausible sounding but incorrect suggestions as you expect your students to be.\n* If you use",
    "length": 9650,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University generative AI policy",
    "title": "Generative AI Updates – Live Syllabus and Faculty Development Resources – A&S Office of Teaching Excellence and Innovation",
    "url": "https://wp.nyu.edu/fas-edtech/2024/01/generative-ai-updates-live-syllabus-and-faculty-development-resources/",
    "text": "Generative AI Updates – Live Syllabus and Faculty Development Resources – A&S Office of Teaching Excellence and Innovation\n\nAs we begin another semester and set expectations with our students, it’s important to include our expectations for generative AI use in our syllabi and initial course discussions. Your approach is dependent upon your context, including your discipline, course, student cohort, or the learning outcomes you have set for a particular assignment. For some, generative AI use may be helpful for the brainstorming phase of writing but not be appropriate again until the final draft of written work through the use of tools like grammar checkers. For others, generative AI use may be embedded into the learning process to facilitate critical digital literacy skills. Whatever your approach, clear communication with students about your expectations and your justification for your generative AI use policies should be on your beginning of the semester agenda.\n\nWe know this task is daunting, especially as generative AI technologies continue to improve and their use becomes more widespread. There are a number of resources available to you as you determine what generative AI use policies are appropriate for each of your assignments and courses.\n\nThe following guides provide a wealth of information to inform your course design process.\n\n- [Instructor Generative AI Guide] \n- [Library Generative AI Citation Guide] \n- [Faculty: AI and Coursework at NYU — Frequently Asked Questions] \n\nIf you’d like to learn more of the generative AI basics on your own, you may also be interested in checking out our asynchronous [Getting Started with Generative AI Course on Brightspace]. We will be publishing a second set of units in that course focused on Prompt Engineering soon, so keep an eye out for more opportunities to explore generative AI capabilities and limitations.\n\nFinally, our team is here to support you as you develop a generative AI use policy that fits your context. Contact our team at fas-edtech-group@nyu.edu or use the [Liaison Finder] to find your department’s educational technology specialist to set up a consultation.",
    "length": 2154,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University generative AI policy",
    "title": "Generative AI Tools for Academic Research",
    "url": "https://guides.nyu.edu/ai-tools/discovery",
    "text": "For Discovery - Generative AI Tools for Academic Research - Research Guides at New York University[Skip to Main Content] \n[![NYU Libraries logo.]] \nSearch this GuideSearch\n# Generative AI Tools for Academic Research\nSupport for critical approaches to GenAI tools for academic research.\n* [Generative AI Tools for Academic Research] \n* [For Discovery] \n* [AI Tools for Discovery] \n* [GenAI-enhanced Search Tools] \n* [Chatbots] \n* [Personalized Knowledge Management and Research Organization Tools] \n* [Google Gemini and NotebookLM at NYU] \n* [Citation Chasing and Visualization] \n* [Evaluating AI Tools for Discovery] \n* [Additional Resources] \n* [For Transcription] \n* [For Translation] \n## Related Research Guides\n* [Generative AI and Large Language Models (LLMs)] \n* [Citation Style Guide] \n* [Citation Style Guide: Citing and evaluating AI-Generated text] \n* [Plagiarism and How to Avoid It] \n* [Generative AI and Academic Integrity] \n* [Images and AI in Academic Research] \n* [Media and Misinformation] \n* [AI and Qualitative Research] \n## Subject Librarian\n[\n![] \nRoberta Muñoz\n] \n[Email Me] \n## Subject Librarian\n[\n![] \nCarol Choi\n] \n[Email Me] \n**Subjects:**[Public Policy & Administration],[Urban Planning] \n## Guide Contributors\n* Joshua Eisenstat\n* [Alla Roylance] \n* [Lia Warner] \n## AI Tools for Discovery\nGenAI tools are marketed to perform a number of tasks as part of the academic research workflow including brainstorming, search, summarizing, coding, and more. Evaluating their usefulness starts with an understanding of the tools themselves - how they&rsquo;&rsquo;re built and work - as well as careful validation and human oversight to ensure currency, reliability, authority, purpose (point of view/bias), and truthfulness in conjunction with the time it takes to verify outputs.\n**All search tools that use Generative AI can return misinformation, including fake facts and fabricated citations.**\nBelow is a brief overview of the types of tools/tasks currently available.\n## GenAI-enhanced Search Tools\nThis type of feature has been added to tools you are already familiar with:\n* **Search engines/sites**like Google.com and DuckDuckGo &ldquo;&ldquo;crawl&rdquo;&rdquo; the internet, index pages and match your search terms to priorities such as relevance and currency. Now, the results may also provide an AI-generated summary.\nAI summaries do not appear with every search. These AI features are a separate function powered by large language models and other tools (e.g. Google AI Overview uses Google&rsquo;s Gemini LLM, and is &ldquo;supplemented with aspects of the company&rsquo;s Search system, like the[Knowledge Graph] &rdquo;&rdquo; according to this[May 16, 2024 article in Wired by Reece Rogers]).\n* **Some Library databases**now include generative AI features including search/keyword suggestions, article summaries, suggestions for research questions, and related resources (e.g.[Statista Research AI Assistant],[JSTOR]). These tools use commercial LLMs as underlying infrastructure and use retrieval-augmented generation (RAG) trained on the database&rsquo;&rsquo;s corpus in order to focus the outputs; this allows AI-generated responses to cite sources from within the database only, or to generateoutputs that are relevant to the subject domain of the platform. These features may still generate lies, misinformation, or be misleading and even harmful. Outputs must always be independently verified and evaluated.\nNYU Libraries provides access to approximately 1,500 databases. AI features in these resources are evolving rapidly and we are evaluating them as they develop. If you are unsure about whether a specific NYU Libraries database uses AI or about how this will affect your research process,[contact a librarian].\n**Note:[ProQuest&rsquo;s AI Research Assistant] was evaluated by NYU librarians in December 2024 and was found to be unsuitable for inclusion in NYU Libraries databases. The tool will be re-evaluated and re-considered at a future date.**\n## Chatbots\nChatbots are sometimes referred to as &quot;&quot;answer engines&quot;&quot; (as opposed to search engines). Chatbots generate a synthesized response (output) to a user query (input) based on a probabilistic and statistical algorithm. The responses appear as conversational summaries. Some chatbots have conversational memory and can build and follow-up on questions and queries.\nChatbots can:\n* Have their own platform (e.g. ChatGPT, Claude, Microsoft CoPilot, Perplexity), which can be multi-modal - offering different Gen AI tools on the same platform.\n* Be an add-on/extension (e.g.[Perplexity Chrome extension])\n* Be a feature within a library resource (e.g. Statista Research AI Assistant)\nSome of these tools generate outputs with hyperlinks to sources/citations to help users verify information. Please note that it is still possible for the outputs to include misinformation. Many of these tools do not cite scholarly, academic sources. The number of sources may be limited. The accuracy and relevance of sources must be verified and evaluated.\n## Personalized Knowledge Management and Research Organization Tools\nDigital AI Notebooks and Research Organization tools allow users to upload and query documents that can range from PDFs of articles, bibliographies, citations, links, personal notes, and paper drafts written by the user (e.g.[Elicit],[ChatGPT],[Google NotebookLM]). The tool then provides summaries, suggests connections between the uploaded materials, and/or allows users to generate inputs that &ldquo;query&rdquo; the materials in the form of a chat exchange similar to the tools described above.\nThese tools use RAG AI and results are subject to the same risk of false, synthetic information and confabulations as AI generated tools.\n**Note: Exercise caution when uploading material into these tools as there are privacy and legal concerns to consider.**\n**The materials you upload may include content that should remain private and/or may be subject to restrictive licensing agreements. For instance, PDFs of articles retrieved via NYU Libraries&rsquo; resources are for non-commercial, academic purposes only; some companies reserve the right to add uploaded material to their training data or use for other commercial purposes and/or outputs generated may violate licensed use. It is the responsibility of each user to carefully review the terms of services and related policies.**\n## Google Gemini and NotebookLM at NYU\nAs of February 2025, NYU provides access to Google Gemini and Google NotebookLM to current students, faculty, and staff. The latest information on the NYU instances of these tools including data privacy settings and how to access them can be found via[NYU Generative AI (GenAI) Services].\nConsider both[the note above regarding data privacy and restrictions on uploading NYU library resources] along with the rubric below when integrating these tools into your research workflow.\n## Citation Chasing and Visualization\nCitation chasing is the process of using an article that you have in-hand as a starting point then tracking down other sources connected to that work as you create a literature review (e.g.[Elicit],[Research Rabbit],[Inciteful]). Connections are made via citations (i.e. a paper is cited in or cites a connected paper), shared authors, shared subject matter, etc. Some tools generate a visualization that maps these connections.\n## Evaluating AI Tools for Discovery\nMany researchers select a tool based on what is commonly used by peers in a department or field. As a researcher, it is your responsibility to investigate tools independently. In addition to identifying your own research or accessibility requirements, there are a number of other things to consider.\nThe table below provide a rubric for evaluating AI tools for discovery.|**Criteria**|**Considerations**|\nAccuracy and Verification|GenAI tools are based on statistical probability and predicting text,**not retrieving information**. GenAI has been proven to create responses with false summaries and/or imaginary citations and sources that do not exist. The reliability and authenticity of every piece of information must be independently verified regardless of the GenAI tool(s) you are using.|\nSources/Training Data|\nAre the training data sources transparent? Have the sources and data been ethically sourced?\nWhat are the sources of information the tool draws on or what is the training data (these can be different)? Are the subjects and disciplines relevant to your search included?\nDoes the tool provide verifiable citations in the form of links to information sources? Does it use scholarly databases? Peer-reviewed material? The open web?\n**Note: Confabulations occur even in tools that draw data from verified scholarly datasets or databases.**|\nPrivacy and Data Collection|\nIs the tool cloud-based or run locally on your device? How is data transfer and privacy managed for either?\nHow will your inputs (queries, uploaded files, etc.) be used? Are chatbot conversations, research queries, and personal data**protected**? Will your data be used to train the tool? Are your search queries**archived**or**preserved**, or will they be lost if you stop subscribing to the tool?\n|\nLicensing|Do you have permission to provide your inputs/files to the platform/tool? (seeUpload and Query Documents in the above table)|\nAccess and Equity|\nDoes it cost money to use this tool? If so, how much and how much are you willing/able to pay? Are there different tiers with different fees? Is the tool easy or",
    "length": 9547,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University generative AI policy",
    "title": "NYU Launches Generative AI Resources for Instructors and Researchers",
    "url": "https://www.nyu.edu/research/navigating-research-technology/stories/nyu-launches-resources-for-instructors-exploring-generative-ai.html",
    "text": "NYU Launches Generative AI Resources for Instructors and Researchers\n[![New York University homepage]![New York University homepage]] \nSearch Box\nSearch\nSearch\nAll NYU\nClose\n[] \n[Login to NYU Home] \nGlobal Locations\n* * [New York] \n* [Abu Dhabi] \n* [Shanghai] \n* * [Accra] \n* [Berlin] \n* [Buenos Aires] \n* [Florence] \n* [London] \n* [Los Angeles] \n* [Madrid] \n* [Paris] \n* [Prague] \n* [Sydney] \n* [Tel Aviv] \n* [Tulsa] \n* [Washington DC] \nSchools\n* [Arts and Science] \n* [College of Arts and Science] \n* [Graduate School of Arts and Science] \n* [Liberal Studies] \n* [College of Dentistry] \n* [Courant Institute of Mathematical Sciences] \n* [Gallatin School of Individualized Study] \n* [Grossman School of Medicine] \n* [Institute for the Study of the Ancient World] \n* [Institute of Fine Arts] \n* [Leonard N. Stern School of Business] \n* [Long Island School of Medicine] \n* [Robert F. Wagner Graduate School\nof Public Service] \n* [Rory Meyers College of Nursing] \n* [School of Global Public Health] \n* [School of Law] \n* [School of Professional Studies] \n* [Silver School of Social Work] \n* [Steinhardt School of Culture,\nEducation, and Human Development] \n* [Tandon School of Engineering] \n* [Tisch School of the Arts] \nMenu[Skip to All NYU Navigation] [Skip to Main Content] \n[NYU] \nSearchSearch SiteAll NYU\n[NYU Home] \n[Login toNYU Home] \nAll NYU\n[NYU] \nSearch Site\n# NYU Launches Generative AI Resources for Instructors and Researchers\n## Site includes glossary, resources, and Generative AI pilot\nNYU has been active for many years in areas of artificial intelligence (AI) and machine learning for experimentation and research. The rise in attention to the technology and potential impact of AI and the increase in publicly available AI tools has made discussion around AI a robust topic of conversation in higher education.\nTo help NYU instructors and researchers navigate the fast-evolving AI landscape, NYU Information Technology, in collaboration with the Office of the Provost, has launched a new web resource.[Artificial Intelligence at NYU] contains information to aid the NYU community in making informed decisions about the role AI could play in teaching, learning, research, and work. The new side includes:\n* **[Artificial Intelligence at NYU] info hub**: introduces key AI questions and providing a glossary of terms and links to AI resources at NYU.\n* **[NYU Community Generative AI Tools] **: a guide to the most popular public AI tools, including ChatGPT, Bard, and Bing Chat.\nIf you have any remaining questions or concerns about the use of generative AI for NYU academic or research purposes, or would like to add an AI-related NYU resource to this list, please email[genai-support@nyu.edu].\n**November 2, 2023\n**Keith Allison\n[###### More Research &amp; Instructional Technology Stories\n]",
    "length": 2809,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University generative AI policy",
    "title": "Steinhardt AI Hub",
    "url": "https://steinhardt.nyu.edu/faculty-and-staff/academic-affairs/steinhardt-ai-hub",
    "text": "[Skip to main content] \n\n## Search NYU Steinhardt\n\nSearch\n\nClose Search\n\n# Steinhardt AI Hub\n\n## Artificial Intelligence at NYU Steinhardt\n\nThe Office of Academic Affairs and the Office of Digital Innovation and Learning at NYU Steinhardt are dedicated to supporting the exploration of AI in the college classroom. We provide comprehensive resources and guidance for faculty, students, and staff to enhance teaching, learning, and working with AI technologies.\n\n## [Getting Started with Generative AI] \n\nAI is transforming education by providing new ways to support teaching and learning. This page serves as a starting point for understanding how AI can be integrated into your teaching practice.\n\n[Read More] \n\n## [Academic Integrity and Syllabus Support in the Age of Generative AI] \n\nCreating clear policies around AI use is essential to maintaining academic integrity and setting student expectations. These policies outline how AI tools can be used and ensure students understand the implications of AI in academic work.\n\n[Read More] \n\n## [Enhancing Teaching and Learning with Generative AI] \n\nThis collection offers resources, tools, and best practices to support Steinhardt faculty in integrating AI into their courses, enhancing teaching effectiveness, and fostering student engagement.\n\n[Read More] \n\n## Watch the Recordings! Steinhardt AI Workshop Series\n\n**Thank you for joining our 2024 AI Workshop Series!** Throughout the series, we delved into how AI can be integrated into education and professional practice. Our sessions covered various topics, including using AI for student writing, enhancing feedback, differentiating instruction with GPTs, applying AI in research and clinical simulations, overcoming creative blocks, and exploring AI in music creation.\n\nIf you missed any of our workshops, don’t worry—you can still access the recordings and presentation materials to further explore and apply AI in your academic and workplace environments!\n\n[View the Recordings and Resources] \n\n## AIAI Board\n\nAs part of our ongoing commitment to fostering innovation and excellence in the field of artificial intelligence (AI) at Steinhardt, we are excited to introduce the establishment of the Steinhardt AI Advisory and Insights (AIAI) Board. This board brings together a diverse group of individuals (faculty, students, and administrators) to provide guidance, offer ideas, and address concerns related to AI within our academic community.\n\nThe faculty who make up the AIAI Board possess a keen interest in AI and are capable of articulating departmental concerns and ideas effectively.\n\n### Key Responsibilities of AIAI Board Members:\n\n- Provide guidance on AI-related projects and initiatives.\n- Foster interdisciplinary collaboration and communication on AI matters.\n- Act as a conduit for conveying concerns and ideas from their respective departments.\n- Participate in discussions to shape the university and school’s approach to AI education and research.\n\n### 2024-2025 Board Members\n\n- **Anne Washington,** Applied Statistics and Humanities\n- **Carolyn Strom,** Teaching & Learning\n- **Ed Kang,** Media, Culture, & Communications\n- **Emilie Ricco,** Steinhardt Student Affairs\n- **Ethan Balk,** Nutrition & Food Studies\n- **Greg Gao,** Physical Therapy\n- **Jennifer Astuto,** Applied Psychology\n- **Kelsey Cook,** Digital Innvoation and Learning\n- **Kevin McCoy,** Art & Art Professions\n- **Lorena Llosa,** Academic Affairs\n- **Panayotis Mavromatis,** Music and Performing Arts Professions\n- **Sinead Harrington,** Occupational Therapy\n- **Sonakshi Gupta,** USG Representative\n- **Tara McAllister,** Communicative Sciences and Disorders\n- **Vinny Nelson,** GSO representative\n- **Xavier Ochoa,** Administration, Leadership, & Technology\n- **Office of Digital Innovation & Learning,** NYU Steinhardt",
    "length": 3820,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University generative AI policy",
    "title": "Machines and Society",
    "url": "https://guides.nyu.edu/data/ai-governance",
    "text": "Copyright, Authorship, and Governance - Machines and Society - Research Guides at New York University Skip to Main Content\n\nSearch\n\n# Machines and Society\n\nA growing guide on the latest in data-driven research and emerging technologies at the intersection of society, information and technology.\n\n## Copyright Considerations\n\nIntellectual property law across the globe is reckoning with the implications of generative AI for creators of copyrighted works and the artists, programmers, and scholars who would use those works for generative AI outputs. There are many questions implicated, including the copyrightability, authorship and ownership of generative AI outputs; the merits of a fair use defense when using copyrighted works to train AI tools; and what regulations, if any, should be imposed in response to this dramatic shift in technology and society. At this time, there is [not a clear answer] for many of these questions.\n\n## Ownership and Copyrightability of Generative AI Outputs\n\nMost copyright regimes have certain requirements that must be satisfied before protecting a work under copyright, patent, trademark, or other forms of intellectual property law. These requirements may be based on the subject matter of the output; the originality and creativity vested in the work; or a standard of fixation. (In fact, if a prompt given to a generative AI tool satisfies these requirements, it may be eligible for copyright protection itself, even if the resulting output is not).\n\nThese requirements can be found in the text of [§102] of the US Copyright Act (17 USC) and in Chapter I of the [Copyright Law of the People’s Republic of China] (中华人民共和国著作权法)\n\nBeyond this, most copyright regimes have requirements with regards to the authorship of a work in question before conferring copyright protection to a work.\n\n## “AI-generated” versus “AI-assisted” Outputs\n\nThe answer to questions about ownership and authorship of AI works under patent, trademark, and copyright laws will vary across jurisdictions and whether the work is “AI-generated” or “AI-assisted”. The World Intellectual Property Organization (WIPO) Secretariat offers definitions in paragraph 12 of the Revised Statement on Intellectual Property Policy and Artificial Intelligence ([WIPO/IP/AI/2/GE/20/1 Rev.]):\n\n“AI-generated” and “generated autonomously by AI” are terms that are used interchangeably and refer to the generation of an output by AI without human intervention. In this scenario, AI can change its behavior during operation to respond to unanticipated information or events. This is to be distinguished from “AI-assisted” outputs that are generated with material human intervention and/or direction.\n\nWhen considering if your AI-generated or AI-assisted output is copyrightable, expert legal advice should be sought.\n\nIn the United States, authors of a copyrighted work must be human: the 9th Court of Appeals affirmed in [Naruto v. David Slater et al.] (2016) that non-human animals lack statutory standing for protection under the Copyright Act, and the US Copyright Office has refused to register AI-generated works produced autonomously without human involvement. However, in [Copyright Registration Guidance for Works Containing AI-Generated Material], the Office distinguishes between works that “are the result of “mechanical reproduction” instead of an author’s “own original mental conception, to which [the author] gave visible form.” (Quoting Burrow-Giles v. Sarony).\n\nThe question of protecting AI-generated works has already arisen in the context of Chinese copyright law, as well. The Cyberspace Administration of China (CAC, 国家互联网信息办公室) is [drafting measures] for the management and regulation of generative AI systems, [open for public comment until 10 May 2023].\n\nIn 2019, the Nanshan District People’s Court in Shenzhen drew a distinction between “AI-generated” and “AI-assisted” outputs in [Shenzhen Tencent v. Shanghai Yingxun] (you can read the full text of the court’s decision [here], though you’ll need to register with a phone number first). The Court granted copyright protection to the works in question, determining that the content generated were written works (a copyrightable subject matter) and that the creative team was sufficiently involved in the input, selection, arrangement, and other intellectual activities that the works were original and creative enough to be ultimately the product of human authorship.\n\n## Fair Use and Exclusive Rights\n\nWhen using emerging tools for generative AI projects, researchers, artists, programmers, and others should consider the expertise of legal counsel in guiding their use of training data ethically, as well as protecting the outputs of those tools.\n\nAlthough scraping content to create datasets may often be considered an example of \"fair use\" in US copyright law, that does not mean that all generative AI projects will fall within the ambit of this exception. Claiming a fair use defense for any generative AI project will need to be assessed on the facts of that specific instance using the [four-factor test].\n\nData and materials used to train generative AI tools may themselves be copyrighted and protected by both property and personality (or \"moral\") rights. In recent years, owners of copyrighted works have demonstrated a willingness to challenge the unauthorized use of their intellectual properties.\n\nIn 2021 the estate of artist Pablo Picasso invoked the author’s [moral right to disclose a work] to demand that his works not be used without permission for generative AI artworks.\n\nIn 2023, multiple lawsuits were brought against unauthorized uses of artworks for training generative AI tools and producing new visual works. In the United Kingdom, [Getty Images] filed a complaint against Stability AI with the High Court of Justice in London. Getty argues that they offer licenses for uses such as these, and that when Stability AI ignored these viable licensing options Getty’s copyright was infringed. In the United States, a class action lawsuit was filed on behalf of three artists against Stability AI and others. Counsel for the plaintiffs does not mince words, likening Stability AI to “a par­a­site that, if allowed to pro­lif­er­ate, will cause irrepara­ble harm to artists, now and in the future.” You can view the complaint & exhibits from the plaintiffs [here]. Thus, it is not clear-cut that using existing copyrighted works to train generative AI tools will be covered by a fair use (or similar) defense.\n\n## Contact and Support\n\nFor Research Support Contact Caitlin MacKenzie Mannion Head of Reference & Instruction Services and Librarian for the Arts & Humanities Email: shanghai.librarian@nyu.edu Book an appointment: https://nyu-shanghai.libcal.com/appointments/CMKM\n\nThe library is unable to provide legal advice or guidance. If you have specific questions about your project’s compliance with local IP Law, please seek official legal counsel.\n\nNYU Shanghai community members may also contact the University’s office of Legal Compliance.\n\n- [Print Page] \n- URL: https://guides.nyu.edu/data\n- Last Updated: Aug 28, 2025 1:28 AM\n\n[Author Log-in] \n\n[Report a problem] \n\nSubjects: [Data Science], [Multidisciplinary], [Social Sciences], [Technology] \n\nTags: [artificial intelligence], [computational research], [computing], [data], [information technology] \n\n[Accessibility]",
    "length": 7375,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University AI policy academic integrity",
    "title": "Academic Integrity and Syllabus Support in the Age of Generative AI",
    "url": "https://steinhardt.nyu.edu/faculty-and-staff/academic-affairs/steinhardt-ai-hub/academic-integrity-and-syllabus-support-age",
    "text": "Academic Integrity and Syllabus Support | NYU Steinhardt[Skip to main content] \n[![Steinhardt School of Culture, Education, and Human Development]] \nSearch\nOpen Main MenuClose Main Menu\n## Search NYU Steinhardt\nSearch\nClose Search\n![NYU building with University flag] \n# Academic Integrity and Syllabus Support in the Age of Generative AI\nCreating clear policies around AI use is essential to maintaining academic integrity and setting student expectations. These policies should outline when and how AI tools like ChatGPT, Perplexity.ai, or Grammarly can be used and ensure students understand the ethical implications of AI in academic work.\nIf you’re interested,[check out this AI Chatbot we created] that can provide you with sample syllabus statements based on your unique course information and preferences.\n## Considerations for AI Policy Creation\n### Permitted Use Cases\nClearly define what AI tools can be used for in your course (e.g., brainstorming, idea generation, or drafting) and where they are prohibited (e.g., completing graded assignments without supervision).\n**Example Policy Statement:***\"Students may use AI tools like ChatGPT for initial idea generation and draft creation, but final submissions must reflect the student's original thoughts and revisions.\"*\n### Prohibited Use Cases\nEstablish boundaries for AI use to prevent academic misconduct, such as using AI to generate full essays or solutions to homework problems.\n**Example Policy Statement:***\"Using AI tools to generate any work is considered plagiarism and will result in disciplinary action.\"*\n### Ethical AI Use\nInclude guidelines on ethical AI usage, including proper attribution when AI-generated content is used in assignments.\n**Example Policy Statement:***\"Any AI-generated content used in assignments must be properly attributed. Failure to disclose AI assistance may result in plagiarism charges.\"*\n## AI Syllabus Statement Templates\nTo help streamline the process of adding AI policies to your syllabus, here are templates and examples that can be adapted for your course. These templates ensure students are fully informed about when AI can be used and how to properly acknowledge AI-generated content. Remember that you can establish different AI policies for each assignment, depending on how you want the tools to be used (or not used). Just make sure to clearly communicate this decision to your students.\n### General AI Use Template\n* \"AI tools, such as ChatGPT or Grammarly, may be used for brainstorming or refining ideas, but all work submitted must be your own. If AI assistance is used in drafting, please include a note explaining how the tool was used.\"\n* \"AI tools, such as DALL-E or MidJourney, may be used for brainstorming or idea generation in art projects, but the student must create and refine all final artwork. If AI tools are used in any part of the creative process, students must disclose their role and provide a written reflection or recorded demonstration about how AI contributed to their creative decisions.\"\n* \"AI tools, such as AIVA or Amper Music, may be used for generating initial musical ideas or experimenting with different styles. However, students are required to modify and develop their compositions independently. Any AI-generated musical elements must be disclosed, and students must provide a written reflection on how they used AI in their compositional process.\"\n### AI in Writing and Research Assignments\n* \"Students may use AI tools to help with research, but all final written content must be original. Cite all sources, including AI-generated suggestions, where appropriate.\"\n* \"AI tools can be used to assist in music analysis or transcription tasks, such as identifying chord progressions or analyzing harmonic structures. However, students must critically evaluate AI output and include their own insights. AI tools must not be used to bypass critical analysis and understanding.\"\n### AI in Group Projects\n* \"In group work, AI can be used as a collaborative tool for idea generation or outlining, but students must document the specific AI tool used and how it contributed to the project.\"\n* \"AI tools can be used to assist in collaborative art projects for idea generation or visual research. However, the final artwork must be original and primarily created by students. All AI-generated concepts or visuals must be properly credited and documented in the project submission.\"\n### Templates for Reflecting on AI Use in Art &amp; Music\n* \"If AI tools are used during the creative process, students must include a 1-2 page reflection outlining how the AI contributed to their project, the specific tools used, and how they adapted or refined the AI-generated content to fit their vision.\n* If art or music-based, “The reflection should also address the ethical implications of using AI in creative arts.\"\n## Engaging Students in AI Policy Discussions\nTo foster a better understanding of AI’s role in education, engage students early in conversations about how AI should be used in academic work. These discussions can help students grasp the ethical responsibilities and critical thinking skills required to effectively and responsibly use AI.\n[] \n* [### Classroom Discussions\n] \n* [### Reflection Assignments\n] [] \nStart the semester with an open discussion on using AI tools, including the ethical implications and expectations for proper use.\n#### Discussion Prompts\n\"How do you think AI will impact your learning experience? What are the potential risks and benefits?\"\n“How do you think AI should be used in our classroom? How can we establish agreed-upon norms for AI usage?”\n[**Discussion Guide**(NetID Login Required)] \nAssign students a reflection on how AI may assist them in their work and the importance of critical thinking beyond relying on AI-generated responses.\n#### Example Assignments\n\"Write a reflection on how you used AI for your project and explain how it influenced your thinking process.\"\n“Reflect on how relying on AI may have influenced your problem-solving approach and identify any gaps in understanding that could arise from over-reliance on AI-generated outputs.”\n## Privacy and Data Security Considerations\nWhen using AI tools, it’s essential to consider privacy and data security. Do not share work containing student identifiers with any third-party services—no student names or other unique identifiers like NetID or N-numbers. Sharing such identifiers with services like ChatGPT or Google Gemini violates the Federal Educational Records Privacy Act (FERPA), which mandates careful handling of student records and restricts their disclosure to third parties. Sharing data that identifies students with tools that NYU has not licensed will never be FERPA-compliant, as FERPA requires the institution to have a specific sort of business relationship. ([NYU’s Academic Integrity for Students at NYU].)\n## Addressing Academic Integrity Concerns\nWith the rise of AI tools like ChatGPT and other generative AI applications, concerns about academic integrity have become increasingly relevant. As AI becomes more integrated into the educational experience here at NYU Steinhardt, both faculty and students must navigate the fine line between appropriate use and academic dishonesty. Clear guidelines are necessary to help students understand when and how AI can be used responsibly.\nIf you suspect a violation, follow NYU Steinhardt’s policy on[reporting an academic integrity violation].\nKey strategies to address academic integrity concerns include:\n* **Establishing Clear AI Use Policies:**Instructors must create explicit policies outlining when AI tools can be used and what constitutes misuse. For example, using AI for initial drafts may be allowed, but passing off fully AI-generated work as one's own without modification or attribution is not.\n* **Promoting Critical Thinking:**Instead of banning AI, educators should focus on teaching students to use AI as a learning tool while encouraging them to critically evaluate AI-generated content. As AI is reshaping how work is done across industries, it’s essential for educators to adapt and incorporate these changes into their teaching practices, helping students navigate and responsibly engage with AI technologies.\n* **Ethical AI Use:**Educators should emphasize ethical practices, such as proper attribution for AI assistance and transparency about the use of AI in assignments.\n* **Define Plagiarism with AI:**Clarify what constitutes plagiarism when AI tools are involved, such as submitting AI-generated work as your own or failing to attribute AI contributions.### Example\n\"Submitting AI-generated content without proper attribution is considered academic dishonesty and will be subject to disciplinary action.\"\n## Assessments and AI in Academic Integrity\nIntegrating AI considerations into assessments is crucial for maintaining academic integrity and aligning AI use with course objectives. Here are key elements to consider:\n* **Assessment Design**: Design assignments that encourage original thought and critical analysis, minimizing opportunities for academic misconduct. For instance, open-ended questions, reflective responses, and analysis-based projects can make it harder for students to rely solely on AI-generated content.\n* **Clear Guidelines for AI in Assessments**: Specify when and how students can use AI assessment tools. For example, “AI tools can be used for initial research and brainstorming, but the final submission should be your original work.” If AI is prohibited for certain tasks (e.g., producing written essays or solving complex problems), clearly outline this.\n* **Reflective Assessment on AI Use**: Include assignments where students reflect on their use of AI in completing tasks. This can help students critically assess AI’s impact on their learning and ensure that AI is a supplement, not a replacement",
    "length": 9884,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University AI policy academic integrity",
    "title": "Academic Integrity for Students at NYU",
    "url": "https://www.nyu.edu/about/policies-guidelines-compliance/policies-and-guidelines/academic-integrity-for-students-at-nyu.html",
    "text": "Academic Integrity for Students at NYU\nMenu[Skip to All NYU Navigation] [Skip to Main Content] \n[NYU] \nSearchSearch SiteAll NYU\n[NYU Home] \n[Login toNYU Home] \nAll NYU\n[NYU] \nSearch Site\nPolicy# Academic Integrity for Students at NYU\n## Policy Contents\n* [STATEMENT OF POLICY] \n* [To Whom the Policy Applies] \n* [POLICY AND PROCEDURES] \n* [Notes] \n## STATEMENT OF POLICY\n[top] \nThis policy sets forth core principles and standards with respect to academic integrity for students at New York University. Each school at New York University may establish its own detailed supplemental guidelines for academic integrity, consistent with its own culture, and consistent with the University-wide general guidelines described in this document.\n## To Whom the Policy Applies\n[top] \nThis policy applies to all students at NYU.\n## POLICY AND PROCEDURES\n[top] \nAt NYU, a commitment to excellence, fairness, honesty, and respect within and outside the classroom is essential to maintaining the integrity of our community. By accepting membership in this community, students take responsibility for demonstrating these values in their own conduct and for recognizing and supporting these values in others. In turn, these values will create a campus climate that encourages the free exchange of ideas, promotes scholarly excellence through active and creative thought, and allows community members to achieve and be recognized for achieving their highest potential.\nIn pursuing these goals, NYU expects and requires its students to adhere to the highest standards of scholarship, research and academic conduct. Essential to the process of teaching and learning is the periodic assessment of students' academic progress through measures such as papers, examinations, presentations, and other projects. Academic dishonesty compromises the validity of these assessments as well as the relationship of trust within the community.  Students who engage in such behavior will be subject to review and the possible imposition of penalties in accordance with the standards, practices, and procedures of NYU and its colleges and schools. Violations may result in failure on a particular assignment, failure in a course, suspension or expulsion from the University, or other penalties.\nFaculty are expected to guide students in understanding other people's ideas, in developing and clarifying their own thinking, and in using and conscientiously acknowledging resources - an increasingly complex endeavor given the current environment of widely available and continually emerging technologies that can produce text, images, code, video and the like. In addition, students come to NYU from diverse educational contexts and may have understandings regarding academic expectations that differ from those at NYU. NYU values and respects all academic traditions; however, while at NYU, students are expected to adhere to the norms and standards of academic integrity espoused by the NYU community and will be assessed in accordance with these standards. Students should ask their professors for guidance regarding these standards, including where instructor permission might override these definitions, as well as style guide preferences for citation or acknowledgement of sources for assignments in their courses.\nFollowing are examples of behaviors that compromise the academic and intellectual community of NYU. The list is not exhaustive.  Students should consult the websites and guidelines of their individual schools for an extended list of examples and for further clarification.\n1. Plagiarism: Plagiarism is a form of fraud. It involves presenting work without adequate acknowledgement of its source (e.g., another person, your own earlier work, an AI tool, etc.), as though it were one’s own current work. We all stand on the shoulders of others, and we must give credit to the creators of the works that we incorporate into products that we call our own.  Some examples of plagiarism:\n·a sequence of words incorporated without quotation marks\n·an unacknowledged passage paraphrased from another's work\n·the use of ideas or materials from another source as  though it were one’s own\n2. Cheating: deceiving a faculty member or other individual who assess student performance into believing that one’s mastery of a subject or discipline is greater than it is by a range of dishonest methods, including but not limited to:\n·bringing or accessing unauthorized materials during an examination (e.g., notes, books, or other information accessed via cell phones, computers, other technology or any other means)\n·providing assistance to acts of academic misconduct/dishonesty (e.g., sharing copies of exams via cell phones, computers, other technology or any other means, allowing others to copy answers on an exam)\n·submitting the same or substantially similar work in multiple courses, either in the same semester or in a different semester, without the express approval of all  instructors\n·submitting work (papers, homework assignments, computer programs, experimental results, artwork, etc.) that was created by another, substantially or in whole, as one's own\n· submitting answers on an exam that were obtained from the work of another source; or providing answers or assistance to others during an exam\n·submitting evaluations of group members’ work for an assigned group project which misrepresent the work that was performed by another group member\n·altering or forging academic documents, including but not limited to admissions materials, academic records, grade reports, add/drop forms, course registration forms, etc.\n3. Participating in any adverse action against an individual for making a good faith report of prohibited conduct or for participating in any academic integrity proceeding under this policy or the academic policies set forth by the student's NYU School, department, or division.\n4. Any behavior that violates the academic policies set forth by the student’s NYU School, department, or division.\n###### Notes\n[top] \n1. Dates of official enactment and amendments: Aug 1, 2011\n2. History: enacted August 1, 2011, updated May 24, 2024; Last Updated August 25, 2025\n3. Cross References: N/A\n## About This Policy\nEffective DateAug 25, 2025SupersedesMay 24, 2024Issuing AuthorityProvostResponsible OfficerVice Provost for Undergraduate Academic Affairs\nDefinitions\nNone\nRelated Policies\nSchool Policies as found in the[New York University Bulletins]",
    "length": 6445,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University AI policy academic integrity",
    "title": "CDS Academic Integrity Statement and Policy - NYU Center for Data Science",
    "url": "https://cds.nyu.edu/academics/academic-integrity-statement-policy/",
    "text": "[Skip to content] \n\nSearch for:\n\nAll students, faculty, instructional staff, administrators, and individuals involved in the Center for Data Science must follow the academic integrity policies listed below. Academic integrity is a shared responsibility; therefore, all must make a serious commitment to academic integrity. The consequences of violating academic integrity are serious for those involved and for the Center as a whole. Particularly,\n\n- Faculty must define, communicate, and enforce academic integrity and collaboration policies for their courses.\n- Instructional staff must be alert for signs of academic integrity violations and report possible violations to the instructor.\n- Students are expected to adhere to all academic integrity policies. This includes communicating with other students in any way and/or use of any materials or technology not explicitly allowed by the instructor.\n\n[Academic Integrity for Students at NYU] \\| [GSAS Statement on Academic Integrity] \n\n## **Procedures and Policies**\n\nIf an instructor suspects academic dishonesty, the instructor should contact the Director of Graduate Studies and the Director of Academic and Student Affairs. The Director of Academic and Student Affairs will then contact the student and meet with him or her to discuss the incident.\n\nIf an academic integrity violation is determined, penalties are set by the Director of Graduate Studies. Penalties for violations of the academic integrity policy are serious and swift. These penalties include failing the relevant course, having their case referred to GSAS, and termination from the program. All and any of these penalties may be enacted for a first offense.\n\n### [NYU Center for Data Science] \n\n× Close Panel",
    "length": 1734,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University AI policy academic integrity",
    "title": "",
    "url": "https://www.nyu.edu/content/dam/nyu/provost/documents/Academic-Integrity-Policy-Memo.pdf",
    "text": "Office of the Provost\nElmer Holmes Bobst Library\n70 Washington Square South, Room 1221\nNew York, New York 10012-1091\nTelephone: 212 998 3077\nFacsimile: 212 995 3190\ndavid.mclaughlin@nyu.edu\nDavid W. McLaughlin Provost\nMEMORANDUM\nTo: All Deans and Directors\nUniversity Leadership Team\nFrom: David W. McLaughlin, Provost\nRe: University Policy on Academic Integrity for Students at NYU\nDate: August 15, 2011\nI write to bring your attention to the newly developed University-wide policy on Academic\nIntegrity for Students at NYU. This is the first University-wide statement of its kind,\nalthough the Schools have their own policies regarding expectations of academic integrity\namong students. The new policy is a general statement of NYU’s standards regarding\nacademic integrity and is applicable to all students at all NYU schools. The individual\nschool policies further address issues in academic integrity and school-based processes.\nThis policy is the product of the diligent work of many dedicated faculty and administrators\nacross the University. In 2009, I charged the Executive Committee of the Faculty Senators\nCouncil (FSC) with the task of reporting on best practices in assessment in higher\neducation. The recommendations of the Task Force on Best Practices in Student\nPerformance Assessment, chaired by Professor Carol Shoshkes Reiss, then a member of\nthe FSC Executive Committee, were submitted to the University-wide Assessment Council.\nThe Assessment Council, assembled by Vice Provost for Academic Affairs, Jane Tylus,\nand comprised of faculty and administrators from across the University, formulated the\npolicy on Academic Integrity for Students at NYU over the course of this past academic\nyear in consultation with deans, General Counsel, and others.\nThe policy is posted online at:\nwww.nyu.edu/about/policies-guidelines-compliance/policies-and-guidelines/academic\u0002integrity-for-students-at-nyu.html School policies can be accessed by clicking on the\n“Related Policies” link.\nPlease distribute this document as appropriate within your units. In particular, I am asking\nthe Deans and Directors to share this document widely within the Schools, and to ensure\nthat School faculties are aware of the policy. If you have questions about the policy,\nplease contact Michaela Rome, Assistant Vice Provost for Assessment, at\nMichaela.Rome@nyu.edu.",
    "length": 2355,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University AI policy academic integrity",
    "title": "EWP Statement on Academic Integrity",
    "url": "https://cas.nyu.edu/ewp/faq/statement-on-academic-integrity.html",
    "text": "- [Skip to Main] \n\n# EWP Statement on Academic Integrity\n\nAt NYU, you are expected to write in conversation with other thinkers, honoring their words and ideas just as professional scholars do. In our class, you will learn strategies for representing, analyzing and citing the work of others. But ultimately, you are responsible for your academic integrity and for avoiding plagiarism. According to the [College of Arts and Science Honor Code], it is a violation of the integrity of the academic community to “represent the words, works, or ideas of others as \\[your\\] own.” Plagiarism can include using:\n\n-  a phrase, sentence, or passage copied or paraphrased from another writer's work without quotation marks and citation;\n- facts, ideas, or written text gathered or downloaded from the Internet without attribution;\n- a purchased paper or \"research\" from a peer, company or online service;\n- your own writing recycled from a current or previous course;\n- writing that is ghost-written by someone else, like a family member or tutor;\n- text generated or translated by an Artificial Intelligence writing assistance tool and presented as your own.\n\nPlagiarism is a serious academic offense. Final drafts with instances of plagiarism will be downgraded or marked with an F and may result in failure of the course. Further, all cases of plagiarism in EWP courses must be reported to the Director of the Expository Writing Program and the Dean of your college. Disciplinary consequences will range from a warning, to suspension, to expulsion from the university.\n\n### What is Academic Integrity? (and other FAQs)\n\n#### _What is Academic Integrity?_\n\nAcademic integrity, at its most basic level, is being honest, responsible, and clear about where a source’s idea begins and ends, and what your unique response to that idea is. Whether deliberate or accidental, if you are not honest or clear in this manner, you have committed plagiarism, and your doing so may result in your essay being penalized or even your failure of the course.\n\nSee [here] for more on CAS’s and NYU’s policy on Academic Integrity.\n\nWhy this emphasis on who owns ideas? The University can be understood as a vast set of conversations on a wide range of subjects. This conversation cannot advance if you simply repeat someone else’s idea as if it were your own. If everyone did this we would get nowhere. The basic move in academic discourse is learning to distinguish your thinking from that of others. (There’s even a book whose title sums up the whole game we are playing: [They Say, I Say] by Gerald Graff and Cathy Birkenstein.)\n\n#### FAQs:\n\n_**I’ve never written a college paper before, and I’m worried I’ll do it wrong and/or say something stupid. Is it okay if I get help from my parent/sibling/smart friend to help me craft my paper?**_\n\nWhen we’re new to something, it’s natural to seek out tutors to guide us. The Writing Center ( [https://cas.nyu.edu/content/nyu-as/cas/ewp/writing-center.html]) can help you train in three key skills:\n\n1. Active reading. This is the ability to isolate intriguing quotes and ideas in a source and make connections to other sources and ideas.\n\n2. How to foster _your own curiosity_ of those quotes and ideas. This means generating questions you are genuinely invested in ( _What does this quote really mean? Can I explain this complex concept back to myself and others? What happens if I place Idea X against or in conversation with Idea Y?_)\n\n3. How to craft thoughtful, coherent arguments that answer those questions in ways that only you could produce.\n\n\nIf you recruit a friend or family member to help you with such work, there is a danger that they will unintentionally do too much of the active reading/questioning/responding work that is for  you. There is a fine line between helpful collaboration and excessive help, and consultants in the Writing Center will know how to assist you without crossing that line.\n\n_**I wrote something I’m proud of in another class/back in high school. Can I re-use it?**_\n\nWe write to forge new insights for ourselves and our audiences, and so recycling previously-written essays (in their entirety or large sections from them) undermines the purpose of writing in a new situation. It’s normal to revisit work you felt was exploring fertile territory, but discuss with your professor (or a Writing Center consultant) how to develop new ideas from your old writing.\n\n_**I don’t want to plagiarize, but I’m embarrassed that I still don’t fully understand what it means to represent and cite sources ethically, honestly, and responsibly.**_\n\nMany students (and even expert, professional writers!) are unclear about what constitutes plagiarism; intellectual property is not an easy issue to grasp. If in doubt, simply ask your professor. Additionally, Writing Center consultants can clarify the difference between plagiarizing another writer’s idea and borrowing a cited idea in order to respond to it and develop your own line of thought.\n\n_**Is it plagiarism if I change the words/phrasing from a source?**_\n\nIf the core idea came from a source other than you, no amount of re-phrasing the language of that idea makes it yours, so you must cite where you got the idea. If you don’t, this is “patchwriting”--a common form of plagiarism.\n\nSee here for more on “patchwriting”: [https://www.merriam-webster.com/words-at-play/words-were-watching-patchwriting] \n\n_**Is it plagiarism to put an uncited idea in my own writing if I think that idea is common knowledge?**_\n\nThis is tricky. As a newcomer to the university, don’t assume you know what is or isn’t “common knowledge” in the same way that an expert in the field might. Remember that you are writing for a community of diverse readers, and their frames of reference could be very different from yours. Even if you think it is obvious you are alluding to a lyric from a famous pop song, anticipate your reader may not know it, and note the source. When in doubt, cite it.\n\nSee here for more on “common knowledge”: [https://integrity.mit.edu/handbook/citing-your-sources/what-common-knowledge] \n\n_**I put the author’s words in quotes, so I’m done, right?**_\n\nNot quite. Citation is about more than acknowledging that an idea isn’t yours. It also helps your fellow scholars track down the sources that you found helpful. If all you do is put quotes around borrowed words, how could your reader ever find out more about your source if they get curious about it? When looking over your work, ask yourself the following: (1) Will your reader be able to identify where each quote comes from--what writer or source? (2) Does each quoted source have a full companion entry in the Works Cited List? (3) Could your reader track down the exact source using the Works Cited list as their guide?\n\n_**I found a great idea/quote in my notes, but I didn’t keep track of the source. Can I still use it?**_\n\nAs many new scholars learn the hard way, the answer is no. Develop a habit of recording quotes with their author/title. Maybe snap a photo of the book cover/article link/etc., along with the quote. Whenever you use a sourceless idea or quote in your writing, that’s plagiarism.\n\n_**There are so many different citation styles (APA, Chicago, MLA, etc.) Can I use whichever I want?**_\n\nEach subject will have specific requirements. Ask your professor, but all EWP courses  require MLA.\n\n_**What happens if I plagiarize?**_\n\nYour professor will meet with you to discuss the language in question. If the plagiarism is extensive you may fail the course; if it’s less extensive you may be asked to re-write the paper and be marked down. All instances of plagiarism must be reported to the Director of the Expository Writing Program and to the Dean of your college.\n\n**_As long as smart ideas get on the page, why does it matter whether or not they are mine?_**\n\nThis question cuts to the core of why we have a university in the first place: to develop more thoughtful, rigorous, creative minds and more accountable individuals who will help us to solve problems in our world. There will always be pressure on us to cut corners or to be dishonest for short term gains. But the truth is that every time we pretend to understand something we don’t, or impersonate a wiser voice, or steal a unique viewpoint, we weaken ourselves. Every act of plagiarism (this includes using paper mills or hiring a ghost-writer) confirms to you that you cannot succeed on your own. Plagiarism corrodes your sense of personal power and ability.\n\nConversely, following scholarly protocol (such as clearly representing your sources) encourages you to develop your own ideas, find your own intellectual voice, and actively join the conversation. Our community gains when that happens because we need your fresh ideas for the future and not just the old ideas we already have.",
    "length": 8841,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University AI policy academic integrity",
    "title": "Academic Integrity",
    "url": "https://as.nyu.edu/departments/cns/UndergraduateProgram/AcademicIntegrity.html",
    "text": "Academic Integrity \n* [Skip to Main] \n* [About Us] \n* [About Us] \n* [Facilities and Resources] \n* [Affiliated Programs and Centers] \n* [Careers] \n* [Contact Us] \n* [Community and Outreach] \n* [People] \n* [Core Faculty] \n* [Other Faculty] \n* [Administration] \n* [Doctoral Program] \n* [Undergraduate Program] \n* [Postdoctoral Program] \n* [News &amp; Events] \n* [Event Calendar] \n* [Event Descriptions] \n* [News] \n* [CNS Video Archive] \n* [Internal Resources] \n# Academic Integrity\n**CNS Policy on Academic Integrity**\nCNS students must adhere to NYU’s principles of[academic integrity], and the[CAS Honor Code].\nAcademic integrity means that all of the work that you submit is original.\nViolations of academic integrity include:\n* Cheating on exams, quizzes, or other graded assignments\n* [Plagiarism]: appropriating the ideas, words, and images of others\n* Fabrication or falsification of data\nConsequences of a single violation of the principles of academic integrity are a grade of F on\nthe scored assignment or examination, and a formal report to the Dean’s Office. The grade of F\nmust be factored into the course’s final grade.\nIn cases of serious violation(s) of these standards, the department will seek dismissal of the\nstudent from the university.",
    "length": 1254,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University AI policy academic integrity",
    "title": "Academic Integrity Policy",
    "url": "https://tisch.nyu.edu/student-affairs/important-resources/academic-integrity-policy",
    "text": "Academic Integrity PolicyAcademic Integrity Policy\n[Skip to Navigation] [skip to main content] \n[Student Affairs] \n# Academic Integrity Policy\nPlease see the Tisch Policy on Academic Integrity in the NYU Tisch Bulletin:\n[NYU Tisch Bulletin] \n[New York University] \nEqual Opportunity and Non-Discrimination at NYU - New York University is committed to maintaining an environment that encourages and fosters respect for individual values and appropriate conduct among all persons. In all University spaces physical and digital programming, activities, and events are carried out in accordance with applicable law as well as University policy, which includes but is not limited to its[Non-Discrimination and Anti-Harassment Policy].",
    "length": 729,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University ChatGPT policy students",
    "title": "Beyond Privacy: Regulating ChatGPT for Young Adults in Educational Contexts",
    "url": "https://jipel.law.nyu.edu/beyond-privacy-regulating-chatgpt-for-young-adults-in-educational-contexts/",
    "text": "Beyond Privacy: Regulating ChatGPT for Young Adults in Educational Contexts &#8211; NYU Journal of Intellectual Property &amp; Entertainment Law\n[Skip to content] \n[![NYU Journal of Intellectual Property &amp; Entertainment Law]] \n[JIPEL Vol. 14 - No. 2] \n# Beyond Privacy: Regulating ChatGPT for Young Adults in Educational Contexts\n[![]] \n#### By[Yeseul Do, JD '25] \n**May 5, 2025\nYeseul Do[**\\***] \n**Download a PDF version of this article[here].**\nConversations about artificial intelligence (AI) regulation in lawmaking and legal scholarship typically focus on data privacy issues. This Note breaks from that tendency, engaging AI regulation from an educational perspective that focuses instead on the pedagogical implications of AI use. In particular, it examines the role of ChatGPT in educational settings for young adults, a group that is often overlooked in regulatory discussion. Unlike other arguments that emphasize the privacy risks posed by AI, this Note argues that AI regulation is too privacy focused, to the detriment of overlooking other important risks that young adults face in educational settings. In fact, there is too little attention given to regulating ChatGPT for young adults and in education, especially in recognizing the risks of inequitable access to these technologies. Despite recognition by regulators, policymakers, educators, and students of the disruptive potential of ChatGPT in secondary classrooms, many of the concerns raised by lawmakers do not align with those of educators. In recognizing these challenges, I offer several strategies to begin thinking about how to effectively regulate ChatGPT by harnessing the technology’s benefits while simultaneously safeguarding against its risks.\n[Introduction] \n[I. Current Educational Landscape for Young Adults] \n[A.*The Recent EdTech Landscape*] \n[B.*Education’s Resistance to Change*] \n[C.*The Advent of ChatGPT in Schools*] \n[1.*Defining ChatGPT*] \n[2.*Social Definitions of AI*] \n[D.*ChatGPT in Education*] \n[1.*Education’s Misunderstanding of ChatGPT*] \n[E.*Unique Challenges to Regulating Education*] \n[II. AI Risks for Young Adults in Education] \n[A.*Overlooked and Under-Protected: Young Adults as a Protected Group*] \n[B.*Protecting Young Adults Through Educational Contexts*] \n[C.*An Educator’s Perspective on the Benefits and Risks of ChatGPT*] \n[1.*ChatGPT’s Benefits*] \n[2.*ChatGPT’s Risks*] \n[2.1.*AI Access and Literacy*] \n[2.2.*Pedagogical Harms*] \n[2.3.*Developmental Harms*] \n[2.4.*Unethical AI Misuse*] \n[D.*A Critical Look on AI Regulation –Continued Onus on Teachers*] \n[III. Current AI Regulations and Their Gaps in Protecting Young Adults] \n[A.*Federal Education Privacy Laws’ Shortcomings: COPPA and FERPA*] \n[1.*FERPA*] \n[2.*COPPA*] \n[B.*The 2023 Biden AI Executive Order*] \n[C.*State Laws*] \n[1.*Privacy Laws*] \n[2.*Child Design Laws and Social Media Moderation]*](#IIIC2)\n[IV. Suggestions] \n[A.*AI Regulation is Necessary*] \n[B.*The Case Against Banning ChatGPT –No Putting the Genie Back in the Bottle*] \n[C.*Building on the Legacy of Biden AI E.O.: Creating an Eduction-Informed AI Toolkit*] \n[1.*Addressing Ethical and Pedagogical Considerations*] \n[2.*Stakeholders in Charge of Creating AI Guidelines*] \n[3.*Increasing Access: A Public Utility Argument*] \n[4.*Increasing AI Literacy*] \n[D.*Developing a “School Safe ChatGPT”: Responsible AI Integration*] \n[Conclusion] \n### Introduction[1] \nBrian, my seventeen-year-old, high school student cousin, asked me to look over his college entrance essay for the Common App. However, upon reading the first few sentences, something felt amiss. The sentences were grammatically correct, and there was not a single typo throughout the essay. Perhaps it was that, due to my former experience working as a high school English teacher, I knew how seventeen-year-olds normally write, or maybe it was just my innate intuition that the writing sounded off. I couldn’t quite put my finger on exactly why, but it was clear after reading the first two paragraphs that Brian was not the author. As I skimmed through the rest of the essay, I paused and asked Brian, “did you use ChatGPT to write this?” Bewildered, my teenage cousin responded, “is it that obvious?”.\nMy experience with Brian’s essay is neither unusual nor rare. An online survey of around a thousand high school students in fall of 2023 showed that one in five teenagers have used ChatGPT for school assignments.[2] Brian’s sheepish reaction to me asking if his essay was AI-generated also affirms a finding from the same survey, which showed that 57% of these teens felt it was not acceptable to write essays using ChatGPT.[3] My anecdote with Brian opens up the door to an entire slew of questions and concerns –how are young adults using AI? Is AI safe? Do teachers know about it? Is independent essay writing a thing of the past?\nA deeper dive into AI regulation in schools shows that research in this area is very limited, and the research that does occur from the legal space focuses nearly exclusively on information privacy questions. There is surprisingly little about AI’s effects on education and young adults in legal discourse. On the other hand, schools and the education space are largely focused on pedagogical questions, such as how AI fits into teaching students and concerns about academic integrity. There is also a significant disconnect between policymakers’ views of AI and educators’ concerns surrounding AI.\nPart I of this Note begins by discussing the current educational landscape and its approach to technology as schools begin to grapple with and manage the availability of AI. In this section, I also offer different definitions of AI and explore the challenges that come with defining the technology, along with explaining how ChatGPT (currently the most widely-used generative AI chatbot app) functions.\nPart II discusses the multifaceted risks that AI poses for young adults in educational settings beyond the commonly discussed privacy concerns. This includes concerns about accessibility, AI literacy, pedagogical effectiveness, and ethical use.\nPart III explores the current regulatory and legislative landscape for AI and criticizes AI regulation’s narrow obsession with privacy concerns. I argue that the current regulatory environment for AI is overly preoccupied with privacy issues, at the expense of addressing a broader spectrum of ethical, social, and pedagogical challenges presented by AI technologies. This oversight becomes increasingly evident when scrutinizing AI regulation for young adults in educational contexts.\nPart IV sets forth suggestions for future AI regulation for young adults in educational contexts, utilizing the 2023 Biden Executive Order on AI as a baseline. By drawing on the 2023 Biden Executive Order’s guiding principles, this section lays out strategies in formulating effective regulation of ChatGPT and other generative AI apps for the future.\n### I. Current Educational Landscape for Young Adults\n#### A. The Recent EdTech Landscape\nK-12 schools have experienced rapid technological developments thanks to being forced into virtual learning by the COVID-19 pandemic. Had it not been for the pandemic, many schools would have technologically remained decades behind, where laptops were only seldom used during class time, but students would all be Snapchatting their friends on smartphones during bathroom breaks.\nHowever, despite the necessity of virtual learning having forced some schools to integrate more technology into their classrooms, the world of secondary education remains resistant to change. While many young adults (ages 13-17) seem to own a smartphone, many also struggled to adapt when education moved online. When the world was forced to move to solely digital communication in the lockdowns of March 2020, I personally saw many of my students struggle.\nMost classes at my school did not use laptops in the classroom prior to the pandemic, and I observed firsthand my high school students’ poor technological literacy. Due to a lack of familiarity with computers and online classroom tools, students struggled to use basic internet tools during the pandemic. For example, I regularly had students send entire emails in the subject line. Gen Z and Gen Alpha young adults are presumed to be more tech-savvy because this generation grew up with screens from a young age, but my experience as a teacher illuminated that technological literacy remains extremely low.[4] Most of my students in my English I class (ages 13-17) frequently fell for phishing scams and did not know how to use the Google search bar.\nMy school also had serious bars to technological access. Despite my school not qualifying for Title I funding (federal financial assistance to schools that record at least 40% of their students as low-income status),[5] nearly none of my students had access to a computer during the pandemic shutdowns of March 2020. My students logged into class on Google Meets on their phones, and the few who were lucky enough to have access to a computer frequently had network connectivity issues or had to disconnect from the call midway, as their siblings also needed to use the single computer in the house to attend their respective classes.\nThe technology access issue was so bad that the Hawaii Department of Education (HIDOE) made school optional for the rest of that school year. In the span of weeks, learning moved from my classroom of thirty desk chairs to just five students logging onto Google Meets. The state",
    "length": 9529,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University ChatGPT policy students",
    "title": "Dear all, This is an advisory update on use of ChatGPT in ...",
    "url": "https://www.nyu.edu/content/dam/nyu/provost/documents/Chat%20GPT%20email.pdf",
    "text": "This is an advisory update on use of ChatGPT in the classroom. Please share it with faculty who may be facing these issues. This is the first full semester ... Read more 1 page",
    "length": 176,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University ChatGPT policy students",
    "title": "Generative AI and Large Language Models (LLMs)",
    "url": "https://guides.nyu.edu/c.php?g=1307730&p=9624166",
    "text": "Using Generative AI - Generative AI and Large Language Models (LLMs) - Research Guides at New York University Skip to Main Content\n\nSearch\n\n# Generative AI and Large Language Models (LLMs)\n\nUnderstanding LLMs (e.g., ChatGPT) and the concept, use, and ethics of Generative AI tools and platforms.\n\n## Generative AI and Academic Integrity\n\nUsing Generative AI tools is not cheating if a faculty member approves its use in a class assignment.\n\nHowever, if these tools have not been approved, students run the risk of violating [NYU's Academic Integrity Policy] as it defines cheating as:\n\n\"Deceiving a faculty member or other individual who assess student performance into believing that one’s mastery of a subject or discipline is greater than it is by a range of dishonest methods, including but not limited to:\n\n- altering or forging academic documents, including but not limited to admissions materials, academic records, grade reports, add/drop forms, course registration forms, etc.\"\n- submitting answers on an exam that were obtained from the work of another person or providing answers or assistance to others during an exam when not explicitly permitted by the instructor\n- submitting work (papers, homework assignments, computer programs, experimental results, artwork, etc.) that was created by another, substantially or in whole, as one's own\n- bringing or accessing unauthorized materials during an examination (e.g., notes, books, or other information accessed via cell phones, computers, other technology or any other means)\n\nAcademic integrity can also be violated by participating in \"any behavior that violates the academic policies set forth by the student’s NYU School, department, or division.\"\n\nThus, it is important for students and faculty to clarify the extent of the use of AI tools in specific classes and assignments.\n\n## NYU Gen AI Services\n\nNYU offers a number of [Generative AI services] for student, staff, and faculty use.\n\nIn addition to providing information regarding the institutional instances of Gemini and Notebook LM, NYU offers general guidance for [student learning] and [faculty teaching] tools and platforms.\n\n[Gemini] — Google Gemini is a GenAI chatbot that can be used to create new content, streamline repetitive tasks, assist with communications, and more. Gemini is part of NYU Google Workspace Services, accessed alongside your other Google-based apps (e.g., as found in your NYU Email). However, this instance of Gemini is currently used as a standalone tool and is not integrated directly into other NYU Google apps such as Email and Docs. When you’re logged into Gemini with your NYU NetID account, Gemini never trains its AI model on your data. While it will save your past queries and Gemini's results, they are only available to you, and you can delete them at any time, ensuring your data remains private to you.\n\n[Notebook LM] — NotebookLM is a personalized research assistant. You can upload various file types to the tool, ask questions about those files, receive answers with cited sources, and produce outputs such as summaries, briefing docs, timelines, FAQs, study guides, and audio overviews. Currently, NotebookLM is part of NYU Google Workspace Services, accessed alongside your other Google-based apps (e.g., as found in your NYU Email). However, like Gemini, Notebook LM is currently not used as a standalone tool and not integrated directly into NYU Google apps such as Email and Docs.\n\n[NYU Microsoft 365 (including Copilot)] — Access all Microsoft web applications using your NYU Net ID. Copilot, a GenAI chatbot, may be accessed with login credentials.\n\n## AI Detection and TurnItIn\n\n### TurnItIn\n\n[AI Writing Detection] has been disabled in the Turnitin Similarity Reports. For more information, see the NYU Knowledge Base articles below:\n\n- [NYU Brightspace: TurnItIn Integration for Instructors] \n- [NYU Brightspace: TurnItIn Integration for Students] \n- [NYU Brightspace: TurnItIn Integration (Main Article)] \n\nIt should be noted that AI writing detection tools are unreliable and their use is cautioned.\n\n## Evaluating AI-Generated Text\n\nIt is unclear exactly how Generative AI tools work. This uncertainty raises some questions that may help evaluate the accuracy, reliability, relevance, and authority of the text that AI tools produce.\n\n- Has the information the AI tool used been peer-reviewed?\n- Can the information provided by the AI tool be verified?\n- Is the AI tool's output paraphrasing or using entire sections of text that belong to someone else?\n- Do the citations listed exist? Are they accurate?\n- Who or what materials are not cited?\n- Can you identify the authors of the works the AI tool is citing or pulling paragraphs from?\n- Where does the AI tool get its information from?\n\nFinally, students may want to consider whether there is more value to using information from its original source versus what Generative AI tools generate.\n\n## Acknowledging (or Citing) AI-Generated Text\n\nIn most cases, AI writing tools should not be used as an academic source of information. If used, it is always best to cite the original sources the tool lists as its citations, especially because AI tools often generate false citations (also known as \"hallucinations\").\n\nHowever, if Generative AI is permitted for use in an assignment, instructors may want it acknowledged (or cited) when appropriate.\n\nThe main three citation styles, [APA], [MLA], and [CMS] all consider AI-generated text as \"personal communication.\" This means the text generated by AI tools often cannot be verified, replicated, retrieved, nor recovered by anyone other the original author at the time of its generation. Even persistent URLs generated by AI tools can often only be accessed by the author. It is suggested that authors copy or save their entire prompt history and full generated responses for reference, formal acknowledgement (e.g., an appendix).\n\nIn general, acknowledgements of AI tools should include the following points (be sure to reference the citation style above for the proper ordering):\n\n- Date the output was generated\n- Platform version\n- Name of tool platform (e.g., Open AI, Google)\n- Prompt\n- Name of generative AI tool (e.g., ChatGPT, Gemini)\n\nNote: Some instructors may want you to paste the entire response in an appendix. Be sure to clarify with instructors about their expectations.\n\n[Scribbr], a proofreading/citation checking site, offers some guidance for each style.\n\nFor additional citation assistance, please see the Libraries' [Citation Guide].\n\n- [Print Page] \n- URL: https://guides.nyu.edu/chatgpt\n- Last Updated: Oct 7, 2025 1:49 PM\n\n[Author Log-in] \n\n[Report a problem] \n\n[Accessibility]",
    "length": 6683,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University ChatGPT policy students",
    "title": "Generative AI - Generative AI and Large Language Models (LLMs) - Research Guides at New York University",
    "url": "https://guides.nyu.edu/chatgpt",
    "text": "Generative AI - Generative AI and Large Language Models (LLMs) - Research Guides at New York University Skip to Main Content\n\nSearch\n\n# Generative AI and Large Language Models (LLMs)\n\nUnderstanding LLMs (e.g., ChatGPT) and the concept, use, and ethics of Generative AI tools and platforms.\n\n## Generative AI Primer\n\n### What is generative AI?\n\nGenerative AI (GAI) is a type of artificial intelligence that can generate text, images, videos, and other content in response to a user prompt, based on its training data.\n\nThis guide focuses on text-based AI generators. For information on image and video AI generators, see the [Machines and Society] guide.\n\n### Text-based generative AI: LLMs\n\nLarge language model (LLMs) are the foundation of GAI. LLMs are trained on vast amounts of text to understand existing content and generate original content. They function as chatbots, responding to user prompts by processing natural language in a conversational, human-like way. They can perform a variety of language-based tasks, like generating, summarizing, and translating text.\n\n#### What are some of the LLMs out there?\n\n[ChatGPT]: (OpenAI) Has free and fee-based options\n\n[Copilot:] (Microsoft) Free\n\n[Gemini]: (Google) Free to anyone with a Google account\n\n[Llama2]: (Meta) Free for download\n\n### What types of things can ChatGPT and other LLMs do?\n\nWhen asked what it is capable of doing, this is one way ChatGPT has answered:\n\n- Part-of-speech tagging: I can identify the part of speech (noun, verb, adjective, etc.) of each word in a given sentence.\n- Named entity recognition: I can identify and extract named entities such as people, places, and organizations from text.\n- Sentiment analysis: I can analyze text to determine the overall sentiment or emotion expressed within it.\n- Conversational AI: This refers to my ability to engage in natural language conversations with humans, responding to prompts and questions in a conversational manner.\n- Text translation: I can translate text from one language to another, with varying levels of accuracy depending on the language pairs.\n- Summarization: I can summarize longer pieces of text into shorter summaries while retaining the main ideas and important details.\n- Question-answering: I can answer questions by identifying the most relevant information from my training data and generating an appropriate response.\n- Text completion: This involves predicting and generating the most likely words or phrases to complete a given sentence or paragraph based on context.\n- Text generation: This refers to my ability to generate new text based on a given prompt or topic. I can use my understanding of language and my training data to produce sentences, paragraphs, or even longer pieces of text.\n\n(ChatGPT, personal communication, March 14, 2023)\n\n### How do LLMs work, for example ChatGPT?\n\nWhat is behind ChatGPT's mystique? This is one way that ChatGPT has responded to the question of how it works:\n\nChatGPT is a language model that utilizes a range of concepts, architectures, processes, and data inputs to perform its tasks. Here are some of the key elements that enable ChatGPT to work:\n\nLarge language model: ChatGPT is a large language model that is designed to process and generate large amounts of natural language text. It is trained on massive amounts of text data, including books, articles, websites, the Common Crawl, Wikipedia, and other sources. These datasets provide the foundational knowledge that ChatGPT draws on when processing input text and generating responses.\n\nArtificial Neural Networks (ANNs): ANNs are mathematical models that simulate the way that the human brain processes information. They are used extensively in ChatGPT to process input text and generate responses.\n\nNatural Language Processing (NLP): This is the use of computational techniques to analyze and understand human language. ChatGPT uses NLP to process input text and generate responses.\n\nTransformer architecture: The transformer architecture is a type of neural network that is used in GPT models. It enables ChatGPT to process input text and generate responses in a way that is both efficient and effective.\n\nGenerative Pre-trained Transformer (GPT): ChatGPT is based on GPT, a type of deep learning model specifically designed for natural language processing. GPT is trained on vast amounts of text data to learn the patterns and structures of language, enabling it to generate human-like responses to input prompts.\n\nTransfer learning: ChatGPT is trained on a vast corpus of text data that covers a wide range of topics and styles. Transfer learning enables ChatGPT to transfer knowledge learned in one domain to another related domain, allowing it to generate responses to a diverse range of input prompts.\n\nReinforcement learning: ChatGPT uses reinforcement learning to improve its performance over time. This involves training it on a dataset of prompts and human-generated responses, and then adjusting its behavior based on feedback from humans.\n\nAttention mechanism: The attention mechanism is a component of the transformer architecture that allows ChatGPT to focus on specific parts of the input text when generating a response. This helps it to generate more accurate and relevant responses.\n\nOverall, ChatGPT utilizes a complex combination of technologies and processes to analyze and understand human language, enabling it to generate responses that are similar to those produced by humans.\n\n(ChatGPT, personal communication, March 14, 2023)\n\n## ChatGPT Q&A Examples\n\n### Example 1\n\nUser question: Can you provide a diverse list of the best books of the 20th century?\n\nChatGPT answer: The 20th century produced an incredible amount of great literature across a wide range of genres and styles. Here are some of the best books of the 20th century, in no particular order, that represent a diverse range of voices and perspectives:\n\n1. \"The Diary of Anne Frank\" by Anne Frank\n2. \"The Lord of the Rings\" by J.R.R. Tolkien\n3. \"Brave New World\" by Aldous Huxley\n4. \"The Handmaid's Tale\" by Margaret Atwood\n5. \"The Sun Also Rises\" by Ernest Hemingway\n6. \"The Color Purple\" by Alice Walker\n7. \"A Passage to India\" by E.M. Forster\n8. \"Things Fall Apart\" by Chinua Achebe\n9. \"The Bell Jar\" by Sylvia Plath\n10. \"Slaughterhouse-Five\" by Kurt Vonnegut\n11. \"Their Eyes Were Watching God\" by Zora Neale Hurston\n12. \"The Grapes of Wrath\" by John Steinbeck\n13. \"The Sound and the Fury\" by William Faulkner\n14. \"The Catcher in the Rye\" by J.D. Salinger\n15. \"Invisible Man\" by Ralph Ellison\n16. \"The Great Gatsby\" by F. Scott Fitzgerald\n17. \"Beloved\" by Toni Morrison\n18. \"One Hundred Years of Solitude\" by Gabriel Garcia Marquez\n19. \"1984\" by George Orwell\n20. \"To Kill a Mockingbird\" by Harper Lee\n\nThis is by no means an exhaustive list, but it includes some of the most influential and widely-read books of the 20th century.\n\n(ChatGPT, personal communication, March 14, 2023)\n\n---\n\n### Example 2\n\nUser question: What is the most efficient cardio-vascular exercise?\n\nChatGPT answer: There is no single \"most efficient\" cardio-vascular exercise as different exercises offer different benefits and are suited for different individuals and fitness goals. However, some cardio exercises are generally considered more effective than others for improving cardiovascular fitness and burning calories.\n\nHere are a few examples of popular cardio exercises that are generally considered effective:\n\n1. High-Intensity Interval Training (HIIT): HIIT workouts involve short bursts of high-intensity exercise followed by periods of rest. These workouts can be very effective for improving cardiovascular fitness and burning calories in a short amount of time.\n2. Swimming: Swimming is a low-impact exercise that works your whole body and can improve cardiovascular fitness. It's also a great option for people with joint problems or injuries.\n3. Cycling: Cycling is a low-impact exercise that can be done indoors or outdoors. It's a great way to work your legs and get your heart rate up, and can be adjusted to suit different fitness levels.\n4. Running: Running is a great way to get your heart rate up and improve your cardiovascular fitness. It also burns a significant number of calories per minute and can be done indoors or outdoors.\n\nUltimately, the most efficient cardio exercise for you will depend on your individual fitness level, goals, and preferences. It's important to choose an exercise that you enjoy and can stick to in the long term, as consistency is key to seeing results.\n\n(ChatGPT, personal communication, March 13, 2023)\n\n---\n\n### Example 3\n\nUser question: What should I make for dinner tonight?\n\nChatGPT answer: I'm happy to help you come up with some ideas for dinner tonight! Here are a few suggestions based on different dietary preferences and ingredients you might have on hand:\n\n- Baked salmon with a side of steamed green beans and quinoa. You could season the salmon with lemon, garlic, and herbs for added flavor.\n- Black bean tacos with avocado, salsa, and a side of brown rice. You could also add some grilled vegetables, such as onions and bell peppers, for extra flavor.\n- Spaghetti with tomato sauce and sautéed vegetables, such as zucchini, mushrooms, and bell peppers. You could also add some ground turkey or lentils to the sauce for protein.\n- Grilled chicken or tofu with a side of roasted vegetables, such as broccoli, carrots, and sweet potatoes.\n\n(ChatGPT, personal communication, March 13, 2023)\n\n- [Print Page] \n- URL: https://guides.nyu.edu/chatgpt\n- Last Updated: Oct 7, 2025 1:49 PM\n\n[Author Log-in] \n\n[Report a problem] \n\n[Accessibility]",
    "length": 9630,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University ChatGPT policy students",
    "title": "Machines and Society",
    "url": "https://guides.nyu.edu/data/chatgpt-campus-life",
    "text": "[Skip to Main Content] \n\nSearch this Guide\nSearch\n\n# Machines and Society\n\nA growing guide on the latest in data-driven research and emerging technologies at the intersection of society, information and technology.\n\n- [Home] \n- [Large Language Models] \n - [What Large Language Models Are] \n - [Using Large Language Models] \n - [Technical Overview] \n - [Bias] \n- [Generative AI for Research and Creative Use] \n - [Generative AI for Data-driven Research] \n - [Generative AI for Application Development] \n - [Generative AI for Visual Design] \n - [Generative AI in Literature Searching] \n - [Introduction] \n - [Selected Tools] \n - [How to use these AI tools wisely and responsibly] \n - [Contact] \n- [Emerging AI Tools for Teaching and Learning] \n - [Generative AI Quickstarts] \n - [Setting Up Local Generative AI Tools] \n - [Suggestions for Teaching and Learning] \n - [Citing Generative AI] \n- [Technology and Society] \n - [Copyright, Authorship, and Governance] \n - [Business and Industry] \n- [Computational Social Research] \n - [The Field of Computational Social Science] \n - [Web Mining for Digital Disease Surveillance] \n - [Data Collection with Crowdsourcing Technology] \n\n## Introduction\n\nGenerative AI tools can be powerful allies in your literature search, helping you discover relevant research, identify connections between papers, and streamline your review process. This guide introduces a selection of these tools and provides advice on how to use them effectively and responsibly.\n\nPage last updated: June 2025\n\n## Selected Tools\n\n**Elicit** [Elicit] automates time-consuming research tasks like summarizing papers, extracting data, and synthesizing your findings. It tends to work best for empirical domains that involve experiments and concrete results. It can assist in literature review, systematic reviews and meta-analysis.\n\n- [Find papers: Search over 200MM academic papers in Elicit] (YouTube video)\n- [Extract data from PDFs] (YouTube video)\n- [List of Concepts: Summarize concepts and examples across multiple papers] (YouTube video)\n- [Tips and information to help you get the most out of using Elicit] \n\n**Litmaps** [Litmaps] visualizes research papers as network graphs based on publication date, citations, citing relations, and title similarity. It suggests related papers based on the connections between papers. This tool helps explore a topic beyond your known literature and assists you in literature review.\n\n- [Introduction to Litmaps] (YouTube video)\n- [How to quickly visualize a collection of articles with Litmaps] (YouTube video)\n- [How to accelerate your literature review with Litmaps] (YouTube video)\n\n**ResearchRabbit** [ResearchRabbit] is a free online tool designed for literature exploration and mapping. By starting with one or more “seed papers”, it suggests and visualizes relevant literature and researchers. This tool is particularly useful when planning essays, projects, or literature reviews.\n\n- [How I use ResearchRabbit for academic research] (YouTube video)\n- [A Total Beginners Guide to ResearchRabbit: How to find relevant research articles] (YouTube video)\n- [How to Create a Literature Review Outline with ResearchRabbit] (YouTube video)\n\n**SciSpace** [SciSpace] is designed to help you explore, read and understand research papers. It can help you find connected papers, authors, topics, and more. It can assist in literature review, generating citations, paraphrasing texts, and detecting AI in scholarly writing.\n\n- [SciSpace: AI for Researchers] (YouTube video)\n- [SciSpace AI Literature Review Workspace: Find and survey relevant papers in minutes] (YouTube video)\n- [Online workshop: How to use SciSpace tools for research] (YouTube video)\n\n**scite.ai** [scite.ai] is designed for discovering and evaluating scientific articles via Smart Citations. Smart Citations allow users to see how a publication has been cited by providing the context of the citation and a classification describing whether it provides supporting or contrasting evidence for the cited claim.\n\n- [What is scite? Meet the future of citations] (YouTube video)\n- [How scite can help you with your homework] (YouTube video)\n- [scite webinar: How to use scite to help with your research] (YouTube video)\n\n**Semantic Scholar** [Semantic Scholar] provides free, AI-driven search and discovery tools, and open resources for the global research community. It helps to extract meaning and identifies connections from within papers, then surfaces these insights to help scholars discover and understand research.\n\n- [Find Literature with AI using Semantic Scholar for Free] (YouTube video)\n- [Semantic Scholar: AI for Researchers] (YouTube video)\n- [AI Literature Review Tools for Researchers: Semantic Scholar] (YouTube video)\n\n## How to use these AI tools wisely and responsibly\n\n**Use AI tools to complement library search methods, not replace them**\nGenerative AI tools are designed to _assist_ your research, not to do the work for you. While AI tools can expand your search, library databases and subject-specific resources often offer more comprehensive coverage and controlled vocabularies, ensuring that you don't miss crucial research.\n\n**Understand limitations of data sources**\nMany AI literature search tools primarily draw from open-access sources like Semantic Scholar or OpenAlex. This means they might not have access to articles behind paywalls, which are often crucial for comprehensive research.\n\n**Verify information generated by AI tools**\nAI models can sometimes \"hallucinate\" or produce inaccurate, biased, or outdated information. Always cross-reference any information generated by these tools with original, authoritative scholarly sources.\n\n**Protect privacy and intellectual property**\nBe cautious about uploading sensitive or confidential information, or copyrighted materials, into AI tools, as there are privacy and legal concerns to consider. The materials you upload may include content that should remain private and/or may be subject to restrictive licensing agreements. It is the responsibility of each user to carefully review the terms of services and related policies.\n\n**Be transparent about AI use and maintain academic integrity**\nAlways disclose how you used AI tools in your coursework or research. This demonstrates academic integrity and allows others to understand the processes behind your work.\n\n## Contact\n\nYe Zhai\nReference and Research Services Librarian for Social Sciences & Economics\nyz62@nyu.edu\n\n- [<< **Previous:** Generative AI for Visual Design] \n- [**Next:** Emerging AI Tools for Teaching and Learning >>] \n\n[Accessibility(opens\\\nin new window)]",
    "length": 6634,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University ChatGPT policy students",
    "title": "Machines and Society",
    "url": "https://guides.nyu.edu/data/chatgpt",
    "text": "Overview of ChatGPT - Machines and Society - Research Guides at New York University Skip to Main Content\n\nSearch\n\n# Machines and Society\n\nA growing guide on the latest in data-driven research and emerging technologies at the intersection of society, information and technology.\n\nThis page is not currently available due to visibility settings.\n\n- [Print Page] \n- URL: https://guides.nyu.edu/data\n- Last Updated: Aug 28, 2025 1:28 AM\n\n[Author Log-in] \n\n[Report a problem] \n\nSubjects: [Data Science], [Multidisciplinary], [Social Sciences], [Technology] \n\nTags: [artificial intelligence], [computational research], [computing], [data], [information technology] \n\n[Accessibility]",
    "length": 676,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University ChatGPT policy students",
    "title": "Machines and Society",
    "url": "https://guides.nyu.edu/data/chatgpt-developer",
    "text": "Generative AI for Application Development - Machines and Society - Research Guides at New York University[Skip to Main Content] \n[![Banner]] \nSearch this GuideSearch\n# Machines and Society\nA growing guide on the latest in data-driven research and emerging technologies at the intersection of society, information and technology.\n* [Home] \n* [Large Language Models] \n* [What Large Language Models Are] \n* [Using Large Language Models] \n* [Technical Overview] \n* [Bias] \n* [Generative AI for Research and Creative Use] \n* [Generative AI for Data-driven Research] \n* [Generative AI for Application Development] \n* [Introduction] \n* [Assistive Usage: Accelerating the Development Process] \n* [Application Backend: Enhancing Functionality via API] \n* [Specialized Applications: Refining ChatGPT] \n* [Privacy Concerns: Safeguarding User Data] \n* [Contact] \n* [Generative AI for Visual Design] \n* [Generative AI in Literature Searching] \n* [Emerging AI Tools for Teaching and Learning] \n* [Generative AI Quickstarts] \n* [Setting Up Local Generative AI Tools] \n* [Suggestions for Teaching and Learning] \n* [Citing Generative AI] \n* [Technology and Society] \n* [Copyright, Authorship, and Governance] \n* [Business and Industry] \n* [Computational Social Research] \n* [The Field of Computational Social Science] \n* [Web Mining for Digital Disease Surveillance] \n* [Data Collection with Crowdsourcing Technology] \n## Introduction\nDevelopers can leverage ChatGPT&#39;s potential in various capacities, enhancing their work across multiple aspects of application development. Two vital areas when using ChatGPT is particularly beneficial include assistive usage and application backend. You should also be careful about privacy concerns while using ChatGPT.\n## Assistive Usage: Accelerating the Development Process\nChatGPT can significantly aid developers in writing code and expediting the development process. By providing context-aware suggestions, it can help:\n* **Generate Code Snippets:**Developers can input a brief description of the desired functionality, and ChatGPT can generate relevant code snippets in multiple programming languages, saving time and effort.\n* **Debugging:**ChatGPT can assist in identifying common coding issues, offering suggestions to fix errors and improve code quality.\n* **Documentation:**Developers can utilize ChatGPT to create clear and concise documentation, ensuring that their code is easily understandable by other team members.\n* **Translation:**Developers can use ChatGPT to translate their interface to different languages without needing to import/export any data.\nBelow, you can find a list of specialized ChatGPT instances to assist your coding.\n|Product|Description|Website|\nGitHub Copilot|GitHub Copilot is an AI-powered code completion tool developed by Microsoft and OpenAI that suggests code snippets and blocks to developers in real-time.|[https://github.com/features/copilot] |\nGitHub Copilot X|Supercharged Copilot capable of assisting you with CLI commands, documentation, issues and more.|[https://github.com/features/preview/copilot-x] |\n## Application Backend: Enhancing Functionality via API\nChatGPT can be integrated to many applications as a backend via the OpenAI API. It is versatile in handling numerous tasks such as NLP, machine translation, classification, and content generation. The possibilities of utilization are only limited by imagination.\nAn illustrative presentation of the emerging application stack for ChatGPT integrated applications can be viewed[here].\n[![application stack for ChatGPT integrated applications]] \nChatGPT acts as the core of the application, harmonizing with various components that facilitate interaction within different parts of the stack.\nAdditionally, in the course of application development, consider utilizing the following libraries to bolster functionality:\n1. [LlamaIndex] \n* Offers data connectors.\n* Structures data efficiently.\n* Facilitates advanced retrieval/query interface over data.\n* Promotes easy integrations.\n* [LangChain] \n* Integrates LLMs with varied computational sources for enriched functionalities.\n* Demonstrates application versatility in chatbots, agents, and question-answering systems.\n* Provides detailed documentation and examples, aiding developers in crafting powerful applications.\nReview and compare these libraries based on your specific requirements during the development process.\n## Specialized Applications: Refining ChatGPT\nVarious methodologies are available to tailor ChatGPT to meet the specific needs of your application. Here are four imperative techniques:\n1. [Fine-tuning] \n* Yields results of superior quality compared to prompting.\n* Facilitates training on a more substantial number of examples than possible in a prompt.\n* Promotes token savings due to more concise prompts.\n* Ensures lower latency in requests.\n* [Guidance] \n* Structures outputs for enhanced syntactical accuracy and coherence.\n* [Representation Engineering (RepE)] \n* Augments the transparency of Large Language Models (LLMs), focusing on broad-level representations.\n* Addresses issues such as truthfulness and memorization inherent in large language models.\n* [Retrieval-Augmented Generation] \n* Combines the retrieval of external documents with text generation capacities.\n* Elevates the richness and relevance of the content generated by augmenting it with retrieved information.\nThese refinements are crucial for optimizing the performance and output of ChatGPT in various applications.\n## Privacy Concerns: Safeguarding User Data\nUsing ChatGPT through its API or proxies can lead to privacy concerns since OpenAI or proxy providers store all the data. To address these issues and ensure user data protection, developers should ensure:\n* **Encryption:**Implement end-to-end encryption for data transmission between ChatGPT and the application, safeguarding sensitive information.\n* **Data Retention:**Establish strict data retention policies and practices, which dictate the duration and circumstances in which user data is stored or deleted.\n* **Transparency:**Inform users about the usage of ChatGPT and the potential privacy implications, allowing them to provide informed consent.\n* **Anonymization:**Anonymize user data by removing personally identifiable information (PII) before processing it through ChatGPT, minimizing the risks of unintended data exposure.\n* **Proxy Usage:**Avoid using any services that offer ChatGPT through a proxy if possible. It is very easy for proxies to collect information, which could result in unintended data exposure.\n## Contact\nUtku Ege Tuluk\nSenior Associate of Emerging Technologies\nuet200@nyu.edu\n* [&lt;&lt;**Previous:**Generative AI for Data-driven Research] \n* [**Next:**Generative AI for Visual Design &gt;&gt;] \n* Last Updated:Aug 28, 2025 1:28 AM\n* URL:https://guides.nyu.edu/data\n* [**Print Page] \n[Author Log-in] \n[Report a problem] \nSubjects:[Data Science],[Multidisciplinary],[Social Sciences],[Technology] \nTags:[artificial intelligence],[computational research],[computing],[data],[information technology] \n[****] \n[Accessibility(opens\nin new window)]",
    "length": 7125,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University ChatGPT policy students",
    "title": "Machines and Society",
    "url": "https://guides.nyu.edu/data/chatgpt-research",
    "text": "Generative AI for Data-driven Research - Machines and Society - Research Guides at New York University Skip to Main Content\n\nSearch\n\n# Machines and Society\n\nA growing guide on the latest in data-driven research and emerging technologies at the intersection of society, information and technology.\n\n## Introduction\n\nIn this section, we explore various approaches of utilizing generative AI as research assistants or research methods for data-driven research. Generative AI has the potential to enhance academic performance in multiple stages of scientific research, and can be done with caution in conjunction with human evaluation and interpretation. The major incentive for integrating generative AI into the research process is that it enables researchers to concentrate on the fundamental tasks by delegating supplementary responsibilities to generative AI.\n\nHowever, when conducting research with generative AI, it is crucial to evaluate the model's limitations and potential variability in performance. In the end, it is domain expertise, the ability to generate unique insights, and ethical considerations that will be essential in distinguishing research outcomes.\n\n## Coding Assistant for Data Analysis\n\nOne of the most apparent use cases is using generative AI as a coding assistant across various stages in the data workflow. Researchers can use the tool to\n\n- debug code\n- optimize code for efficiency, simplicity, readability, and maintainability\n- complete code\n- generate sample code\n- translate between programming languages\n- ask \"how to code\" questions\n- explain code in a step-by-step manner\n\nNote that generative AI's performance in these cases depends on the level of support for the particular language or software package. Additionally, researchers should be cautious about using generative AI for anything beyond coding assistance. Even tasks as seemingly straightforward like data cleaning require making many small decisions based on clearly defined objectives. Relying on generative AI for more complex tasks like model selection without evaluating the outputs is also not recommended.\n\n## Text Analysis\n\n* This section is outdated and will be updated.\n\nResearchers may leverage generative AI as a natural language processing tool for various tasks, including labeling topics, extracting entities, and assessing sentiments for given text data, among other tasks.\n\nThere are some experiments using ChatGPT for tasks with potential for feature generation, including\n\n- [identifying entities in historical documents] through named entity recognition and classification on locations, persons, organizations, time periods, human works, and physical objects\n- [coding open-text survey responses into analytic categories] in public opinion research\n- [thematic analysis of semi-structured interviews] \n- [text annotation on relevance, stance, topics, and frames detection] of tweets\n\nNote that this technique may be helpful for researchers to obtain preliminary understanding of their data and documents at the initial stages of research. However, the generation process is not transparent and arguably not reproducible when the full technical details of the model are absent, making it challenging to make informed decisions along the way.\n\n## Social Simulations\n\nLLMs are implicit computational models of humans (often referred to as homo silicus) by nature of their training on vast human-generated data. This makes them potent for building autonomous agents that simulate individuals and societies in single-agent setups, multi-agent systems, or human-AI interactions.\n\nLLM agents are utilized in social simulations widely. They are constructed to explore social dynamics, develop or test theories of human behavior, or populate virtual spaces with realistic social phenomena. They provide ethical, scalable alternatives to real-world human studies, including topics very difficult to examine or populations very difficult to access.\n\nEconomics\n\nHorton, J. J. (2023). Large language models as simulated economic agents: What can we learn from homo silicus? (No. w31122). National Bureau of Economic Research.\n\nManning, B. S., Zhu, K., & Horton, J. J. (2024). Automated Social Science: Language Models as Scientist and Subjects (No. arXiv:2404.11794). arXiv. [https://doi.org/10.48550/arXiv.2404.11794] \n\nLeng, Y. (2024). Folk Economics in the Machine: LLMs and the Emergence of Mental Accounting (SSRN Scholarly Paper No. 4705130). Social Science Research Network. [https://doi.org/10.2139/ssrn.4705130] \n\nSocial computing\n\nPark, J. S., O’Brien, J. C., Cai, C. J., Morris, M. R., Liang, P., & Bernstein, M. S. (2023). Generative Agents: Interactive Simulacra of Human Behavior (No. arXiv:2304.03442). arXiv. [https://doi.org/10.48550/arXiv.2304.03442] \n\nGao, C., Lan, X., Lu, Z., Mao, J., Piao, J., Wang, H., Jin, D., & Li, Y. (2025). S3: Social-network Simulation System with Large Language Model-Empowered Agents (No. arXiv:2307.14984). arXiv. [https://doi.org/10.48550/arXiv.2307.14984] \n\nSocial theories\n\nAher, G. V., Arriaga, R. I., & Kalai, A. T. (2023). Using Large Language Models to Simulate Multiple Humans and Replicate Human Subject Studies. Proceedings of the 40th International Conference on Machine Learning, 337–371. [https://proceedings.mlr.press/v202/aher23a.html] \n\nTörnberg, P., Valeeva, D., Uitermark, J., & Bail, C. (2023). Simulating Social Media Using Large Language Models to Evaluate Alternative News Feed Algorithms (No. arXiv:2310.05984). arXiv. [https://doi.org/10.48550/arXiv.2310.05984] \n\n---\n\nLLM agents use modular components to enhance human-like behavior in dynamic settings: profiling module to identify roles, memory module to recall past behaviors, planning module to plan future actions, and action module to translate the agent’s decisions into specific outputs.\n\nEvaluation strategies of LLM agents include subjective assessments by human judges who score or rank agent outputs or differentiate them from human outputs, as well as quantitative metrics and standardized benchmarks.\n\nDeploying LLM agents for social simulations requires careful consideration, as model limitations may affect the accuracy of outputs or lead to unintended consequences.\n\nBias: LLMs tend to give responses not representative of the diverse public (see Bias section for more details).\n\nAlignment: LLMs are usually fine-tuned to align with human values. Besides, as a byproduct of fine-tuning, some models tend to be overly agreeable. However, an ideal social simulation of real-world problems may require representing negative human behaviors, which is often restricted.\n\nLow variance of response distributions: LLMs generate less diverse responses than humans would.\n\nTemporal gaps: The temporal information in LLM training data (e.g., from the internet) is often lost, making it risky to simulate historical contexts or current populations accurately if there's a gap between the model's training data cutoff and the period being modeled.\n\nCross-linguistic influence: If a model has been trained on a mixture of languages, knowledge and attitudes from one socio-linguistic system may affect others in the model. For instance, lthe internal representations can be partially language-agnostic, partially biased toward English-centric reasoning, and partially differentiated by language.\n\nLack of sensory experience: LLMs lack embodied experiences, limiting their understanding of real-world context.\n\nAlien cognition: LLMs may at times deviate from natural human behavior, generating misleading human simulations. For instance, surprises that emerge from analysis may be misconstrued as discoveries when they are mere errors in simulation.\n\nKnowledge boundary: LLMs' vast knowledge can be disadvantageous when simulating scenarios requiring agents to operate with limited or specific knowledge, as they might make decisions based on information real users wouldn't have.\n\nDillion, D., Tandon, N., Gu, Y., & Gray, K. (2023). Can AI language models replace human participants? Trends in Cognitive Sciences, 27(7), 597–600. [https://doi.org/10.1016/j.tics.2023.04.008] \n\nShanahan, M., McDonell, K., & Reynolds, L. (2023). Role play with large language models. Nature, 623(7987), 493–498. [https://doi.org/10.1038/s41586-023-06647-8] \n\nWang, L., Ma, C., Feng, X., Zhang, Z., Yang, H., Zhang, J., Chen, Z., Tang, J., Chen, X., Lin, Y., Zhao, W. X., Wei, Z., & Wen, J. (2024). A survey on large language model based autonomous agents. Frontiers of Computer Science, 18(6), 186345. [https://doi.org/10.1007/s11704-024-40231-1] \n\nGuo, T., Chen, X., Wang, Y., Chang, R., Pei, S., Chawla, N. V., Wiest, O., & Zhang, X. (2024). Large Language Model based Multi-Agents: A Survey of Progress and Challenges. arXiv. [https://doi.org/10.48550/arXiv.2402.01680] [GitHub repo: [Awesome LLM-based Multi-Agents Papers]]\n\nBail, C. A. (2024). Can Generative AI improve social science? Proceedings of the National Academy of Sciences, 121(21), e2314021121. [https://doi.org/10.1073/pnas.2314021121] \n\nKozlowski, A. C., & Evans, J. (2025). Simulating Subjects: The Promise and Peril of Artificial Intelligence Stand-Ins for Social Agents and Interactions. Sociological Methods & Research, 54(3), 1017–1073. [https://doi.org/10.1177/00491241251337316] \n\n## Synthetic Data Generation\n\n## Contact\n\nYun Dai [Data Services] yun.dai@nyu.edu\n\n- [Print Page] \n- URL: https://guides.nyu.edu/data\n- Last Updated: Aug 28, 2025 1:28 AM\n\n[Author Log-in] \n\n[Report a problem] \n\nSubjects: [Data Science], [Multidisciplinary], [Social Sciences], [Technology] \n\nTags: [artificial intelligence], [computational research], [computing], [data], [information technology] \n\n[Accessibility]",
    "length": 9686,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University ChatGPT policy students",
    "title": "Generative AI and Large Language Models (LLMs)",
    "url": "https://guides.nyu.edu/c.php%3Fg%3D1307730%26p%3D9624166",
    "text": "However, if these tools have not been approved, students run the risk of violating NYU's Academic Integrity Policy as it defines cheating as: \"Deceiving a ...",
    "length": 158,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University provost generative AI guidance",
    "title": "NYU Office of the Provost Generative AI Workshop: (Re)Designing Assignments and (Re)thinking Assessment for Learning in the Age of GenAI",
    "url": "https://nexus.sps.nyu.edu/post/nyu-office-of-the-provost-generative-ai-workshop-re-designing-assignments-and-re-thinking-assessm",
    "text": "-- NYU Office of the Provost Generative AI Workshop: (Re)Designing Assignments and (Re)thinking Assessment for Learning in the Age of GenAI\n\ntop of page\n\nRecently, the NYU Office of the Provost offered a morning of [Generative AI Workshops].\n\nI attended “(Re)Designing Assignments and (Re)thinking Assessment for Learning in the Age of GenAI.”\n\n## Approaches\n\nOf multiple topics covered during the training, I appreciated how [Associate Vice Provost DeAngela Duff] framed two approaches for professors to consider when it comes to student assignment or assessment completion: Human-First vs. AI-First.\n\nHuman-First AI Use: In this approach, students first independently brainstorm, research, and draft. Then, they ask AI to help refine, iterate, and even innovate. By the end, students ensure they have vetted all outputs for accuracy and quality. Associate Vice Provost Duff shared that as a professor, she favors this approach, calling it the “human sandwich”: Human generation - AI editing - Human finalizing.\n\n[To] me, this approach empowers and preserves human creativity and critical\n\nthinking skills—even confidence—through productive struggle (Lee et al., 2025). AI is\n\nemployed as an assistant or editor for humans to ultimately vet and finalize outputs,\n\nrather than the other way around.\n\nAI-First AI Use: This approach acknowledges that many students are already using generative AI to create first drafts of written assignments, presentations, and more. After this step, human-intervention is then paramount to evaluate accuracy, prompt and edit, and revise before finalizing: AI generation - Human editing and iterating with AI - Human finalizing.\n\nI appreciate that the latter approach helps realign habits away from students using AI only to complete assignments for them, which is a common concern expressed by professors today.\n\nEach approach offers positives and challenges, including ethical questions, for professors to explore. There is no right answer; it depends on the professor and content area.\n\n## AI Policies & Student Choice\n\nNYU provides [guidelines and considerations for generative AI], but Associate Vice Provost Duff emphasized that it’s up to professors how students should be using AI in their assignments and assessments. Professors might come up with a blanket syllabus statement, and/or create guidelines for acceptable AI use in different assignments.\n\n[The guidelines] also note that instructors are fully responsible for any use of AI in their courses, including the design of assessments, the grading of student work, the writing of feedback, and the protection of student privacy and information. Faculty use of GenAI to develop course materials and/or student feedback should always be disclosed to students.\n\nDuff also cautioned professors not to assume that all students use, or even want to use, AI in their assignments. For example, Dartmouth professor, Scott Anthony, felt surprised by his [Gen Z students’ fear and anxiety] of having their humanity and critical thinking skills replaced by artificial intelligence (Lichtenberg, 2025). For this reason, professors might create [classroom AI policies collaboratively] (NYU login required) with students to include their views on how they can/will use AI in their coursework.\n\n## GenAI Learning Strategies\n\nRather than only share restrictions of AI use, this workshop offered positively-framed strategies for effective, responsible completion of assignments with AI. For example:\n\nMeta-reflections: Have students continuously reflect and capture notes on the process of completing an assignment, not just the output.\n\nBrainstorm with AI: Have students prompt AI for options rather than one answer.\n\nCompare and Contrast: Have students compare and pull from several prompts or several AI tools before choosing.\n\nConfirm Ownership: Emphasize that your students are responsible for everything, including accuracy, in an assignment.\n\n## Assessment Strategies\n\nTo ensure student accountability for learning, Associate Vice Provost Duff shared the following direct assessment strategies:\n\nLive Demonstrations\n\nOral Defenses\n\nPost-Presentation Q+A\n\nPeer Review\n\nTraditional Written Exams\n\nProcess Portfolios\n\nGoogle Doc Written Assignments (Version History)\n\nMeta-Reflections (e.g. Reflective Journaling on AI Use)\n\nand more!\n\n## My Meta-Reflection: Process for Writing this Blog\n\nAlthough I strongly prefer a “Human-First/Human-Mostly\" approach to GenAI, I decided to test an AI-First approach to write this blog post. This section models a process reflection that professors might consider integrating into student assignment submissions.\n\nFirst, I uploaded my general notes, resources, and ideas from the NYU GenAI workshop into Google Gemini, and prompted it to come up with a first draft.*\n\nThough it captured the content of some of my ideas, the level and quality of writing felt generic and uninspiring to me. What I found after a couple of iterative prompts to help shape it is that I deeply enjoy the craft of writing—ever since childhood—as a way to integrate my learning from my mind and my notes into my own voice and finally into words. The process is important to me, and it makes me feel inspired and happy.\n\nBy experimenting with an AI-First approach, I also reconfirmed for myself that although I’ve learned to be a careful editor from 20+ years of experience, I do not love editing. It’s tedious.\n\nTherefore, given the poor quality of the initial drafts from generative AI, I concluded that I still value a Human-First—well, Human-Only or Human-Mostly—approach when it comes to writing and creative work.\n\nHow I did use generative AI as my assistant in my Human-Mostly approach:\n\nFormatting APA references, which I vetted and finalized in this publication.\n\nA quick check of grammar, especially when a colleague isn’t available for a peer-proofread. (I still prefer the latter. After all, it is human beings - you! - who are my audience, so having a second pair of human eyes helps.) :)\n\nFor more information and resources, check out the (Re)designing Assignments and (Re)thinking Assessments workshop [slide deck] (NYU login required).\n\nReferences\n\n*Google. (2026). Gemini [Large language model]. [https://gemini.google.com] \n\nLee, H.-P. (Hank), Sarkar, A., Tankelevitch, L., Drosos, I., Rintel, S., Banks, R., & Wilson, N. (2025). The impact of generative AI on critical thinking: Self-reported reductions in cognitive effort and confidence effects from a survey of knowledge workers (Tech. Rep.). Microsoft Research. In Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems (CHI ’25). [https://doi.org/10.1145/3706598.3713778] \n\nLichtenberg, N. (2025, December 20). ‘They’ll lose their humanity’: Dartmouth professor says he’s surprised just how scared his Gen Z students are of AI. Fortune. [https://fortune.com/2025/12/20/does-ai-make-you-dumb-dartmouth-professor-says-gen-z-scared] \n\n## *Appendix: Gemini-Generated Blog\n\nHeader image credit: NYU Office of the Provost GenAI Workshop, 2026\n\nbottom of page",
    "length": 7043,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University provost generative AI guidance",
    "title": "Still wondering about Generative AI? Here are some ...",
    "url": "https://wp.nyu.edu/fas-edtech/2024/10/still-wondering-about-generative-ai-here-are-some-nyu-resources/",
    "text": "Oct 7, 2024 — For those of you who missed it, the Office of the Provost offered a series of Generative AI workshops in August of 2024 to address the many ...",
    "length": 157,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University provost generative AI guidance",
    "title": "AI and Technology in Education",
    "url": "https://www.nyu.edu/about/leadership-university-administration/office-of-the-president/office-of-the-provost/ai-and-technology-in-education.html",
    "text": "Organization Chart\n\n# AI and Technology in Education\n\nClay Shirky\n,\nVice Provost\n\nClay Shirky is Vice Provost for AI and Technology in Education. In this role, he designs, develops, and enhances all academic aspects of technology-based teaching and learning, University-wide; oversees the development of NYU’s instructional technology strategy, working with deans, faculty, NYU IT, and other university offices; maintains an inventory of online education offerings; and helps schools use educational technology to recruit new students, help existing students learn and progress, and generate costs savings or new revenues. He chairs the University’s Future of Technology-Enhanced Education Committee.\n\n[Usability Lab] \n\n## Head of Unit\n\n[Clay Shirky] \n\nVice Provost for AI and Technology in Education\n\n[clay.shirky@nyu.edu] \n\n## Key People\n\n### In AI and Technology in Education\n\n[De Angela Duff] \n\nAssociate Vice Provost\n\n[deangela.duff@nyu.edu] \n\n[Claire Menegus] \n\nDirector, NYU Usability Lab\n\n[cm3884@nyu.edu]",
    "length": 1013,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University provost generative AI guidance",
    "title": "Enhancing Teaching and Learning with Generative AI",
    "url": "https://steinhardt.nyu.edu/faculty-and-staff/academic-affairs/steinhardt-ai-hub/enhancing-teaching-and-learning-generative-ai",
    "text": "Enhancing Teaching and Learning with Generative AI | NYU Steinhardt[Skip to main content] \n[![Steinhardt School of Culture, Education, and Human Development]] \nSearch\nOpen Main MenuClose Main Menu\n## Search NYU Steinhardt\nSearch\nClose Search\n![NYU classroom] \n# Enhancing Teaching and Learning with Generative AI\n## Integrating AI into the Classroom\nThis guide is designed for educators seeking to integrate AI into their teaching practices. It offers actionable strategies, practical resources, and detailed examples to help enrich student learning with AI tools. AI can enhance personalized learning, automate routine tasks, and boost student engagement, but aligning its use with clear learning objectives and ethical guidelines is essential for effective implementation.\n### Best Practices for AI Integration\n#### Define Clear Objectives for AI Use\n**Purpose-driven AI integration:**Before using AI, clarify the goals it will support. Define how AI can enhance learning outcomes, such as personalized feedback, content creation, or research assistance.\n**Example:**Use AI to brainstorm project topics. Explicitly tell students when they should stop utilizing generative AI for this project.\n#### Maintain Transparency with Students\n**Explain AI’s role in the classroom:**Be transparent with students about how AI will be used and explain its capabilities and limitations. This promotes ethical use and helps students understand AI’s strengths and weaknesses.\n**Example:**Introduce students to AI tools like ChatGPT by explaining how it generates responses and the importance of critically evaluating AI-generated content. Create an introductory assignment that requires students to use ChatGPT to generate written work. Ask that students critically evaluate the output and submit that for grading and large &amp; small group reflection.\n#### Encourage the Ethical Use of AI\n**Teach responsible AI use:**Develop guidelines around AI usage, such as proper attribution of AI-generated content and the ethical considerations of using AI for assignments.\n**Example:**Incorporate early discussions on academic integrity, plagiarism, and the appropriate use of AI for research and writing assistance.\n#### Use AI to Foster Critical Thinking\n**Complement, don’t replace:**AI should be used to complement learning, not as a substitute for critical thinking and problem-solving. Encourage students to critically assess AI-generated suggestions or solutions.\n**Example:**Have students use AI tools for brainstorming or drafting, but require them to analyze and refine the output with their own insights. Require students to reflect on these exercises using in-class discussions or asynchronous online discussions utilizing NYU Brightspace.\n#### Personalize Learning Experiences\n**Leverage AI for adaptive learning:**Use AI-powered tools to tailor instruction based on individual student needs, providing personalized learning experiences that adapt to student progress.\n**Example:**Create personalized study plans for your different learning styles. Try imputing your activity or assignment into chatGPT and asking it to provide you with ideas on how to adjust the assignment for learners with anxiety or depression or for students who might be new to the subject matter and need more scaffolding.\n#### Integrate AI with Collaborative Learning\n**Facilitate group projects with AI:**Use AI to enhance collaboration by allowing students to engage in AI-driven group discussions, idea generation, and content refinement.\n**Example:**Students can use AI to collectively generate project ideas or feedback, fostering peer learning and critical evaluation of AI outputs. Ask students to assess the AI output for bias and misinformation.\n#### Continuously Assess and Adjust AI Use\n**Monitor effectiveness:**Regularly assess the impact of AI on student learning outcomes. Be prepared to adjust its use based on feedback and learning progress.\n**Example:**Conduct regular check-ins with students to gauge how AI aids their learning and where it may need adjustment or further guidance. You can facilitate this through a reflective discussion, anonymous feedback via Google Forms, or anonymous discussions on NYU Brightspace.\n#### Create Clear Policies\n**Develop AI usage policies:**Set clear policies on how AI can and cannot be used in coursework. Include these guidelines in the syllabus and ensure students understand the expectations.\n**Example:**Clearly state that AI-generated text must be cited or only used in specific parts of an assignment (e.g., brainstorming).\n#### Offer Training and Support\n**Provide AI tool training:**Ensure students are adequately trained in using AI tools. Offer tutorials or resources to help everyone use AI effectively and ethically. Don’t assume that just because your learners are younger, they’re comfortable with AI!\n**Example:**Request that the*Digitial Innovation and Learning*Team host an AI workshop at the start of the semester to familiarize students with the AI tools they’ll be using in class.\n#### Address AI’s Limitations\n**Be mindful of AI’s weaknesses:**Educate students about AI’s limitations, such as potential biases, factual inaccuracies, or lack of contextual understanding, and how these can impact output quality.\n**Example:**Have students cross-check AI-generated research content with primary sources to verify accuracy. Additionally, have students intentionally examine the output for*bias*and share the findings with the larger audience.\n## Sample Classroom Activities\nThese lesson plans are designed to support critical thinking, creativity, and engagement through the thoughtful use of AI. Whether you're new to AI or looking to enhance your existing lessons, these plans offer practical ways to bring AI into various subjects, helping students develop digital literacy and navigate AI's role in education. Explore ready-to-use templates and ideas for fostering interactive, AI-supported learning experiences.\n### Ctrl+Alt+Debate: AI-Powered Argumentation and Debate Strategies\n**Best for:**Undergraduate &amp; Graduate\n**Activity Type:**Discussion &amp; Critical Thinking\n**Description:**Students use AI to generate arguments for or against a topic and then engage in a structured debate. This activity helps students analyze AI-generated reasoning, refine arguments, and improve their debate skills.\n**Lesson Plan Steps:**\n1. Assign students a debate topic related to the course material.\n2. Have students use an AI tool (like ChatGPT or Gemini) to generate arguments for both sides.\n3. Pair students and assign them positions (pro/con).\n4. Students refine AI-generated responses with evidence from course readings.\n5. Conduct live debates in class.\n**Materials Needed:**\n1. Access to an AI chatbot\n2. Course readings\n3. Debate rubric\n**Prep Time:**15-20 minutes\n**Activity Duration:**30-45 minutes\n[Activity Lesson Plan] \n### AI Writes, You Refine: A Storytelling Activity\n**Best for:**Undergraduate\n**Activity Type:**Creative Writing &amp; AI Interaction\n**Description:**Students generate AI-assisted short stories by remixing different styles, perspectives, or time periods. This activity encourages creativity, genre analysis, and critical evaluation of AI-generated content while reinforcing course concepts.\n**Lesson Plan Steps:**\n1. Provide students with a historical event, concept, or case study from the course.\n2. Have them prompt an AI to rewrite the event in a specific genre (e.g., sci-fi, dystopian, detective).\n3. Students revise and add their own analysis.\n4. Share and discuss how AI changes the narrative perspective.\n**Materials Needed:**\n1. AI text generator (ChatGPT, Gemini, etc.)\n2. Course materials for context\n**Prep Time:**10 minutes\n**Activity Duration:**45-60 minutes\n[Activity Lesson Plan] \n### Spot the Bot: AI Research Challenge\n**Best for:**Graduate &amp; Upper-Level Undergraduate\n**Activity Type:**Critical Thinking\n**Description:**Students analyze AI-generated fake research papers to identify biases and inaccuracies.\n**Lesson Plan Steps:**\n1. Provide AI-generated \"fake\" research papers with errors.\n2. Students analyze papers for logical inconsistencies, bias, or misrepresented sources.\n3. Discuss AI's role in academic integrity and research credibility.\n**Materials Needed:**\n1. AI-generated research excerpts\n2. Fact-checking resources\n**Prep Time:**20 minutes\n**Activity Duration:**45-60 minutes\n[Activity Lesson Plan] \n### AI-Powered Podcast Host\n**Best for:**Undergraduate\n**Activity Type:**Media &amp; Communication\n**Description:**Students create a short podcast episode using AI-generated scripts and then refine them.\n**Lesson Plan Steps:**\n1. Assign students a course-related topic.\n2. Have them generate a script with a generative AI software.\n3. Students revise for accuracy and engagement.\n4. Record and share their podcast episodes and reflect on the work of AI in podcasting.\n**Materials Needed:**\n1. AI chatbot\n2. Recording software (iphone,Anchor, Audacity, etc.)\n**Prep Time:**20-30 minutes\n**Activity Duration:**60-90 minutes\n[Activity Lesson Plan] \n### AI-Powered Exam Question Generator\n**Best for:**Undergraduate &amp; Graduate\n**Activity Type:**Study &amp; Review\n**Description:**Students use AI to generate potential exam questions and critique their quality.\n**Lesson Plan Steps:**\n1. Assign students key topics or themes to review.\n2. Have them generate exam questions using AI.\n3. Students refine and critique AI-generated questions.\n4. Submit the best ones for peer review or instructor use.\n**Materials Needed:**\n1. AI chatbot\n2. Access to course themes and materials\n**Prep Time:**10 minutes\n**Activity Duration:**30-45 minutes\n[Activity Lesson Plan] \n### AI-Powered Ethical Dilemmas –Human vs. AI Decision-Making\n**Best for:**Undergraduate &amp; Graduate\n**Activity Type:**Ethics &amp; Decision-Making\n**Description:**Students engage with AI-generated ethical dilemmas related to course themes.",
    "length": 9919,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University provost generative AI guidance",
    "title": "Provost Letter to New York Faculty",
    "url": "https://www.nyu.edu/about/leadership-university-administration/office-of-the-president/office-of-the-provost/provostial-communications/provost-letter-to-new-york-faculty.html",
    "text": "Provost Letter to New York Faculty\nMenu[Skip to All NYU Navigation] [Skip to Main Content] \n[NYU] \nSearchSearch SiteAll NYU\n[NYU Home] \n[Login toNYU Home] \nAll NYU\n[NYU] \nSearch Site\n# Provost Letter to New York Faculty\n**Date:**October 16, 2024\n**To:**NYU Faculty\n**From:**Provost Georgina Dopico\nDear faculty colleagues,\nI hope the new academic year has started off well for you and that you are making the best of these last warm days of fall. I write with some updates and announcements (thank you for reading to the end), but before turning to those, I want to express my sincere appreciation for all you continue to do and for the generosity and commitment with which you do it.\n## New Faculty Hires and New Promotions\nI want to start by offering a very warm welcome to the 232 new faculty members joining us at our Washington Square and Brooklyn campuses. It was a pleasure meeting many of you at our new faculty orientation last month. I hope you are beginning to feel settled, and that New York and NYU are feeling more and more like home. Thank you to all those who were involved in their recruitment and in helping them find their way in our academic community.\nI also want to congratulate our 100 tenured and tenure-track faculty and 91 continuing contract faculty who were recently promoted at NYU-NY. One of the very best parts of my job is getting to read promotion and tenure dockets and learning about all the extraordinary work you are doing, not only to advance our research and teaching missions but, through the impact of your work, to be a force for good in the world.\n## Class of 2028\nNYU has[recently released data on the entering undergraduate class of 2028]. Since its founding, and throughout its history, a cornerstone of NYU's educational mission has been to create and expand educational opportunities for students of all backgrounds and experiences. Diversity has been a core part of our identity and one of our greatest strengths. That has not changed. This year, in the wake of last summer’s SCOTUS decision, our results did not reflect the demographic diversity we have consistently achieved over the past years, a diversity we believe is critical to our mission and one that makes us better. We have an incredibly gifted class of first-year students and have met or surpassed last year’s already high percentage of first-generation and Pell-eligible students. However, we have less racial and ethnic diversity in our entering class than in recent years; while this was not unanticipated, given the Supreme Court’s landmark decision, it is disappointing. We will continue to follow the law; we will also continue to seek new approaches: enhancing our access programming; doubling down on our efforts to recruit widely across all demographics; increasing entry points into the University for non-traditional students, first-gen students, and low-income students; building new pipelines; strengthening retention and success programs; and engaging in global inclusion efforts in the hope that every student can feel they belong here. The task ahead will not be an easy one, but it is one to which we are deeply committed.\n## The Research Enterprise and Academic Facilities\nNYU’s research enterprise has never been stronger. We owe that remarkable trajectory to all of you. In fiscal year 2024, 651 principal investigators across Washington Square, Brooklyn, Abu Dhabi and Shanghai received the most funding ever awarded to NYU, more than $350 million in sponsored projects, representing the arts, sciences, humanities, social sciences (including applied social sciences), health, and related fields. Over the last decade, our overall research expenditures, together with the Grossman School of Medicine, have grown by 225% to some $1.4 billion per year. In the NSF’s Higher Education Research and Development ranking, NYU now stands 15th nationally, 2nd in New York State, and 1st in New York City—all record rankings for us.\nTo support our growth in research and to continue to improve our classrooms, we are opening several new academic spaces in Brooklyn this fall: the Global AI Frontier Lab that brings together US and Korean scholars, as well as new laboratory facilities for Tandon’s Departments of Biomedical Engineering and of Chemical and Biomolecular Engineering. Not far away, in Industry City, Tisch is opening the Martin Scorsese Virtual Production Center, a best-in-class facility that will train students on the most cutting-edge production technologies. We have also opened a new home for the Robert F. Wagner Graduate School of Public Service on 17th street in Manhattan.\n## Faculty Advisory Committee\nFollowing advice we heard in this summer’s Listening Forums to seek greater faculty input on matters related to protest and dissent, President Mills and I have appointed a Faculty Advisory Committee, to be led by Professor Trevor Morrison, a constitutional law scholar and dean*emeritus*of the Law School. The Committee’s charge will be to review and provide advice on the University’s protocols for demonstrations and protests. They will also review the disciplinary materials used by the Office of Student Conduct; consider the role of a Faculty Intervention Group (faculty with expertise or interest in conflict resolution who might serve as intermediaries during a protest); and review the University’s communications plans in the event of significant disruptions.\nI wish to extend my thanks to the members of the Faculty Advisory Committee for agreeing to serve and for taking on this important assignment. In addition to Professor Morrison, they are: Chris Dickey (GPH; CFSC); Pat Egan (FAS; Wagner); Ryan Hartman (Tandon; TFSC); Diane Hughes (Steinhardt; TFSC); Beth Latimer (Nursing; CFSC); Michael Lindsey (Silver); Sonali McDermid (FAS); and Alejandro Velasco (Gallatin). Please feel free to provide input or questions to the committee by emailing[faculty.advisory.committee@nyu.edu].\n## Resources for the Classroom\nMajor events—international, national, local, or personal—can have a significant impact on teaching and learning. To support faculty, the Learning Experience Design (LED) team in the Office of the Provost offers resources on &quot;[Teaching in Challenging Times and Inclusive Teaching],&quot; including guidance on how to handle difficult conversations in the classroom sensitively and effectively. In addition, the LED team regularly hosts Zoom-based[TeachTalks] on these and other relevant topics. In September, LED offered a TeachTalk on “Planning for Unexpected Sensitive Conversations in the Classroom,”[a video of which can be viewed here]. In response to faculty demand, the LED team has organized additional sessions,[the next of which is scheduled for October 17]. Planning is currently underway to expand support in this area, and additional opportunities for engagement will be announced on the[LED web page]. If you have ideas for teaching support for faculty, on these or other issues, please send an email to the LED team at[teaching@nyu.edu].\n## Guidance and Expectations on Student Conduct\nThe University’s longstanding commitment to ensuring that no member of the NYU community is harassed, intimidated, or threatened is codified in[NYU’s Non-Discrimination and Anti-Harassment (NDAH) Policy]. In late August, students received a[Guidance and Expectations document], which was intended to aid in the understanding of that policy and to provide examples of how it is applied. Some faculty have raised questions concerning the document’s possible impact on teaching and scholarship. To respond to those questions, the University has posted further clarification in the form of a[Guidance and Expectations FAQ].\nI want to reiterate the University’s unwavering commitment to academic freedom and to make clear that there have been no changes to NYU’s Non-Discrimination and Anti-Harassment (NDAH) Policy or to its definition of antisemitism. The Guidance and Expectations document is not meant to restrict peaceful protest or the free exchange of ideas, nor to inhibit academic or public discourse, classroom instruction, scholarship, or the critique of political ideologies, of particular countries, or of their policies or actions. No books are banned or bannable under NYU’s NDAH policies or under the Guidance and Expectations. I have met with several Departments who have raised questions about the implications of the Guidance and Expectations document and welcome more dialogue with faculty on this issue.\n## Democracy and Election-Related Events\nThe Provost’s Office is sponsoring a series of faculty panel discussions on Democracy and the 2024 election. The first of these, Social Media and the US Presidential Election, held last week, featured Josh Tucker (A&amp;S Politics; Center for the Study of Social Media and Politics [CSMaP]), Solomon Messing (CSMaP), Lama Mohammed (CSMaP), and Jonathan Nagler (A&amp;S Politics; CSMaP). Last night, we featured Deborah Amos (Princeton), Mohamad Bazzi (A&amp;S Journalism; Kevorkian Center), and Lihi Ben Shitrit (A&amp;S Hebrew and Judaic Studies; Taub Center) in a compelling discussion of the Middle East and the US presidential election. Upcoming are:\n* **Polarization and the US Presidential Election (October 23)**featuring Delia Baldassarri (A&amp;S Sociology), Pat Egan (A&amp;S Politics; Wagner), and Bryant Moy (A&amp;S Politics).\n* **Freedom and the US Presidential Election (October 30)**featuring Melissa Murray (Law), David Stasavage (A&amp;S Politics), and Kenji Yoshino (Law).\n* In addition, NYU’s Migration Network is hosting a virtual roundtable on**Global Comparisons of Immigration Policies and Electoral Politics (October 21)**.\n* And look for election-related events including the**Town Hall: Election 2024 in Perspective (October 28)**at the[Brademas Center] and",
    "length": 9827,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University provost generative AI guidance",
    "title": "Key AI Resources at NYU",
    "url": "https://www.nyu.edu/life/information-technology/artificial-intelligence-at-nyu/resources.html",
    "text": "NYU AI Services & Tools · Google AI for Education Accelerator · AI Guidance & Governance · NYU AI Center of Excellence · Generative AI Primer · Key AI Resources ...",
    "length": 164,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University teaching and learning generative AI guidance",
    "title": "Teaching and Learning with Generative AI",
    "url": "https://stern.nyu.edu/portal-partners/faculty-staff/learning-science-lab/teaching-technologies/teaching-and-learning-generative-ai",
    "text": "[Skip to main content] \n\nOpen Menu\n\nSearch the NYU Stern SiteSearch\n\nSearch the NYU Stern SiteSearch\n\n# [Learning Science Lab] \\| Teaching and Learning with Generative AI\n\n# Teaching and Learning with Generative AI\n\nThe past few months have shown a significant increase in the popularity of generative AI (GenAI) tools - like ChatGPT - in and outside of the classroom. Here at the Learning Science Lab, we understand that drastic technological advances can feel overwhelming. However, we believe change can also be a great opportunity to innovate and educate one another.\n\n[**Explore our Generative AI resource**] \n\n## Brush up on new techniques and technologies.\n\nOur workshops are a great place to learn new skills and enhance your teaching.\n\n[Save Your Spot] \n\n### Questions? We're available weekdays, 9am-5pm to respond to email queries.\n\n[learning.science@stern.nyu.edu]",
    "length": 875,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University teaching and learning generative AI guidance",
    "title": "Student Learning with Generative AI - NYU",
    "url": "https://www.nyu.edu/faculty/teaching-and-learning-resources/Student-Learning-with-Generative-AI.html",
    "text": "Below are some general principles to consider when using generative AI in your studies. Follow Your Instructor's Guidance For Each Course.",
    "length": 138,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  },
  {
    "query": "site:nyu.edu New York University teaching and learning generative AI guidance",
    "title": "Adapting Assignments to Generative AI",
    "url": "https://www.nyu.edu/faculty/teaching-and-learning-resources/teaching-with-generative-tools/adapting-assignments-to-generative-AI.html",
    "text": "Adapting Assignments to Generative AI\n\n# Adapting Assignments to Generative AI\n\n--\n\nWhile there are many individual strategies faculty can adopt for assignments, they can be broadly grouped into three categories:\n\n- Forbidding: Students are told they should not use generative AI\n- Avoiding: Assignments are (re)designed so that generative AI is less relevant\n- Integrating: Students are allowed or required to use generative AI, so long as that use stays within guidelines and is acknowledged\n\nNote that as adoption of AI continues to grow, strategies of avoiding and forbidding are becoming less effective, as students can use AI in most assignments in most classes.\n\n### 1. Integrating Use of Generative AI\n\nIntegrating use of generative AI involves giving students explicit permission to use the tool in a course or on an assignment, but in approved ways. The list of possible ways these tools can be integrated into coursework is large and growing: a [list of strategies collected by UNESCO] on page 9 runs to nearly a dozen items.\n\nThe advantage of integrating these tools is that it will encourage students to discuss their use in the context of the class. The disadvantage is that understanding student use will require new effort by the instructor. Involving students in this way will also make them more like co-designers of the assignments, which has both advantages (more engagement) and disadvantages (less predictability.)\n\nSample statement for syllabus: Use of Gemini and related tools is allowed in this class, but only in ways noted in the assignments. (Taking credit for work you did not create is a violation of NYU’s Academic Integrity policy.) As with all assignments, learning from the work is your responsibility. You must use the tools in a way that involves effort you learn from.\n\nFor every assignment, you should also describe:\n\n- Be prepared to discuss your work in class or in conversation with me\n- What you learned from the work\n- Which tools and techniques you used and for which parts of the assignment\n\nWhere an instructor decides to design assignments that integrate generative AI, they should consider one or more of the following strategies:\n\n- Design multi-step assignments that invite student deliberation, analysis, critique, and decision during the creation process\n- Highlight the student’s responsibility for the accuracy of any work they submit, and the need to verify any references or claims in the text\n- Share examples of effective uses of the tool for brainstorming and iterating the output, rather than just copying and pasting the results of a single query\n\n### 2. Avoiding Use of Generative AI\n\nMaking generative AI less relevant means designing an assignment to require the kind of work where humans still significantly outperform machines.\n\nThe advantage of avoiding use of these tools is that assignments will be designed to require student effort. The disadvantage is that these assignments will be a moving target, as things the tools cannot do well this semester may become possible next semester, requiring regular review of their effectiveness. Strategies that worked in 2023, like asking for integrated text and images, are no longer effective for students using contemporary AIs.\n\nSample statement for syllabus:\n\nThough you are welcome to use generative AI tools to brainstorm in the early phases of an assignment, you are expected to produce the assignments themselves on your own. (Taking credit for work you did not create is a violation of NYU’s Academic Integrity policy.) The assignments have been designed around tasks or outputs the tools do not perform well, and your work will be graded down, perhaps substantially, if it fails to meet those expectations regardless of how it was created.\n\nWhere an instructor decides to design assignments that make use of generative AI less relevant, they should consider one or more of the following strategies:\n\n- Design assignments that require oral presentation or in-class discussion\n- Design assignments tightly tied to specific course readings or concepts\n- Design assignments that require integration of discussions in class\n- Ask for specific references or quotes from material studied in class\n- Design assignments with greater emphasis on process — iterative work, submission of rough drafts, preserving edit history\n- Collect early student thoughts about an assignment in class, to get a sense of how they work unaided\n\n### 3. Advising Against Use of Generative AI\n\nPersuading students not to use these tools for some or all assignments will require explaining that the things you want them to learn from the assignment require that they do the work themselves. It also asks students to self-police, as there is no regular way to detect use of these tools. Note that this strategy works less well than it did in 2023, as a majority of students have now adopted these tools.\n\nThe advantage of asking students not to use these tools is that this strategy can preserve some of the design of individual assignments or a whole course. The disadvantage is that while you can recommend against use of these tools, you cannot prevent their use. Given the relative difficulty in detecting use of these tools, academic integrity cases can be harder to adjudicate, because most evidence is circumstantial.\n\nSample statement for syllabus: You will only learn from these assignments if you do the work yourself. You should not use Gemini or other AI tools as a shortcut or substitute for drafting and editing work in this class. Taking credit for work you do not do is a violation of NYU’s Academic Integrity policy.\n\nAdvising against use of generative AI is compatible with designing assignments to avoid use of generative AI. Faculty may want to consider using elements of both strategies, instructing students not to use these tools and designing assignments that cannot easily be completed by these tools.",
    "length": 5915,
    "domain_restricted": true,
    "university": "New York University",
    "domain": "nyu.edu"
  }
]