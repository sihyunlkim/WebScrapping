[
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Examples of possible academic integrity policies that address ...",
    "url": "https://www.cmu.edu/teaching/technology/aitools/academicintegrity/index.html",
    "text": "Examples of possible academic integrity policies that address student use of generative AI tools - Eberly Center - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[Eberly Center] ## Teaching Excellence &amp; Educational Innovation\n[Eberly Center] &#160;&#8250;&#160;[Technology for Education] &#160;&#8250;&#160;[Generative AI Tools FAQ] &#160;&#8250;&#160; Examples of possible academic integrity policies that address student use of generative AI tools\n# Examples of possible academic integrity policies that address student use of generative AI tools\n*The following examples represent a range of options one could adapt or adopt, based on their teaching context and course&#8217;s student learning objectives.*\n## Example 1: Students may NOT use generative AI in any form.\nTo best support your own learning, you should complete all graded assignments in this course yourself, without any use of generative artificial intelligence (AI). Please refrain from usingAI tools to generate any content (text, video, audio, images, code, etc.) for an assignment or classroom exercise.Passing off any AI generated content as your own (e.g., cutting and pasting content into written assignments, or paraphrasing AI content) constitutes a violation of[CMU&#8217;s academic integrity policy]. If you have any questions about using generative AI in this course please email or talk to me.\n*Adapted from CMU colleagues in the Heinz College of Information Systems and Public Policy*&#160;\n## Example 2: Students may NOT use generative AI in any form.\nI expect that all work students submit for this course will be their own. I have carefully designed all assignments and class activities to support your learning. Doing your own work, without human or artificial intelligence assistance, is best for your achievement of the learning objectives in this course. In instances when collaborative work is assigned, I expect for the submitted work to list all team members who participated. I specifically forbid the use of ChatGPT or any other generative artificial intelligence (AI) tools at all stages of the work process, including brainstorming. Deviations from these guidelines will be considered violations of[CMU&#8217;s academic integrity policy]. Note that expectations for &#8220;plagiarism, cheating, and acceptable assistance&#8221; on student work may vary across your courses and instructors. Please ask me if you have questions regarding what is permissible and not for a particular course or assignment.\n*Adapted from Harvard University (*[*https://oue.fas.harvard.edu/ai-guidance*] *)*\n## Example 3: Students are fully encouraged to use generative AI.\nI encourage students to explore the use of generative artificial intelligence (AI) tools, such as ChatGPT, for all assignments and assessments. Any such use must be appropriately acknowledged and cited, following the guidelines established by[the APA Style Guide], including the specific version of the tool used. Submitted work should include the exact prompt used to generate the content as well as the AI&#8217;s full response in an Appendix. Because AI generated content is*not*necessarily accurate or appropriate, it is each student&#8217;s responsibility to assess the validity and applicability of any generative AI output that is submitted. Youmay not earn full credit if inaccurate, invalid, or inappropriate information is found in your work. Deviations from these guidelines will be considered violations of[CMU&#8217;s academic integrity policy].Note that expectations for &#8220;plagiarism, cheating, and acceptable assistance&#8221; on student work may vary across your courses and instructors. Please email me if you have questions regarding what is permissible and not for a particular course or assignment.\n*Adapted from Harvard University (*[*https://oue.fas.harvard.edu/ai-guidance*] *)*\n## Example 4: Students are fully encouraged to use generative AI.\nYou are welcome to use generative AI programs (ChatGPT, DALL-E, etc.) in this course.&#160; These programs can be powerful tools for learning and other productive pursuits, including completing some assignments in less time, helping you generate new ideas, or serving as a personalized learning tool.&#160;\nHowever, your ethical responsibilities as a student remain the same. You must follow&#160;[CMU&#8217;s academic integrity policy]. Note that this policy applies to all uncited or improperly cited use of content, whether that work is created by human beings alone or in collaboration with a generative AI. If you use a generative AI tool to develop content for an assignment, you are required to cite the tool&#8217;s contribution to your work. In practice, cutting and pasting content from any source without citation is plagiarism. Likewise, paraphrasing content from a generative AI without citation is plagiarism. Similarly, using any generative AI tool without appropriate acknowledgement will be treated as plagiarism.&#160;\n**Here are some specific expectations for your use of AI generation tools in this course:**\n* You can include AI generated content verbatim into a writing assignment with quotations and a citation.&#160;\n* You can paraphrase AI generated content with a citation.\n* You can include non-text AI generated content (images, video, code, etc.) with an appropriate citation, when expressly permitted in the assignment prompt.\n* You will conduct your own research and generate bibliographies yourself for topics that you have researched.\n* You will not use or present generative AI content that you pass off as your own work.&#160;\nFinally, it is important that you recognize that generative AI tools frequently provide users with incorrect information, create professional-looking citations that are not real, generate contradictory statements, incorporate copyrighted material without appropriate attribution, and sometimes integrate biased or offensive concepts. Code generation models may produce inaccurate outputs. Image generation models may create misleading or offensive content.&#160;\nWhile you may use these tools in the work you create for this class, it is important to note that you understand**you are ultimately responsible for the content that you submit.**Work that is inaccurate, biased, unethical, offensive, plagiarized, or incorrect will be treated as such during the evaluation of your work.&#160;\n*Adapted from CMU colleagues in the Heinz College of Information Systems and Public Policy*\n## Example 5: Students may use generative AI in some cases, but not others\nCertain assignments in this course will permit or even encourage the use of generative artificial intelligence (AI) tools, such as ChatGPT. When AI use is permissible, it will be clearly stated in the assignment prompt posted in Canvas. Otherwise, the default is that use of generative AI is disallowed. In assignments where generative AI tools are allowed, their use must be appropriately acknowledged and cited. For instance, if you generated the whole document through ChatGPT and edited it for accuracy, your submitted work would need to include a note such as &#8220;I generated this work through Chat GPT and edited the content for accuracy.&#8221; Paraphrasing or quoting smaller samples of AI generated content must be appropriately acknowledged and cited, following the guidelines established by[the APA Style Guide]. It is each student&#8217;s responsibility to assess the validity and applicability of any AI output that is submitted. You may not earn full credit if inaccurate on invalid information is found in your work. Deviations from the guidelines above will be considered violations of[CMU&#8217;s academic integrity policy].Note that expectations for &#8220;plagiarism, cheating, and acceptable assistance&#8221; on student work may vary across your courses and instructors. Please email me if you have questions regarding what is permissible and not for a particular course or assignment.\n*Adapted from Harvard University (*[*https://oue.fas.harvard.edu/ai-guidance*] *)*\n## Example 6: Students may use generative AI in some cases, but not others\nDuring some class sessions, we may leverage generative AI tools to support your learning, provide you with an opportunity to explore how they can be used, and/or&#160; better understand their benefits and limitations. Learning how to use AI is an emerging skill, and we will work through the implications of these evolving systems together, during class sessions. However, use of generative AI will be limited to exercises during class sessions. I will always indicate when and where use of AI tools during class sessions is appropriate (and not). Examples of use during ungraded classroom exercises might include:&#160;\n* brainstorming new ideas,\n* developing example outlines or approaches to your work, and/or\n* generating different ways to talk about a problem.\nIn contrast, you may*not*use AI tools to generate work for an assignment to be submitted for a grade, as this cannot be considered a substitute for developing the fundamental skills and expertise represented by the learning objectives of this course. Please note that generative AI tools rely on predictive models to generate content that may appear correct, but has been shown to sometimes be incomplete, inaccurate, taken without attribution from other sources, and/or biased. Consequently, an AI tool should not be considered a substitute for traditional approaches to research and you should complete all graded assignments without any assistance from AI tools. You are ultimately responsible for the content of the information you submit and may not attempt to pass off any work generated by an AI program as your own.&#160;\n*Adapted from CMU colleagues in the Heinz College of Information Systems and Public Policy*&#160;\n**Eberly Center\n**4765 Forbes Avenue\nTepper Quad, Suite 1310\nPittsburgh, PA 15213\n(412) 268-2896\n[Contact Us] \n![]![]![]![] &#160;This work is licensed under a&#160;[Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License].\n&#160;\n&#160;",
    "length": 10140,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "AI Guidelines - Computing Services - Office of the CIO - Carnegie Mellon University",
    "url": "https://www.cmu.edu/computing/services/ai/index.html",
    "text": "Generative Artificial Intelligence (AI) - Computing Services - Office of the CIO - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[Computing Services] ## [Office of the CIO] \n[Office of the CIO] &#160;&#8250;&#160;[Computing Services] &#160;&#8250;&#160;[Services] &#160;&#8250;&#160; Generative Artificial Intelligence (AI)\n# Explore Generative Artificial Intelligence (AI) at CMU\nGenerative AI (GenAI) helps you create text, images, music, and videos, just by describing what you need. These tools can support your learning, creativity, and work across many roles at CMU. Explore our resources below to learn the basics and get familiar with the tools available to you. Then, dive into building more advanced skills.\n## [Learn and Connect] \nDiscover campus AI events, topic-based communities, and other learning opportunities.\n## [Protected&#160;AI Tools] [] \nLearn about the AI tools that are safe to use within CMU&#8217;s environment.\n## [Use AI Safely at CMU] \nLearn how to use AI safely and ethically, following CMU&#8217;s policies and guidelines.\n* [About] \n* [Computing Services InfoCenter] \n* [CSS Awards and Recognition] \n* [News] \n* [Service Status] \n[Log In to Services] \n* [Computing Services Help Center] \n* [412-268-4357 (HELP)] \n* [it-help@cmu.edu]",
    "length": 1342,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Generative Artificial Intelligence (AI) - Computing Services",
    "url": "https://www.cmu.edu/computing/services/ai/",
    "text": "# Explore Generative Artificial Intelligence (AI) at CMU\n\nGenerative AI helps you create text, images, music, and videos—just by describing what you need. These tools can support your learning, creativity, and work across many roles at CMU. Just getting started? Check out our beginner guides and sample prompts to try today. Then, when you're ready, explore advanced tools, prompt techniques, and community learning opportunities.\n\n# Choose your AI journey…\n\n## Get Started with AI\n\n- [Meet AI] \n- [What can I use AI for?] \n- [How do I use AI?] \n- [Protected AI Tools You Can Use at CMU] \n- [Use AI Safely at CMU] \n\n## Build on Your AI Skills\n\n- [Protected AI Tools You Can Use at CMU] \n- [Prompt Library] \n- [Prompt Strategies for Power Users] \n- [How To Use Cloud AI APIs] \n- [Fine-Tuning Generative AI for Content Creation] \n- [Learn and Connect with Our AI Community] \n\n## Use Our Featured Tools\n\n- [AI Gateway] \n- [ChatGPT Edu] \n- [Gemini Web App] \n- [Microsoft Copilot] \n- [Notebook LM] \n- [Zoom AI Companion] \n\n**Need help getting started?** Browse our **[Prompt Library] ** for examples you can copy, adapt, and try today!\n\n- [About] \n- [Computing Services Intranet] \n- [CSS Awards and Recognition] \n- [News] \n- [Service Status] \n\n[Log In to Services] \n\n- [Computing Services Help Center] \n- [412-268-4357 (HELP)] \n- [it-help@cmu.edu]",
    "length": 1343,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "What’s the Eberly Center’s position on adapting teaching to generative AI (GAI) tools?",
    "url": "https://www.cmu.edu/teaching/gaitar/positionstatement.html",
    "text": "GenAI Position Statement - Eberly Center - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[Eberly Center] ## Teaching Excellence &amp; Educational Innovation\n[Eberly Center] &#160;&#8250;&#160;[GAITAR Initiative] &#160;&#8250;&#160; GenAI Position Statement\n# What&#8217;s the Eberly Center&#8217;s position on adapting teaching to generative AI (GAI) tools?&#160;\n## *GAI can be viewed as a challenge and/or an opportunity for students and instructors.*\nIn some contexts, GAI*has the potential*to enhance learning outcomes, student equity, or instructor efficacy/efficiency. However, in others, it may not, or actually be detrimental to learning, equity, or academic integrity. For a particular teaching context and learning objective, often, any of the outcomes above are plausible (see also the Eberly Center[FAQ on GAI]). Ultimately, the impacts of GAI may depend on the underlying teaching and learning principles that are at play given a particular implementation. Regardless,**rigorous****data directly comparing learning outcomes with and without student use of GAI are lacking.**\nConsequently, we do not view GAI as a &#8220;hammer&#8221; and we do not think every teaching and learning challenge is a &#8220;nail.&#8221; In other words, we are NOT advocating that instructors use GAI just to use it. Instead, we advocate an intentional, student-centered, inclusive, and evidence-based approach to adapting to GAI in teaching (described below).&#160;\nEberly colleagues welcome the opportunity to discuss the pros and cons of different possible strategies for adapting your CMU courses. Email us at[eberly-assist@andrew.cmu.edu].\n## *The impact of GAI on higher education is an open &#8220;teaching as research&#8221; question and the Eberly Center is here to help instructors.*\nBecause we do NOT yet know how its use will affect student learning or equity, our approach is to explore the impacts of genAI through action research (i.e., research to inform practice).**Our goal is to help CMU instructors collect, analyze, interpret, and disseminate data that directly measures the impacts of GAI on student learning and attitudes**, rather than relying entirely on intuition and/or theory to inform practice. We define data broadly, but it refers to direct measures. And, we always consider and test the alternative hypotheses that implementing GAI may increase, decrease, or not affect student outcomes. Leveraging our expertise in quantitative and qualitative education research methods,**our mission is to make it easier for instructors to leverage a data-informed, iterative approach to exploring innovations in teaching and learning.**\nContact us at[eberly-assist@andrew.cmu.edu] to discuss your ideas for innovating with and collecting data on the impacts of GAI tools in CMU courses.&#160;\n## *Adoption and study of GAI in teaching must navigate ethical concerns.&#160;*\nWe consider potential implementations and studies of GAI with an open mind, but with caution because there are conspicuous ethical concerns related to educational applications, depending on the use case, tool, and implementation (e.g., privacy, accessibility, data security, IP, costs to students, legal implications and more). With any use case or study, we seek to mitigate concerns and avoid harm.\n## *Learning objectives, backward design, and direct measures of student outcomes should guide explorations of the impacts of GAI.*\n### We advocate the following heuristic:\n1. Think intentionally about a learning objective and formulate a research question about it with respect to GAI. How might it affect student learning or equity?&#160;\n2. Then, design how one could collect data to test that question in a CMU course (i.e., learning with vs. without AI use OR which AI use works better for learning). What are possible sources of data directly measuring student learning or attitudes? What comparison groups are possible to infer causality in observed data?&#160;\n3. And finally, ideate and select options for how you might implement a gen AI tool to test your research question.\n4. What are possible implications for diversity, equity, inclusion and belonging?\nWe acknowledge that conducting the thought experiment above might result in your decision to NOT pursue the research question or implement gen AI in your teaching. Similarly, results of studies might influence whether or not you continue to employ GAI in your teaching. However, these choices would be OK with us because they would be the result of an intentional thought process.\nAnd, if you end up NOT pursuing a research question about GAI or do NOT use GAI at all, the Eberly Center can still support your study of other educational research questions or teaching interventions in CMU courses. We have other fellowships, programs, and 1-on-1 consults that are available to support teaching as research as part of your regular practice as educators!\n**We are here to help:****[eberly-assist@andrew.cmu.edu] **[] \n&#160;\n**Eberly Center\n**4765 Forbes Avenue\nTepper Quad, Suite 1310\nPittsburgh, PA 15213\n(412) 268-2896\n[Contact Us] \n![]![]![]![] &#160;This work is licensed under a&#160;[Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License].\n&#160;\n&#160;",
    "length": 5314,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Protected AI Tools You Can Use",
    "url": "https://www.cmu.edu/computing/services/ai/meet-ai/tools/ai-gateway/how-to/team.html",
    "text": "Protected AI Tools You Can Use - Computing Services - Office of the CIO - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[Computing Services] ## [Office of the CIO] \n[Office of the CIO] &#160;&#8250;&#160;[Computing Services] &#160;&#8250;&#160;[Services] &#160;&#8250;&#160;[Generative Artificial Intelligence (AI)] &#160;&#8250;&#160; Protected AI Tools You Can Use\n# ![] \nProtected AI Tools You Can Use\nThe AI tools listed on this page are available at CMU. When you sign in with your Andrew ID and password, each tool is FERPA-compliant and will not use your data to train its AI models.\n## Interested in New Tools?\nAI tools that have not yet been reviewed or licensed by CMU might not offer the same data protections and approved services.&#160;\nSubmit a[software request] for review and approval.\n# Use AI Safely at CMU\nBefore using CMU's protected AI tools, please review our[policies and guidelines for safe and ethical use].\n# DAO Accessibility Tools\nExplore[tools endorsed by the Digital Accessibility Office] that have AI capabilities.\n# Approved AI Tools\n## [AI Gateway] \n## [ChatGPT Edu] \n## [Gemini Web App] \n## [Microsoft Copilot] \n## [NotebookLM] \n## [Zoom AI Companion] \n## Tool Comparison Table\n|Tool|Purpose|Best For|Available To|Cost|\n[AI Gateway] |AI Developer tool makes AI models easier to access.|Accessing&#160; management to models via API keys.|Faculty and Staff|No cost; however an Oracle String is required to pass on any costs incurred from using a model endpoint.&#160;|\n[ChatGPT Edu] |Synthesizes info, summarizes, and generates content.|Research, writing, and problem-solving.|Faculty and Staff; Students sponsored by a faculty or staff member|$240 / per year|\n[Gemini Web App] |Google's AI that handles text, voice, and files.|Meeting summaries, working with Google Apps, and searching across formats.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n[Microsoft Copilot Chat] |AI support for Office tasks, images, and code.|Microsoft files, documents, and coding help.|Students, Faculty, and Staff|Available with your Andrew account.|\n[NotebookLM] |Creates AI-powered notebooks from uploads.|Organizing ideas, summarizing sources, and creating podcasts.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n[Zoom AI Companion] |Adds summaries and action items to meetings.|Real-time help during virtual meetings.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n**Note:**Available add-ons for protected AI tools have been thoroughly reviewed and vetted for use at CMU. For example, ChatGPT Edu with[Agents] is already available to paid ChatGPT Edu subscribers.\n* [About] \n* [Computing Services InfoCenter] \n* [CSS Awards and Recognition] \n* [News] \n* [Service Status] \n[Log In to Services] \n* [Computing Services Help Center] \n* [412-268-4357 (HELP)] \n* [it-help@cmu.edu]",
    "length": 2961,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Use AI Safely at CMU - Computing Services - Office of the CIO",
    "url": "https://www.cmu.edu/computing/services/ai/meet-ai/secure-ai.html",
    "text": "Use AI Safely at CMU - Computing Services - Office of the CIO - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[Computing Services] ## [Office of the CIO] \n[Office of the CIO] &#160;&#8250;&#160;[Computing Services] &#160;&#8250;&#160;[Services] &#160;&#8250;&#160;[Generative Artificial Intelligence (AI)] &#160;&#8250;&#160;[Meet AI] &#160;&#8250;&#160; Use AI Safely at CMU\n# ![] \nUse AI Safely at CMU\nAs Generative AI tools evolve, we must be aware of the associated data privacy, security, ethical, and legal concerns and use them responsibly.\n## Guidance\nCMU has partnered with the following AI services to ensure approved university contract terms are in place when these services are accessed through Web Login with your Andrew userID and password:\n* [ChatGPT Edu] \n* [Google NotebookLM] \n* [Google Gemini Web App] \n* [Microsoft Copilot Chat] \n* [Zoom AI Companion] \nThey may be used (including Custom GPTs, Google Gems, and Microsoft Copilot Agents) with any CMU data except[Controlled Unclassified Information (CUI)]. Always follow[CMU&#8217;s Data Classification Guidelines] and any sponsor/regulatory/contractual requirements.\n# Checklist:&#160;Use AI Safely at CMU\nBefore using generative AI tools, follow these steps to keep your data secure and use AI responsibly:\n* **Review the**[Guidelines for Data Classification] to ensure the security of university data and protect the privacy of our students and colleagues.\n* **Report suspicious activity**, such as phishing or synthetic media (e.g., Deepfakes), to the[Information Security Office].\n* **Copyright guidance regarding authorship is still unclear.**Adding personal modifications to Generative AI output may increase the likelihood of copyright protection, but exercise caution.&#160;Please be aware that current legal rules state that auto-generated content does not get copyright protection.\n* **Review AI outputs for accuracy.**A human-in-the-loop is required to catch hallucinations or errors.\n* **Always use CMU-licensed and approved tools when logging in with your Andrew userID and password**. Institutional safeguards do not cover tools not approved by CMU and should be considered &#8220;use at your own risk.&#8221;\n* Review the university&#8217;s[Computing] and[Information Security] policies.\nAlso, consider these steps for your role:\n* **Faculty:**[Add a syllabus statement] explaining what AI use is permitted in your course. Follow the[Eberly Center&#8217;s guidance] on course design and responsible AI use.\n* **Staff:**Review the[data types] you can safely input into generative AI tools.\n* **Students:**Read CMU's[Academic Integrity Policy], especially the \"Unauthorized Assistance\" section.\n* **Researchers:**Consult your grant agency&#8217;s guidelines.\n# Important\nRemember, you should only use CMU-licensed and approved tools that require logging in with your Andrew userID and password. This ensures your data is protected under the university&#8217;s[Computing] and[Information Security] policies.\n# CMU Guidelines\n* [Academic Integrity Policy] \n* [Computing Policy] \n* [Course Design and Teaching] \n* [Data Classification] \n* [Digital Copyright and DMCA] \n* [Information Security] \n# Know the Difference&#8212;Public vs. Protected AI Tools\n## Public AI Tools\nPublic AI tools can be identified as:\n* Any AI tool for which you create an account with a personal email (e.g., Claude, ChatGPT, Jules, etc.).\n* Any AI tool that you log into with your Andrew account that does not bring you to a CMU Web Login page.\nWhen you use a public AI account, like a personal or free ChatGPT account, or don&#8217;t log in with your Andrew account:\n* You risk losing control over how your data is stored, processed, and reused.\n* Your data could be stored and used to train the model.\n* CMU data could be sold to advertisers or used to train the AI model.\nRemember, these tools should only be used for general exploration. Never use public AI tools with student data, confidential research, or sensitive administrative tasks.\n## Protected AI Tools\nWhen you access one of[CMU&#8217;s approved AI tools] through a protected environment:\n* You retain control over how your data is stored, processed, and reused.\n* Your data remains private and secure.\n* Your data will not be sold to advertisers or used to train AI models.## Sharing in GenAI\n**General Sharing**: Custom GPTs, Google Gems, or Microsoft Copilot Agents that include Private, Restricted, or Restricted-Specified data as defined in[CMU&#8217;s Data Classification Guidelines] may only be shared with individuals who have the appropriate access rights, as determined by the[CMU Data Stewards].\n**Research Data Sharin**g: If a Custom GPT, Google Gem, or Microsoft Copilot Agent contains research data subject to a Data Use Agreement (DUA), the terms of the DUA must be followed. DUAs may impose further restrictions beyond CMU&#8217;s data classification requirements. Such research data is typically classified as Restricted-Specified under CMU's[Data Classification Guidelines].\n* [About] \n* [Computing Services InfoCenter] \n* [CSS Awards and Recognition] \n* [News] \n* [Service Status] \n[Log In to Services] \n* [Computing Services Help Center] \n* [412-268-4357 (HELP)] \n* [it-help@cmu.edu]",
    "length": 5303,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "CMU, Accenture Advance AI in Workforce Training",
    "url": "https://www.cs.cmu.edu/news/2025/cmu-accenture-advance-ai",
    "text": "CMU, Accenture Advance AI in Workforce Training\n# [![] Carnegie Mellon University School of Computer Science] \n[Skip to Main Content] Search**\nSearch**\n# CMU, Accenture Advance AI in Workforce TrainingThe Carnegie Mellon Accenture Center of Excellence for AI Will Address Demand for Technology Skills Development\nAaron AupperleeWednesday, October 22, 2025[**Print this page.] \n![] The Carnegie Mellon Accenture Center of Excellence for AI will advance the understanding and application of AI in workforce development and strategy.\nOrganizations face a growing demand for technology skills among their workers. Carnegie Mellon University and[Accenture] are uniting the university's deep expertise in developing and deploying artificial intelligence systems for real-world change with Accenture's industry-leading training solutions to advance the understanding and application of AI in workforce development and strategy.&#160;\nThis new initiative &#8212; the[Carnegie Mellon Accenture Center of Excellence for AI] (ACE-AI) &#8212; will explore the potential of AI to enhance the training process, create modular content personalized for each learner, and capture and analyze learning data for improved outcomes. ACE-AI aims to take personalized training experiences to new heights by building AI agents that serve as tutors, coaches and career counselors, while extracting insights to optimize training methods and identify at-risk learners for timely interventions.\n\"Technology continues to reshape the workplace, and at a particular speed over the past few years with the widespread adoption of AI,\" said Kishore Durg, global lead for Accenture[LearnVantage]. \"For organizations to keep pace with technology transformation, they need skilling programs for their people that can quickly adapt and scale as the business landscape shifts.\"&#160; &#160;\nA multidisciplinary team of CMU faculty, working with learning experts from Accenture, will drive the center's work. Researchers in computer science, human-computer interaction and public policy will use the latest AI tools to design systems that enhance the training process and achieve industry goals.&#160;\n\"At Carnegie Mellon, we see AI as a force multiplier for how people learn and work. We are excited to combine our expertise in AI research with Accenture's unparalleled reach in workforce training,\" said[Seth Copen Goldstein,] an associate professor in the[Computer Science Department] at CMU's School of Computer Science (SCS). \"ACE-AI will explore how to deliver AI that makes learning more effective, trustworthy and human-centered. We will support people at every level, from the C-suite to the frontline, by rapidly generating tailored content, deploying intelligent tutors and coaching agents, and using analytics to surface needs and opportunities in real time. Together, we are reimagining how organizations prepare their people to thrive in an AI-enabled future.\"\nA key component of the endeavor is developing dynamic intelligent tutoring systems and AI agents that deliver customized training plans and personalized content to learners.&#160;\nThroughout every stage, the system will capture, analyze and model learning analytics to provide adaptive training with continuous feedback. It will also offer insights to individual learners and a clear view of how AI-powered engagement drives efficiency in the learning process.\nGoldstein leads CMU's ACE-AI team, which also includes SCS faculty members[Christopher Bogart],[Can Kultur],[Bruce McLaren] and[Jaromir Savelka]; The team also includes Christophe Combemale, Ramayya Krishnan, and Beibei Li from the[Heinz College of Information Systems and Public Policy]; and members of the[Technology for Effective and Efficient Learning Lab],[McLearn Lab], and[AI Measurement Science and Engineering Center].&#160;&#160;\nFrom Accenture LearnVantage, Durg is sponsoring this effort with leadership from[Majd Sakr], also faculty in SCS, as well as Swati Sharma, Michael Conway and Aditya Palnitkar.\nFor more information about the center,[visit the ACE-AI website].\n**For More Information**\nAaron Aupperlee | 412-268-9068 | aaupperlee@cmu.edu",
    "length": 4154,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "AI is Here to Stay. How do we Govern It?",
    "url": "https://www.heinz.cmu.edu/media/2024/June/ai-policy-regulation",
    "text": "startwitterfacebookenvelopelinkedininstagramyoutubelogoalert-redalerthomeleft-quotechevronhamburgerminusplussearchtrianglex\n\nSearch CMU HeinzSearch\n\n## AI is Here to Stay\n\n* * *\n\nHow do we regulate it?\n\n# AI is Here to Stay. How do we Govern It?\n\n* * *\n\nBy Bill Brink\n\nBefore Pandora’s box was an idiom, it was, well, a box–actually, a jar, in the original Greek tale. Told never to open it, Pandora couldn’t resist, unleashing a torrent of evil and misery upon the world. But what gets lost in the phrase’s modern usage is the box’s final ingredient: hope.\n\nWhat computer scientists, technologists, policy makers and ethicists must do now, in an age where artificial intelligence is inextricably intertwined with our everyday lives and growing more powerful by the month, is flip the idiom on its head: Proceed in such a way that the hope AI represents can escape the box and be brought to bear against the problems of our society while its risks remain squashed inside, marginalized and mitigated. And the hope has never been greater.\n\n“We sometimes joke about really smart people, 'They’re going to cure cancer someday,'” said Martial Hebert, the Dean of Carnegie Mellon University’s School of Computer Science. “Well, these people working on AI _are_ going to cure cancer. All the main human diseases, I totally believe, are going to be cured by giant computer clusters, doing large-scale machine learning and related techniques. And we’re just scratching the surface now.”\n\n![Watch video on YouTube] \n\n[iframe] \n\n## The Birthplace of AI\n\n* * *\n\nCMU Professor Rayid Ghani is one of dozens of expert faculty that make Carnegie Mellon a leader in AI innovation.\n\nBut who makes the rules? Who has jurisdiction? Do we need a new Cabinet department or can we bake it into existing government agencies?\n\nThe European Union took the lead by passing the AI Act, the world’s first comprehensive law governing AI. U.S. states are introducing bills regulating aspects of AI, such as deepfakes, privacy, generative AI and elections. In October, the White House issued a broad AI executive order that provided for monumental innovation and addressed security, privacy, equity, workplace disruption and deepfakes. The bipartisan Future of AI Innovation Act, introduced in the U.S. Senate in April, aims to promote American leadership in AI development via partnerships between government, business, civil society, and academia, and the Secure Artificial Intelligence Act, introduced in the Senate in May, seeks to improve the sharing of information regarding security risks and vulnerability reporting.\n\nSenate Majority Leader Chuck Schumer has made a point of educating lawmakers about the benefits and risks of AI; in March, he announced $10 million in funding for the National Institute of Standards and Technology (NIST) to support the recently established U.S. AI Safety Institute.\n\nWhile governing something in which very little is clear, one thing is.\n\n“Don’t regulate the technology,” said Ramayya Krishnan, the Dean of CMU’s Heinz College of Information Systems and Public Policy, “because the technology will evolve.”\n\n## **What are we regulating?**\n\nArtificial intelligence has existed in some form for decades, but advances in computing power have accelerated both its capabilities and the conversations about its risks. The recent improvement of generative AI tools like ChatGPT, DALL-E and Synthesia, which can create text, images and video with startling realism, increased the calls for governance. Silicon Valley and lawmakers generally agree on the pillars of this governance: AI models should be safe, fair, private, explainable, transparent and accurate.\n\nWe have mechanisms in place to investigate and punish those who commit crimes. Whether you rob a bank with a ski mask or AI-generated polymorphic malware, the FBI still has jurisdiction. But can the current institutions keep up with this rapidly changing technology, or do we need a central clearinghouse?\n\nBoth. There are more than 400 federal agencies. If, say, the European Union or Red Cross is attempting to liaise with the U.S. government on AI, it can’t do so across hundreds of different bureaucratic institutions.\n\n![Watch video on YouTube] \n\n[iframe] \n\n## \"A pro-human view of AI\"\n\n* * *\n\nHeinz College Dean Ramayya Krishnan is an international leader in AI innovation.\n\n“You do need to boost capability in oversight,” Krishnan said. “The Equal Employment Opportunity Commission has to have AI oversight capability. The Consumer Financial Protection Bureau has to have AI oversight capability. In other words, each of these executive agencies that have regulatory authority in specific sectors needs to have the capability to govern use cases where AI is used. In addition, we need crosswalks between frameworks in use in the U.S., such as the NIST AI Risk Management Framework, and frameworks developed and deployed in other jurisdictions to enable international collaboration and cooperation.”\n\n## **“Real-world risks and impacts at the problem formulation stage”**\n\nNIST plays an important role in any conversation regarding AI and its risks. Within NIST, Reva Schwartz, the institute’s Principal Investigator for AI Bias, bridges the gap between algorithms and humanity. She contributed to the creation of [NIST’s AI Risk Management Framework] and studies the field from a socio-technical perspective, asking questions about AI’s safety and impact on people.\n\nThe responsible development and deployment of AI goes beyond making sure the model works. Ideally, the system will be accurate, and not prone to hallucination as some generative AI models are. It will be fair, especially when its outputs lead to a significant impact on people’s lives as in the cases of criminal sentencing and loan approval. It will be explainable and transparent: How did it reach its conclusion? It will not reveal identifiable personal information that may have been included in the information used to train it.\n\n“Currently, people tend to look at the AI lifecycle as just the quantitative aspects of the system,” Schwartz said. “But there’s so much more to AI than the data, model and algorithms. To build AI responsibly, teams can start by considering real-world risks and impacts at the problem formulation stage.”\n\nBy including safe and responsible AI practices during the model's creation rather than slapping them on after the fact, organizations can use these practices to gain a leg up in the market.\n\n“In practice, promoting these principles often not only doesn’t hurt innovation and economic growth; it actually helps us develop better quality products,” said Hoda Heidari, the K&L Gates Career Development Assistant Professor in Ethics and Computational Technologies at Carnegie Mellon and co-lead of CMU’s Responsible AI initiative, housed in the Block Center for Technology and Society.\n\n## **The aviation corollary**\n\nHebert and Schwartz both compared the governance of AI to that of air travel, and the allegory works on two levels. Passengers don’t need to know how the airplane works to fly; they only have to trust that the pilots do, and that they will operate the plane properly and within the rules. Safe air travel is also made possible by the agreement between airlines and manufacturers to share details of any incident, no matter how small, that the entire community can learn from.\n\nWhile decades of air travel records exist, we’re too early in the development of AI–or generative AI, at least–for that kind of catalog.\n\n![Watch video on YouTube] \n\n[iframe] \n\n## Potential for Good\n\n* * *\n\nMartial Hebert believes AI at scale will help us solve monumental societal problems.\n\n“Something that I’ve been negatively surprised with is how haphazard some of the practices around AI are,” Heidari said. “This is not a fully mature technology. We don’t currently have well-established standards and best practices. And as a result, when you don’t have that frame of reference, it is very easy for it to be misused and abused, even with no bad intention.”\n\nHeidari recently contributed to a [report] on the safety of advanced AI from the AI Seoul Summit, a joint effort between South Korea and the United Kingdom. Krishnan, Heidari and Professor Rayid Ghani [testified before Congress last summer] and met with legislators from both parties to educate them on the opportunities and risks of generative AI.\n\n“We’re in the center of the ongoing policy debate in Washington and elsewhere around, how should we regulate this new tool that will likely impact every industry?” said Steve Wray, the executive director of the Block Center. “We’re also in the middle of trying to understand, what does it mean for the future of work?”\n\nDecades of work, from Turing to Minsky to Simon and Newell to Hinton, have led us to this point. Lawmakers the world over, from the EU to Capitol Hill to state houses, must ensure we harness the hope of AI, for the greater good, and slam the lid shut on the rest.",
    "length": 8971,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Protected AI Tools You Can Use",
    "url": "https://www.cmu.edu/computing/services/ai/meet-ai/tools/ai-gateway/index.html",
    "text": "Protected AI Tools You Can Use - Computing Services - Office of the CIO - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[Computing Services] ## [Office of the CIO] \n[Office of the CIO] &#160;&#8250;&#160;[Computing Services] &#160;&#8250;&#160;[Services] &#160;&#8250;&#160;[Generative Artificial Intelligence (AI)] &#160;&#8250;&#160; Protected AI Tools You Can Use\n# ![] \nProtected AI Tools You Can Use\nThe AI tools listed on this page are available at CMU. When you sign in with your Andrew ID and password, each tool is FERPA-compliant and will not use your data to train its AI models.\n## Interested in New Tools?\nAI tools that have not yet been reviewed or licensed by CMU might not offer the same data protections and approved services.&#160;\nSubmit a[software request] for review and approval.\n# Use AI Safely at CMU\nBefore using CMU's protected AI tools, please review our[policies and guidelines for safe and ethical use].\n# DAO Accessibility Tools\nExplore[tools endorsed by the Digital Accessibility Office] that have AI capabilities.\n# Approved AI Tools\n## [AI Gateway] \n## [ChatGPT Edu] \n## [Gemini Web App] \n## [Microsoft Copilot] \n## [NotebookLM] \n## [Zoom AI Companion] \n## Tool Comparison Table\n|Tool|Purpose|Best For|Available To|Cost|\n[AI Gateway] |AI Developer tool makes AI models easier to access.|Accessing&#160; management to models via API keys.|Faculty and Staff|No cost; however an Oracle String is required to pass on any costs incurred from using a model endpoint.&#160;|\n[ChatGPT Edu] |Synthesizes info, summarizes, and generates content.|Research, writing, and problem-solving.|Faculty and Staff; Students sponsored by a faculty or staff member|$240 / per year|\n[Gemini Web App] |Google's AI that handles text, voice, and files.|Meeting summaries, working with Google Apps, and searching across formats.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n[Microsoft Copilot Chat] |AI support for Office tasks, images, and code.|Microsoft files, documents, and coding help.|Students, Faculty, and Staff|Available with your Andrew account.|\n[NotebookLM] |Creates AI-powered notebooks from uploads.|Organizing ideas, summarizing sources, and creating podcasts.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n[Zoom AI Companion] |Adds summaries and action items to meetings.|Real-time help during virtual meetings.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n**Note:**Available add-ons for protected AI tools have been thoroughly reviewed and vetted for use at CMU. For example, ChatGPT Edu with[Agents] is already available to paid ChatGPT Edu subscribers.\n* [About] \n* [Computing Services InfoCenter] \n* [CSS Awards and Recognition] \n* [News] \n* [Service Status] \n[Log In to Services] \n* [Computing Services Help Center] \n* [412-268-4357 (HELP)] \n* [it-help@cmu.edu]",
    "length": 2961,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Generative AI Tools FAQ - Eberly Center - Carnegie Mellon University",
    "url": "https://www.cmu.edu/teaching/technology/aitools/index.html",
    "text": "Generative AI Tools FAQ - Eberly Center - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[Eberly Center] ## Teaching Excellence &amp; Educational Innovation\n[Eberly Center] &#160;&#8250;&#160;[Technology for Education] &#160;&#8250;&#160; Generative AI Tools FAQ\n# Generative AI Tools FAQ\nThe rapid evolution of AI tools like ChatGPT, DALL&#183;E 2, and GitHub Copilot, along with their widespread media coverage and ever increasing ubiquity within other tools, raises important questions for teaching and learning. In what ways are GenAI tools opportunities or threats? When is it appropriate for students to use them? Do instructors need to adapt their approaches?&#160;\nWhile such questions aren&#8217;t entirely new, the answers are complex and depend on disciplinary norms, course goals, assignments, and student backgrounds. Unsurprisingly, recent advances in AI have sparked both excitement and concern among instructors.\nIn response to inquiries from CMU colleagues, we&#8217;ve compiled a list of[frequently asked questions]. Our answers draw on evidence-based, inclusive teaching strategies, CMU policies, and the current state of AI tools. We approached this work with two guiding beliefs:\n1. The challenges and opportunities posed by AI may feel daunting, but instructors can and do continue to teach effectively.\n2. Students will not automatically make dishonest choices simply because new technologies exist.\nWe hope this resource supports thoughtful, intentional teaching with evolving technologies. To discuss your specific context or to share a use case that could inform this resource please contact us at&#160;[eberly-assist@andrew.cmu.edu].\n# Generative AI Teaching as Research (GAITAR)\n![gaitardiagram-air-highlight.png] \n*Do generative AI tools increase, decrease, or not change student learning and equity? In what teaching contexts?&#160;*Take a look at what CMU instructors are investigating with us.\n[Visit our GAITAR website] \n&#160;\n## 1. What are generative AI tools?\nArtificial Intelligence (AI) tools can generate art, computer code, or natural language which may often be difficult to distinguish from human work. Using a range of parameters, you can prompt a given tool to*instantly*respond to simple and complex requests, like writing comparative essays, producing the steps for some math problems, writing or fixing bugs in code, generating an image, and writing emails.&#160;\nPerhaps the most well known new AI tool is[ChatGPT,] a &#8220;chatbot&#8221; which can produce writing and code, including common assignment forms such as reading reflections, generating and/or fixing code, or research essays. If it cannot fulfill a request, it will respond with clarifying questions. Because ChatGPT is not a &#8220;mind,&#8221; but a model trained on existing writing, its results may sound convincing but be factually incorrect. And the tool cannot be used to assess the validity or sourcing of information that it has generated. (More reliable research alternatives are collected in this document from[CMU LIbraries].) ChatGPT is being updated rapidly, and many other AI chatbotsare coming on the market, including some specialized for programming languages.\nIt is important to know that students may use these tools in more creative ways than simply generating a full, final product. Anecdotal evidence from students across the country suggests that students are using AI tools to look up information, create study guides, brainstorm possible topics or approaches to problems, write outlines or pseudocode, and polish or correct the English grammar of their own written work.&#160;\nBecause AI tools can generate natural language, functioning code, or artistic products, they can be concerning for instructors who rely on assessing these forms of student work. It is important to continue to be*intentional*in your teaching choices, because being reactive (only) isn&#8217;t sustainable in our technologically advancing world. You can take this opportunity to think deeply about your courses, and the kinds of knowledge, skills, values, and attitudes you want your students to develop. As with any new technology &#8211; such as graphing calculators, search engines, or Wikipedia &#8211; the[fundamental principles of how learning works] and what we can intentionally do to facilitate learning remains largely the same.&#160;If you would like to discuss your courses in light of emerging AI tools with an Eberly Center consultant, please contact[eberly-assist@andrew.cmu.edu].\n&#160;\n## 2. How should I write an academic integrity policy that includes generative AI tools?\nThe university&#8217;s policy on academic integrity is not changing as a response to generative AI tools. According to CMU&#8217;s Office of Community Standards and Integrity,[CMU&#8217;s academic integrity policy] already implicitly covers such tools, as they may be considered a type of unauthorized assistance. However, this policy is intentionally designed to allow instructors to define what is &#8220;authorized&#8221; vs. &#8220;unauthorized&#8221; and what constitutes &#8220;plagiarism&#8221; and &#8220;cheating.&#8221;*We recommend that instructors carefully examine their own policies to make these distinctions clear in both writing and verbally to students.**\n*\n**Please see these[example syllabus policies] which include prohibiting and encouraging generative AI use as well as blend of these policies.&#160;**\n**Note that expectations vary between instructors and what is considered authorized assistance in one course may not be acceptable in yours; clarity is key, especially because expectations, norms, and policies may vary across instructors.\nWe recommend that you adopt an academic integrity policy that considers the following:\n* Whether or not AI tools are considered authorized or unauthorized assistance and in what circumstances.&#160;\n* How students should cite assistance from or content/ideas generated by either AI tools or humans.&#160;\nAdditionally, consider doing the following:\n* Engage students in transparent discourse about the rationale behind your policies, learning objectives and assignments.\n* Discuss academic integrity with students, including its importance and your expectations. Don&#8217;t assume that students know what is acceptable and not in your context. Norms change across disciplines, cultures, and courses. Sometimes this is referred to as &#8220;the hidden curriculum.&#8221;\n* Include improvement across assignments, rather than performance alone, as a component of how you calculate grades.&#160;&#160;\n* Talk to your students about AI tools as they relate to all of the above.\nFor more general help, see this resource on[crafting your own academic integrity policy].&#160;\n&#160;\n## 3. How should I talk with my students about the use of generative AI tools in my course?\nEach semester, students take multiple courses, all of which may have different expectations and policies.*It is important to talk with your students about your own expectations so they don&#8217;t make incorrect assumptions*. If your policies are not explicitly stated, then your students may NOT be able to effectively interpret what kinds of AI use are authorized or not in your course (for example, in cases of suspected violations of academic integrity).[See FAQ 2] for what you can consider as you write an academic integrity policy.\nThere are several access points to start a conversation. We encourage you to be curious and have an open mind when discussing AI tools with students, rather than assuming or focusing on the worst-case scenario.&#160;\n***Communicate the purpose of your assignments and why they will benefit your students&#8217; learning.\n***Knowing why they are doing an assignment can help students to increase their motivation.How does the assignment connect to your course&#8217;s learning objectives and to the world beyond your course. Describe the skills you want your students to practice and/or the knowledge you&#8217;d like them to gain through completing an assignment. Alternatively, for larger assignments, you could ask students to think about the purposes of the assignment in small groups or as a class before you share your perspective. You can also give students time to reflect on how the assignment connects to their personal or professional goals or values.\n***Convey confidence in your students' ability.\n***Let them know your goal is to support their learning. Discuss your course learning objectives and why they matter. Provide positive encouragement that students can succeed with effort, good strategies, and support (see[Promoting a Growth Mindset]).\n***Talk about academic integrity early on and why it's important.***\nDefine what plagiarism, unauthorized assistance, and cheating look like in the context of your course because students may assume another course&#8217;s policies are the same as yours or may have a different cultural understanding of academic integrity. Provide examples of what kinds of work is appropriate and not. Use AI tools, like ChatGPT, as an example and discuss the ways in which it can be appropriately used (if any) in the context of your course and discipline.&#160;\n***Ask students about their experiences with AI tools generally.***\nHave they heard of them? Do they know what they do? For many, these are exciting, fun tools. Acknowledging that can provide a way to connect with your students. If students are familiar with AI tools, what kinds of prompts have they plugged into them and what did they think of the responses? Try playing with an AI tool yourself using both class-related and non-class-related prompts so you can also share about your experiences.&#160;\n***Be transparent about why AI tools are concerning or exciting to you in the context of your course.***\nThis is an opportunity to explain how your assignments are structured to help students develop key skills and expertise, and how the use of AI may disrupt or enhance this process, either helping or hindering student development in the short and long term. Articulate for your students the inherent inequities that arise when some students are generating their own work for the class, while others are automating that labor. Being transparent about the purpose of your policies around academic integrity and assignment guidelines helps students understand why they are beneficial, rather than arbitrary.&#160;\n***Give students multiple opportunities or means to ask questions about academic integrity.\n***Starting from the perspective that students do not want to cheat, allow students to ask questions about academic integrity and AI tools without judgment. This can be as simple as inviting questions using any of the above approaches and by encouraging students to contact you outside of class or in office hours. Remind students that it&#8217;s better for them to ask you well before an assignment is due than to operate from a place of uncertainty and anxiety as they are trying to complete it.\n&#160;\n## 4. How can I design my assignments to facilitate students generating their own work?\nRegardless of the technological environment, the first thing to consider in assessment design is always whether what you are having students*do*aligns with what and how you want them to*learn*. Be transparent with your students about why your assessments are designed to support their learning and help them develop the skills and patterns of thought that they will want to rely on in their future professions. Additional structure that illuminates the*how*of their assessments, like grading criteria, evaluation rubrics, and assignment briefs, will often make it easier for your students to engage in the work than not.&#160;\n***Scaffold assessments:***\nBreak your assessments into smaller pieces that will build on each other. The final product could be a culmination of the prior components, which also had the chance to benefit from formative feedback and low-stakes evaluation. Alternatively, consider requiring multiple drafts and value improvement across drafts in response to your feedback. Provide in-class time for students to work on these components but allow them to expand on or refine their work outside of class as well. Rather than focusing on the product alone, scaffolded assessments like this prioritize the process of generating the final deliverable. Students are less likely to turn to quick solutions for a deliverable if they&#8217;ve already put in considerable time and effort, and gained their own expertise, to the point where they feel confident in their own ability to do quality work in a timely fashion.&#160;\n***Schedule assessments to balance workload:\n***Students may turn to AI tools if they are feeling stressed, overwhelmed, unsupported, or out of time. Even if they are motivated and engaged, external pressures and incentives can often lead them to make choices that save time rather than enhance their learning. Consider timing assessments to take place outside of typical exam weeks (see also[Assign a Reasonable Amount of Work]). Prioritize preserving students&#8217; breaks (for wellness) and giving a longer time horizon for when items are due. Build in some time in-class for students to work on assignments or projects.\n***Focus on process*****:**\nAsk students to explain their process and reflect on their own learning. This could look like:&#160;\n* a reflection checklist or rubric\n* a list of specific steps they took, what they could have done differently, and why\n* annotations on an assignment or deliverable justifying the creative choices they made (or a separate deliverable reflecting on and referencing specific aspects of their previous work).\nYou might consider assessing students on how much they have improved rather than on one instance of their performance, which traditional exams and final papers often do. This could mean awarding additional points for students who are able to articulate mistakes, why the mistake was made, and how they can avoid them in the future.\n***Design assessments to make learning visible through connections:***\nIn his 2013 book*Cheating Lessons: Learning from Academic Dishonesty*, James Lang defines &#8220;original student work&#8221; as that in which students &#8220;create an original*network of connections.&#8221;*This network can be made from various sources that the student is uniquely positioned to curate (e.g., information presented in the course, from other courses in their curriculum, their personal experiences, and external sources they&#8217;ve encountered), and is helpful for learning as those connections between their prior knowledge and new course content make students more likely to remember and be able to apply the new information in the future. This idea can be leveraged in assessment design, where the emphasis is less on the originality of the ideas students are generating (countless scholars have already analyzed the same poem, or have written a similar line of computer code and their work is out there), and more on how students relate these disparate ideas to one another. This can be accomplished by reframing assignment descriptions and rubric criteria, as well as considering the types of deliverables that best align with the learning objectives and which allow students to demonstrate the original network they&#8217;ve created (see also[Designing Aligned Assessments]). Remember that providing an environment of positive support, which instills in your students the confidence to generate their own unique and successful ideas, can go a long way in promoting students&#8217; motivation.\n***Provide choice, creativity, and flexibility for assignments*****:**\nStudents may turn to plagiarism or AI tools when they lack motivation to complete assignments. One way to increase the value perceived by students (thus increasing their motivation to complete them authentically) is to provide more choice on the assignment deliverable. For instance, if your goal is to assess how students synthesize, evaluate, and communicate about multiple sources, some students may choose to write an essay, while others could demonstrate those same skills in a video or by designing an infographic, as long as the deliverable demonstrates the required learning objectives. Consider the component skills your assignment is targeting and what competencies students must demonstrate. Then design an assignment prompt that includes these skills, but which allows more choice in what the final product looks like. Finally, design a rubric with criteria that are agnostic of the form of the deliverable.[Click here] for additional examples and considerations for designing assessments that allow for student choice.&#160;&#160;\n***Avoid over-reliance on hand-written deliverables, in-class evaluations, or oral exams and presentations:\n***We do not recommend drastically changing your assessments to exclusively or excessively rely on the aforementioned approaches*as a reaction to concerns regarding generative AI tools.*While one or more of these approaches may appear to be a simple solution, these changes could raise more difficulties than they solve, particularly for reasons of equity and inclusion. For example, some of these approaches may inadvertently disadvantage English language learners or students requiring accommodations for disabilities ([see also FAQ 5]). Prioritizing student success means providing an environment where everyone has an equitable opportunity to demonstrate their capabilities. Timed, hand-written exams, for example, may disadvantage students who know the material well, but are unable to hand-write their answers quickly. Oral presentations may put extra stress on students with anxiety, who then are faced with additional challenges which their peers do not face. Does completing a writing assignment during a class session, without the ability to adequately revise while drafting, authentically and fairly assess written communication skills across students? We suggest reflecting on who will be advantaged or disadvantaged by particular assessment choices and how well they align with your highest priority learning objectives. Ultimately, a mix of assessment approaches and providing support for student success maximizes equity and inclusion.\n***Don&#8217;t necessarily redesign all assessments to focus on the perceived, current limitations of AI tools:&#160;\n***All new technologies have limitations. However, limitations change over time as technologies are refined by their developers. The capabilities of AI tools have evolved rapidly. A tool may now (or soon) perform well on a task on which it performed poorly six months ago. For example, natural language generators, like ChatGPT, are trained on historical data that needs to exist and be available to the tool online prior to the training. When it was originally released, Chat GPT was not particularly good at responding to prompts about current events. It also struggled to cite peer reviewed literature accurately, could not leverage data that was protected by paywalls, such as JSTOR articles, and could not reference classroom discussions. Nevertheless, AI technologies evolve just as the new data they train upon and generate evolves. Therefore, some of the limitations of ChatGPT described above have changed and will continue to change over time. Consequently, designing assignments around any current limitations of an AI tool&#160; may be a temporary solution, but not a sustainable one. Instead, consider some of the strategies discussed previously.\n&#160;\n## 5. What equity and inclusion considerations should I be thinking about?\nUnauthorized assistance, cheating, and plagiarism create inequities; all are unfair to students who do the work themselves. However,*some approaches to preventing academic dishonesty, or students&#8217; use of AI tools, may inadvertently create inequities or marginalize some students*. All teaching strategies have pros and cons, so we recommend that you consider potential implications for equity and inclusion.\n***Designing assessments:***\nSome assessment strategies directly support equity and inclusion. These includeproviding student choice when appropriate in assignment deliverables or topics, varying the type of required assessments or deliverables, strategically leveraging low stakes assessments, scaffolding high stakes assignments to include milestones and drafts, and more (see also&#160;[How to enhance inclusivity and belonging in teaching] &#160;and&#160;[Creating a Welcoming Classroom Climate]. However, other strategies may disadvantage certain students. For instance, some commonly discussed potential strategies to eliminate the use of AI tools include intentionallyshifting assessment designs toward hand-written deliverables, in-class evaluations, or oral exams.Relying exclusively or excessively on these approaches may prevent English language learners or students with disabilities requiring accommodations from fully demonstrating their learning. Additionally, in-class writing or other time-limited assessments may not align well with learning objectives. Adopting such approaches may result in assessing students&#8217; speed more than their true competency. Consider whether speed is a high priority learning objective or a fair assessment criteria across your students. For additional support on determining how assessments may impact students with disabilities or how to make appropriate accommodations for CMU students, please contact the[Office of Disability Resources].&#160;\n***Considerations for choosing resources:***\nRequiring students to purchase particular texts or resources (e.g., the newest editions of textbooks, subscriptions to educational cases including newspapers, or purchasing sample data) to avoid the expertise of certain AI tools may disadvantage students with limited resources and cause undue financial burdens. Consider how you can provide such resources for free through Canvas or University Libraries. Additionally, if you are encouraging use of AI tools, consider whether or not they are digitally accessible to all learners. Please carefully consider the legal considerations of requiring students to use AI tools in your courses ([see FAQ 8])&#160;\n***AI tool output may be biased:\n***AI tools will reproduce any latent biases in the data on which it was trained. Depending on the prompt, AI tool output can directly cause harm to underrepresented or marginalized students via[microaggressions]. Also, relying on these tools will inherently bias student work towards mainstream, existing ideas, if the data they train on is biased or not representative of underrepresented or marginalized student identities. Consequently, some applications of AI tools for education may be at odds with efforts to center diversity, equity, inclusion, and belonging. Careful consideration must be given to how to still engage with[marginalized ideas or viewpoints.] \n&#160;\n## 6. How can I integrate generative AI tools like ChatGPT into my course?\n*Remember that AI Tools are web resources, and like other such tools may not always be accessible to you or your students. Before planning any activities or assignments using this tool, ensure you and your students can go online and successfully and equitably access it ([see also FAQ 5]). Additionally, carefully consider the legal considerations of using or requiring AI tools in your course ([see FAQ 8]).*\nAs with any new technology, there are often exciting avenues for new or enhanced learning experiences. It is important to be transparent with your students about the purpose you have in mind. Let them know the best way to approach the technology to maximize their learning. Try connecting this purpose to one of your existing learning objectives.\n### What generative AI tools have been vetted by CMU?\nA growing list of tools have been vetted by CMU that are FERPA compliant and therefore able to be used for teaching and learning purposes.GenAI tools currently licensed by Computing Services include:&#160;[Microsoft Copilot],[ChatGPT edu], Google&#8217;s[Gemini], and[NotebookLM].\nIMPORTANT NOTES FOR MAINTAINING FERPA COMPLIANCE:&#160;\n1. Individuals must be logged in as instructed via CMU authenticated mechanisms.&#160;\n2. Not all tools listed on Computing Services site are FERPA compliant and are typically indicated as such (see CMU&#8217;s[Google Workspace for Education webpage here] showing &#8220;Core&#8221; vs &#8220;Additional&#8221; services). If you are uncertain about whether or not a tool you are using or want to use is meeting these privacy and legal requirements, don&#8217;t hesitate to[contact us].\n3. If you wish to use tools*that are not yet FERPA compliant (i.e., any tool that the university has not vetted and approved as FERPA compliant)*,&#160;[reach out to us] to get the tool vetted.### Make a clear statement in your course syllabus about the use of these tools\nIf you are allowing or encouraging the use of generative AI tools, consider adding language to your generative AI syllabus statement to let your students know that Microsoft Copilot is a tool vetted by the university for compliance with the Americans with Disabilities Act (ADA) and the Family Educational Rights and Privacy Act (FERPA) and for other considerations.\nSample syllabus language:[Microsoft Copilot] provides data protection when accessed with your AndrewID. Unlike open commercial tools, Microsoft will not retain your prompts or responses to train its AI models when using CMU's licensed version and appropriately logged in with your Andrew credentials.\n### If you would like to integrate AI tools into your course, here are some ideas:\n***Explore the limitations*****:**\nLet your students explore the capabilities and limitations of AI generation. Guide them on big questions surrounding what defines things like communication and interaction. For example, if a GenAI tool like ChatGPT writes your emails for you, are you really communicating? Have your students think about the nature of the data an AI tool pulls from and its intersections with ethics. For example, what is the range of &#8220;inappropriate requests&#8221; and why? What might your students want to change about an AI tool&#160; to make it more useful for their lives? What does it mean to create with or without AI assistance? How might the use of an AI tool enhance equity or create inequities?\n***Spot the differences:\n***Prepare a class session where students attempt to identify differences between two pieces of writing or art or code, one created by their peers, and the other created by an AI. In advance, choose a set of prompts to provide to small groups of students to input into the AI. For example, ask students to request a paragraph, email, or poem from a GenAI tool in a particular style or from a certain perspective to a specific audience on a topic. Next, ask each group to write their own response to a different prompt and collect them. Then match the student- and AI-generated responses to the same prompt. Give each pair to a group. Be sure you don&#8217;t give students the same prompt that they wrote on. Challenge your students to identify differences in tone, clarity, organization, meaning, style, or other relevant disciplinary habits of mind, as well as which sample was AI-generated.&#160;\nIf you&#8217;re teaching a math course or computer science course, input some homework problems, and have your students critique where the AI succeeds or not (and how it could improve) or articulate alternative solutions. Can your students determine whether code was written by humans or an AI?&#160;&#160;&#160;\n***Facilitate discussion:\n***Have students prompt a GenAI tool to generate discussion questions for the next class session, then have students create their own responses to those questions. The GenAI tool can also ask follow-up questions and responses of its own, and students can continue their discussions with AI assistance. This approach to discussion facilitation could work well in small groups first, with a large group debrief afterwards. This helps students engage and learn about the topic while fostering and sustaining discussion, but it will also bring up interesting secondary questions. For example: Will the small groups have all learned and discussed the same things? Different things? Did the GenAI tool lead some groups off topic?\n***Language prompts:\n***Assign a topic and let your students come up with different ways to input it into a GenAI tool. Then task them with writing the same thing, but in a different way. Ask your students to explain their decisions. How might they change the language? Why? What rhetorical strategies could make it sound better, worse, more beautiful, more parsimonious, or more confusing? Have your students take on the role of an instructor and &#8220;grade&#8221; the GenAI tool on its output.&#160;\n***Generate samples for students to critique*****:**\nHave your students enter your assignment prompt into a&#160;GenAI tool. Then ask them to use your grading criteria/rubric to evaluate the output that the tool generates. This can be a helpful way to provide &#8220;sample&#8221; work to your students who may be looking for examples or curious about what a &#8220;good&#8221; and &#8220;bad&#8221; version of the deliverable looks like. You can also include your own comments and critiques and use the AI-generated output like you would use an example of a past student&#8217;s work. This approach not only enhances transparency of grading criteria, but also helps students practice and get feedback on necessary skills.\n***Have fun****:**\n***Have a GenAI tool write an academic integrity policy forbidding its use. Ask it to write an email to students&#8217; pets. After requesting that it write in another language, compare the output to other translation algorithms. Input an unsolvable math or coding problem into a GenAI tool. Be creative! Regardless, talk about what it means to do things &#8220;the human way;&#8221; have your students make a list of all the things they would rather do than have an AI tool do for them, then have them ask an AI tool to write up that list and compare!\nSee[additional ideas for classroom learning activities leveraging AI tools that generate code or text] and[considerations for responsible use of AI tools] (created by colleagues in the Heinz College of Information Systems and Public Policy).&#160;\n&#160;\n## 7. How can I tell if students are using generative AI (e.g., what detection tools are available)?\nThe Eberly Center recommends extreme caution when attempting to detect whether student work has been aided or fully generated by AI. Although companies like Turnitin offerAI detection services,*none have been established as accurate.*\nIn addition to false positives and false negatives, detection tools may often produce inconclusive results. A detection tool can provide an estimate of how much of a submission has the characteristics of AI-generated content, but the instructor will need to use more than just that number to decide whether the student violated the academic integrity policy. For example, an instructor will need to have a plan for how to proceed if a tool estimates that 34% of a submission was moderately likely to be AI-generated. Even very strong evidence that a student used AI may be irrelevant unless you have a clear[academic integrity policy] establishing that the student&#8217;s use of the AI tool constitutes &#8220;unauthorized assistance&#8221; in your course. Furthermore, research suggests that the use of detection tools may disproportionately impact English language learners.&#160;&#160;\nUntil (and after) robust and stable AI detection tools are available, we recommend that you consider the variety of instructional design and teaching strategies provided in this resource. You might first want to consider if AI output will pose a problem for your teaching and learning context. Start by trying out a few applicable tools using your assignment prompt to see if you need to make any adjustments ([see FAQ 4]).\n&#160;\n## 8. What legal implications should I consider before using an AI tool in my course?\nThe university vets teaching technologies for pedagogical value, compliance with both the[Family Educational Rights and Privacy Act] (FERPA) and the[Americans with Disabilities Act] (ADA), security, and stability. Before using any technology tool or app, including AI tools, ensure that its use falls within the university&#8217;s legal guidelines.&#160;\nFor more information or help finding a vetted tool that fits your and your students&#8217; needs, please contact[eberly-assist@andrew.cmu.edu] to schedule a consultation.\n### **Can I require students to use an AI tool to complete an assignment?**\nWe encourage you to use a[CMU vetted generative tool (see FAQ 6)]. As long as these tools are used with an Andrew email/ID, students&#8217; data will be kept confidential.\nFor example, when using Co-pilot, this statement should appear near the prompt entry box:\n![Statement reading: Your personal and company data are protected in this chat.] \nNote that this will NOT appear if you do not sign in with your Andrew email!\nConsumer tools that have not been vetted through the university and/or are not FERPA compliant (i.e., student work, which is part of their academic record, is being shared with third-party individuals and/or platforms), means that students cannot legally be required to create an account to use an AI tool for course assignments or work. Note that this is and always has been true for any third-party, unvetted platform or app! Therefore, if you plan to use such tools in your course, you will need an alternative plan for any student who does not want to create an account.\nConsumer tools that have not been vetted by the university and/or are not FERPA-compliant (i.e.,&#160;student work, which is part of their academic record, is being shared with third-party individuals and/or platforms) means that instructors cannot legally require students to create accounts and/or use these tools to complete course assignments.\nNote that this has always been true for any unvetted third-party platform or app. Therefore, if you plan to use these tools in your course, you must**provide an alternative**for students who choose not to create an account.&#160;\n***For example:**&#160;*If the original plan was for students to, individually, enter a prompt question into a non-FERPA compliant tool and analyze the response generated, then here are just two types of alternatives you could offer:\n**Alternative 1:**&#160;in the case of a student does not have an account -- work with a partner to enter a prompt question into ChatGPT and analyze the response.\n**Alternative 2:**&#160;outside of the tool environment, students generate the prompt language and the instructor inputs it into the tool and shares the responses with the class, and then students analyze the response.\nIf you would like to discuss ideas or alternative assignments for your course(s), please contact[eberly-assist@andrew.cmu.edu] to schedule a consultation.\n### **Can I prohibit the use of AI tools in my course?**\nAs the instructor, you are allowed to prohibit the use of AI tools in your course. (See[FAQ 2] on how to**write an academic integrity policy**that includes generative AI tools.) If you choose to do so, make sure to**be transparent about why**you are not allowing their use (see[FAQ 3] for examples on how to**talk with your students about the use of AI tools)**, and remember that detection is extremely limited, so enforcement may be both difficult and unreliable (see[FAQ 7] for more explanation).\n### **Can I encourage students to purchase a subscription to a particular generative AI tool?**\nPlease consider whether the cost of the tool may disadvantage students with limited resources and cause undue financial burden. Additionally, if you are encouraging the use of AI tools, consider whether or not they are digitally accessible to all learners. (See[FAQ 5] for other equity considerations.)\nEberly Center consultants can meet to discuss the particular context of your course and, if necessary, help you navigate the process. Please contact[eberly-assist@andrew.cmu.edu] to schedule a consultation.\n### **What kinds of student data or work can be shared with an AI tool platform (and by whom)?**\nThe main concern with sharing student work relates to students&#8217; privacy rights. FERPA protection begins after an instructor accepts an assignment for assessment and grading. If you are permitting the use of generative AI in your course, that is*not*FERPA complian, students are allowed to (but, again, should not be required to) submit their own work into the AI tool. However, you should set up an assignment workflow where students export their course work from the tool (e.g., saving the work as a PDF), which they then submit for review and grading using a FERPA compliant tool like Canvas. The instructor should not need to access the AI tool directly to see or grade the submitted work.\nSome instructors may be interested in using an AI tool to grade student work. If you choose to do so, every effort must be made to anonymize the student&#8217;s work by not connecting that work to any Directory Information on the student (see the[FERPA] guidance for examples of Directory Information).\nIf you would like to discuss various tools to assist with grading, please contact eberly-assist@andrew.cmu.edu to schedule a consultation.[See also FAQ 9&#160;] [What should instructors consider before using GenAI for grading and feedback?] \nFor more on the use of AI tools for various academic contexts, please see the[Guidance Memorandum from University Contracts (current as of Summer 2023).] \n### **What legal issues about using outputs generated by AI should my students and I be aware of?**\nIn terms of copyright, the US Copyright Office and recent court decisions have stated that the originator must be a human being to claim copyright protection, so work made by AI will not be considered copyrightable.\nLegal principles apply to generative AI outputs. An AI tool may have inherent biases and inaccuracies from its training, and using problematic statements generated by AI can subject users to legal liabilities.\n### **How can the use of generative AI tools be acknowledged and cited?**\nOpenAI[provides an example] of how to acknowledge the use of ChatGPT:*&#8220;The author generated this text in part with GPT-3, OpenAI&#8217;s large-scale language-generation model. Upon generating draft language, the author reviewed, edited, and revised the language to their own liking and takes ultimate responsibility for the content of this publication.&#8221;&#160;*\nSeveral style guides also offer instructions on how to cite content created by generative AI tools including:&#160;[APA] &#160;|&#160;[Chicago] &#160;|&#160;[MLA] \n## NEW! 9. What should instructors consider before using generative AI for grading and feedback?\nThe introduction and evolution of generative AI (genAI) tools continues to disrupt higher education in ways that are challenging to navigate. These tools seem to offer potential ways to enhance or circumvent learning, depending on how they are used and to what end.\n[See our guide to&#160;questions to consider before using generative AI for grading and feedback.] \n&#160; &#160;\n**Eberly Center\n**4765 Forbes Avenue\nTepper Quad, Suite 1310\nPittsburgh, PA 15213\n(412) 268-2896\n[Contact Us] \n![]![]![]![] &#160;This work is licensed under a&#160;[Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License].\n&#160;\n&#160;",
    "length": 39780,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "GAITAR - Eberly Center - Carnegie Mellon University",
    "url": "https://www.cmu.edu/teaching/gaitar/index.html",
    "text": "GAITAR Initiative - Eberly Center - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[Eberly Center] ## Teaching Excellence &amp; Educational Innovation\n# The Generative AI Teaching As Research (GAITAR) Initiative\n# Eberly Center launches 3-year Generative AI Initiative\nIn October 2023, the Eberly Center launched the Generative Artificial Intelligence Teaching as Research (GAITAR) Initiative to measure the impacts of the generative artificial intelligence (GAI) tools on students&#8217; learning and educational experiences at Carnegie Mellon University. This three-year initiative is funded by the Provost, Vice Provost for Teaching and Learning Innovation, and Eberly Center.\nThe emergence and evolution of GAI tools represents a major disruption to norms in higher education.&#160;[The Eberly Center&#8217;s position on GAI] &#160;is that it can be viewed as both a challenge*and*opportunity for teaching and learning. However, the impacts of GAI on teaching, learning, and the student experience are unknown. How instructors adapt to or implement GAI in their educational ecosystem may increase, decrease, or not change student learning or equity in outcomes.\nConsequently, we designed the GAITAR Initiative to help CMU instructors&#8217;**adapt, innovate, research, and disseminate.**These four pillars leverage Eberly Center expertise in teaching as research (TAR), evidence-based pedagogy, technology-enhanced learning, and inclusive teaching.\n## GAITAR Initiative programs and services aim to synergistically:&#160;\n1. **Create and sustain communities of practice&#160;**among CMU educators to foster adaptive and innovative teaching strategies, evidenced-based teaching, and applied education research.\n2. **Cultivate and support**the design and implementation of effective**teaching adaptations and/or innovations**across disciplines and educational contexts at CMU.\n3. **Rigorously measure the impacts**of educational uses of GAI tools on student learning, equity in student outcomes, and the student experience at CMU.\n4. **Center student voices and diversity, equity, inclusion, and belonging**as instructors adapt to and/or innovate with GAI in teaching and learning.\n5. **Disseminate**and foster adoption of**transferable, evidence-based, educational applications of GAI tools**, at both CMU and beyond.\n## GAITAR@Scale\n*GAITAR@Scale&#160;**projects focus on reproducibility and generalization of scholarship across many teaching contexts for a few high-priority learning objectives and research questions.*\n[See the GAITAR@Scale projects] \n## GAITAR Fellowships\n*Do generative AI tools (such as ChatGPT, Dall-E, Copilot) increase, decrease, or not change student learning and equity? In what teaching contexts?*\n[See What GAITAR Fellows Are Investigating] \n## Eberly Center's Position on GenAI\n1. GAI can be viewed as a challenge and/or an opportunity for students and instructors.\n2. The impact of GAI on higher education is an open &#8220;teaching as research&#8221; question and the Eberly Center is here to help instructors.\n3. Adoption and study of GAI in teaching must navigate ethical concerns.\n4. Learning objectives, backward design, and direct measures of student outcomes should guide explorations of the impacts of GAI.\n[Read More About Our Position] \nEberly colleagues welcome the opportunity to discuss the pros and cons of different possible strategies for adapting your CMU courses. Email us at[eberly-assist@andrew.cmu.edu].\n# To achieve these objectives, the Eberly Center is launching seven new complementary programs:\n## GAITAR Institutes\n*... generate potential GAI innovations and TAR projects across many teaching contexts and learning objectives*\n&#160;\n**[Learn more] **\n## GAITAR Fellowships\n*... incentivize and lower barriers to instructor-led**GAI teaching innovation and TAR across**many**teaching contexts and**many**learning objectives*\n&#160;\n**[Learn more] **\n## GAITAR@Scale\n*... systematically collects generalizable data at scale (i.e., across**many**instructors, courses, and teaching contexts) for a**few**high-priority research questions*\n&#160;\n**[Learn more] **\n## Eberly Center Student Partners (ESPs) Co-Creator Program\n*... centers DEIB and student voices within instructors&#8217; adaptations to and innovations with GAI while providing high-impact educational experiences**for student co-creators*\n&#160;\n**[Learn more] **\n## GAITAR Scholarly Writing Program\n*... support GAITAR Fellows in writing and disseminating their research through weekly writing accountability groups (WAGs); workshops on scholarly writing productivity and writing and publishing TAR/SoTL; writing consultations; manuscript reviews; and writing retreats*\n&#160;\n**[Learn more] **\n## GAI Special Interest Groups (SIGs)&#160;\n*... build communities of practice regarding challenges, opportunities, and lessons learned across**many**teaching contexts and learning objectives*\n## GAI Working Groups\n*... create and disseminate guidance, resources, and pilot projects on how best to adapt to GAI within specific educational contexts and/or learning objectives*\n&#160;\n**Eberly Center\n**4765 Forbes Avenue\nTepper Quad, Suite 1310\nPittsburgh, PA 15213\n(412) 268-2896\n[Contact Us] \n![]![]![]![] &#160;This work is licensed under a&#160;[Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License].\n&#160;\n&#160;",
    "length": 5440,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Chapter in New Report Explores Role of Generative AI in Using ...",
    "url": "https://www.heinz.cmu.edu/media/2025/May/chapter-in-new-report-explores-role-of-generative-ai-in-using-copyrighted-material",
    "text": "\n \n Report Is Part of Volume on Economic Issues at Intersection of AI and Copyright Policy Generative artificial intelligence (AI) facilitates the compilation of huge volumes of data, which often include copyrighted materials. While debates about the legality of the process abound, in a recent report issued by the US Copyright Office, researchers examine to what degree allowing or restricting this practice serves the economic objectives of copyright. In short, does AI shift the balance between incentives and access, and what policies could recalibrate that balance? The chapter, written by researchers at Carnegie Mellon University, appears in a book on AI and copyright policy edited by the chief economist at the U.S. Copyright Office. The report features discussions by members of an ad hoc committee of economic scholars convened to address economic issues at the intersection of AI and copyright policy. “One of the goals of copyright is to facilitate cultural and scientific innovation, which requires balancing the economic rewards that can be captured by producers of creative works with their ability to access existing works as part of the creative process,” explains Michael D. Smith, Professor of Information Technology and Public Policy at Carnegie Mellon’s Heinz College, who contributed to the report. “That cumulative creative process is the foundation of innovation, and some consider generative AI as similar because it ingests existing works and produces something ostensibly new,” Smith continues. “In that sense, the algorithms are engaging in the sort of innovation process that copyright policy aims to encourage.” However, two questions are key, say the researchers: What social benefits come from developers having access to training materials? And what are the implications for the incentives of human creators to produce works? In the report, they consider the second question by examining the impact of using generative AI to compile data on commercial incentives to create and on intrinsic incentives to create, and by suggesting licensing as a potential solution. “There are few available policy instruments to combat incentives for holders of copyrights to further limit public access to their works in response to ingestion,” suggests Rahul Telang, Professor of Information Systems and Management at Carnegie Mellon’s Heinz College and at its Tepper School of Business, who contributed to the report. “Indeed, the only potentially viable solution may be a licensing requirement for ingestion, although it can come with challenges and limitations, including issues related to transparency and enforcement.” The report includes a discussion of the issues associated with requiring copyright holders to opt out of having their copyrighted data used to train models, which the European Union mandates. This would change the nature of current copyright protections by shifting the burden for action from the user of the copyrighted material to the copyright owners, which represents a meaningful burden on rightsholders, the authors say.   Summarized from a chapter in Identifying the Economic Implications of Artificial Intelligence for Copyright Policy: Context and Direction for Economic Research (Lutes, B., Ed.), “The Effects of AI Ingestion on Rightsholders’ Incentives,” by Smith, MD (Carnegie Mellon University), and Telang, R (Carnegie Mellon University). Copyright 2025 U.S. Copyright Office. All rights reserved. About Heinz College of Information Systems and Public Policy The Heinz College of Information Systems and Public Policy is home to two internationally recognized graduate-level institutions at Carnegie Mellon University: the School of Information Systems and Management and the School of Public Policy and Management. This unique colocation combined with its expertise in analytics set Heinz College apart in the areas of cybersecurity, health care, the future of work, smart cities, and arts &amp; entertainment. In 2016, INFORMS named Heinz College the  #1 academic program  for Analytics Education. For more information, please visit  www.heinz.cmu.edu. \n \n",
    "length": 4117,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "AI Division Publications",
    "url": "https://www.sei.cmu.edu/library/ai-division-publications/",
    "text": "AI Division Publications\nicon-carat-rightmenusearchcmu-wordmark\n[Carnegie Mellon Universitycmu-wordmark] \n# AI Division Publications\n###### September 23, 2025•Collection\n###### By\nSoftware Engineering Institute\nThis collection includes publications authored by AI Division staff, showcasing their work at the forefront of artificial intelligence and machine learning.\n###### Publisher\nSoftware Engineering Institute\n###### Topic or Tag\n[Artificial Intelligence] [Artificial Intelligence Engineering] \n### Collection Items\nResults per page102550100\n[![Concept-ROT: Poisoning Concepts in Large Language Models with Model Editing]] \n[#### Concept-ROT: Poisoning Concepts in Large Language Models with Model Editing\n] ###### September 4, 2025•White Paper\n##### By[Keltin Grimes,] [Marco Christiani,] [David Shriver,] [Marissa Connor] \nThis work introduces Concept-ROT, a method for inserting trojans into LLMs that trigger on high-level concepts, bypassing safety and enabling harmful behaviors.\n[**Read**] \n[![Physics-Informed Deep B-Spline Networks for Dynamical Systems]] \n[#### Physics-Informed Deep B-Spline Networks for Dynamical Systems\n] ###### March 21, 2025•White Paper\n##### By[Zhuoyuan Wang (Carnegie Mellon University, Department of Electrical and Computer Engineering),] [Raffaele Romagnoli (Duquesne University),] [Jasmine Ratchford,] [Yorie Nakahira (Carnegie Mellon University, Department of Electrical and Computer Engineering)] \nIn this work, we integrate B-spline functions and physics informed learning to form physics-informed deep B-spline networks that can efficiently learn parameterized PDEs with varying initial and boundary conditions.\n[**Read**] \n[![Red-Teaming for Generative AI: Silver Bullet or Security Theater?]] \n[#### Red-Teaming for Generative AI: Silver Bullet or Security Theater?\n] ###### February 7, 2025•White Paper\n##### By[Michael Feffer,] [Anusha Sinha,] [Wesley H. Deng (Carnegie Mellon University),] [Zachary C. Lipton (Carnegie Mellon University),] [Hoda Heidari] \nIn this work, we identify cases of red-teaming activities in the AI industry and conduct a survey of to characterize the scope, structure, and criteria for AI red-teaming practices.\n[**Read**] \n[![Building Hybrid B-Spline And Neural Network Operators]] \n[#### Building Hybrid B-Spline And Neural Network Operators\n] ###### December 16, 2024•White Paper\n##### By[Raffaele Romagnoli (Duquesne University),] [Jasmine Ratchford,] [Mark H. Klein] \nThis paper proposes a B-spline neural operator for real-time CPS safety, combining neural networks with inductive bias to predict system behavior on a quadrotor.\n[**Read**] \n[![Transparency in the Wild: Navigating Transparency in a Deployed AI System to Broaden Need-Finding Approaches]] \n[#### Transparency in the Wild: Navigating Transparency in a Deployed AI System to Broaden Need-Finding Approaches\n] ###### June 5, 2024•White Paper\n##### By[Violet Turri,] [Katelyn Morrison (Carnegie Mellon University),] [Katherine-Marie Robinson,] [Collin Abidi,] [Adam Perer (Carnegie Mellon University),] [Jodi Forlizzi (Carnegie Mellon University),] [Rachel Dzombak] \nThis case study focuses on incorporating various data sources and connecting with a broad ecosystem of stakeholders to support our analysis.\n[**Read**] \n[![Assessing LLMs for High Stakes Applications]] \n[#### Assessing LLMs for High Stakes Applications\n] ###### May 31, 2024•White Paper\n##### By[Shannon Gallagher,] [Jasmine Ratchford,] [Tyler Brooks,] [Bryan Brown,] [Eric Heim,] [Bill Nichols,] [Scott McMillan,] [Swati Rallapalli,] [Carol J. Smith,] [Nathan M. VanHoudnos,] [Nick Winski,] [Andrew O. Mellinger] \nThis work explores LLM deployment in intelligence reporting, highlighting key challenges in data, scaling, and assessment.\n[**Read**] \n[![Gone but Not Forgotten: Improved Benchmarks for Machine Unlearning]] \n[#### Gone but Not Forgotten: Improved Benchmarks for Machine Unlearning\n] ###### May 29, 2024•White Paper\n##### By[Keltin Grimes,] [Collin Abidi,] [Cole Frank,] [Shannon Gallagher] \nThis paper describes and proposes new methods to evaluate unlearning algorithms, revealing key limitations through experiments across state-of-the-art models and vision datasets.\n[**Read**] \n[![Trustworthy by Design]] \n[#### Trustworthy by Design\n] ###### May 20, 2024•White Paper\n##### By[Carol J. Smith] \nThe rise of generative AI sparks demand for human-centered, trustworthy systems. Decades of HCI can guide responsible design for dynamic AI challenges.\n[**Read**] \n[![Tales from the Wild West: Crafting Scenarios to Audit Bias in LLMs]] \n[#### Tales from the Wild West: Crafting Scenarios to Audit Bias in LLMs\n] ###### May 12, 2024•White Paper\n##### By[Katherine-Marie Robinson,] [Violet Turri,] [Carol J. Smith,] [Shannon Gallagher] \nThis work introduces a scenario-based audit using RPG-style prompts where LLMs role-play characters to reveal bias in descriptions of individuals around them.\n[**Read**] \n[![Deep Operator Learning-Based Surrogate Models for Aerothermodynamic Analysis of AEDC Hypersonic Waverider]] \n[#### Deep Operator Learning-Based Surrogate Models for Aerothermodynamic Analysis of AEDC Hypersonic Waverider\n] ###### May 6, 2024•White Paper\n##### By[Khemraj Shukla (Brown University, Applied Mathematics Department),] [Jasmine Ratchford,] [Luis Bravo (DEVCOM Army Research Laboratory),] [Vivek Oommen (Brown University, Applied Mathematics Department),] [Nicholas Plewacki (DEVCOM Army Research Laboratory),] [Anindya Ghoshal (DEVCOM Army Research Laboratory),] [George Karniadakis (Brown University, Applied Mathematics Department)] \nIn this work, we built a DeepONet-based surrogate model for 3D flow, showing the two-step method improves shock prediction and interpretability vs. baseline models.\n[**Read**] \n[![An Analytic Solution to Covariance Propagation in Neural Networks]] \n[#### An Analytic Solution to Covariance Propagation in Neural Networks\n] ###### May 2, 2024•White Paper\n##### By[Oren Wright,] [Yorie Nakahira (Carnegie Mellon University, Department of Electrical and Computer Engineering),] [José Moura (Carnegie Mellon University, Department of Electrical and Computer Engineering)] \nThis paper presents an analytic moment propagation technique to accurately characterize the input-output distributions of deep neural networks.\n[**Read**] \n[![Augmenting Intelligence: Ethical Challenges in the Age of AI]] \n[#### Augmenting Intelligence: Ethical Challenges in the Age of AI\n] ###### March 25, 2024•White Paper\n##### By[Carol J. Smith] \nAs AI evolves rapidly, this paper offers a framework to guide responsible review, integration, and management of emerging technologies in organizations.\n[**Read**] \n[![Towards Better Understanding of Domain Shift on Linear-Probed Visual Foundation Models]] \n[#### Towards Better Understanding of Domain Shift on Linear-Probed Visual Foundation Models\n] ###### October 27, 2023•White Paper\n##### By[Eric Heim] \nThis study finds some visual foundation models fail domain transfer, as linear probes on shifted data often show low training accuracy and poor transfer.\n[**Read**] \nNo results available for the selected filters.\n##### SHARE\n* [**] \n* [**] \n* [**] \n* [**] \n* [**] \n[Ask a question about this Collection]",
    "length": 7218,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Shaping AI Policy — The Link",
    "url": "https://magazine.cs.cmu.edu/shaping-ai-policy",
    "text": "Shaping AI Policy &mdash; The Link - The Magazine of CMU&#39;s School of Computer Science\n[\n0\n] \n[Skip to Content] \n[![The Link - The Magazine of CMU&amp;#39;s School of Computer Science]] \n[Fall 2025] \nOpen MenuClose Menu\n[![The Link - The Magazine of CMU&amp;#39;s School of Computer Science]] \n[Fall 2025] \nOpen MenuClose Menu\n![] \n# **SHAPING AI POLICY**\n***TRICIA MILLER KLAPHEKE***\n# **SCS Faculty Advise Government Officials on Benefits, Threats and Regulations Required for Ethical AI Implementation**\nThe executive order on artificial intelligence that President Joseph Biden announced in October of 2023 followed years of conversation between policymakers and academics on how AI can be used responsibly. Though not an entirely new phenomenon, faculty from across CMU have since provided expertise and a sense that AI can help policymakers in specific circumstances.\n![Martial Hebert, Dean of SCS] \nMartial Hebert, Dean of SCS\n![Tom Mitchell] \nTom Mitchell, Founders University Professor in Computer Science\nSCS Dean**Martial Hebert**said the revolution around AI reminds him of the digital revolution, except that advances are coming much more rapidly. As with many political issues, the reaction to that is often binary: some leaders fear that AI is evil and could lead to increasingly dangerous outcomes, while others feel AI is a force for good that can solve many problems. The reality, SCS faculty agree, lies somewhere in the middle.\nWhile it is important for experts advising government officials to have a deep understanding of both technical details and public policy surrounding AI issues, sending a consistent message to government entities will help coordinate efforts across individual circumstances. Hebert identified three priorities for the government in crafting policy: training people to use AI, researching potential new uses for AI, and establishing frameworks to make AI trustworthy. Explaining the nuances of each of those priorities can be difficult.\nCarnegie Mellon and SCS are uniquely positioned to advise U.S. government officials at the federal, state and local levels on such policies. In addition to having expertise in AI, SCS faculty collaborate broadly across the university, working closely with faculty from the Heinz College of Information Systems and Public Policy, the Dietrich College of Humanities and Social Sciences, and the Tepper School of Business, as well as from other universities across the country, to give recommendations that consider each question from every angle.\nEvery time AI has had a potentially big impact,**Tom Mitchell,**Founders University Professor in Computer Science, has been there to advise government officials. He first briefed federal officials about AI in the early 1990s when he spoke to the Information Sciences and Technology (ISAT) committee within the Defense Advanced Research Projects Agency (DARPA), the Department of Defense’s funding agency for research. As a member of ISAT, Mitchell spoke about where technology was heading and where ISAT might want to invest its resources. Since then, he has traveled to Washington frequently, briefing officials from different government branches and agencies about how they should be taking advantage of AI as well as how it should be regulated.\n![Group of people meeting at dark wooden table] \nTom Mitchell (left), meets with Rep. Susie Lee (NV-03) to discuss the latest advancements, research, opportunities and challenges surrounding AI. Also meeting: members of CMU’s Block Center Responsible AI leadership team: Hoda Heidari (center front) expert in AI ethics, fairness and accountability and Ramayya Krishnan (right front) faculty director of the Block Center. Not pictured but attending: Rayid Ghani, expert in AI, policy and social impact.\nIn the late ‘90s Mitchell joined the National Academies of Science (NAS) Computer Science and Telecommunications Board. Following the attacks of September 11, 2001, he participated in and chaired NAS’ Workshop on Information Fusion and Counter-Terrorism, briefing the workshop on the use of AI in counterterrorism. Soon after, he testified before a congressional committee on how AI could be used to help the Veterans Administration process medical claims.\n**> “All of the interactions I’ve had with government people have made me more optimistic about our government function than what I read in the newspapers,” he said.\n**\nIn 2023 Mitchell attended multiple private meetings with members of Congress and spoke publicly to Senate Republican staffers about large language models. With a nonpartisan think tank called the Special Competitive Studies Project, Mitchell chairs a task force that will give government officials recommendations on generative AI, advising how the U.S. can remain competitive with other countries as officials learn how to use the technology ethically. Mitchell also works with the U.S. National Academies on a congressionally-mandated study on AI and the future of work. Both will be published in 2024.\nMitchell said three broad principles should be followed as they design the government response: most regulations should target the application of AI, not AI at large; a small percentage of regulations should target general purpose AI tools such as Chat GPT; and ultimately, no matter how diligent they are in anticipating potential issues, some will come up that can’t be anticipated and an organization will need to be in place to address those.\n### **AI Helping Humans Make Good Decisions**\n**Aarti Singh**, professor in the Machine Learning Department, briefed members of Congress and their staff for the first time in September 2023 when the NSF brought together the leaders of all 25 AI research institutes it is funding to Capitol Hill to raise awareness of how AI can positively impact society. Singh is the co-director of the AI Institute for Societal Decision Making (AI-SDM), which opened at Carnegie Mellon in June 2023 thanks to a $20 million, five-year grant from the National Science Foundation.\nResearchers from an array of disciplines and institutions collaborate at AI-SDM to advance AI and use it to better inform decisions people make. The institute focuses on two specifics: as a matter of public health, the researchers are looking at ways AI can help identify patients at high risk for certain pregnancy complications early on and ways to engage them with health services.\nIn the area of emergency management, AI-SDM explores ways to use autonomous robots and drones to go places too dangerous for humans. Getting into these areas supplies emergency managers with more informed data to make critical decisions. These challenges are ideal for academics to explore, since they are not the kind of projects that profitability-driven companies have shown interest in.\nSingh has continued to answer questions from Congressional staff following the September event.\n**> “My takeaway was that people talk a lot about what AI can do, both positively and negatively, so that leads to both the hype and the fear of it,” said Singh, “but what people talk less about is what AI cannot do and that’s so important to convey.”\n**\nSingh will continue to engage with policymakers and the other AI research institutes. NSF hopes to host another showcase for the AI institutes on Capitol Hill, and Carnegie Mellon will host the annual summit for the AI institutes in October 2024.\n![Aarti Singh, professor in MDL and director of AI-SDM] \nAarti Singh, professor in MDL and director of AI-SDM\n### **Encouraging Smart Government Acquisition**\nOne of the primary ways the federal government can influence how artificial intelligence evolves, even while it moves slowly to establish regulations and laws, is through its acquisition of technology. As one of the largest buyers in the market, government agencies can encourage ethical, effective technology to be developed by buying from companies that produce it well. Once that technology is built for the government, it can more easily be adapted for private buyers.\nIn September**Rayid Ghani**, distinguished career professor in the Machine Learning Department and the Heinz College of Information Systems and Public Policy, testified before the Senate Homeland Security and Governmental Affairs Committee on Acquisition and Procurement.\n“Too often, organizations go on the market to buy AI without completely understanding, defining and scoping the concrete problem they want to tackle, without assessing whether AI should even be part of the solution, and without including individuals and communities that will be affected,” Ghani wrote in his testimony. “AI systems are neither applicable for all problems facing government agencies, nor are they one-size-fits-all. By starting with the concrete problem at hand, and understanding how it’s being tackled today, an effective, collaborative and inclusive scoping process can help determine the requirements that the AI system needs to fulfill.”\nGhani has testified before Congressional committees before and often works with government staff at the local, state and federal levels as they look for technology solutions. He said that each time he has testified before a committee that starts a conversation, it continues as staffers work to understand the nuances of potential policies.\nGoing forward, Ghani said he sees three avenues where CMU faculty can help government in interesting and impactful ways. The first: helping local governments figure out how to use AI to allocate resources, making sure that the government’s services and supplies are reaching the people who need them. The second: helping regulatory agencies determine how to use AI responsibly in their efforts to audit companies in their jurisdiction and enforce the law. The third: to continue supporting the National Institute of Standards and Technology, an office within the U.S. Department of Commerce, as it develops broader guidelines that make up the AI Risk Management Framework.\n![Rayid Ghani (left) testifying before the Senate Homeland Security and Governmental Affairs Committee on Acquisition and Procurement.] \nRayid Ghani (left) testifying before the Senate Homeland Security and Governmental Affairs Committee on Acquisition and Procurement.\n![] \n![Jodi Forlizzi] \nJodi Forlizzi, Herbert A. Simon Professor in Computer Science and the Human-Computer Interaction Institute\n### **Supporting Workers**\n**Jodi Forlizzi**, the Herbert A. Simon Professor in Computer Science and the Human-Computer Interaction Institute, is deeply involved with the AFL-CIO’s Technology Institute. As AI continues to reshape the responsibilities of frontline workers, Forlizzi and her HCII collaborators, faculty member Sarah Fox and Ph.D. student Franchesca Spektor, work with the union to think about how these workers can be part of developing technology that makes their jobs easier, not harder.\nIn October 2023, Forlizzi spoke to the AI Insight Forum on AI Innovation, hosted by two senators from each party. Senate Majority Leader Chuck Schumer (N.Y.) and Senator Martin Heinrich (N.M.) represented the Democrats and Senator Mike Rounds (S.D.) and Todd Young (Ind.) represented the Republicans.\nForlizzi built on the previous closed-door briefings she had delivered to members of Congress, emphasizing the involvement of workers in the design, development and deployment processes of AI to ensure workers’ expertise is reflected in the AI systems created. At the forum, Forlizzi cited housekeepers at hotels as an example.\n**> “For housekeepers, algorithmic managers (AMs) increase work, increase job requirements and decrease worker autonomy,” she wrote in her testimony. “Instead of letting housekeepers clean rooms in the order that makes the most sense to them based on their ability to complete their room quotas with a minimum of wear and tear on their bodies, AMs send them back and forth and up and down in hallways and elevators, while they push 200- to 300-pound carts. We have heard again and again from housekeepers that the AM ‘wastes my time.’ AMs increase wear on the worker by assigning several check-out rooms, which require heavy cleaning, back-to-back, as opposed to alternating them with the lighter physical requirements of rooms in which only sheets and towels need changing. Housekeeping is also an entry-level job that traditionally did not require technology skills or even fluent English. This, combined with typical connectivity issues, has altered the job of the housekeeper greatly, with little to no increased training or increased compensation.”\n**\n![Image of a hotel housekeeper pushing her cleaning cart] \nAlong with UNITE HERE, an AFL-CIO member that is the largest hospitality union in the U.S., Forlizzi will lead a research team, a hospitality training center and a software company that provides algorithmic management solutions for the hospitality industry in 2024. Funded by the NSF, the collaborators will develop recommendations to prepare workers for the future.\nForlizzi, who earned her master’s degree in interaction design and her Ph.D. in design in human-computer interaction, both from Carnegie Mellon, said those groundbreaking experiences inform the way she works and advises officials on issues that are developing now.\n“We were some of the first people doing the kinds of design work that we’re doing today. Our program was really new. In some ways we were making it up as we went and creating new knowledge, so it taught me to be comfortable with uncertainty,” Forlizzi recalled. “You’re making a lot of judgments as a designer and a researcher to try to improve the state of the world, and that’s something I’m still doing.”\nOf course, many more CMU AI experts have given their testimony to government officials at all levels, including the United Nations, and will continue to do so as AI policy develops. At a time when the technologies advance at a dizzying pace, the U.S. government continues to look to CMU for expertise not only to understand the advances in AI and the guardrails needed to keep people safe, but also how to best implement AI ethically and with fairness for all.",
    "length": 14123,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Protected AI Tools You Can Use",
    "url": "https://www.cmu.edu/computing/services/ai/meet-ai/tools/index.html",
    "text": "Protected AI Tools You Can Use - Computing Services - Office of the CIO - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[Computing Services] ## [Office of the CIO] \n[Office of the CIO] &#160;&#8250;&#160;[Computing Services] &#160;&#8250;&#160;[Services] &#160;&#8250;&#160;[Generative Artificial Intelligence (AI)] &#160;&#8250;&#160; Protected AI Tools You Can Use\n# ![] \nProtected AI Tools You Can Use\nThe AI tools listed on this page are available at CMU. When you sign in with your Andrew ID and password, each tool is FERPA-compliant and will not use your data to train its AI models.\n## Interested in New Tools?\nAI tools that have not yet been reviewed or licensed by CMU might not offer the same data protections and approved services.&#160;\nSubmit a[software request] for review and approval.\n# Use AI Safely at CMU\nBefore using CMU's protected AI tools, please review our[policies and guidelines for safe and ethical use].\n# DAO Accessibility Tools\nExplore[tools endorsed by the Digital Accessibility Office] that have AI capabilities.\n# Approved AI Tools\n## [AI Gateway] \n## [ChatGPT Edu] \n## [Gemini Web App] \n## [Microsoft Copilot] \n## [NotebookLM] \n## [Zoom AI Companion] \n## Tool Comparison Table\n|Tool|Purpose|Best For|Available To|Cost|\n[AI Gateway] |AI Developer tool makes AI models easier to access.|Accessing&#160; management to models via API keys.|Faculty and Staff|No cost; however an Oracle String is required to pass on any costs incurred from using a model endpoint.&#160;|\n[ChatGPT Edu] |Synthesizes info, summarizes, and generates content.|Research, writing, and problem-solving.|Faculty and Staff; Students sponsored by a faculty or staff member|$240 / per year|\n[Gemini Web App] |Google's AI that handles text, voice, and files.|Meeting summaries, working with Google Apps, and searching across formats.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n[Microsoft Copilot Chat] |AI support for Office tasks, images, and code.|Microsoft files, documents, and coding help.|Students, Faculty, and Staff|Available with your Andrew account.|\n[NotebookLM] |Creates AI-powered notebooks from uploads.|Organizing ideas, summarizing sources, and creating podcasts.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n[Zoom AI Companion] |Adds summaries and action items to meetings.|Real-time help during virtual meetings.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n**Note:**Available add-ons for protected AI tools have been thoroughly reviewed and vetted for use at CMU. For example, ChatGPT Edu with[Agents] is already available to paid ChatGPT Edu subscribers.\n* [About] \n* [Computing Services InfoCenter] \n* [CSS Awards and Recognition] \n* [News] \n* [Service Status] \n[Log In to Services] \n* [Computing Services Help Center] \n* [412-268-4357 (HELP)] \n* [it-help@cmu.edu]",
    "length": 2961,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Study Finds Generative AI Significantly Boosts Graduate-Level ...",
    "url": "https://www.heinz.cmu.edu/media/2024/September/study-finds-generative-ai-significantly-boosts-graduate-level-writing-efficiency-and-quality",
    "text": "Study Finds Generative AI Significantly Boosts Graduate-Level Writing Efficiency and Quality | Carnegie Mellon University's Heinz Collegestartwitterblueskylinkedinfacebookenvelopelinkedininstagramyoutubelogoalert-redalerthomeleft-quotechevronhamburgerminusplussearchtrianglex\nSearch CMU HeinzSearch\n[] \n# Study Finds Generative AI Significantly Boosts Graduate-Level Writing Efficiency and Quality\nA new study on the impact of generative AI on graduate-level writing finds that, with proper instruction, it can drastically reduce writing time and elevate average grades, demonstrating its transformative potential in academic and professional writing. The findings have important implications for educational strategies in teaching writing with AI assistance and for professional writing practices.&#160;\nThe research examines the effects of generative AI tools, such as ChatGPT and Microsoft Copilot, on the productivity and quality of writing among graduate students engaged in graded assignments within an actual classroom setting. After receiving targeted instruction on the effective use of these tools, students experienced not only a significant reduction in writing time but also a noticeable improvement in the quality of their work. This enhancement was observed across both native English speakers and ESL (English as a Second Language) students, demonstrating the broad applicability of generative AI in academic contexts.\nThe study, conducted by researchers at Carnegie Mellon University, is published as a[working paper] on the Social Science Research Network.&#160;\n&#8220;Our findings show that with proper guidance, generative AI can be a powerful tool for efficiently creating sophisticated graduate-level content,&#8221; says Jordan Usdan, the lead researcher and adjunct instructor of Generative AI: Applications, Implications, and Governance at Carnegie Mellon&#8217;s Heinz College. &#8220;This research underscores the importance of a tailored educational curriculum to fully leverage these tools. We're only beginning to explore AI's potential to revolutionize learning and enhance human expression.&#8221;\nThe capabilities of generative AI are particularly relevant in educational and professional settings, where demand for high-quality, efficient writing is high. But despite its widespread adoption, many find it challenging to use the technology effectively.\nIn this study, researchers measured how classroom instruction about the tool affected graduate students&#8217; use of generative AI on a graded writing assignment. Participants were 27 graduate students enrolled in a course toward a degree program at Carnegie Mellon in spring 2024, a mix of native English speakers and ESL graduate students from a variety of academic disciplines.\nStudents were first assigned a professional memo writing task that required research, data analysis, policy development, and policy analysis, to be completed without the assistance of generative AI. Following this, they received comprehensive instruction on generative AI, covering system development, operation, prompt engineering, and common pitfalls, along with practical exercises across various research and writing sub-tasks. Finally, students were given a similar professional writing task where they had the option to use generative AI&#8212;an option that all participants chose to utilize.\nGenerative AI reduced students&#8217; average writing time by 65% and improved their average writing quality from a B+ to an A. These benefits occurred for both native English-speaking students and ESL students, though they were slightly more pronounced for the ESL students, suggesting a leveling effect that helped ESL students catch up to initially higher-performing, faster peers. These improvements were consistent across both strong and weak writers.\"\nWhen students were polled about their experiences using generative AI, they said they found it to be most useful for reducing the amount of time it took them to write, for summarizing information, and for general assistance in writing. They also found it helpful for web research, policy development, and analysis, though to a slightly lesser extent. ESL students found generative AI to be significantly more useful in the writing process than did native English speakers.\n&#8220;Our results are further evidence that teaching students how to appropriately leverage generative AI for writing assistance is becoming an essential job for educators,&#8221; says Harley Chang, a learning engineer at Carnegie Mellon&#8217;s Eberly Center for Teaching Excellence &amp; Educational Innovation, who coauthored the study. &#8220;Given these benefits, all colleges should consider incorporating generative AI instruction into curricula in undergraduate and graduate programs.&#8221;\nWhile the study demonstrated significant improvements in both grades and writing efficiency with the use of generative AI, the authors acknowledge the challenges of isolating AI's impact within a real-world classroom setting. However, students themselves credited 66% of their productivity improvements to the AI rather than to additional writing practice. Another limitation is that the study's findings are based on a self-selected sample of participants, which may limit the generalizability of the results.\n&#8220;Generative AI has strong potential to help not only student writers but also professionals in the workplace,&#8221; notes Allison Connell Pensky, a senior data science research associate at Carnegie Mellon&#8217;s Eberly Center for Teaching Excellence &amp; Educational Innovation, who co-authored the study. &#8220;The pedagogical method we used may also be helpful for workplace training to maximize the potential benefits of generative AI while managing its challenges and ethical considerations.&#8221;\nThe research was funded by Carnegie Mellon University.\n###\n**About Heinz College of Information Systems and Public Policy**\nThe Heinz College of Information Systems and Public Policy is home to two internationally recognized graduate-level institutions at Carnegie Mellon University: the School of Information Systems and Management and&#160;the School of Public Policy and Management. This unique colocation combined with its expertise in analytics set Heinz College apart in the areas of cybersecurity, health care, the future of work, smart cities, and arts &amp; entertainment. In 2016, INFORMS named Heinz College the&#160;[#1 academic program] &#160;for Analytics Education. For more information, please visit&#160;[www.heinz.cmu.edu].\nShare\n* [] \n* [] \n* [] \n* [] \n## In This Story\n![Jordan Usdan] \n[**Prof. Jordan Usdan**] \nExpert on the intersection of technology, business, and society\n---\n## Contact Us\nCaitlin KizielewiczMedia Relations5000 Forbes AvenueHamburg HallPittsburgh,PA15213-3890[412-554-0074] [ckiz@andrew.cmu.edu] \n## Related Articles\n&#32;\n## Carnegie Mellon University Launches the Center for Collaboration Science\n[Read More] \n&#32;\n## Kirsten Martin Appointed the H. John Heinz III Dean of the Heinz College of Information Systems and Public Policy\n[Read More] \n&#32;\n## The National Academy of Sciences Elects Daniel Nagin to the Academy\n[Read More] \nAll News Link\ntiktok",
    "length": 7227,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Industry Engagement - \n                Center for Intelligent Business -     Tepper School of Business - Carnegie Mellon University",
    "url": "https://www.cmu.edu/intelligentbusiness/industry-engagement/index.html",
    "text": "Industry Engagement - Center for Intelligent Business - Tepper School of Business - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[Center for Intelligent Business] ## [Tepper School of Business] \n[Tepper School of Business] &#160;&#8250;&#160;[Center for Intelligent Business] &#160;&#8250;&#160; Industry Engagement\n**We welcome dialogue with companies faced with challenges in deploying AI and data related technologies, and offer a neutral platform to level set best practices. Beyond tactical deployment problems, our expertise can inform longer term strategic directions.**\n**PROBEs (PRoblem-Oriented Business Explorations)**are at the core of Center for Intelligent Business corporate engagements, helping us to investigate the collaboration potential between CMU/Tepper and the innovative ideas of industry.&#160;[Visit our News &amp; Events page for summaries of previous PROBEs] \nThrough our**Student Educational Projects (capstone or course projects),**teams of MBA, masters students or undergraduate students can explore company data and business context to formulate recommendations that are aligned with the long-term interests of your organization and/or industry. We have seen it serve to retain talent in data-rich organizations that value such deeper modeling collaborations**.**\n* Work with a team of students to complete a (preferably) open-source project over the course of a semester.&#160; An educational project is a great way to engage with the next generation of business leaders and help your company, startup, nonprofit or government agency pilot a new idea or develop a framework for a new solution.\n* There is opporutunity to match projects in both the fall and spring semesters, depending on the program.\n* Projects are sourced according to company preference of program, and matched according to student skill sets and interests.\nWe welcome proposals from corporate, government and research sponsors with a particular focus on projects using publicly available data sets. Please review each step eblow for instructions on preparing and submitting your proposal.\n* **Step 1: Review CMU Educational Project Agreement (EPA) -**sponsorship of a student educational project is done under a standard CMU EPA.[Sample agreement for Spring 2025] \n* **Step 2: Review Intelliectual Property Policy -**&#160;CMU students retain ownership of their intellectual property. Through an executed EPA, sponsoring companies receive a non-exclusive, royalty-free, commercial-use license to use the student work product from the project course. Additionally, the teams share an archive of their work with the sponsor at the end of the semester.[Learn more] \n* **Step 3: Pitch Your Project Idea! -**&#160;[Submit your proposal] \n![Illustration - light bulbs in perpetual motion against a yellow background with last light bulb lit up with rainbow idea inside] \n# Explore More\n* [Provide Thought Leadership] \n* [Sponsor Student Projects] \n* [Support Research] \n* [Tap Into Talent]",
    "length": 3064,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Responsible Use of Generative AI in the Classroom - Eberly Center",
    "url": "https://www.cmu.edu/teaching/technology/aitools/use/index.html",
    "text": "Responsible Use of Generative AI in the Classroom - Eberly Center - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[Eberly Center] ## Teaching Excellence &amp; Educational Innovation\n[Eberly Center] &#160;&#8250;&#160;[Technology for Education] &#160;&#8250;&#160;[Generative AI Tools FAQ] &#160;&#8250;&#160; Responsible Use of Generative AI in the Classroom\n# Responsible Use of Generative AI in the Classroom\n*The following considerations were developed by colleagues in the Heinz College of Information Systems and Public Policy.*\nIf you want to dig deeper, here are some key considerations when responsibly using generative AI tools such as ChatGPT.&#160; Doing so requires attention to privacy and security, ownership, bias, validity, and context.&#160; You can consider using these as seed prompts of things like policy discussions or usability assessments of existing tools.&#160;&#160;\n**Privacy and security**concerns include confidentiality and potential for data breaches. Does the tool allow your private data to leak? Does it allow you to acquire other people's private data? Is the system that you're running the tool on secure? Are you sure the tool itself is legitimate?\n**Ownership**considerations include the provenance of generated content. Is any of the content copyright protected? Can you copyright the generated content? Can a student claim the generated content as their own?&#160;\n**Bias**relates to the potential for drawing conclusions that may be prejudiced or discriminatory due to the training data not being representative.&#160; Can you tell what data the tool was trained on?&#160; Are there categories of people (age, gender, race, religion, sexual orientation) that may be under-represented in the training data?&#160;\n**Validity**concerns relate to the trust placed in the output of the tool. How does one review generated content for factuality or other forms of validity (perhaps realism, in the case of images)? Does correctness of the answer depend on having more recent data than the data used to train the tool?\n**Context.**Are some tasks more or less suitable for use with the tool - for example, generating an email may be less problematic than generating an essay or doing data analysis? Will the output of the tool be used by people who may not understand the limitations of generative AI or the data it is trained on? Can students and instructors use the tool without citation? What skills are appropriate to delegate to the tool?\n**Other considerations.**&#160; Cost, including recurring costs through subscriptions; Liability (FERPA, student privacy concerns, vetted software); and more. Careful consideration of these questions is required before using generative AI in the classroom.\n# Examples of in-class exercises, activities or assignments using ChatGPT\n*The following examples were developed by colleagues in the Heinz College of Information Systems and Public Policy.*\n## Challenge exercise: Who does ChatGPT think you are?\n## Why this matters\nThis exercise demonstrates some of the limitations of ChatGPT - namely, that because of the way that it generates answers, they are partly based on probabilities of things like word order in previous source information. The result is that for information that isn&#8217;t widely known or discussed in the training data, the tool will try to fill in the blanks.&#160; When this happens for a person&#8217;s biographies, the results are likely very divergent from reality.&#160;\n## Time to complete: 15-20 minutes\nDivide the students into teams of two or three.&#160; If students are likely to know each other, use the Groups feature on Canvas to randomly assign groups of two or three students each.\nInstructions:\n1. Have each student introduce themselves to the other (sharing nothing more than their name), and write down the name of the other student(s). Note: make sure the students understand using their real names is optional.&#160; If they don&#8217;t feel comfortable, have them make up an entirely fictitious name.&#160; Or, ask them to select an obscure topic, location, or thing that they know a lot about.&#160;\n2. Using ChatGPT, have each student ask the program who the classmate is.&#160; They can use any prompt they feel is appropriate.&#160;\n3. With the new &#8220;bio&#8221;, each student should now introduce the other, using the information from the bio.&#160; What did it get right?&#160; What did it get wrong?&#160; Why?\n4. Students can continue asking questions.&#160; What does the person like to eat?&#160; What are their favorite sports?&#160; What did they do before coming to CMU?\n5. After everyone has had a chance to share within the group, come back together and discuss. Ask the students if they would feel comfortable using this as their bio on LinkedIn or on a cover letter.&#160;\n6. Create a list of strengths and weaknesses of using ChatGPT.&#160; This can be a good time to share how on the surface the information might appear trustworthy until you go back to the original source.&#160; Ask the students to discuss what this might mean when using ChatGPT to research topics they are less familiar with.&#160;\n## Challenge exercise: Flash brief (aka ChatGPT karaoke)!\n## Why this matters:&#160;\nIn this exercise we demonstrate the ability of ChatGPT to generate a &#8220;flash brief&#8221; on a critical, timely topic. Builds on this idea of &#8220;ChatGPT Karaoke&#8221;.&#160; By introducing a fair amount of uncomfort by trying to present content generated by ChatGPT, students should recognize its limitations when used as an unvarnished generative tool.&#160;\n## Time to complete: 45 minutes\nDivide the students into teams of four.&#160; Before class, give each group a policy brief topic to become familiar with.&#160; A good source is the Day One Project:&#160;\n[https://fas.org/publications-archive/?s=&amp;i=day-one] \n#### Instructions - Generative AI team\n1. Using ChatGPT (or other tool identified by the instructor), develop prompts to create the Flash Brief\n2. Using only the content developed by the tool, create the policy brief.&#160;\n3. Present the policy brief#### Instructions - Traditional research team\n1. Research the topic as normal\n2. Develop the policy brief\n3. Present the policy brief\nOnce the presentations are complete, discuss!&#160; What are the strengths and weaknesses of each approach?\nFor instructors, this is a good time to talk about how it can be hard for generative AI tools to be specific, accurate, or appropriate for the audience. But, it&#8217;s also worth noting how it can be helpful for developing ideas around language, approach, and brainstorming.&#160;\n## Challenge exercise: How do I earn an A on this assignment?\n## Why this matters:&#160;\nThis classroom exercise is motivated by providing students with practice and feedback to develop challenging skills with the support of your assignment rubric and ChatGPT. Research shows that the following teaching strategies support learning:&#160;\n1. providing transparent evaluation criteria in advance,\n2. actively engaging students with examples that illustrate effective habits of mind, and&#160;\n3. creating opportunities for targeted low-stakes practice and feedback.&#160;\nCommon ways instructors enact these strategies include:\n1. providing and discussing the grading rubric with students prior to completing assignments,\n2. providing anonymized examples of work from previous students, representing a range of quality, and\n3. classroom exercises during which students individually or collaboratively evaluate anonymized samples of student work using the assignment rubric and then engage in a class discussion to enhance their understanding of criteria and explore how to improve the samples.&#160;\nAI Tools provide additional opportunities to implement these strategies and foster student development and learning,*without*requiring access to or curation of examples of prior student work.&#160;\n## Time to complete during class: 60 minutes\\*\n\\*Note: To shorten the activity, the initial segment marked with an asterisk (\\*) in the instructions below could be assigned as pre-class, individual work.\n## Set-up:&#160;\n1. Before class, enter your assignment prompt into ChatGPT. Evaluate the output using your assignment rubric to familiarize yourself with pros and cons of the deliverables it produces. Also consider testing tweaks to the assignment prompt.&#160;\n2. Divide the students into teams of three or four.&#160;&#160;\n3. Provide students with the assignment prompt and assignment rubric in Canvas.\n4. Provide each group with a set of 4 notecards each labeled with a large visible letter, &#8220;A&#8221;, &#8220;B&#8221;, &#8220;C&#8221; or &#8220;D&#8221;.&#160;&#160;## Instructions for classroom exercise:\n**1. (10 min\\*) Group work.**Ask students to read and discuss the assignment prompt and grading rubric in their groups to identify and prioritize clarification questions. Groups can enter their questions in a Google Doc that the instructor can monitor and respond to in real time. Provide each group with a dedicated space in the document to write.\n**2. (10 min) Whole class discussion.**&#160;Solicit any remaining high priority clarification questions from each group and discuss.&#160;\n* Discuss common themes observed across groups&#8217; questions.&#160;\n* Discuss areas of challenge experienced by prior students (if you have used this assignment previously).&#160;\n**3. (20 min) Group work.Ask students to enter your assignment prompt into ChatGPT. Then, collaboratively evaluate the AI Tool&#8217;s output using the assignment rubric. Use these prompts as a heuristic:\n**\n1. * How would you rate ChatGPT&#8217;s performance on each rubric criterion?&#160;\n* What does ChatGPT do well and not?&#160;\n* Imagine you were the instructor and ChatGPT was your student, what feedback would you provide to improve the output you evaluated?\n* Can you engineer an additional prompt for ChatGPT that would improve the output?**4. (15 min) Whole class discussion.**\n* Take a straw poll.&#160;\n* How would your group rate this deliverable overall? What letter grade would you give it?&#160;\n* Countdown from 3 and ask groups to simultaneously hold up the letter card with their response for all to see.&#160;\n* Verbally summarize the distribution of ratings.\n* Solicit a discussion across groups with different ratings.&#160;\n* Ask groups to explain their rationale based on the assignment rubric.\n* Ask other groups with the same rating to suggest how to improve the deliverable.\n* As criteria are referenced in the discussion, you may ask for additional straw pools. How did you group rate performance on this criterion? Hold up a letter card please.\n* Conclude the discussion by crowdsourcing a pros/cons list. What did ChatGPT do well? Where did it struggle? Record consensus responses on the board under headings of pros versus cons.**5. (5 min) Instructor wrap up.**&#160;Clarify course policy and expectations regarding the use of AI Tools to complete this assignment, and\n* Provides final advice on strategies for success and common pitfalls to avoid.&#160;&#160;\n\\*Alternatively, assign Step 1 as individual, pre-class work in Canvas. Start the exercise with Step 2, modifying it as follows:\n* (2 min) Turn to a neighbor. Discuss what is most unclear about the assignment prompt or grading criteria in the rubric.&#160;\n* (8 min) Call on volunteers to ask their highest priority clarification questions and then discuss.&#160;&#160;\n## Challenge exercise: Practicing important skills during class\n## Why this matters:&#160;\nResearch shows that implementing active learning during class sessions improves both learning outcomes and student persistence. However, designing materials for classroom exercises can be time consuming. This approach leverages AI Tools to generate the examples students work on during class, in real time. The premise underlying the practice exercise is that students must find, explain, and correct any errors generated by AI Tools. The sample below focuses on coding/debugging skills. However, it could be adapted for practicing writing or other skills.&#160;\n## Time to complete during class: 25 minutes\n## Set-up:&#160;\n1. Before class, pilot test prompts in ChatGPT that will purposefully generate output containing an error. For example, generate a block of code in [*insert coding language here*] to do X, Y, and Z, but that contains at least one error that will prevent it from running successfully.\n2. Repeat step 1 above, with different X, Y, and Z functions, as needed.\n3. Divide the students into teams of two.\n4. Randomly assign tested prompts to student pairs.&#160;&#160;&#160;\n5. Optional: consider adding a scenario to make things more interesting.&#160; For example:*&#8220;You&#8217;ve been tasked with figuring out if a work sample provided by a potential new hire is a real reflection of their coding ability.&#160; Can you figure out the real, working code from the sample generated by AI?&#8221;*## Instructions for classroom exercise:\n**1. (10 min) Pair work.**Students collaboratively&#8230;enter their assigned prompt into ChatGPT.&#160;\n* run the code generated to verify an error is present.&#160;\n* Diagnose the errors in the code and attempt to debug them, re-running the code to verify success.&#160;\n**2. (10 min) Whole class discussion.**&#160;\n* What kinds of errors did ChatGPT generate, when prompted to make errors?\n* How did you figure out it was an error?&#160;&#160;\n* Are these common human errors in programming?\n* What questions did you ask yourself while debugging?\n* What was hard or easy about debugging? What did you learn?\n* What debugging strategies were most effective? Are those strategies unique to this problem or transferable to other coding tasks?&#160;**3. (5 min) Instructor wrap up.**&#160;Clarify course policy and expectations regarding the use of AI Tools to complete coding assignments, and\n* Provide final advice on strategies for success and common pitfalls to avoid.&#160;&#160;\n## Discussion/Case Study: ChatGPT Wrote My Policy Brief\n## Why this matters\nThis assignment is designed for Writing for Public Policy course, but could easily be adapted for any course that deals with public policy, client consulting, or communicating cutting edge content.&#160;\nThis discussion prompt attempts to give students a real world scenario to consider about how ChatGPT use (or any other generative AI platform) might impact their professional work. Heinz students are often very focused on professional development and industry expectations, so discussions about the downsides of generative AI in an academic setting might not be as effective as how those downsides might manifest in a professional context.&#160;\nBy placing the students in a managerial position, it gives them the opportunity to reflect on complications for this kind of AI misuse in multiple directions in a professional hierarchy. The ethics of this situation are intentionally difficult and there is likely not a single good answer, but the intention is to get students to reflect on both the misuse of ChatGPT as well as professional ethos, the need for good research/citation practices, and communication of expectations in a managerial setting.&#160;\nTime to complete\n**Think-Pair-Share discussion in class**- 20-25 minutes\n5 minutes for students to read the prompt and brainstorm their own answers&#160;\n5 minutes to pair up and discuss with a partner or small group\n10-15 minute discussion with the class\n**Discussion with team deliverable**(email to interns) - 30 minutes\nPresent the prompt to the class\n5-10 minutes for discussion\n10-15 minutes for team to draft deliverable\n## Set up\n**Think-Pair-Share discussion in class**\n1. Provide students with the prompt and discussion questions (ideally as a handout and/or on class slides)\n2. Present the prompt to the students and the discussion questions you would like for them to think through.&#160;\n3. Prepare discussion questions on slides\n**Discussion with team deliverable**&#160;\n1. Provide students with the prompt, discussion questions, and deliverable instructions\n2. Create a space for the students to turn in the deliverable (i.e. a discussion thread on Canvas, a Google Drive folder)\n3. Decide if students will complete the deliverable in teams or individually, in class or as a homework assignment.&#160;## Prompt\nYou are a policy analyst at a major policy think tank in Pittsburgh. Yesterday, on short notice, the think tank was asked by a local representative[insert city, state, or national figure here as is relevant]to brief them on current issues involving[insert topic related to course material here].Your boss assigned you to attend the meeting today, brief the policy maker and determine what kind of help the think tank can provide moving forward.\nAs is the regular practice at the think tank,&#160; you ask the interns to pull together research and create a 1 page policy briefing document. One of the interns, Brad, sent you the 1 pager late last night. After glancing through the document quickly first thing this morning, you forwarded it to the policy maker and their staff.&#160;\nYou arrived early for the meeting and while waiting in the conference room for the policy maker to arrive, you take a few moments to read through the briefing document more thoroughly. You decide to read through some of the references to get a deeper understanding of the material but when you click on the link to the first one, it comes up as a 404 error. You click on the second reference link and get a similar error. With a sinking feeling, you click through the rest of the references and realize that none of them actually link to content.&#160;\nYou pull out your phone and quickly message Brad in Slack to ask if there is an issue with the hyperlinks. After a quick exchange, Brad admits, &#8220;I was really pressed for time last night, so I used ChatGPT to write the brief. I didn&#8217;t double check the references but now that I&#8217;m looking at it, I think ChatGPT made them all up.&#8221;\n&#8220;Did you double check that all the numbers and statistics in the briefing are accurate?&#8221; you write back.&#160;\nThere is a very long pause. You can hear people outside of the conference room; the policy maker and staff are preparing to enter the conference room for the meeting.&#160;\n&#8220;I just googled the first three statistics listed in the document and it looks like they are incorrect&#8221; Brad writes back. &#8220;I&#8217;m so sorry. I think the whole document is likely bad information.&#8221;&#160;\nAt that moment, the policy maker enters the room. &#8220;Thank you so much for coming on short notice! I&#8217;m eager to hear what you have to say about this topic.&#8221;&#160;\n## Possible Discussion Questions\n1. What do you do? What actions do you take in this immediate moment? (Cancel the meeting? Ask the staff to disregard the briefing document? Apologize?)&#160;\n2. How would you explain the situation to the policy maker? To your boss?\n3. Who is at fault in this situation?&#160;\n4. What impact might these actions have on your reputation and the reputation of your company?\n5. As a manager, what should you have done differently?&#160;\n6. As a manager, what steps do you need to take to address this situation with Brad the intern? What consequences should he face?\n7. As an employee of the think tank, how can you ensure this situation does not happen to any other policy analysts? What policies or procedures might you recommend to upper management?\n## Instructions&#160;\n**Think-Pair-Share discussion in class**\n1. Read through the prompt with the class and give the students time to brainstorm their responses individually to the questions (alternatively, you could provide the prompt and have the students read and respond individually for homework)\n2. Ask the students to share their responses with a partner in the class and discuss their reactions.&#160;\n**Discussion with team deliverable**\n1. Read through the prompt with the class.&#160;\n2. Walk through a few discussion questions with the class, giving them an opportunity to dig in to the ideas. Use the questions that focus on the outcomes you are trying to emphasize.&#160;\n3. Break the team into small groups (2-3) and ask them to draft a deliverable document. You can choose one that best fits your course goals or allow students to choose one. They will not be able to complete more than one in class.&#160;\n1. Deliverable prompt 1: In a small group, work to draft an email to Brad the intern which outlines the issues with the brief he delivered. This email should include guidelines on drafting a brief, guidelines for proper use of AI technology, and the consequences (if any) resulting from this incident.&#160;\n2. Deliverable prompt 2: In a small group, draft an email to all the interns at the policy think tank. This email should issue guidelines on the use of AI (especially ChatGPT) when composing documents at work. Your group may decide whether or not to disclose the incident that prompted these guidelines. Your group may also decide what kinds of consequences would be offered for violating this new policy\n3. Deliverable prompt 3: In a small group, draft an email/after action report to your boss at the think tank, giving her a full accounting of the incident. Your email will need to include relevant details about the incident, the steps you have/will take, proposed consequences for the intern and/or for you, and recommendations for new policies or procedures moving forward.&#160;\n4. When you have completed your draft, submit the deliverable to the discussion board for today.&#160;\n1. Alternatively, you can have the students brainstorm their solutions together and then ask each student to draft and turn in a deliverable as a homework assignment.\n**Eberly Center\n**4765 Forbes Avenue\nTepper Quad, Suite 1310\nPittsburgh, PA 15213\n(412) 268-2896\n[Contact Us] \n![]![]![]![] &#160;This work is licensed under a&#160;[Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License].\n&#160;\n&#160;",
    "length": 22199,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Protected AI Tools You Can Use",
    "url": "https://www.cmu.edu/computing/services/ai/chatgpt/index.html",
    "text": "# Protected AI Tools You Can Use\n\nThe AI tools listed on this page are available at CMU. When you sign in with your Andrew ID and password, each tool is FERPA-compliant and will not use your data to train its AI models.\n\n## Interested in New Tools?\n\nAI tools that have not yet been reviewed or licensed by CMU might not offer the same data protections and approved services.\n\nSubmit a [software request] for review and approval.\n\n# Use AI Safely at CMU\n\nBefore using CMU's protected AI tools, please review our [policies and guidelines for safe and ethical use].\n\n# DAO Accessibility Tools\n\nExplore [tools endorsed by the Digital Accessibility Office] that have AI capabilities.\n\n# Approved AI Tools\n\n## [AI Gateway] \n\n## [ChatGPT Edu] \n\n## [Gemini Web App] \n\n## [Microsoft Copilot] \n\n## [NotebookLM] \n\n## [Zoom AI Companion] \n\n## Tool Comparison Table\n\n| Tool | Purpose | Best For | Available To | Cost |\n| --- | --- | --- | --- | --- |\n| [AI Gateway] | AI Developer tool makes AI models easier to access. | Accessing  management to models via API keys. | Faculty and Staff | No cost; however an Oracle String is required to pass on any costs incurred from using a model endpoint. |\n| [ChatGPT Edu] | Synthesizes info, summarizes, and generates content. | Research, writing, and problem-solving. | Faculty and Staff; Students sponsored by a faculty or staff member | $240 / per year |\n| [Gemini Web App] | Google's AI that handles text, voice, and files. | Meeting summaries, working with Google Apps, and searching across formats. | Students, Faculty, Staff, and Sponsored | Available with your Andrew account. |\n| [Microsoft Copilot Chat] | AI support for Office tasks, images, and code. | Microsoft files, documents, and coding help. | Students, Faculty, and Staff | Available with your Andrew account. |\n| [NotebookLM] | Creates AI-powered notebooks from uploads. | Organizing ideas, summarizing sources, and creating podcasts. | Students, Faculty, Staff, and Sponsored | Available with your Andrew account. |\n| [Zoom AI Companion] | Adds summaries and action items to meetings. | Real-time help during virtual meetings. | Students, Faculty, Staff, and Sponsored | Available with your Andrew account. |\n\n**Note:** Available add-ons for protected AI tools have been thoroughly reviewed and vetted for use at CMU. For example, ChatGPT Edu with [Agents] is already available to paid ChatGPT Edu subscribers.\n\n- [About] \n- [Computing Services InfoCenter] \n- [CSS Awards and Recognition] \n- [News] \n- [Service Status] \n\n[Log In to Services] \n\n- [Computing Services Help Center] \n- [412-268-4357 (HELP)] \n- [it-help@cmu.edu]",
    "length": 2623,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "CMU’s Generative AI + Education Modules - Eberly Center - Carnegie Mellon University",
    "url": "https://www.cmu.edu/teaching/gaitar/genaimodules/index.html",
    "text": "CMU&#8217;s Generative AI + Education Modules - Eberly Center - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[Eberly Center] ## Teaching Excellence &amp; Educational Innovation\n# CMU&#8217;s Generative AI + Education Modules\nAs part of CMU&#8217;s broader[strategy regarding Generative AI and education], the Office of the[Vice Provost for Teaching and Learning Innovation] is developing a series of instructional modules on generative AI.\nThe[first set of modules] is designed as a primer for CMU students &#8211; to support them in their role as learners. It targets several fundamental learning objectives related to learners&#8217; effective*and responsible*use of generative AI tools.\nBy the end of these modules, learners should be able to&#8230;\n1. Describe the basic mechanisms behind how generative AI tools are built and how they work.\n2. Analyze the ethical implications and other concerns related to these tools &#8211; in order to be a responsible user and/or creator.\n3. Explain why students&#8217; decisions about and applications of generative AI tools will differ across individuals, contexts, tasks, and goals.&#160;\n4. Identify and apply strategies to appropriately and responsibly use generative AI for a given educational task.&#160;\nIn addition to developing students&#8217; knowledge and skills in the above areas, these modules are designed to promote students&#8217; self-efficacy for appropriately using generative AI tools.\n## Studying the modules&#8217; impact*in action!*\nAn exciting project associated with these modules has involved a collaboration with the Eberly Center, more than 30 instructors, and more than 2,000 students in which we investigated the modules&#8217; impacts on learning and self-efficacy via a randomized, controlled trial. This large-scale study was the first GAITAR@Scale project, conducted in September, 2024. The data are currently being analyzed (so check back here for future updates!). Results will be used not only to gauge the effectiveness of the v1 modules but also to guide iterative improvements that will be incorporated into v2!&#160;**\n### Key Contributors\n* **Hoda Heidari**,**&#160;**Assistant Professor,&#160;MLD,&#160;S3D,&#160;HCII\nSubject-Matter Expert and module co-author\n* **Nicky Agate**,**&#160;**Principal Librarian, University Libraries\nSubject-Matter Expert and module co-author\n* **Elaine Gombos**, Computer Science\nStudent contributor and module co-creator\n* **Chuong Truong**, Philosophy\nStudent contributor and module co-creator\n* **Harrison Leon**, Machine Learning Department\nStudent contributor and module co-creator\n* **Zach Mineroff**,**&#160;**Senior Learning Engineer, Eberly Center\nLead Learning Engineer coordinating and guiding the modules&#8217; design\n* **Avi Chawla**,Senior**&#160;**Learning Engineer, Eberly Center\nLearning Engineer assisting in the modules&#8217; design and implementation\n* **Judy Brooks**,&#160;Director of Design, Technology-Enhanced Learning &amp; Online Programs, Eberly Center\n## Primer Outline\n## Module 1: Basics of how Generative AI Tools Work\n1. **Module 1 Overview**\n2. **Generative AI Primer**\n1. ask students to sign into Copilot and enter prompts, then reflect on usefulness\n2. **How LLMs Work**\n1. MCQ on LLM mechanisms\n2. **The Central Role of Training Data**\n1. MCQ on training data sources\n2. **Comparison with&#160; Traditional Web Search**\n1. categorize features as being associated with generative AI vs trad. search engine\n2. **Risks of Hallucinations**\n1. Identify generative AI outputs as hallucinations vs not\n2. **Attribution for AI-Generated Content**\n1. MCQ about attribution\n## Module 2: Ethical Implications and Other Concerns\n1. **Module 2 Overview**\n2. **A Framework for Responsible Use of Generative AI**\n1. MCQ on technology risk\n2. **Who Stands to be Harmed**\n1. Given scenarios, select entity most at risk of harm\n2. **A Taxonomy of Harms for Generative AI**\n1. Given scenarios, select category of harm that best fits the situation\n2. **Sources of Generative AI Risks**\n1. MCQ on identifying main cause of harmful outcomes in scenarios\n## Module 3: Opportunities and Risks for Different Students\n1. **Module 3 Overview**\n2. **Generative AI and the Learning Process**\n1. MCQs about general opportunities/risks\n2. **Learners Have Different Needs**\n1. Describe your own reaction to generative AI, then consider how others might react\n## Module 4: Appropriate and Responsible Use\n1. **Decoding the Syllabus**\n1. Identify acceptable actions based on syllabus examples\n2. **Appropriate Use: Generative AI as Study Aid or Learning Companion**\n3. **How to Build an Effective Chatbot Prompt**\n1. Prompting a Study Sidekick: Prompt Copilot to generate practice materials\n2. MCQ: identify how to make a prompt better\n3. **Responsible Use: Decide, Verify, Cite, Rectify**\n4. **Responsible Use: Lateral Reading**\n1. Use lateral reading to evaluate generative AI output\n2. MCQ on lateral reading strategies\n## Interested in trying out the modules or learning more?\nEmail your questions, suggestions, and further thoughts to[eberly-assist@andrew.cmu.edu]!\n**Eberly Center\n**4765 Forbes Avenue\nTepper Quad, Suite 1310\nPittsburgh, PA 15213\n(412) 268-2896\n[Contact Us] \n![]![]![]![] &#160;This work is licensed under a&#160;[Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License].\n&#160;\n&#160;",
    "length": 5436,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Protected AI Tools You Can Use",
    "url": "https://www.cmu.edu/computing/services/ai/meet-ai/tools/chatgpt/index.html",
    "text": "# Protected AI Tools You Can Use\n\nThe AI tools listed on this page are available at CMU. When you sign in with your Andrew ID and password, each tool is FERPA-compliant and will not use your data to train its AI models.\n\n## Interested in New Tools?\n\nAI tools that have not yet been reviewed or licensed by CMU might not offer the same data protections and approved services.\n\nSubmit a [software request] for review and approval.\n\n# Use AI Safely at CMU\n\nBefore using CMU's protected AI tools, please review our [policies and guidelines for safe and ethical use].\n\n# DAO Accessibility Tools\n\nExplore [tools endorsed by the Digital Accessibility Office] that have AI capabilities.\n\n# Approved AI Tools\n\n## [AI Gateway] \n\n## [ChatGPT Edu] \n\n## [Gemini Web App] \n\n## [Microsoft Copilot] \n\n## [NotebookLM] \n\n## [Zoom AI Companion] \n\n## Tool Comparison Table\n\n| Tool | Purpose | Best For | Available To | Cost |\n| --- | --- | --- | --- | --- |\n| [AI Gateway] | AI Developer tool makes AI models easier to access. | Accessing  management to models via API keys. | Faculty and Staff | No cost; however an Oracle String is required to pass on any costs incurred from using a model endpoint. |\n| [ChatGPT Edu] | Synthesizes info, summarizes, and generates content. | Research, writing, and problem-solving. | Faculty and Staff; Students sponsored by a faculty or staff member | $240 / per year |\n| [Gemini Web App] | Google's AI that handles text, voice, and files. | Meeting summaries, working with Google Apps, and searching across formats. | Students, Faculty, Staff, and Sponsored | Available with your Andrew account. |\n| [Microsoft Copilot Chat] | AI support for Office tasks, images, and code. | Microsoft files, documents, and coding help. | Students, Faculty, and Staff | Available with your Andrew account. |\n| [NotebookLM] | Creates AI-powered notebooks from uploads. | Organizing ideas, summarizing sources, and creating podcasts. | Students, Faculty, Staff, and Sponsored | Available with your Andrew account. |\n| [Zoom AI Companion] | Adds summaries and action items to meetings. | Real-time help during virtual meetings. | Students, Faculty, Staff, and Sponsored | Available with your Andrew account. |\n\n**Note:** Available add-ons for protected AI tools have been thoroughly reviewed and vetted for use at CMU. For example, ChatGPT Edu with [Agents] is already available to paid ChatGPT Edu subscribers.\n\n- [About] \n- [Computing Services InfoCenter] \n- [CSS Awards and Recognition] \n- [News] \n- [Service Status] \n\n[Log In to Services] \n\n- [Computing Services Help Center] \n- [412-268-4357 (HELP)] \n- [it-help@cmu.edu]",
    "length": 2623,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Protected AI Tools You Can Use",
    "url": "https://www.cmu.edu/computing/services/ai/meet-ai/tools/copilot/index.html",
    "text": "Protected AI Tools You Can Use - Computing Services - Office of the CIO - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[Computing Services] ## [Office of the CIO] \n[Office of the CIO] &#160;&#8250;&#160;[Computing Services] &#160;&#8250;&#160;[Services] &#160;&#8250;&#160;[Generative Artificial Intelligence (AI)] &#160;&#8250;&#160; Protected AI Tools You Can Use\n# ![] \nProtected AI Tools You Can Use\nThe AI tools listed on this page are available at CMU. When you sign in with your Andrew ID and password, each tool is FERPA-compliant and will not use your data to train its AI models.\n## Interested in New Tools?\nAI tools that have not yet been reviewed or licensed by CMU might not offer the same data protections and approved services.&#160;\nSubmit a[software request] for review and approval.\n# Use AI Safely at CMU\nBefore using CMU's protected AI tools, please review our[policies and guidelines for safe and ethical use].\n# DAO Accessibility Tools\nExplore[tools endorsed by the Digital Accessibility Office] that have AI capabilities.\n# Approved AI Tools\n## [AI Gateway] \n## [ChatGPT Edu] \n## [Gemini Web App] \n## [Microsoft Copilot] \n## [NotebookLM] \n## [Zoom AI Companion] \n## Tool Comparison Table\n|Tool|Purpose|Best For|Available To|Cost|\n[AI Gateway] |AI Developer tool makes AI models easier to access.|Accessing&#160; management to models via API keys.|Faculty and Staff|No cost; however an Oracle String is required to pass on any costs incurred from using a model endpoint.&#160;|\n[ChatGPT Edu] |Synthesizes info, summarizes, and generates content.|Research, writing, and problem-solving.|Faculty and Staff; Students sponsored by a faculty or staff member|$240 / per year|\n[Gemini Web App] |Google's AI that handles text, voice, and files.|Meeting summaries, working with Google Apps, and searching across formats.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n[Microsoft Copilot Chat] |AI support for Office tasks, images, and code.|Microsoft files, documents, and coding help.|Students, Faculty, and Staff|Available with your Andrew account.|\n[NotebookLM] |Creates AI-powered notebooks from uploads.|Organizing ideas, summarizing sources, and creating podcasts.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n[Zoom AI Companion] |Adds summaries and action items to meetings.|Real-time help during virtual meetings.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n**Note:**Available add-ons for protected AI tools have been thoroughly reviewed and vetted for use at CMU. For example, ChatGPT Edu with[Agents] is already available to paid ChatGPT Edu subscribers.\n* [About] \n* [Computing Services InfoCenter] \n* [CSS Awards and Recognition] \n* [News] \n* [Service Status] \n[Log In to Services] \n* [Computing Services Help Center] \n* [412-268-4357 (HELP)] \n* [it-help@cmu.edu]",
    "length": 2961,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "AI Materials Design: Enabling the Next Generation of US Energy Infrastructure | Carnegie Mellon University",
    "url": "https://www.cmu.edu/work-that-matters/energy-innovation/ai-materials-design-enabling-next-generation-us-energy",
    "text": "AI Materials Design: Enabling the Next Generation of US Energy Infrastructure | Carnegie Mellon University[Skip to main content] \n[] \nWhat can we help you find?\nPopular Searches\n* [Undergraduate Admissions] \n* [Career Center] \n* [Majors and Programs] \n* [Cancer Research] \n* [Pulitzer Prize] \n# AI Materials Design: Enabling the Next Generation of US Energy Infrastructure\n*By:*[*Elizabeth Dickey*] *,*[*Mohadeseh Taheri-Mousavi*] *,*[*Emma Strubell*] \nAI is poised to revolutionize the way new materials are discovered and deployed, a shift that has the potential to speed up the development of novel materials necessary for the future U.S. energy infrastructure. Carnegie Mellon University’s field-leading materials design and manufacturing researchers have the expertise to lead the nation in accelerating the development of innovative materials solutions across the energy sector.\n**Why it matters:**The U.S. needs to develop new materials with superior properties —such as radiation tolerance, corrosion resistance in extreme environments, and high thermal conductivity —to build next-generation energy systems like advanced nuclear reactors, hydrogen infrastructure and grid-scale storage. Without a national-scale, AI-driven approach to materials innovation, the U.S. risks falling behind in the race to build energy systems that are efficient, secure, and sustainable.\n**The path forward:**Designing advanced materials is a complex challenge that is not just about choosing the right elements, but also requires understanding how those materials are processed and manufactured. Adding to the difficulty, researchers must account for real-world constraints like energy consumption, the availability of rare or critical elements, or variations in raw materials.\nTo make this process faster and more efficient, researchers are using a mix of automated simulations and experiments, along with decades of data drawn from across scientific fields. With human oversight, virtual AI agents can now take on the heavy lift —identifying material design needs, writing and running simulation, and directing lab robots to perform experiments and provide feedback. The virtual agents can pull together information from every area of science —text, images, audio, and video —and make informed decisions on what to do next, improving and iterating until a material achieves the required performance. The methods build on progress from the Material Genome initiative, which has already cut the design cycle from 20 to just seven years. With AI fully integrated into the process, researchers believe that they can shorten the timeline further, to just 2-3 years.\n**What we did:**Carnegie Mellon’s field-leading materials design and manufacturing researchers have significantly accelerated the discovery-to-deployment of innovative materials solutions across the energy sector. For example, the CMU-developed[AlloyGPT] is automating critical mineral extraction and material design. CMU is also leading initiatives in the certification and qualification of new materials before their employment in critical applications. By combining AI and digital twins of the material design from initial processing to component-level manufacturing, the whole certification process will become significantly shorter.\nThese initiatives are also training a new generation of scientists and engineers in AI-driven materials design. These future scientists and engineers will have deep disciplinary expertise while being able to harness and lead AI agents in a new paradigm for the design of manufactured materials.\n**Policy takeaways:**A national AI-materials design ecosystem is a strategic asset for energy security and economic competitiveness. To realize its potential, policymakers should:\n* Support sustained federal investment in AI-integrated materials research infrastructure.\n* Incentivize public-private partnerships to accelerate material deployment in energy-critical applications.\n* Embed material innovation into national strategies for clean energy, grid modernization, and critical mineral independence.\n* Promote data standards and access, while protecting intellectual property.\n* Incentivize and enable startup companies in this area.\n**The bottom line:**Without a national-scale, AI-driven approach to material innovation, the U.S. risks falling behind in critical technologies that depend on high-performance materials —from aerospace to clean energy.\n**Go deeper:**\n* CMU’s[Mohadeseh Taheri-Mousavi discusses her research], which aims to design next generation structural alloys with higher performance and contribute to material sustainability.\n* CMU’s[Anthony Rollett describes the new NASA Space Technology Research Initiative] that will focus on modeling for metals additive manufacturing.\n* An interdisciplinary team of[faculty from CMU’s materials science and engineering and chemical engineering team partners with the Naval Nuclear Laboratory] to develop advanced alloys.\n[Download White Paper PDF] \n## More on Accelerating Innovation and Discovery\n[From Research to Commercialization: Encouraging Energy and Climate Tech Entrepreneurship] \n[Carnegie Foundry: Bridging the Gap from Lab to Market in AI, Robotics, Energy Innovation &amp; Deep Tech Commercialization] \n[The CMU Start-Up Speeding Grid Innovation] \n[Unlocking American Research Dominance: Opportunities and Chokepoints in AI for Science] \n[Supercharging American Innovation: Harnessing Advances In AI and Robotics To Transform Science]",
    "length": 5500,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Protected AI Tools You Can Use",
    "url": "https://www.cmu.edu/computing/services/ai/meet-ai/tools/chatgpt/digital_twin_gpt.html",
    "text": "# Protected AI Tools You Can Use\n\nThe AI tools listed on this page are available at CMU. When you sign in with your Andrew ID and password, each tool is FERPA-compliant and will not use your data to train its AI models.\n\n## Interested in New Tools?\n\nAI tools that have not yet been reviewed or licensed by CMU might not offer the same data protections and approved services.\n\nSubmit a [software request] for review and approval.\n\n# Use AI Safely at CMU\n\nBefore using CMU's protected AI tools, please review our [policies and guidelines for safe and ethical use].\n\n# DAO Accessibility Tools\n\nExplore [tools endorsed by the Digital Accessibility Office] that have AI capabilities.\n\n# Approved AI Tools\n\n## [AI Gateway] \n\n## [ChatGPT Edu] \n\n## [Gemini Web App] \n\n## [Microsoft Copilot] \n\n## [NotebookLM] \n\n## [Zoom AI Companion] \n\n## Tool Comparison Table\n\n| Tool | Purpose | Best For | Available To | Cost |\n| --- | --- | --- | --- | --- |\n| [AI Gateway] | AI Developer tool makes AI models easier to access. | Accessing  management to models via API keys. | Faculty and Staff | No cost; however an Oracle String is required to pass on any costs incurred from using a model endpoint. |\n| [ChatGPT Edu] | Synthesizes info, summarizes, and generates content. | Research, writing, and problem-solving. | Faculty and Staff; Students sponsored by a faculty or staff member | $240 / per year |\n| [Gemini Web App] | Google's AI that handles text, voice, and files. | Meeting summaries, working with Google Apps, and searching across formats. | Students, Faculty, Staff, and Sponsored | Available with your Andrew account. |\n| [Microsoft Copilot Chat] | AI support for Office tasks, images, and code. | Microsoft files, documents, and coding help. | Students, Faculty, and Staff | Available with your Andrew account. |\n| [NotebookLM] | Creates AI-powered notebooks from uploads. | Organizing ideas, summarizing sources, and creating podcasts. | Students, Faculty, Staff, and Sponsored | Available with your Andrew account. |\n| [Zoom AI Companion] | Adds summaries and action items to meetings. | Real-time help during virtual meetings. | Students, Faculty, Staff, and Sponsored | Available with your Andrew account. |\n\n**Note:** Available add-ons for protected AI tools have been thoroughly reviewed and vetted for use at CMU. For example, ChatGPT Edu with [Agents] is already available to paid ChatGPT Edu subscribers.\n\n- [About] \n- [Computing Services InfoCenter] \n- [CSS Awards and Recognition] \n- [News] \n- [Service Status] \n\n[Log In to Services] \n\n- [Computing Services Help Center] \n- [412-268-4357 (HELP)] \n- [it-help@cmu.edu]",
    "length": 2623,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Sarah Cen - College of Engineering at Carnegie Mellon University",
    "url": "https://engineering.cmu.edu/directory/bios/cen-sarah.html",
    "text": "Sarah Cen - College of Engineering at Carnegie Mellon University\n[Skip to Main Content] \n[Carnegie Mellon College of Engineering Home Page![] Carnegie Mellon College of Engineering Home Page] \n[Menu] \n[Carnegie Mellon College of Engineering Home Page![] Carnegie Mellon College of Engineering Home Page] \nSearchSearch\nPopular Searches\n* [Admitted students] \n* [Master’s of AI Engineering] \n* [Engineering Magazine] \n* [graduate programs] \n* [Manufacturing Futures Institute] \n* [Rethink the Rink] \nSocial Media\n* [CMUEngineering] \n* [College of Engineering] \n* [CMUEngineering] \n* [CMUEngineering] \n* [RSS Feed] \n* [@CMUEngineering] \n* [Home] \n* [Directory] \n# Sarah Cen\nAssistant Professor,[Electrical and Computer Engineering],[Engineering and Public Policy] \n![Directory] \n![Directory] \nSarah H. Cen is an assistant professor of Electrical &amp; Computer Engineering and Engineering &amp; Public Policy at Carnegie Mellon University. Cen&#8217;s research lies at the intersection of machine learning, statistics, economics, law, and public policy. Her recent work includes projects on AI audits, AI supply chains, social media regulation, algorithmic fairness, causal inference under network interference, individual rights in the age of AI, and procedural due process for AI-driven decisions. She was previously an HAI postdoctoral researcher at Stanford, jointly affiliated with Stanford Law School's RegLab and the Department of Computer Science, working with Daniel Ho and Percy Liang.\nCen earned her Ph.D. in electrical engineering and computer science at MIT, advised by Aleksander M&#261;dry and Devavrat Shah; a master&#8217;s in robotics at Oxford University with Paul Newman, where she worked on autonomous vehicles; and a BSE in mechanical engineering at Princeton with Naomi Leonard, where she studied control systems.\nEmail[&#115;&#x61;rah&#x63;e&#110;&#64;&#x61;n&#x64;&#x72;&#101;w&#46;&#x63;m&#x75;&#46;e&#100;&#117;] \n## Research Interests\n* [artificial intelligence] \n* [cybersecurity + privacy] \n* [engineering and public policy] \n* [privacy] \n* [statistics] \n* [technology policy] \n[Update your page]",
    "length": 2123,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Protected AI Tools You Can Use",
    "url": "https://www.cmu.edu/computing/services/ai/meet-ai/tools/chatgpt/how-to/connector.html",
    "text": "Protected AI Tools You Can Use - Computing Services - Office of the CIO - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[Computing Services] ## [Office of the CIO] \n[Office of the CIO] &#160;&#8250;&#160;[Computing Services] &#160;&#8250;&#160;[Services] &#160;&#8250;&#160;[Generative Artificial Intelligence (AI)] &#160;&#8250;&#160; Protected AI Tools You Can Use\n# ![] \nProtected AI Tools You Can Use\nThe AI tools listed on this page are available at CMU. When you sign in with your Andrew ID and password, each tool is FERPA-compliant and will not use your data to train its AI models.\n## Interested in New Tools?\nAI tools that have not yet been reviewed or licensed by CMU might not offer the same data protections and approved services.&#160;\nSubmit a[software request] for review and approval.\n# Use AI Safely at CMU\nBefore using CMU's protected AI tools, please review our[policies and guidelines for safe and ethical use].\n# DAO Accessibility Tools\nExplore[tools endorsed by the Digital Accessibility Office] that have AI capabilities.\n# Approved AI Tools\n## [AI Gateway] \n## [ChatGPT Edu] \n## [Gemini Web App] \n## [Microsoft Copilot] \n## [NotebookLM] \n## [Zoom AI Companion] \n## Tool Comparison Table\n|Tool|Purpose|Best For|Available To|Cost|\n[AI Gateway] |AI Developer tool makes AI models easier to access.|Accessing&#160; management to models via API keys.|Faculty and Staff|No cost; however an Oracle String is required to pass on any costs incurred from using a model endpoint.&#160;|\n[ChatGPT Edu] |Synthesizes info, summarizes, and generates content.|Research, writing, and problem-solving.|Faculty and Staff; Students sponsored by a faculty or staff member|$240 / per year|\n[Gemini Web App] |Google's AI that handles text, voice, and files.|Meeting summaries, working with Google Apps, and searching across formats.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n[Microsoft Copilot Chat] |AI support for Office tasks, images, and code.|Microsoft files, documents, and coding help.|Students, Faculty, and Staff|Available with your Andrew account.|\n[NotebookLM] |Creates AI-powered notebooks from uploads.|Organizing ideas, summarizing sources, and creating podcasts.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n[Zoom AI Companion] |Adds summaries and action items to meetings.|Real-time help during virtual meetings.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n**Note:**Available add-ons for protected AI tools have been thoroughly reviewed and vetted for use at CMU. For example, ChatGPT Edu with[Agents] is already available to paid ChatGPT Edu subscribers.\n* [About] \n* [Computing Services InfoCenter] \n* [CSS Awards and Recognition] \n* [News] \n* [Service Status] \n[Log In to Services] \n* [Computing Services Help Center] \n* [412-268-4357 (HELP)] \n* [it-help@cmu.edu]",
    "length": 2961,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "The Latest Work from the SEI: an OpenAI Collaboration, Generative AI, and Zero Trust",
    "url": "https://www.sei.cmu.edu/blog/the-latest-work-from-the-sei-an-openai-collaboration-generative-ai-and-zero-trust/",
    "text": "The Latest Work from the SEI: an OpenAI Collaboration, Generative AI, and Zero Trust\nicon-carat-rightmenusearchcmu-wordmark\n[Carnegie Mellon Universitycmu-wordmark] \n[\n# SEIBlog\n] \n### Cite This Post\n&times;\n* [AMS] \n* [APA] \n* [Chicago] \n* [IEEE] \n* [BibTeX] \nAMS Citation\nSchmidt, D., 2024: The Latest Work from the SEI: an OpenAI Collaboration, Generative AI, and Zero Trust. Carnegie Mellon University, Software Engineering Institute's Insights (blog), Accessed February 12, 2026, https://www.sei.cmu.edu/blog/the-latest-work-from-the-sei-an-openai-collaboration-generative-ai-and-zero-trust/.\nCopy\nAPA Citation\nSchmidt, D. (2024, April 10). The Latest Work from the SEI: an OpenAI Collaboration, Generative AI, and Zero Trust. Retrieved February 12, 2026, from https://www.sei.cmu.edu/blog/the-latest-work-from-the-sei-an-openai-collaboration-generative-ai-and-zero-trust/.\nCopy\nChicago Citation\nSchmidt, Douglas. \"The Latest Work from the SEI: an OpenAI Collaboration, Generative AI, and Zero Trust.\"*Carnegie Mellon University, Software Engineering Institute's Insights (blog)*. Carnegie Mellon's Software Engineering Institute, April 10, 2024. https://www.sei.cmu.edu/blog/the-latest-work-from-the-sei-an-openai-collaboration-generative-ai-and-zero-trust/.\nCopy\nIEEE Citation\nD. Schmidt, \"The Latest Work from the SEI: an OpenAI Collaboration, Generative AI, and Zero Trust,\"*Carnegie Mellon University, Software Engineering Institute's Insights (blog)*. Carnegie Mellon's Software Engineering Institute, 10-Apr-2024 [Online]. Available: https://www.sei.cmu.edu/blog/the-latest-work-from-the-sei-an-openai-collaboration-generative-ai-and-zero-trust/. [Accessed: 12-Feb-2026].\nCopy\nBibTeX Code\n@misc{schmidt\\_2024,\nauthor={Schmidt, Douglas},\ntitle={The Latest Work from the SEI: an OpenAI Collaboration, Generative AI, and Zero Trust},\nmonth={{Apr},\nyear={{2024},\nhowpublished={Carnegie Mellon University, Software Engineering Institute's Insights (blog)},\nurl={https://www.sei.cmu.edu/blog/the-latest-work-from-the-sei-an-openai-collaboration-generative-ai-and-zero-trust/},\nnote={Accessed: 2026-Feb-12}\n}\nCopy\n# The Latest Work from the SEI: an OpenAI Collaboration, Generative AI, and Zero Trust\n![Headshot of Douglas Schmidt.] \n###### [Douglas Schmidt (William &amp; Mary)] \n###### April 10, 2024\n##### PUBLISHED IN\n[Software Engineering Research and Development] \n##### CITE\nGet Citation**\n##### SHARE\n* [**] \n* [**] \n* [**] \n* [**] \n* [**] \nAs part of an ongoing effort to keep you informed about our latest work, this blog post summarizes some recent publications from the SEI in the areas of[large language models for cybersecurity],[software engineering and acquisition with generative AI],[zero trust],[large language models in national security],[capability-based planning],[supply chain risk management],[generative AI in software engineering and acquisition], and[quantum computing].\nThese publications highlight the latest work of SEI technologists in these areas. This post includes a listing of each publication, author(s), and links where they can be accessed on the SEI website.\n[**Considerations for Evaluating Large Language Models for Cybersecurity Tasks**] \n*by Jeff Gennari, Shing-hon Lau, Samuel J. Perl, Joel Parish (OpenAI), and Girish Sastry (OpenAI)*\nGenerative artificial intelligence (AI) and large language models (LLMs) have taken the world by storm. The ability of LLMs to perform tasks seemingly on par with humans has led to rapid adoption in a variety of different domains, including cybersecurity. However, caution is needed when using LLMs in a cybersecurity context due to the impactful consequences and detailed particularities. Current approaches to LLM evaluation tend to focus on factual knowledge as opposed to applied, practical tasks. But cybersecurity tasks often require more than just factual recall to complete. Human performance on cybersecurity tasks is often assessed in part on their ability to apply concepts to realistic situations and adapt to changing circumstances. This paper contends the same approach is necessary to accurately evaluate the capabilities and risks of using LLMs for cybersecurity tasks. To enable the creation of better evaluations, we identify key criteria to consider when designing LLM cybersecurity assessments. These criteria are further refined into a set of recommendations for how to assess LLM performance on cybersecurity tasks. The recommendations include properly scoping tasks, designing tasks based on real-world cybersecurity phenomena, minimizing spurious results, and ensuring results are not misinterpreted.\n[**Read the white paper**] **.**\n[**The Future of Software Engineering and Acquisition with Generative AI**] \n*by Douglas Schmidt (Vanderbilt University), Anita Carleton, James Ivers, Ipek Ozkaya, John E. Robert, and Shen Zhang*\nWe stand at a pivotal moment in software engineering, with artificial intelligence (AI) playing a crucial role in driving approaches poised to enhance software acquisition, analysis, verification, and automation. While generative AI tools initially sparked excitement for their potential to reduce errors, scale changes effortlessly, and drive innovation, concerns have emerged. These concerns encompass security risks, unforeseen failures, and issues of trust. Empirical research on generative AI development assistants reveals that productivity and quality gains depend not only on the sophistication of tools but also on task flow redesign and expert judgment.\nIn this webcast, SEI researchers explore the future of software engineering and acquisition using generative AI technologies. They examine current applications, envision future possibilities, identify research gaps, and discuss the critical skill sets that software engineers and stakeholders need to effectively and responsibly harness generative AI’s potential. Fostering a deeper understanding of AI’s role in software engineering and acquisition accentuates its potential and mitigates its risks.\nThe webcast covers\n* how to identify suitable use cases when starting out with generative AI technology\n* the practical applications of generative AI in software engineering and acquisition\n* how developers and decision makers can harness generative AI technology\n[**View the webcast**] **.**\n[**Zero Trust Industry Days 2024 Scenario: Secluded Semiconductors, Inc.**] \n*by Rhonda Brown*\nEach accepted presenter at the SEI Zero Trust Industry Days 2024 event develops and proposes a solution for this scenario: A company is operating a chip manufacturing facility on an island where there may be loss of connectivity and cloud services for short or extended periods of time. There are many considerations when addressing the challenges of a zero trust implementation, including varying perspectives and philosophies. This event offers a deep examination of how solution providers and other organizations interpret and address the challenges of implementing zero trust. Using a scenario places boundaries on the zero trust space to yield richer discussions.\nThis year’s event focuses on the Industrial Internet of Things (IIoT), legacy systems, smart cities, and cloud-hosted services in a manufacturing environment.\n[Read the white paper].\n[**Using Large Language Models in the National Security Realm**] \nBy Shannon Gallagher\nAt the request of the White House, the Office of the Director of National Intelligence (ODNI) began exploring use cases for large language models (LLMs) within the Intelligence Community (IC). As part of this effort, ODNI sponsored the Mayflower Project at Carnegie Mellon University’s Software Engineering Institute from May 2023 through September 2023. The Mayflower Project attempted to answer the following questions:\n* How might the IC set up a baseline, stand-alone LLM?\n* How might the IC customize LLMs for specific intelligence use cases?\n* How might the IC evaluate the trustworthiness of LLMs across use cases?\nIn this SEI Podcast, Shannon Gallagher, AI engineering team lead, and Rachel Dzombak, former special advisor to the director of the SEI’s AI Division, discuss the findings and recommendations from the Mayflower Project and provide additional background information about LLMs and how they can be engineered for national security use cases.\n[Listen/View the SEI Podcast].\n[**Navigating Capability-Based Planning: The Benefits, Challenges, and Implementation Essentials**] \n*By Anandi Hira and William Nichols*\nCapability-based planning (CBP) defines a framework that has an all-encompassing view of existing abilities and future needs for strategically deciding what is needed and how to effectively achieve it. Both business and government acquisition domains use CBP for financial success or to design a well-balanced defense system. The definitions understandably vary across these domains. This paper endeavors to consolidate these definitions to provide a comprehensive view of CBP, its potential, and practical implementation of its principles.\n[Read the white paper].\n[**Ask Us Anything: Supply Chain Risk Management**] \n*By Brett Tucker and Matthew J. Butkovic*\nAccording to the[Verizon Data Breach Report], Log4j-related exploits have occurred less frequently over the past year. However, this Common Vulnerabilities and Exposures (CVE) flaw was originally documented in 2021. The threat still exists despite increased awareness. Over the past few years, the Software Engineering Institute has developed guidance and practices to help organizations reduce threats to U.S. supply chains. In this webcast, Brett Tucker and Matthew Butkovic, answer enterprise risk management questions to help organizations achieve operational resilience in the cyber supply chain. The webcast covers\n* enterprise risk governance and how to assess organization’s risk appetite and policy as it relates to and integrates cyber risks into a global risk portfolio\n* regulatory directives on third-party risk\n* the agenda and topics to be covered in the upcoming CERT Cyber Supply Chain Risk Management Symposium in February\n[View the webcast].\n[**The Measurement Challenges in Software Assurance and Supply Chain Risk Management**] \n*by Nancy R. Mead, Carol Woody, and Scott Hissam*\nIn this paper, the authors discuss the metrics needed to predict cybersecurity in open source software and how standards are needed to make it easier to apply these metrics in the supply chain. The authors provide examples of potentially useful metrics and underscore the need for data collection and analysis to validate the metrics. They assert that defining metrics, collecting and analyzing data to illustrate their utility, and using standard methods requires unbiased collaborative work to achieve the desired results.\n[Read the white paper].\n[**The Cybersecurity of Quantum Computing: 6 Areas of Research**] \nBy Tom Scanlon\nResearch and development of quantum computers continues to grow at a rapid pace. The U.S. government alone spent more than $800 million on quantum information science research in 2022. Thomas Scanlon, who leads the data science group in the SEI CERT Division, was recently invited to be a participant in the Workshop on Cybersecurity of Quantum Computing, co-sponsored by the National Science Foundation (NSF) and the White House Office of Science and Technology Policy, to examine the emerging field of cybersecurity for quantum computing. In this SEI podcast, Scanlon discusses how to create the discipline of cyber protection of quantum computing and outlines six areas of future research in quantum cybersecurity.\n[Listen to/view the podcast].\n##### Additional Resources\nView the latest SEI research in the[SEI Digital Library].\nView the latest podcasts in the[SEI Podcast Series].\nView the latest installments in the[SEI Webcast Series].\n##### Written By\n[![Douglas Schmidt (William &amp; Mary)]] \n### Douglas Schmidt (William &amp; Mary)\n###### [Author Page] \n###### [Send a Message] \n##### More By The Author\n[#### Perspectives on Generative AI in Software Engineering and Acquisition\n] \n###### February 27, 2025•By[Anita Carleton],[James Ivers],[Ipek Ozkaya],[John E. Robert],[Douglas Schmidt (William &amp; Mary)],[Shen Zhang] \n[#### Generative AI and Software Engineering Education\n] \n###### September 9, 2024•By[Ipek Ozkaya],[Douglas Schmidt (William &amp; Mary)] \n[#### Applying Large Language Models to DoD Software Acquisition: An Initial Experiment\n] \n###### April 1, 2024•By[Douglas Schmidt (William &amp; Mary)],[John E. Robert] \n[#### 10 Benefits and 10 Challenges of Applying Large Language Models to DoD Software Acquisition\n] \n###### January 22, 2024•By[John E. Robert],[Douglas Schmidt (William &amp; Mary)] \n[#### The Latest Work from the SEI\n] \n###### January 15, 2024•By[Douglas Schmidt (William &amp; Mary)] \n##### More In Software Engineering Research and Development\n[#### The Top 10 Blog Posts of 2025\n] \n###### January 12, 2026•By[Thomas A. Longstaff] \n[#### 7 Recommendations to Improve SBOM Quality\n] \n###### August 25, 2025•By[David Tobar],[Jessie Jamieson],[Mark Priest],[Jason Fricke] \n[#### Delivering Resilient Software Capability to the Warfighter at the Speed of Relevance\n] \n###### June 2, 2025•By[Paul Nielsen] \n[#### The Top 10 Blog Posts of 2024\n] \n###### January 6, 2025•By[Bill Scherlis] \n[#### The Latest Work from the SEI: Insider Risk, Bias in LLMs, Secure Coding, and Designing Secure Systems\n] \n###### December 10, 2024•By[Bill Scherlis] \n##### PUBLISHED IN\n[Software Engineering Research and Development] \n##### CITE\nGet Citation**\n##### SHARE\n* [**] \n* [**] \n* [**] \n* [**] \n* [**] \n### Get updates on our latest work.\nSign up to have the latest post sent to your inbox weekly.\n[Subscribe] [**Get our RSS feed] \n##### More In Software Engineering Research and Development\n[#### The Top 10 Blog Posts of 2025\n] \n###### January 12, 2026•By[Thomas A. Longstaff] \n[#### 7 Recommendations to Improve SBOM Quality\n] \n###### August 25, 2025•By[David Tobar],[Jessie Jamieson],[Mark Priest],[Jason Fricke] \n[#### Delivering Resilient Software Capability to the Warfighter at the Speed of Relevance\n] \n###### June 2, 2025•By[Paul Nielsen] \n[#### The Top 10 Blog Posts of 2024\n] \n###### January 6, 2025•By[Bill Scherlis] \n[#### The Latest Work from the SEI: Insider Risk, Bias in LLMs, Secure Coding, and Designing Secure Systems\n] \n###### December 10, 2024•By[Bill Scherlis] \n### Get updates on our latest work. \nEach week, our researchers write about the latest in software engineering, cybersecurity and artificial intelligence. Sign up to get the latest post sent to your inbox the day it's published.\n[Subscribe] [**Get our RSS feed]",
    "length": 14633,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Protected AI Tools You Can Use",
    "url": "https://www.cmu.edu/computing/services/ai/meet-ai/tools/google-ai-tools/index.html",
    "text": "# Protected AI Tools You Can Use\n\nThe AI tools listed on this page are available at CMU. When you sign in with your Andrew ID and password, each tool is FERPA-compliant and will not use your data to train its AI models.\n\n## Interested in New Tools?\n\nAI tools that have not yet been reviewed or licensed by CMU might not offer the same data protections and approved services.\n\nSubmit a [software request] for review and approval.\n\n# Use AI Safely at CMU\n\nBefore using CMU's protected AI tools, please review our [policies and guidelines for safe and ethical use].\n\n# DAO Accessibility Tools\n\nExplore [tools endorsed by the Digital Accessibility Office] that have AI capabilities.\n\n# Approved AI Tools\n\n## [AI Gateway] \n\n## [ChatGPT Edu] \n\n## [Gemini Web App] \n\n## [Microsoft Copilot] \n\n## [NotebookLM] \n\n## [Zoom AI Companion] \n\n## Tool Comparison Table\n\n| Tool | Purpose | Best For | Available To | Cost |\n| --- | --- | --- | --- | --- |\n| [AI Gateway] | AI Developer tool makes AI models easier to access. | Accessing  management to models via API keys. | Faculty and Staff | No cost; however an Oracle String is required to pass on any costs incurred from using a model endpoint. |\n| [ChatGPT Edu] | Synthesizes info, summarizes, and generates content. | Research, writing, and problem-solving. | Faculty and Staff; Students sponsored by a faculty or staff member | $240 / per year |\n| [Gemini Web App] | Google's AI that handles text, voice, and files. | Meeting summaries, working with Google Apps, and searching across formats. | Students, Faculty, Staff, and Sponsored | Available with your Andrew account. |\n| [Microsoft Copilot Chat] | AI support for Office tasks, images, and code. | Microsoft files, documents, and coding help. | Students, Faculty, and Staff | Available with your Andrew account. |\n| [NotebookLM] | Creates AI-powered notebooks from uploads. | Organizing ideas, summarizing sources, and creating podcasts. | Students, Faculty, Staff, and Sponsored | Available with your Andrew account. |\n| [Zoom AI Companion] | Adds summaries and action items to meetings. | Real-time help during virtual meetings. | Students, Faculty, Staff, and Sponsored | Available with your Andrew account. |\n\n**Note:** Available add-ons for protected AI tools have been thoroughly reviewed and vetted for use at CMU. For example, ChatGPT Edu with [Agents] is already available to paid ChatGPT Edu subscribers.\n\n- [About] \n- [Computing Services InfoCenter] \n- [CSS Awards and Recognition] \n- [News] \n- [Service Status] \n\n[Log In to Services] \n\n- [Computing Services Help Center] \n- [412-268-4357 (HELP)] \n- [it-help@cmu.edu]",
    "length": 2623,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Course Catalog | Carnegie Mellon University's Heinz College",
    "url": "https://www.heinz.cmu.edu/current-students/courses/95-767",
    "text": "Course Catalog | Carnegie Mellon University's Heinz Collegestartwitterfacebookenvelopelinkedininstagramyoutubelogoalert-redalerthomeleft-quotechevronhamburgerminusplussearchtrianglex\nSearch CMU HeinzSearch\n[] \n# Course Catalog\n[Back] \n# Cybersecurity for Artificial Intelligence &amp; Machine Learning\n#### 95-767\nUnits:6\n## Description\nAdvancements in Artificial Intelligence (AI) and Machine Learning (ML) have allowed for a surge in adoption of AI &amp; ML solutions to address problems across numerous domains. With this rising reliance on AI &amp; ML in many organizations, it is critical that such systems are protected from malicious activities. This course will discuss AI &amp; ML cybersecurity issues, explore case studies of AI &amp; ML cyber incidents, present AI &amp; ML adversarial techniques, and demonstrate secure design approaches to protect AI &amp; ML systems. With an emphasis on machine learning, the course will focus on secure machine learning systems development approaches and secure machine learning operations (MLOps). Students are expected to have knowledge of fundamental statistics and the ability to program in Python.\n## Learning Outcomes\n* **Cybersecurity Foundations***:*Confidentiality/Integrity/Availability; Cyber Kill Chain; Threat Actors &amp;&amp; Threat Modeling; Cybersecurity Frameworks\n* **ML Fundamentals:**Supervised, semi-supervised, Unsupervised and Reinforcement Learning; Neural Networks &amp;&amp; Deep Learning; Regression, Classification, Clustering, and Anomaly Detection\n* **Adversarial Machine Learning**:\n* **Data Security:**Data Curation; Data Poisoning; Label Flipping; Input Manipulation Attacks,\n* **Model Security**: Model Extraction; Membership Inference Attacks; Model Inversion Attacks; Model Supply Chain Attacks;\n* **AI/ML Defenses &amp; Mitigations**: Data Sanitization; Input Sanitization; Model Inspection; Data Encryption; Adversarial Training\n* **Generative AI Security:**Protecting LLMs; LLMs for Secure Code Generation; LLM Cyber Risks; Deepfake Media; Digital Authenticity\n* **Secure MLOps**: MLOps; AI/ML Software Security; Data Versioning; Model Versioning; Model Deployment; Model Operation &amp; Model Monitoring\n## Prerequisites Description\n90-812 Python Programming I &lt;or&gt;\n95-888 Data Focused Python &lt;&lt;or&gt;&gt;\n95-898 Introduction to Python\nAND\n90-707 Statistical Reasoning &lt;&lt;or&gt;&gt;\n90-711 Statistical Reasoning with R\n## Syllabus\n* [Syllabus (Thomas Scanlon - S26)] \n* [Syllabus (Thomas Scanlon - F25)] \n* [Syllabus (Grant Schumock - F25)] \ntiktok",
    "length": 2555,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Protected AI Tools You Can Use",
    "url": "https://www.cmu.edu/computing/services/ai/meet-ai/tools/chatgpt/how-to/existing-accounts.html",
    "text": "Protected AI Tools You Can Use - Computing Services - Office of the CIO - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[Computing Services] ## [Office of the CIO] \n[Office of the CIO] &#160;&#8250;&#160;[Computing Services] &#160;&#8250;&#160;[Services] &#160;&#8250;&#160;[Generative Artificial Intelligence (AI)] &#160;&#8250;&#160; Protected AI Tools You Can Use\n# ![] \nProtected AI Tools You Can Use\nThe AI tools listed on this page are available at CMU. When you sign in with your Andrew ID and password, each tool is FERPA-compliant and will not use your data to train its AI models.\n## Interested in New Tools?\nAI tools that have not yet been reviewed or licensed by CMU might not offer the same data protections and approved services.&#160;\nSubmit a[software request] for review and approval.\n# Use AI Safely at CMU\nBefore using CMU's protected AI tools, please review our[policies and guidelines for safe and ethical use].\n# DAO Accessibility Tools\nExplore[tools endorsed by the Digital Accessibility Office] that have AI capabilities.\n# Approved AI Tools\n## [AI Gateway] \n## [ChatGPT Edu] \n## [Gemini Web App] \n## [Microsoft Copilot] \n## [NotebookLM] \n## [Zoom AI Companion] \n## Tool Comparison Table\n|Tool|Purpose|Best For|Available To|Cost|\n[AI Gateway] |AI Developer tool makes AI models easier to access.|Accessing&#160; management to models via API keys.|Faculty and Staff|No cost; however an Oracle String is required to pass on any costs incurred from using a model endpoint.&#160;|\n[ChatGPT Edu] |Synthesizes info, summarizes, and generates content.|Research, writing, and problem-solving.|Faculty and Staff; Students sponsored by a faculty or staff member|$240 / per year|\n[Gemini Web App] |Google's AI that handles text, voice, and files.|Meeting summaries, working with Google Apps, and searching across formats.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n[Microsoft Copilot Chat] |AI support for Office tasks, images, and code.|Microsoft files, documents, and coding help.|Students, Faculty, and Staff|Available with your Andrew account.|\n[NotebookLM] |Creates AI-powered notebooks from uploads.|Organizing ideas, summarizing sources, and creating podcasts.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n[Zoom AI Companion] |Adds summaries and action items to meetings.|Real-time help during virtual meetings.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n**Note:**Available add-ons for protected AI tools have been thoroughly reviewed and vetted for use at CMU. For example, ChatGPT Edu with[Agents] is already available to paid ChatGPT Edu subscribers.\n* [About] \n* [Computing Services InfoCenter] \n* [CSS Awards and Recognition] \n* [News] \n* [Service Status] \n[Log In to Services] \n* [Computing Services Help Center] \n* [412-268-4357 (HELP)] \n* [it-help@cmu.edu]",
    "length": 2961,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "OpenAI Collaboration Yields 14 Recommendations for Evaluating LLMs for Cybersecurity",
    "url": "https://www.sei.cmu.edu/blog/openai-collaboration-yields-14-recommendations-for-evaluating-llms-for-cybersecurity/",
    "text": "OpenAI Collaboration Yields 14 Recommendations for Evaluating LLMs for Cybersecurity\nicon-carat-rightmenusearchcmu-wordmark\n[Carnegie Mellon Universitycmu-wordmark] \n[\n# SEIBlog\n] \n### Cite This Post\n&times;\n* [AMS] \n* [APA] \n* [Chicago] \n* [IEEE] \n* [BibTeX] \nAMS Citation\nGennari, J., Lau, S., and Perl, S., 2024: OpenAI Collaboration Yields 14 Recommendations for Evaluating LLMs for Cybersecurity. Carnegie Mellon University, Software Engineering Institute's Insights (blog), Accessed February 11, 2026, https://doi.org/10.58012/1acg-wv61.\nCopy\nAPA Citation\nGennari, J., Lau, S., & Perl, S. (2024, February 21). OpenAI Collaboration Yields 14 Recommendations for Evaluating LLMs for Cybersecurity. Retrieved February 11, 2026, from https://doi.org/10.58012/1acg-wv61.\nCopy\nChicago Citation\nGennari, Jeff, Shing-hon Lau, and Samuel Perl. \"OpenAI Collaboration Yields 14 Recommendations for Evaluating LLMs for Cybersecurity.\"*Carnegie Mellon University, Software Engineering Institute's Insights (blog)*. Carnegie Mellon's Software Engineering Institute, February 21, 2024. https://doi.org/10.58012/1acg-wv61.\nCopy\nIEEE Citation\nJ. Gennari, S. Lau, and S. Perl, \"OpenAI Collaboration Yields 14 Recommendations for Evaluating LLMs for Cybersecurity,\"*Carnegie Mellon University, Software Engineering Institute's Insights (blog)*. Carnegie Mellon's Software Engineering Institute, 21-Feb-2024 [Online]. Available: https://doi.org/10.58012/1acg-wv61. [Accessed: 11-Feb-2026].\nCopy\nBibTeX Code\n@misc{gennari\\_2024,\nauthor={Gennari, Jeff and Lau, Shing-hon and Perl, Samuel},\ntitle={OpenAI Collaboration Yields 14 Recommendations for Evaluating LLMs for Cybersecurity},\nmonth={{Feb},\nyear={{2024},\nhowpublished={Carnegie Mellon University, Software Engineering Institute's Insights (blog)},\nurl={https://doi.org/10.58012/1acg-wv61},\nnote={Accessed: 2026-Feb-11}\n}\nCopy\n# OpenAI Collaboration Yields 14 Recommendations for Evaluating LLMs for Cybersecurity\n![Headshot of Jeff Gennari.]![Headshot of Shing-hon Lau.] \n###### [Jeff Gennari],[Shing-hon Lau],and[Samuel J. Perl] \n###### February 21, 2024\n##### PUBLISHED IN\n[Artificial Intelligence Engineering] \n##### CITE\n[https://doi.org/10.58012/1acg-wv61] \nGet Citation**\n##### SHARE\n* [**] \n* [**] \n* [**] \n* [**] \n* [**] \n[Large language models] (LLMs) have shown a remarkable ability to ingest, synthesize, and summarize knowledge while simultaneously demonstrating significant limitations in completing real-world tasks. One notable domain that presents both opportunities and risks for leveraging LLMs is cybersecurity. LLMs could empower cybersecurity experts to be more efficient or effective at preventing and stopping attacks. However, adversaries could also use[generative artificial intelligence] (AI) technologies in kind. We have already seen evidence of actors using LLMs to aid in cyber intrusion activities (e.g.,[WormGPT],[FraudGPT,] etc.). Such misuse raises many important cybersecurity-capability-related questions including:\n* Can an LLM like GPT-4 write novel malware?\n* Will LLMs become critical components of large-scale cyber-attacks?\n* Can we trust LLMs to provide cybersecurity experts with reliable information?\nThe answer to these questions depends on the analytic methods chosen and the results they provide. Unfortunately, current methods and techniques for evaluating the cybersecurity capabilities of LLMs are not comprehensive. Recently, a team of researchers in the SEI CERT Division worked with[OpenAI] to develop better approaches for evaluating LLM cybersecurity capabilities. This SEI Blog post, excerpted from[a recently published paper that we coauthored with OpenAI researchers] [Joel Parish] and[Girish Sastry], summarizes 14 recommendations to help assessors accurately evaluate LLM cybersecurity capabilities.\n## The Challenge of Using LLMs for Cybersecurity Tasks\nReal cybersecurity tasks are often complex and dynamic and require broad context to be assessed fully. Consider a traditional network intrusion where an attacker seeks to compromise a system. In this scenario, there are two competing roles: attacker and defender, each with different goals, capabilities, and expertise. Attackers may repeatedly change tactics based on defender actions and vice versa. Depending on the attackers’ goals, they may emphasize stealth or attempt to quickly maximize damage. Defenders may choose to simply observe the attack to learn adversary tendencies or gather intelligence or immediately expel the intruder. All the variations of attack and response are impossible to enumerate in isolation.\nThere are many considerations for using an LLM in this type of scenario. Could the LLM make suggestions or take actions on behalf of the cybersecurity expert that stop the attack more quickly or more effectively? Could it suggest or take actions that do unintended harm or prove to be ruinous?\nThese types of concerns speak to the need for thorough and accurate assessment of how LLMs work in a cybersecurity context. However, understanding the cybersecurity capabilities of LLMs to the point that they can be trusted for use in sensitive cybersecurity tasks is hard, partly because many current evaluations are implemented as simple benchmarks that tend to be based on information retrieval accuracy. Evaluations that focus only on the factual knowledge LLMs may have already absorbed, such as having artificial intelligence systems take cybersecurity certification exams, may skew results towards the strengths of the LLM.\nWithout a clear understanding of how an LLM performs on applied and realistic cybersecurity tasks, decision makers lack the information they need to assess opportunities and risks. We contend that practical, applied, and comprehensive evaluations are required to assess cybersecurity capabilities. Realistic evaluations reflect the complex nature of cybersecurity and provide a more complete picture of cybersecurity capabilities.\n## Recommendations for Cybersecurity Evaluations\nTo properly judge the risks and appropriateness of using LLMs for cybersecurity tasks, evaluators need to carefully consider the design, implementation, and interpretation of their assessments. Favoring tests based on practical and applied cybersecurity knowledge is preferred to general fact-based assessments. However, creating these types of assessments can be a formidable task that encompasses infrastructure, task/question design, and data collection. The following list of recommendations is meant to help assessors craft meaningful and actionable evaluations that accurately capture LLM cybersecurity capabilities. The expanded list of recommendations is outlined in our paper.\n### Define the real-world task that you would like your evaluation to capture.\nStarting with a clear definition of the task helps clarify decisions about complexity and assessment. The following recommendations are meant to help define real-world tasks:\n1. *Consider how humans do it*: Starting from first principles, think about how the task you would like to evaluate is accomplished by humans, and write down the steps involved. This process will help clarify the task.\n2. *Use caution with existing datasets:*Current evaluations within the cybersecurity domain have largely leveraged existing datasets, which can influence the type and quality of tasks evaluated.\n3. *Define tasks based on intended use:*Carefully consider whether you are interested in autonomy or human-machine teaming when planning evaluations*.*This distinction will have significant implications for the type of assessment that you conduct.### Represent tasks appropriately.\nMost tasks worth evaluating in cybersecurity are too nuanced or complex to be represented with simple queries, such as multiple-choice questions. Rather, queries need to reflect the nature of the task without being unintentionally or artificially limiting. The following guidelines ensure evaluations incorporate the complexity of the task:\n1. *Define an appropriate scope:*While subtasks of complex tasks are usually easier to represent and measure, their performance does not always correlate with the larger task. Ensure that you do not represent the real-world task with a narrow subtask.\n2. *Develop an infrastructure to support the evaluation:*Practical and applied tests will generally require significant infrastructure support, particularly in supporting interactivity between the LLM and the test environment.\n3. *Incorporate affordances to humans where appropriate:*Ensure your assessment mirrors real-world affordances and accommodations given to humans.\n4. *Avoid affordances to humans where inappropriate:*Evaluations of humans in higher education and professional-certification settings may ignore real-world complexity.### Make your evaluation robust.\nUse care when designing evaluations to avoid spurious results. Assessors should consider the following guidelines when creating assessments:\n1. *Use preregistration:*Consider how you will grade the task ahead of time.\n2. *Apply realistic perturbations to inputs*: Changing the wording, ordering, or names in a question would have minimal effects on a human but can result in dramatic shifts in LLM performance. These changes must be accounted for in assessment design.\n3. *Beware of training data contamination*: LLMs are frequently trained on large corpora, including news of vulnerability feeds, Common Vulnerabilities and Exposures (CVE) websites, and code and online discussions of security. These data may make some tasks artificially easy for the LLM.### Frame results appropriately.\nEvaluations with a sound methodology can still misleadingly frame results. Consider the following guidelines when interpreting results:\n1. *Avoid overgeneralized claims:*Avoid making sweeping claims about capabilities from the task or subtask evaluated. For example, strong model performance in an evaluation measuring vulnerability identification in a single function does not mean that a model is good at discovering vulnerabilities in a real-world web application where resources, such as access to source code may be restricted.\n2. *Estimate best-case and worst-case performance:*LLMs may have wide variations in evaluation performance due to different prompting strategies or because they use additional test-time compute techniques (e.g.,[Chain-of-Thought prompting]). Best/worst case scenarios will help constrain the range of outcomes.\n3. *Be careful with model selection bias:*Any conclusions drawn from evaluations should be put into the proper context. If possible, run tests on a variety of contemporary models, or qualify claims appropriately.\n4. *Clarify whether you are evaluating risk or evaluating capabilities*. A judgment about the risk of models requires a threat model. In general, however, the capability profile of the model is only one source of uncertainty about the risk. Task-based evaluations can help understand the capability of the model.## Wrapping Up and Looking Ahead\nAI and LLMs have the potential to be both an asset to cybersecurity professionals and a boon to malicious actors unless risks are managed properly. To better understand and assess the cybersecurity capabilities and risks of LLMs, we propose developing evaluations that are grounded in real and complex scenarios with competing goals. Assessments based on standard, factual knowledge skew towards the type of reasoning LLMs are inherently good at (i.e., factual information recall).\nTo get a more complete sense of cybersecurity expertise, evaluations should consider applied security concepts in realistic scenarios. This recommendation is not to say that a basic command of cybersecurity knowledge is not valuable to evaluate; rather, more realistic and robust assessments are required to judge cybersecurity expertise accurately and comprehensively. Understanding how an LLM performs on real cybersecurity tasks will provide policy and decision makers with a clearer sense of capabilities and the risks of using these technologies in such a sensitive context.\n## Additional Resources\n[*Considerations for Evaluating Large Language Models for Cybersecurity Tasks*] by Jeffrey Gennari, Shing-hon Lau, Samuel Perl, Joel Parish (Open AI), and Girish Sastry (Open AI)\n##### Written By\n[![Jeff Gennari]] \n### Jeff Gennari\n###### [Author Page] \n###### [Send a Message] \n[![Shing-hon Lau]] \n### Shing-hon Lau\n###### [Author Page] \n###### [Send a Message] \n[![Samuel J. Perl]] \n### Samuel J. Perl\n###### [Author Page] \n###### [Send a Message] \n##### More By The Authors\n[#### Protecting AI from the Outside In: The Case for Coordinated Vulnerability Disclosure\n] \n###### February 24, 2025•By[Allen D. Householder],[Vijay S. Sarvepalli],[Jeff Havrilla],[Matt Churilla],[Lena Pons],[Shing-hon Lau],[Nathan M. VanHoudnos],[Andrew Kompanek],[Lauren McIlvenny] \n[#### Beyond Capable: Accuracy, Calibration, and Robustness in Large Language Models\n] \n###### December 3, 2024•By[Matthew Walsh],[David Schulker],[Shing-hon Lau] \n[#### How Do You Trust AI Cybersecurity Devices?\n] \n###### January 24, 2022•By[Grant Deffenbaugh],[Shing-hon Lau] \n[#### Two Tools for Malware Analysis and Reverse Engineering in Ghidra\n] \n###### November 1, 2021•By[Jeff Gennari] \n[#### GhiHorn: Path Analysis in Ghidra Using SMT Solvers\n] \n###### October 18, 2021•By[Jeff Gennari] \n##### More In Artificial Intelligence Engineering\n[#### My AI System Works…But Is It Safe to Use?\n] \n###### September 9, 2025•By[David Schulker],[Matthew Walsh],[Emil Mathew] \n[#### Artificial Intelligence in National Security: Acquisition and Integration\n] \n###### August 5, 2025•By[Paige Rishel],[Carol J. Smith],[Brigid O&#x27;Hearn],[Rita C. Creel] \n[#### Amplifying AI Readiness in the DoD Workforce\n] \n###### June 23, 2025•By[Eric Keylor],[Robert W. Beveridge],[Jonathan Frederick] \n[#### Out of Distribution Detection: Knowing When AI Doesn&#x27;t Know\n] \n###### June 9, 2025•By[Eric Heim],[Cole Frank] \n[#### 10 Things Organizations Should Know About AI Workforce Development\n] \n###### April 28, 2025•By[Jonathan Frederick],[Dominic A. Ross],[Eric Keylor],[Cole Frank],[Intae Nam] \n##### PUBLISHED IN\n[Artificial Intelligence Engineering] \n##### CITE\n[https://doi.org/10.58012/1acg-wv61] \nGet Citation**\n##### SHARE\n* [**] \n* [**] \n* [**] \n* [**] \n* [**] \n### Get updates on our latest work.\nSign up to have the latest post sent to your inbox weekly.\n[Subscribe] [**Get our RSS feed] \n##### More In Artificial Intelligence Engineering\n[#### My AI System Works…But Is It Safe to Use?\n] \n###### September 9, 2025•By[David Schulker],[Matthew Walsh],[Emil Mathew] \n[#### Artificial Intelligence in National Security: Acquisition and Integration\n] \n###### August 5, 2025•By[Paige Rishel],[Carol J. Smith],[Brigid O&#x27;Hearn],[Rita C. Creel] \n[#### Amplifying AI Readiness in the DoD Workforce\n] \n###### June 23, 2025•By[Eric Keylor],[Robert W. Beveridge],[Jonathan Frederick] \n[#### Out of Distribution Detection: Knowing When AI Doesn&#x27;t Know\n] \n###### June 9, 2025•By[Eric Heim],[Cole Frank] \n[#### 10 Things Organizations Should Know About AI Workforce Development\n] \n###### April 28, 2025•By[Jonathan Frederick],[Dominic A. Ross],[Eric Keylor],[Cole Frank],[Intae Nam] \n### Get updates on our latest work. \nEach week, our researchers write about the latest in software engineering, cybersecurity and artificial intelligence. Sign up to get the latest post sent to your inbox the day it's published.\n[Subscribe] [**Get our RSS feed]",
    "length": 15474,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Protected AI Tools You Can Use",
    "url": "https://www.cmu.edu/computing/services/ai/meet-ai/tools/chatgpt/how-to/index.html",
    "text": "Protected AI Tools You Can Use - Computing Services - Office of the CIO - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[Computing Services] ## [Office of the CIO] \n[Office of the CIO] &#160;&#8250;&#160;[Computing Services] &#160;&#8250;&#160;[Services] &#160;&#8250;&#160;[Generative Artificial Intelligence (AI)] &#160;&#8250;&#160; Protected AI Tools You Can Use\n# ![] \nProtected AI Tools You Can Use\nThe AI tools listed on this page are available at CMU. When you sign in with your Andrew ID and password, each tool is FERPA-compliant and will not use your data to train its AI models.\n## Interested in New Tools?\nAI tools that have not yet been reviewed or licensed by CMU might not offer the same data protections and approved services.&#160;\nSubmit a[software request] for review and approval.\n# Use AI Safely at CMU\nBefore using CMU's protected AI tools, please review our[policies and guidelines for safe and ethical use].\n# DAO Accessibility Tools\nExplore[tools endorsed by the Digital Accessibility Office] that have AI capabilities.\n# Approved AI Tools\n## [AI Gateway] \n## [ChatGPT Edu] \n## [Gemini Web App] \n## [Microsoft Copilot] \n## [NotebookLM] \n## [Zoom AI Companion] \n## Tool Comparison Table\n|Tool|Purpose|Best For|Available To|Cost|\n[AI Gateway] |AI Developer tool makes AI models easier to access.|Accessing&#160; management to models via API keys.|Faculty and Staff|No cost; however an Oracle String is required to pass on any costs incurred from using a model endpoint.&#160;|\n[ChatGPT Edu] |Synthesizes info, summarizes, and generates content.|Research, writing, and problem-solving.|Faculty and Staff; Students sponsored by a faculty or staff member|$240 / per year|\n[Gemini Web App] |Google's AI that handles text, voice, and files.|Meeting summaries, working with Google Apps, and searching across formats.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n[Microsoft Copilot Chat] |AI support for Office tasks, images, and code.|Microsoft files, documents, and coding help.|Students, Faculty, and Staff|Available with your Andrew account.|\n[NotebookLM] |Creates AI-powered notebooks from uploads.|Organizing ideas, summarizing sources, and creating podcasts.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n[Zoom AI Companion] |Adds summaries and action items to meetings.|Real-time help during virtual meetings.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n**Note:**Available add-ons for protected AI tools have been thoroughly reviewed and vetted for use at CMU. For example, ChatGPT Edu with[Agents] is already available to paid ChatGPT Edu subscribers.\n* [About] \n* [Computing Services InfoCenter] \n* [CSS Awards and Recognition] \n* [News] \n* [Service Status] \n[Log In to Services] \n* [Computing Services Help Center] \n* [412-268-4357 (HELP)] \n* [it-help@cmu.edu]",
    "length": 2961,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "AI and Its Growing Energy Demand | Carnegie Mellon University",
    "url": "https://www.cmu.edu/work-that-matters/energy-innovation/ai-and-its-growing-energy-demand",
    "text": "AI and Its Growing Energy Demand | Carnegie Mellon University[Skip to main content] \n[] \nWhat can we help you find?\nPopular Searches\n* [Undergraduate Admissions] \n* [Career Center] \n* [Majors and Programs] \n* [Cancer Research] \n* [Pulitzer Prize] \n# AI and Its Growing Energy Demand\n*By:*[*Zico Kolter*] \nAI models, especially the large models powering systems like ChatGPT, have exploded in capabilities and usage over the past years. In response, there have been many commitments from large companies to spend tens or hundreds of billions of dollars to[build data centers] that can power these AI models.\n**Why it matters:**These data centers, in turn, need to be powered by large amounts of electricity: it’s not uncommon for newly proposed data centers to[consume over 1 Gigawatt (GW) of electrical power]. By comparison,[the entire Pittsburgh area uses an average of between 1-2 GW of electrical power] over the course of a day.\n**The big questions:**But why do AI models use this much electricity? What is driving this rapid increase in demand? And perhaps most subjectively, will the resulting increases in AI capabilities and availability be “worth” the cost in power?\n**Catch up quick:**Doing any kind of computation on a computer requires power: to use your laptop, you need to plug it into an outlet, and if you’re doing a particularly intensive task, you’ll likely even notice it heating up from that power consumption. AI models work the same way but on a much larger scale.\nThe AI models that power systems like ChatGPT work by first transforming the text you type into numbers, then multiplying and adding these numbers many trillions of times, very quickly, to eventually produce a written response, an image, or a video. The costs associated with data centers correspond to: 1) the cost of the building/facilities themselves; 2) the cost of the computer chips that run the computation; and finally 3) the electrical power used to run the chips and run the cooling systems to prevent them from overheating.\n**The details:**AI’s energy demands have grown rapidly for two main reasons.\n* First, because of a phenomenon called the “[scaling laws] ” of AI models. For several years, researchers have recognized that if you increase the number of computations used by the AI models: say going from 100 billion to 1 trillion to 10 trillion operations to produce an output, then the performance of the resulting model will improve by corresponding amount. Due to the desire to create ever-more-capable models, companies want to create models that use more and more computations, and hence more and more energy.\n* The second reason is due to our increasing use of AI. In the past 2.5 years, AI has grown from a set of niche use cases, to a tool that many of us use every day. Thus, the net effect of larger models and massive growth is a rapidly increasing demand for electrical power, even in light of other improvements of efficiency.\n**Worth noting:**We don’t*always*need more electrical power to run the AI models:[the efficiency of computer chips are*also*improving exponentially] as are the efficiency of the underlying algorithmic approaches themselves, which can offset much of the increase in power.\n**The big picture:**All of this finally leads to the natural question: is this increasing demand for power “worth” its cost? The answer, naturally, depends on our individual perception of the value of AI systems. If you are inherently skeptical about the value provided by AI systems, then you may feel that the benefits do not outweigh the energy costs. But if (and I now have to acknowledge that I place myself in this camp) you believe that AI has the potential to substantially transform our world for the better, then the energy cost may seem to be well worth it.\nAI technology, if deployed responsibly, has the potential to drastically increase productivity, to enable us to create software in a faster and more robust manner, to advance science, and to ultimately benefit the human condition. Most revolutions that ultimately have increased the quality of life for the majority of humanity —the industrial revolution, modern transportation, and the introduction of computers —all came with associated increases in energy cost, and AI will likely be no different.\n**What's next:**As work across Carnegie Mellon shows, AI has the potential to drastically*improve*our energy consumption as well, assisting in developing more efficient techniques for[grid operation], building better materials for batteries, and potentially even truly revolutionizing energy through accelerating the development of technologies like[nuclear fusion]. These are all big bets, to be clear, and advancing science is never a sure thing, but AI at its best can be a unique enabler of so many beneficial downstream technologies.\nAs we move AI technology forward, and build the needed infrastructure to power this revolution, it is incumbent upon all of us to ensure that the positive impacts of AI are worth the substantial energy cost. Owning to work at Carnegie Mellon and elsewhere, we are well-positioned to meet this challenge.\n[Download White Paper PDF] \n## More on Meeting AI Energy Demand\n[AI-Driven Discoveries to Catalyze Energy Storage] \n[Sustaining AI Growth Needs Energy and Carbon Efficient Computing Infrastructure] \n[Accelerating Safe Microreactors: AI and Knowledge Graphs for Regulatory Reuse and Human-System Integration] \n[Building American Strength and Resiliency in Critical Minerals for Energy Storage] \n[‘AI Fast Lanes’ for an Electricity System to Meet the AI Moment] \n[Building the Robust Transmission Capacity Necessary to Power America] \n[How AI Can Unlock Fusion Energy] \n[Unlocking Energy Efficient AI] \n[Open Source AI May Reduce Energy Demands]",
    "length": 5773,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Protected AI Tools You Can Use",
    "url": "https://www.cmu.edu/computing/services/ai/meet-ai/tools/copilot/ms-copilot-how-to.html",
    "text": "Protected AI Tools You Can Use - Computing Services - Office of the CIO - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[Computing Services] ## [Office of the CIO] \n[Office of the CIO] &#160;&#8250;&#160;[Computing Services] &#160;&#8250;&#160;[Services] &#160;&#8250;&#160;[Generative Artificial Intelligence (AI)] &#160;&#8250;&#160; Protected AI Tools You Can Use\n# ![] \nProtected AI Tools You Can Use\nThe AI tools listed on this page are available at CMU. When you sign in with your Andrew ID and password, each tool is FERPA-compliant and will not use your data to train its AI models.\n## Interested in New Tools?\nAI tools that have not yet been reviewed or licensed by CMU might not offer the same data protections and approved services.&#160;\nSubmit a[software request] for review and approval.\n# Use AI Safely at CMU\nBefore using CMU's protected AI tools, please review our[policies and guidelines for safe and ethical use].\n# DAO Accessibility Tools\nExplore[tools endorsed by the Digital Accessibility Office] that have AI capabilities.\n# Approved AI Tools\n## [AI Gateway] \n## [ChatGPT Edu] \n## [Gemini Web App] \n## [Microsoft Copilot] \n## [NotebookLM] \n## [Zoom AI Companion] \n## Tool Comparison Table\n|Tool|Purpose|Best For|Available To|Cost|\n[AI Gateway] |AI Developer tool makes AI models easier to access.|Accessing&#160; management to models via API keys.|Faculty and Staff|No cost; however an Oracle String is required to pass on any costs incurred from using a model endpoint.&#160;|\n[ChatGPT Edu] |Synthesizes info, summarizes, and generates content.|Research, writing, and problem-solving.|Faculty and Staff; Students sponsored by a faculty or staff member|$240 / per year|\n[Gemini Web App] |Google's AI that handles text, voice, and files.|Meeting summaries, working with Google Apps, and searching across formats.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n[Microsoft Copilot Chat] |AI support for Office tasks, images, and code.|Microsoft files, documents, and coding help.|Students, Faculty, and Staff|Available with your Andrew account.|\n[NotebookLM] |Creates AI-powered notebooks from uploads.|Organizing ideas, summarizing sources, and creating podcasts.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n[Zoom AI Companion] |Adds summaries and action items to meetings.|Real-time help during virtual meetings.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n**Note:**Available add-ons for protected AI tools have been thoroughly reviewed and vetted for use at CMU. For example, ChatGPT Edu with[Agents] is already available to paid ChatGPT Edu subscribers.\n* [About] \n* [Computing Services InfoCenter] \n* [CSS Awards and Recognition] \n* [News] \n* [Service Status] \n[Log In to Services] \n* [Computing Services Help Center] \n* [412-268-4357 (HELP)] \n* [it-help@cmu.edu]",
    "length": 2961,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "This Stapler Knows When You Need It",
    "url": "https://www.cs.cmu.edu/news/2025/unobtrusive-ai",
    "text": "This Stapler Knows When You Need It\n# [![] Carnegie Mellon University School of Computer Science] \n[Skip to Main Content] Search**\nSearch**\n# This Stapler Knows When You Need ItCMU Researchers Use AI To Turn Everyday Objects Into Proactive Assistants\nMallory LindahlThursday, October 9, 2025[**Print this page.] \n![] The HCII's Alexandra Ion and Violet Han are part of a team using AI to turn everyday objects into proactive personal assistants.\n**The Breakdown**\n* CMU researchers are harnessing AI to help everyday objects sense human activity and respond in useful ways.\n* Their system uses computer vision, LLMs and wheeled platforms to observe behavior, predict intentions and move objects across horizontal surfaces.\n* The team is exploring larger applications of the system, including shelves that unfold from walls when they're needed.\n&#160;&#160;\\*\\*\\*\nA stapler slides across a desk to meet a waiting hand, or a knife edges out of the way just before someone leans against a countertop. It sounds like magic, but in Carnegie Mellon University's[Human-Computer Interaction Institute] (HCII) researchers are combining AI and robotic mobility to give everyday objects this kind of foresight.\nUsing large language models (LLMs) and wheeled robotic platforms, HCII researchers have transformed ordinary items &#8212; like mugs, plates or utensils &#8212; into proactive assistants that can observe human behavior, predict interventions and move across horizontal surfaces to help humans at just the right time.\n\"Our goal is to create adaptive systems for physical interaction that are unobtrusive, meaning they blend into our lives while still dynamically adapting to our needs,\" said[Alexandra Ion], an HCII assistant professor who leads the[Interactive Structures Lab]. \"We classify this work as unobtrusive because the user does not ask the objects to perform any tasks. Instead, the objects sense what the user needs and perform the tasks themselves.\"\nThe Interactive Structures Lab's unobtrusive system uses computer vision and LLMs to reason about a person's goals, predicting what they may do or need next. A ceiling-mounted camera senses the environment and tracks the position of objects. The system then translates what the camera sees into a text-based description of the scene. Next, an LLM uses this translation to infer what the person's goals may be and which actions would help them most. Finally, the system transfers the predicted actions to the item. This process allows for seamless help with everyday tasks like cooking, organizing, office work and more.\n[*[![Embedded YouTube video]] *] \n\"We have a lot of assistance from AI in the digital realm, but we want to focus on AI assistance in the physical domain,\" said[Violet Han], an HCII Ph.D. student working with Ion. \"We chose to enhance everyday objects because users already trust them. By advancing the objects' capabilities, we hope to increase that trust.\"\nIon and her team have started studying ways to expand the scope of unobtrusive physical AI to other parts of homes and offices.\n\"Imagine, for example, you come home with a bag of groceries. A shelf automatically folds out from the wall and you can set the bag down while you're taking off your coat,\" Ion said during her episode of the School of Computer Science's \"[Does Compute] \" podcast. \"The idea is that we develop and study technology that seamlessly integrates into our daily lives and is so well assimilated that it becomes almost invisible, yet is consistently bringing us new functionality.\"\nThe Interactive Structures Lab aims to create intuitive physical interfaces that bring safe, reliable physical assistance into homes, hospitals, factories and other spaces. The team's work in unobtrusive physical AI was accepted to the[2025 ACM Symposium on User Interface Software and Technology], held recently in Busan, Korea.\nTo learn more about the research, visit the[project website].\n**For More Information**\nAaron Aupperlee | 412-268-9068 | aaupperlee@cmu.edu",
    "length": 4012,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Protected AI Tools You Can Use",
    "url": "https://www.cmu.edu/computing/services/ai/meet-ai/tools/chatgpt/how-to/chatgpt-agent.html",
    "text": "# Protected AI Tools You Can Use\n\nThe AI tools listed on this page are available at CMU. When you sign in with your Andrew ID and password, each tool is FERPA-compliant and will not use your data to train its AI models.\n\n## Interested in New Tools?\n\nAI tools that have not yet been reviewed or licensed by CMU might not offer the same data protections and approved services.\n\nSubmit a [software request] for review and approval.\n\n# Use AI Safely at CMU\n\nBefore using CMU's protected AI tools, please review our [policies and guidelines for safe and ethical use].\n\n# DAO Accessibility Tools\n\nExplore [tools endorsed by the Digital Accessibility Office] that have AI capabilities.\n\n# Approved AI Tools\n\n## [AI Gateway] \n\n## [ChatGPT Edu] \n\n## [Gemini Web App] \n\n## [Microsoft Copilot] \n\n## [NotebookLM] \n\n## [Zoom AI Companion] \n\n## Tool Comparison Table\n\n| Tool | Purpose | Best For | Available To | Cost |\n| --- | --- | --- | --- | --- |\n| [AI Gateway] | AI Developer tool makes AI models easier to access. | Accessing  management to models via API keys. | Faculty and Staff | No cost; however an Oracle String is required to pass on any costs incurred from using a model endpoint. |\n| [ChatGPT Edu] | Synthesizes info, summarizes, and generates content. | Research, writing, and problem-solving. | Faculty and Staff; Students sponsored by a faculty or staff member | $240 / per year |\n| [Gemini Web App] | Google's AI that handles text, voice, and files. | Meeting summaries, working with Google Apps, and searching across formats. | Students, Faculty, Staff, and Sponsored | Available with your Andrew account. |\n| [Microsoft Copilot Chat] | AI support for Office tasks, images, and code. | Microsoft files, documents, and coding help. | Students, Faculty, and Staff | Available with your Andrew account. |\n| [NotebookLM] | Creates AI-powered notebooks from uploads. | Organizing ideas, summarizing sources, and creating podcasts. | Students, Faculty, Staff, and Sponsored | Available with your Andrew account. |\n| [Zoom AI Companion] | Adds summaries and action items to meetings. | Real-time help during virtual meetings. | Students, Faculty, Staff, and Sponsored | Available with your Andrew account. |\n\n**Note:** Available add-ons for protected AI tools have been thoroughly reviewed and vetted for use at CMU. For example, ChatGPT Edu with [Agents] is already available to paid ChatGPT Edu subscribers.\n\n- [About] \n- [Computing Services InfoCenter] \n- [CSS Awards and Recognition] \n- [News] \n- [Service Status] \n\n[Log In to Services] \n\n- [Computing Services Help Center] \n- [412-268-4357 (HELP)] \n- [it-help@cmu.edu]",
    "length": 2623,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Protected AI Tools You Can Use",
    "url": "https://www.cmu.edu/computing/services/ai/meet-ai/tools/google-ai-tools/notebook-lm-how-to.html",
    "text": "Protected AI Tools You Can Use - Computing Services - Office of the CIO - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[Computing Services] ## [Office of the CIO] \n[Office of the CIO] &#160;&#8250;&#160;[Computing Services] &#160;&#8250;&#160;[Services] &#160;&#8250;&#160;[Generative Artificial Intelligence (AI)] &#160;&#8250;&#160; Protected AI Tools You Can Use\n# ![] \nProtected AI Tools You Can Use\nThe AI tools listed on this page are available at CMU. When you sign in with your Andrew ID and password, each tool is FERPA-compliant and will not use your data to train its AI models.\n## Interested in New Tools?\nAI tools that have not yet been reviewed or licensed by CMU might not offer the same data protections and approved services.&#160;\nSubmit a[software request] for review and approval.\n# Use AI Safely at CMU\nBefore using CMU's protected AI tools, please review our[policies and guidelines for safe and ethical use].\n# DAO Accessibility Tools\nExplore[tools endorsed by the Digital Accessibility Office] that have AI capabilities.\n# Approved AI Tools\n## [AI Gateway] \n## [ChatGPT Edu] \n## [Gemini Web App] \n## [Microsoft Copilot] \n## [NotebookLM] \n## [Zoom AI Companion] \n## Tool Comparison Table\n|Tool|Purpose|Best For|Available To|Cost|\n[AI Gateway] |AI Developer tool makes AI models easier to access.|Accessing&#160; management to models via API keys.|Faculty and Staff|No cost; however an Oracle String is required to pass on any costs incurred from using a model endpoint.&#160;|\n[ChatGPT Edu] |Synthesizes info, summarizes, and generates content.|Research, writing, and problem-solving.|Faculty and Staff; Students sponsored by a faculty or staff member|$240 / per year|\n[Gemini Web App] |Google's AI that handles text, voice, and files.|Meeting summaries, working with Google Apps, and searching across formats.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n[Microsoft Copilot Chat] |AI support for Office tasks, images, and code.|Microsoft files, documents, and coding help.|Students, Faculty, and Staff|Available with your Andrew account.|\n[NotebookLM] |Creates AI-powered notebooks from uploads.|Organizing ideas, summarizing sources, and creating podcasts.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n[Zoom AI Companion] |Adds summaries and action items to meetings.|Real-time help during virtual meetings.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n**Note:**Available add-ons for protected AI tools have been thoroughly reviewed and vetted for use at CMU. For example, ChatGPT Edu with[Agents] is already available to paid ChatGPT Edu subscribers.\n* [About] \n* [Computing Services InfoCenter] \n* [CSS Awards and Recognition] \n* [News] \n* [Service Status] \n[Log In to Services] \n* [Computing Services Help Center] \n* [412-268-4357 (HELP)] \n* [it-help@cmu.edu]",
    "length": 2961,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Policies & Guidelines -     Trademark Licensing - Carnegie Mellon University",
    "url": "https://www.cmu.edu/trademark/policies-guidelines/index.html",
    "text": "Policies &amp; Guidelines - Trademark Licensing - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n# [Trademark Licensing] \n[Trademark Licensing] &#160;&#8250;&#160; Policies &amp; Guidelines\n### Understand key policies, guidelines and code of conduct language.\nThese are several documents you should be familiar with before using any trademarks of Carnegie Mellon University. Please take the time to read regardless if you plan to use an official or non-official logtype for \"CARNEGIE MELLON UNIVERSITY\" or \"CMU\".\n* [Official Policy for the Use of Carnegie Mellon University Trademarks] \nThe purpose of this policy is to provide information and guidelines to the university community regarding the use of Carnegie Mellon University's trademarks. The overall purpose of the licensing program is to protect Carnegie Mellon University's trademarks and to promote the university.\nThis policy does not concern itself with patents or with use of trademarks licensed by the university Office of Innovation Transfer. Contact the Office of Innovation Transfer for such intellectual property issues. This policy also does not concern itself with the use of Carnegie Mellon University's trademarks on the Internet. &#160;Contact Marketing and Communications with your questions about that type of use.\n* [Code of Workplace Conduct for Trademark Licensees] \nThis Code of Conduct shall apply to all trademark licensees of Carnegie Mellon University. Throughout this Code of Conduct the term \"licensee\" shall include all persons or entities who have entered into a written Trademark Licensing Agreement with Carnegie Mellon to manufacture products bearing the name, trademarks and/or images of Carnegie Mellon.\n* [Guidelines for branding merchandise with any Carnegie Mellon University mark] \nThe following guidelines clarify how and when to use the official and unofficial Carnegie Mellon\nUniversity wordmarks on merchandise. For details about using these wordmarks on other marketing materials (brochures, business cards, letterhead, etc.) see the[Official Brand Identity Guidelines] &#160;&#160;\n* Identity guidelines for using the&#160;[wordmark &amp; unitmarks] \nThe identity guidelines provide a framework for you and your department's current graphic identity.\n* Identity guidelines for use of the[Scotty dog mascot graphics] \nCarnegie Mellon's official mascot debuted in Nov. 10, 2007. The graphic (a registered trademark) features a profile of a distinguished, bold Scottish terrier sporting a plaid scarf around his neck. The dog is contained in a shield, representing Carnegie Mellon's Scottish heritage.",
    "length": 2676,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Generative AI for Grading & Feedback",
    "url": "https://www.cmu.edu/teaching/technology/aitools/gen-ai-for-grading-and-feedback/index.html",
    "text": "Generative AI for Grading &amp; Feedback - Eberly Center - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[Eberly Center] ## Teaching Excellence &amp; Educational Innovation\n[Eberly Center] &#160;&#8250;&#160;[Technology for Education] &#160;&#8250;&#160;[Generative AI Tools FAQ] &#160;&#8250;&#160; Generative AI for Grading &amp; Feedback\n# Generative AI for Grading &amp; Feedback\nThe introduction and evolution of generative AI (genAI) tools continues to disrupt higher education in ways that are challenging to navigate. These tools seem to offer potential ways to enhance or circumvent learning, depending on how they are used and to what end. In our[FAQs page], we covered common questions around student use of genAI tools, including how to decide whether to incorporate them deliberately into the classroom and how to write a syllabus policy. However, it is equally important to consider the use of genAI**by instructors and TAs,**including possible affordances, concerns, and how this will be communicated to students, especially when it comes to**grading and delivering feedback**.&#160;\nHere we provide a heuristic that can help instructors decide whether or not to incorporate genAI tools, in particular[CMU vetted/FERPA compliant GenAI tools], into their grading and feedback processes. We acknowledge that LLMs and genAI technologies are continually evolving rapidly (e.g., ChatGPT 4.0 continues to improve and AI agents are coming into play), but still need further research.\nEach question links to its own section with research and recommendations.\n* [What are your motivations for using genAI for grading or feedback?] &#160;\n* [Do you have enough materials and time to fine-tune the tool to provide high quality feedback? How will you review its output for reliability, accuracy, and fairness?] \n* [What other tools or strategies could accomplish the task?] \n* [If you have TAs, what will you communicate to them about the use of genAI for grading or feedback? How will you train them to appropriately use genAI for this task?&#160;] \n* [What are the legal, ethical, and privacy concerns of students that you should think through before using the tool?] \n* [How will you communicate your decisions to use genAI in grading and feedback (or not) to students? Does your use of it align with your policy for student use of genAI?] \n* [References] \n## **Affordances &amp; Considerations for Generative AI in Grading &amp; Feedback Webinar**\n[![Embedded YouTube video]] \n[GenAI for Grading &amp; Feedback Worksheet] \n[Feedback Form for this Webinar] \n## **Generative AI Teaching as Research**\n![Generative AI Diagram] \n*Do generative AI tools increase, decrease, or not change student learning and equity? In what teaching contexts?&#160;*Take a look at what CMU instructors are investigating with us.\n[Visit our GAITAR website] \n## What are your motivations for using genAI for grading or feedback?\nMany instructors and TAs may be drawn to genAI because of a belief that it can streamline the grading and feedback process, thereby saving them time and effort, as well as getting feedback to students sooner. While this sounds desirable, if true, it does not necessarily suggest a reduction in instructor and/or TA responsibilities, or a reduction in the number of TAs hired. Any increase in efficiency from leveraging technology raises the question: What opportunities does this create for instructors and/or TAs to interact with students differently and more impactfully to further enhance learning?\nRegardless, genAI use for grading and feedback raises additional questions about quality assurance, such as &#8220;How would using genAI impact the reliability of grades, the quality of feedback, and/or student learning?&#8221; Research on genAI tools and their ability to accurately grade and provide effective, quality feedback is still emerging, but initial results suggest instructors and TA should be cautious about how and when to use it, if at all. Here are a few emerging trends:\n## GenAI feedback can potentially provide helpful, &#8220;on-demand&#8221; feedback for students as a supplement to instructor/TA feedback.\nFor instructors who want students to be able to get additional,[formative feedback] during practice or on draft work, genAI automated feedback systems could potentially be another tool for students to use as part of their learning process. Although we lack sufficient experimental data to confirm its utility, some initial studies have integrated genAI as a digital tutor, to give feedback in class and outside of class (Hobert &amp; Berens, 2024; Li. et al. 2023). These studies were not seeking to replace instructor feedback on major deliverables, however, nor did they include a control group without genAI to test whether student improvement was due to genAI specifically.**\n## GenAI feedback is a poor replacement for instructor/TA feedback for writing-based, subjective, or complicated assignments.\nFor standardized tests with objective, finite responses, genAI has been found to have high consistency with human scorers. However, it has low consistency with exams that feature more subjective or nuanced answers, such as essays, or high levels of complexity such as assessments with video components (Coskun &amp; Alper, 2024).\nGenAI has moderate consistency in scoring quantitative work, such as problem sets and coding, but with some important caveats. One analysis of GPT-4&#8217;s grading ability on handwritten physics problems found decent agreement compared to human graders (Kortemeyer, 2023). However, the authors note that even after running every solution through the genAI tool 15 times, it still gave incorrect or misleading statements as part of its feedback, awarded more points than the human graders, and was less accurate at the low end of the grading scale. Similarly, another study compared ChatGPT-3.5 to human graders on Python assignments (Jukiewicz, 2024). Like the previous study, they ran each set of assignments through the tool 15 times to gauge consistency. Once again the agreement with human graders was good, but the genAI tool consistently awarded fewer points compared to human graders. In another study, however, the authors found even lower agreement between ChatGPT-3.5 and Bard on Python problem sets compared to human graders, with an overall accuracy rate of 50% (Est&#233;vez-Ayres et al. 2024). Kiesler et al. 2023 also noted that ChatGPT&#8217;s feedback on programming assignments for an introductory computer science course contained misinformation 66% of the time, which would be particularly problematic for novice learners, since they would likely be led astray.\nFor writing-based assessments more generally, studies have consistently found large discrepancies (i.e., low reliability) between genAI and human scorers. In one study comparing human and genAI scoring of formative feedback on writing, genAI only scored equivalently well on quantitative criteria-based feedback (Steiss et al. 2024; see also Jauhiainen et al. 2024). However, human feedback was of higher quality because it was more accurate and actionable and better prioritized and balanced. These four features are evidence-based characteristics of effective feedback (Hattie &amp; Timperley, 2007). Additionally, genAI feedback quality varied based on essay score, with greater leniency demonstrated on lower quality writing, and overly strict responses on papers that scored above average (Wetzler et al., 2024). Research has also shown that genAI has difficulty with certain types of cognition, such as analogies and abstractions (Mitchell, 2021), as well as nuances and subtle variations in the subject material (Lazarus et al. 2024).&#160;**\n## GenAI grading accuracy varies considerably based on the specific tool used.\n&#160;The genAI tool used also matters: one study found that ChatGPT 3.5 and 4o graded the same essays differently, despite being fine-tuned on the same prompt and rubrics. Both models were significantly different from human scorers (Wetzler et al. 2023). Even when the same genAI tool (ChatGPT-4) was tested 10 times with the same data (assignment prompt, rubric, and student work), the same grade was assigned only 68% of time (Jauhiainen et al., 2024).\nAnother study compared how well ChatGPT, Claude, and Bard could accurately score and provide feedback on both undergraduate and graduate writing samples (Fuller &amp; Bixby, 2024). The rubrics and writing samples were run through ChatGPT and Claude five times each to assess consistency in scoring and feedback. Bard was not able to complete the tasks: although it scored the samples initially, on the second iteration it responded that it was not able to be used for assessment purposes. It was therefore omitted from data collection. As with the other studies, both ChatGPT and Claude had significant discrepancies in their scoring of the same writing samples using the same rubrics through multiple iterations, and also differed widely from the human grader.\n*It is important to note that for all of the above studies, the authors/instructors spent considerable time training the genAI on the assignments and fine-tuning the prompt engineering in order to create the ideal setup to hopefully get the desired grading and feedback output. For instructors or TAs who are not customizing the genAI tool nor running multiple iterations of scoring for quality assurance, the grading and/or feedback quality is likely to be much poorer. See #2 below for more details about customizing a genAI tool.***\n## Students have mixed opinions about receiving genAI feedback.\nIn addition to considering the efficacy of genAI feedback, one should also keep in mind the recipients of that feedback. Although in some cases students report being open to genAI-assessment (Braun et al. 2023, Zhang et al. 2024), many studies show that students prefer human feedback or a combination of human and AI feedback;**they do not trust or feel satisfied receiving AI feedback alone**(Er et al., 2024; Tossell et al., 2024; Chan et al., 2024). We also do not have sufficient research about the impact of receiving genAI feedback on student motivation and engagement in their learning. However, we know that students are more likely to engage with feedback if they feel that it is helpful and fair (Jonsson 2013, Harks et al. 2013, Panadero et al. 2023). Since genAI feedback in its current state is prone to errors, misinformation, and the feedback quality is inferior to a human grader&#8217;s, it is crucial that instructors or TAs review and amend its output to ensure students get feedback that they can trust and can use. Additionally, it is important that instructors and TAs are transparent with students about both evaluation criteria as well as how (and by whom) it is assigned fairly and accurately to students&#8217; work (*see also #6 below about how to communicate your policy and practices to students).*\n[back] \n## Do you have enough materials and time to fine-tune the tool to provide high quality feedback? How will you review its output for reliability, accuracy, and fairness?\nOne of the challenges of incorporating GenAI tools into the classroom is the necessary time investment required up front. Getting the tool to do what you want is not as simple as pasting a prompt or rubric in and expecting it to produce reliable and accurate grading or feedback -- it is not yet &#8220;plug and play.&#8221; Many of the studies above used a customized genAI chatbot, on which the researchers spent a significant amount of time customizing the tool, fine-tuning the prompt engineering, and testing the output.&#160;To appropriately customize a genAI tool for this purpose requires the following:&#160;\n## Materials needed\nA genAI platform of your choice (e.g., ChatGPT), detailed grading rubric, assignment instructions, sample student work, thoughtfully engineered prompts.\n## Norming\nInitially grade a subsample of student work manually and do rubric norming (*see #4 below for more about norming*). Compare these norms against genAI outputs to assess the accuracy of the tool&#8217;s grading as well as the appropriateness and effectiveness of its feedback.\n## Quality assurance\nCheck over AI-generated outputs and incorporate human edits/revisions. Do NOT assume that quality grading occurred or haphazardly share unreviewed genAI feedback with students.&#160;\nAdditionally, as genAI tools continue to evolve and be updated, results may vary and require ongoing review and adjustments. In other words, even after the initial work of customizing the tool to provide reasonable feedback, users need to maintain vigilance for changes in the reliability or accuracy of the tool&#8217;s outputs.\nThe quality of grading and feedback provided by the bot can vary a lot, depending on the following:## Clarity and precision of prompts\nVague or overly broad prompts often yield inconsistent results. Avoid subjective language. Instead, align the prompt with precise explanations of performance expectations for the assignment (e.g.,&#160;[a well-structured rubric]). In the prompt for the genAI tool, it can help to include examples of student submissions of varying quality along with the feedback you would provide each of them.\n## Availability of public material on the topic\n&#160;GenAI models typically perform better on widely discussed topics due to more extensive training data. Assignments on highly specialized or very recent subjects may result in less accurate or reliable outputs.\n## Format of student deliverables\nGenAI tools are primarily text-based, and thus their ability to provide accurate feedback diminishes significantly if submissions include visual elements such as diagrams and images.\nAlthough the swiftness of genAI seems like a promising way to save instructors and TAs time and effort when it comes to grading and delivering feedback, currently the amount of time it takes to set up the tool, test and refine the prompt engineering, and do quality assurance on the output may not differ greatly from human grading/feedback. Overall, one might simply allocate their time differently.\n[back] \n## What other tools or strategies could accomplish the task?\nBefore reaching for a genAI tool, it&#8217;s always good to consider whether existing, vetted tools can help you accomplish a task.&#160;[Canvas], CMU&#8217;s Learning Management System, can make grading easier and more efficient in a number of ways:&#160;\n1. Have students submit their work to&#160;[Canvas Assignments]. This enables you to use&#160;[SpeedGrader] &#160;to assign points and leave comments and annotations directly on student work.\n1. Additionally, you can attach&#160;[Rubrics] &#160;to specific Assignments and&#160;[use them to leave feedback through the SpeedGrader].\n2. Use&#160;[Canvas Quizzes] &#160;to automatically grade certain kinds of questions (i.e., multiple choice and matching questions). You can also&#160;[use SpeedGrader to evaluate other types of Quiz questions].\nOther tools, such as&#160;[Gradescope],&#160;[Autolab], and&#160;[FeedbackFruits] &#160;allow instructors and TAs to partially automate grading.\n1. [Gradescope] &#160;can speed up workflow by using integrated reliable AI tools to analyze student handwriting and group responses by similar answers. This allows the grader to batch grade the same types of student responses and score them using a rubric.\n1. Gradescope also has a&#160;[Programming Assignment] &#160;tool that allows instructors to&#160;[autograde] &#160;student&#8217;s code in any language.\n2. [Autolab] &#160;is another tool for programming assignments that allows you to set up test cases, but still requires careful thought and setup (and is only suitable for certain types of problems).\n3. [FeedbackFruits] &#160;is a suite of tools integrated with Canvas that can automatically assign grades for a number of assignment types, including&#160;[peer review activities],&#160;[document] &#160;or&#160;[video annotation],&#160;[asynchronous discussions], and&#160;[self-assessment].\nThe Eberly Center can support you in finding the right tool for your context and using it effectively. Feel free to&#160;[send us an email to set up a consultation].\n[back] \n## If you have TAs, what will you communicate to them about the use of genAI for grading or feedback? How will you train them to appropriately use genAI for this task?\nFor instructors with TAs, it is important to communicate your policy about GenAI use in the class, both in terms of student use&#160;**and**&#160;instructor/TA use. As with students, TAs may have experienced a different policy in another course. Rather than assume (or let TAs assume), be explicit.\nSome TAs may wish to use genAI in the hopes of making grading or generating feedback easier, especially if they are overwhelmed. In addition to clearly communicating your stance about the use of genAI, it&#8217;s important to also properly train TAs in how to be successful in their various responsibilities. Here are some ideas regarding effective TA training for grading/feedback:\nStrategies are listed in the rows and two columns align related descriptions for why that strategy is important and what to do if using GenAI.|Strategy|Why it&#8217;s important|If using genAI|\n**Meet with the TAs before the semester starts**.\n|\nThis meeting is a chance for the instructor and TAs to build rapport, go over the syllabus, establish a cadence for future meetings, and address any TA questions. This is also an opportunity to review which platforms and tools TAs will be using (e.g., Canvas, Gradescope, etc.). It is particularly important that the instructor and TAs have a shared understanding of course policies, including possible edge cases that can come up, as well as any relevant department policies.\n|\nReview both the student policy for AI use as well as your expectations (and policy) for how TAs will or will not use GenAI. This should include conversations around TAs&#8217; experiences with GenAI, what the research says (see above), and the measures involved for training GenAI on grading and/or providing feedback. Consider TA concerns around using GenAI and whether it makes sense for all TAs to use it (or not), and how it would impact students if only some of the TAs used GenAI.\n|\n**Hold regular meetings with your TAs (e.g., weekly).**\n|\nThese meetings should cover any trends or questions TAs noted since the last meeting, and upcoming material to be covered and assignments. TAs can report what students are struggling with, which could warrant additional coverage by the instructor, and the instructor can give TAs a heads up about where students tend to struggle with upcoming concepts.\n|\nInclude a discussion of how the use of genAI is going on the TA end. How much time are they spending on prompt engineering to refine results? Are they reviewing the output and ensuring it is of high quality? Ensure that TAs are internally consistent with how they are using GenAI so that students receive comparable feedback.\n|\n**For each assignment type, hold a &#8220;grade norming&#8221; session.**\n|\nWhen grading and providing feedback, it is important that TAs are consistent with each other and with the instructor&#8217;s expectations. Norming sessions typically involve instructors and TAs scoring a sample set of student work against a shared rubric, and then comparing and discussing their scores until consensus is reached. This ensures that students receive accurate grades and feedback across TAs and that TAs have clarity on what is expected of them. For assignments of the same type, only one norming session is typically needed. This can be incorporated into the weekly meeting above, or an additional meeting can be scheduled where the TAs and instructor meets together to norm and grade.&#160;*See also Grading Strategies section below for more ideas.*\n|\nHow are TAs expected to utilize GenAI? Has the tool already been trained on the assignment, rubric, and student work (e.g., a custom GPT for a class), or is the TA expected to do this on their own? What should TAs do to ensure quality assurance?\n|\n**Establish which issues should be handled by TAs and which should be handled by the instructor.**\n|\nIt can be helpful to talk through things that arose in previous semesters of teaching, what the TAs have experienced in their other classes, and potential challenges.\n|\nDiscuss possible scenarios where students have questions or concerns about their feedback or how they were graded, as well as cases where students are not using GenAI as directed. What should the TAs handle on their own, and how will they know when to bring it to the instructor? What will regrading policies look like, if genAI is the expectation? What if GenAI calculates a different grade, as shown in section 1 above? Can students request to be graded by the TA directly?\n|\n**Establish a communication policy with TAs.**\n|\nJust as students should know how they can contact the instructor, so too should TAs. Being transparent about when and how TAs can contact and get a response from the instructor can help them feel reassured about getting the support they need.\n|\n*Establish resources for TAs and clear channels of communication in case they run into issues.*\n|\n## **Use grading strategies and TA norming**\nIn addition to technology tools, there are many strategies that instructors and TAs can use to grade efficiently, effectively, and fairly.\n## How to set up your grading for success:\n1. *Use a rubric.*&#160;Randomly select 5-7 assignments to check your rubric and make sure it works. If necessary, adjust your rubric, put those 5-7 assignments back in the pile, and re-grade all of the assignments.\n2. *Work with the other TAs.*&#160;Make sure your grading is consistent among everyone (this is usually called &#8220;grade norming&#8221;). Working together can help with motivation and provide a second set of eyes if you get stuck. You can also divide up labor among TAs to maximize grading/feedback consistency within an assessment item. For example, on an exam or homework assignment, assign TAs to grade all students for a subset of the questions/items, rather than assign TAs to grade all questions/items for a subset of the students.\n3. *Leverage educational technology.*&#160;Depending on your course context, educational technology like Canvas or Gradescope may make your grading easier and more consistent.\n4. *Develop a &#8220;key&#8221; or \"common comments&#8221; document*&#160;(e.g., AWK = awkward phrase, &#8220;TS&#8221; = topic sentence missing or needs revising, etc.). This will save you time so you do not have to write out the same feedback every time.\n## While you&#8217;re grading, here are some other tips to keep in mind to ensure that you are grading&#160;fairly and efficiently:\n* *Grade unbiased by student names.*&#160;Place Post-It notes over students&#8217; names to ensure fair, unbiased grading, and then shuffle the assignments.\n* *Prevent grading drift.*&#160;Go back and compare the first five assignments to the last five. Have your standards changed?\n* *Set a timer.*&#160;This will ensure that you spend the same amount of time on each student, and will also help prevent burnout.\n* *Grade/provide feedback question-by-question.*&#160;Grading one question at a time (e.g., question #1 for everyone, then question #2&#8230;) rather than student-by-student will help you stay in the same mental space.&#160;[**Gradescope can help with this!**] \n* *Provide specific group-level feedback.*&#160;This strategy is an efficient way to provide feedback on common errors, and can be done via Canvas, email, or even verbally at the beginning of class.\n*Talk to Eberly Center about supporting TA training! This can include tailoring our&#160;*[*Graduate &amp; Undergraduate Student Instructor Orientation (GUSIO)*] *&#160;to fit your course context, as well as individualized support for implementing the strategies above, and more!*\n[back] \n## What are the legal, ethical, and privacy concerns of students that you should think through before using the tool?\n```\nPrivacy: data sharing restrictions and FERPA compliance; Legal: IP, digital accessibility; Ethical considerations\n```\nWhen using tools for teaching and learning (and grading), proper data management and FERPA compliance are a must. First and foremost, consider whether or not the tool or system you are using has been licensed by CMU and is FERPA compliant.&#160;\n## CMU Licensed Tools that are FERPA compliant\nGenAI tools currently licensed by Computing Services including&#160;[Microsoft Copilot],&#160;[ChatGPT edu], Google&#8217;s&#160;[Gemini], and&#160;[NotebookLM] &#160;are FERPA compliant.\n## IMPORTANT NOTES FOR MAINTAINING FERPA COMPLIANCE:&#160;\n1. Individuals must be logged in as instructed via CMU authenticated mechanisms.&#160;\n2. Not all tools listed on Computing Services site are FERPA compliant and are typically indicated as such (see CMU&#8217;s&#160;[Google Workspace for Education webpage here] &#160;showing &#8220;Core&#8221; vs &#8220;Additional&#8221; services). If you are uncertain about whether or not a tool you are using or want to use is meeting these privacy and legal requirements, don&#8217;t hesitate to&#160;[contact us].\n## If you wish to use tools&#160;that are not yet FERPA compliant (i.e., any tool that the university has not vetted and approved as FERPA compliant):\n1. [Reach out to us] &#160;to get the tool vetted.\n2. If the tool cannot be made FERPA compliant and you have received guidance from University Contracts on how to proceed (i.e., make sure you are using it responsibly with respect to FERPA compliance and data security), then you should plan out the details of how you work with the tool to ensure responsible use.&#160;\n3. Once your use case and process is well thought out, next consider what data you are entering into any publicly available/consumer tool. Generally speaking you should only be entering data you would share publicly into these systems. Become familiar with the&#160;[classifications of data] &#160;you are handling and using with tools that are not CMU licensed.&#160;\nOnce you have a good handle on FERPA compliance and data management requirements, now let&#8217;s turn to&#160;[digital accessibility] &#160;and&#160;[intellectual property (IP)] &#160;management.\n## Digital Accessibility:\nTools you use and the content you create must be digitally accessible. University licensed tools have been vetted for digital accessibility, but your content also needs to be accessible. There is&#160;[guidance on how to make your content/feedback digitally accessible] &#160;and we can also consult with you on this aspect.\n## IP management:\nDo you have proper copyright permissions to enter data into these tools? Consider what will happen with that data &#8211; in CMU licensed environments, the models will not train the consumer models and privacy is managed. In public/commercial genAI tool environments, the content you enter will be used for training their models and CMU data privacy requirements will&#160;**not**&#160;be met.\nAbove and beyond privacy, legal requirements, and content management, there are important ethical concerns you will want to consider. For example, some graders and students may have personal ethical concerns about the use of generative AI tools that cannot be resolved by any changes to information privacy settings. Also, every one of the tools that is CMU licensed comes with a financial cost. Who will pay for this and should they need to? And there are many other ethical considerations not discussed here. It is important to be prepared with the ways those concerns can be raised, heard, and responded to with potential alternatives.**\n*As always, as you navigate these requirements, guidelines, and process details, we are here to help so feel free to&#160;[reach out for a consultation].*\n[back] \n## How will you communicate your decisions to use genAI in grading and feedback (or not) to students? Does your use of it align with your policy for student use of genAI?\nJust as it is critical to include a syllabus policy for student use of genAI, it is also important to explicitly state how instructors and TAs will use genAI (if at all). A&#160;[student use policy] &#160;should spell out which uses are permitted or prohibited, include a rationale for that policy, and identify the consequences if the policy is violated. Similarly, the instructor/TA genAI use policy should address the following:&#160;\n* What are the parameters under which genAI will be used? Will it be used for all assessments or just certain types, and all others will receive human feedback?&#160;\n* How will instructors train a genAI tool to grade and/or provide feedback, and how will the instructor and/or TAs evaluate/assure the fairness and quality of its output?&#160;\n* How will this policy benefit students, e.g., if it saves instructors time, how will that time be reinvested in supporting student learning?\n* Whether genAI-generated feedback is opt-in or opt-out: will students receive genAI-generated feedback by default (and they can opt out of that process) or human feedback (students can opt-into receiving additional AI feedback)?&#160;\n* How can students express their concerns or questions, if they have them?\nIt&#8217;s important for instructors to also consider whether their policy for student use is in alignment with how they themselves will be incorporating GenAI into the course (or not). For instance, if students are not allowed to use GenAI as a thought partner or to support their learning, but instructors and TAs plan to use it for grading and/or feedback, this can create an unequal dynamic that may cause students to disengage or be less inclined to follow the policy. Not sure whether students should use it or not, or uncertain how to talk to them about it? Check out our&#160;[FAQs page] &#160;for recommendations and ideas.\n### Sample policy language\n## Instructor/TAs to use GenAI for grading on certain assessment types\nTo facilitate the X, the TAs will be using a customized ChatGPT bot to assist in grading and providing feedback on homeworks and draft assignments. This bot has been carefully trained on the assignment types, rubrics, and specific kinds of feedback that we require; additionally, TAs will review its output to ensure that the grading and feedback are accurate. All final deliverables will be graded by the TAs, without the use of GenAI. If you have any questions or concerns about this process, please do not hesitate to reach out to myself or one of the TAs.&#160;\n## Instructors/TAs inviting students to use GenAI as supplemental feedback\nAll assignments in this class will be graded by the instructor and TAs, without the use of GenAI. If you wish to receive additional or more frequent feedback, you are welcome to use the tool yourself (and see Student Use of GenAI policy above). If you have any questions or concerns about this process, please do not hesitate to reach out to myself or one of the TAs.\n## A No-GenAI policy for both instructor/TAs and students\nTo best support your own learning, you should complete all graded assignments in this course yourself, without any use of generative artificial intelligence (AI). Please refrain from using AI tools to generate any content (text, video, audio, images, code, etc.) for any assignment or classroom exercise. Passing off any AI-generated content as your own (e.g., cutting and pasting content into written assignments, or paraphrasing AI content) constitutes a violation of CMU&#8217;s academic integrity policy. If you have any questions about using generative AI in this course please email or talk to me.\nSimilarly, all assignments in this class will be graded by the instructor or TAs, without the use of AI. If you have any questions about the grading and feedback process, please do not hesitate to reach out to myself or one of the TAs.\n## References\nChan, S. T. S., Lo, N. P. K., &amp; Wong, A. M. H. (2024). Enhancing university level English proficiency with generative AI: Empirical insights into automated feedback and learning outcomes.&#160;*Contemporary Educational Technology*, 16(4), ep541.&#160;[https://doi.org/10.30935/cedtech/15607] &#160;\nEr, E., Ak&#231;ap&#305;nar, G., Bayaz&#305;t, A., Noroozi, O., &amp; Banihashem, S. K. (2025). Assessing student perceptions and use of instructor versus AI-generated feedback.&#160;*British Journal of Educational Technology*, 56, 1074&#8211;1091.[&#160;https://doi.org/10.1111/bjet.13558] \nEst&#233;vez-Ayres, I., Callejo, P., Hombrados-Herrera, M. &#193;., Alario-Hoyos, C., &amp; Delgado Kloos, C. (2024). Evaluation of LLM tools for feedback generation in a course on concurrent programming.&#160;*International Journal of Artificial Intelligence in Education*, (2024)&#160;[https://doi.org/10.1007/s40593-024-00406-0] \nFuller, L. P. , &amp; Bixby, C. (2024). The Theoretical and Practical Implications of OpenAI System Rubric Assessment and Feedback on Higher Education Written Assignments.&#160;*American Journal of Educational Research*,&#160;*12*(4), 147-158.\nJauhiainen, J. S., &amp; Garagorry Guerra, A. (2024). Generative AI in education: ChatGPT-4 in evaluating students&#8217; written responses.&#160;*Innovations in Education and Teaching International*, 1&#8211;18.&#160;[https://doi.org/10.1080/14703297.2024.2422337] &#160;\nJukiewicz, M. (2024). The future of grading programming assignments in education: The role of ChatGPT in automating the assessment and feedback process.&#160;*Thinking Skills and Creativity*, 52, 101522.[&#160;https://doi.org/10.1016/j.tsc.2024.101522] \nKiesler, N., Lohr, D., &amp; Keuning, H. (2023). Exploring the potential of large language models to generate formative programming feedback. In 2023 IEEE Frontiers in Education Conference (FIE), College Station, TX, USA (pp. 1&#8211;5).[&#160;https://doi.org/10.1109/FIE58773.2023.10343457] [] \nKortemeyer, G. (2023). Toward AI grading of student problem solutions in introductory physics: a feasibility study.&#160;*Physical Review Physics Education Research,&#160;*19: 020163-1-20.&#160;[https://doi.org/10.1103/PhysRevPhysEducRes.19.020163] \nLazarus, M.D., Truong, M., Douglas, P., Selwyn, N. (2024). Artificial intelligence and clinical anatomical education: Promises and perils.&#160;*Anat Sci Educ*, 17: 249&#8211;262.[&#160;https://doi.org/10.1002/ase.2221] \nMitchell, M. (2021). Abstraction and analogy-making in artificial intelligence. Ann. N.Y.&#160;*Acad. Sci.*, 1505: 79-101.[&#160;https://doi.org/10.1111/nyas.14619] \nSteiss, J., Tate, T., Graham, S., Cruz, J., Hebert, M., Wang, J., Moon, Y., Tseng, W., Warschauer, M., &amp; Olson, C. B. (2024). Comparing the quality of human and ChatGPT feedback of students&#8217; writing,&#160;*Learning and Instruction*, 91: 101894.&#160;[https://doi.org/10.1016/j.learninstruc.2024.101894] &#160;\nSung, G., Guillain, L., &amp; Schneider, B. (2023). Can AI help teachers write higher quality feedback? Lessons learned from using the GPT-3 engine in a makerspace course. In Blikstein, P., Van Aalst, J., Kizito, R., &amp; Brennan, K. (Eds.),&#160;*Proceedings of the 17th International Conference of the Learning Sciences - ICLS 2023&#160;*(pp. 2093-2094).&#160;[https://repository.isls.org//handle/1/10177] &#160;\nWetzler, E. L., Cassidy, K. S., Jones, M. J., Frazier, C. R., Korbut, N. A., Sims, C. M., Bowen, S. S., &amp; Wood, M. (2024). Grading the Graders: Comparing Generative AI and Human Assessment in Essay Evaluation. Teaching of Psychology, 0(0).&#160;[https://doi.org/10.1177/00986283241282696] \n[back] \n&#160;\n&#160;\n**Eberly Center\n**4765 Forbes Avenue\nTepper Quad, Suite 1310\nPittsburgh, PA 15213\n(412) 268-2896\n[Contact Us] \n![]![]![]![] &#160;This work is licensed under a&#160;[Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License].\n&#160;\n&#160;",
    "length": 35999,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "News & Events - \n                Center for Intelligent Business -     Tepper School of Business - Carnegie Mellon University",
    "url": "https://www.cmu.edu/intelligentbusiness/news-events/index.html",
    "text": "News &amp; Events - Center for Intelligent Business - Tepper School of Business - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[Center for Intelligent Business] ## [Tepper School of Business] \n[Tepper School of Business] &#160;&#8250;&#160;[Center for Intelligent Business] &#160;&#8250;&#160; News &amp; Events\n# Latest News &amp; Events from the CIB\n## The Tepper School's Center for Intelligent Business is pioneering insights into the future of business with a focus on AI-driven strategies and innovative data solutions.&#160;\n[Join our email list to recieve exclusive communications about upcoming events, news and other CIB opportunities.] \n[\n## How Small Businesses Are Navigating the AI Frontier\n] \n[\n## News from the CIB - Spring 2025\n] \n[\n## CIB Research Fellows Investigate GenAI Applications in Medicine, Finance, Marketing, and More\n] \n[\n## CIB Teaching Fellows Develop Human-Centered, AI-Powered Educational Tools That Enhance Critical Thinking and Improve Interpersonal Communication\n] \n[\n## CIB Hosts Co-AI Workshop for Faculty\n] \n[\n## New Tepper research highlights the power of distributed ledger technology (DLT) for managing organizational change and structuring internet platform data\n] \n[\n## News from the CIB - Fall 2024\n] \n[\n## Tepper Supports The \"Good\" AI Conference\n] \n# Conversations with Faculty Experts\n[\nThursday, June 26, 2025## GenAI to Revolutionize Personalized Medicine\n] \n[\nWednesday, January 15, 2025## Woolley and Team Explore AI&#8217;s Potential for Enhancing Teams&#8217; Collective Intelligence\n] \n[\nMonday, November 04, 2024## Machine Learning Solutions to Address Disparity and Create Fairness\n] \n[\nThursday, October 31, 2024## Creating Algorithms That Will Make It Faster and Easier For Auditors to Detect Bookkeeping Anomalies\n] \n# PROBE Briefs\n[\nFriday, November 08, 2024## Center Coffee Chat w/Sanjay Patel, Perpetuating, Inc.\n] \n[\nFriday, November 08, 2024## Center Coffee Chat w/Lou Martinez, CTO Westinghouse\n] \n# **CIB Events**\n### **Upcoming PROBEs**\n### ***About PROBES:**&#160;**PR**oblem-**O**riented**B**usiness**E**xplorations are at the core of Center for Intelligent Business corporate engagements, helping us to investigate the collaboration potential between CMU/Tepper and the innovative ideas of industry.[CMU internal - join the mailing list to get notified of future events] *",
    "length": 2422,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Tools and Resources - AI Daily - Computing Services - Carnegie Mellon University",
    "url": "https://www.cmu.edu/ai-daily/how-to/index.html",
    "text": "# Explore Generative Artificial Intelligence (AI) at CMU\n\nGenerative AI (GenAI) helps you create text, images, music, and videos, just by describing what you need. These tools can support your learning, creativity, and work across many roles at CMU. Explore our resources below to learn the basics and get familiar with the tools available to you. Then, dive into building more advanced skills.\n\n## [Learn and Connect] \n\nDiscover campus AI events, topic-based communities, and other learning opportunities.\n\n## [Protected AI Tools] \n\nLearn about the AI tools that are safe to use within CMU’s environment.\n\n## [Use AI Safely at CMU] \n\nLearn how to use AI safely and ethically, following CMU’s policies and guidelines.\n\n- [About] \n- [Computing Services InfoCenter] \n- [CSS Awards and Recognition] \n- [News] \n- [Service Status] \n\n[Log In to Services] \n\n- [Computing Services Help Center] \n- [412-268-4357 (HELP)] \n- [it-help@cmu.edu]",
    "length": 931,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Academic Integrity Policy - Eberly Center - Carnegie Mellon University",
    "url": "https://www.cmu.edu/teaching/designteach/syllabus/checklist/integritypolicy.html",
    "text": "Academic Integrity Policy - Eberly Center - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[Eberly Center] ## Teaching Excellence &amp; Educational Innovation\n[Eberly Center] &#160;&#8250;&#160; Teaching &amp; Learning Resources\n&#160;&#8250;&#160;[Write or Revise Your Syllabus] &#160;&#8250;&#160;[Syllabus Checklist] &#160;&#8250;&#160; &gt;&gt; Academic Integrity Policy\n# Academic Integrity Policy\n[University Policy] states that assistance from campus resources (e.g. Student Academic Success Center, and the Academic Resource Center at CMU-Q) is permitted, but no collaborationor unauthorized assistance&#160;is allowed unless specifically permitted by a course instructor. However, as course instructor, you can choose to specify alternative boundaries for acceptable and unacceptable collaboration and/or assistance.\nWhen writing your academic integrity policy, consider the following questions:\n* How is the policy motivated by the positive dimensions of academic integrity (i.e. academic integrity is about enhancing your education and being a trusted member of the CMU community)?\n* What is and is not permitted with respect to collaboration and/or outside assistance for each type of graded work in your course? Be sure to highlight where and how your policy departs from the default University Policy.\n* What procedures can/should students follow to acknowledge collaboration (if permitted) and/or assistance when they submit graded work?\n* What new technologies may affect your students&#8217; original contributions? For example, what are your standards for AI-assisted versus AI-generated work?[See our AI tools FAQs] for examples of how you may choose to write a policy with these consideration, or how you may want to integrate AI tools in your course.\nNote: You should also provide links to the[University Policy] on Academic Integrity and to the[Carnegie Mellon Code] on Academic Integrity in your syllabus.\n[go to checklist] \nIf you would like to support in crafting or refining your academic integrity policy, please contact[eberly-assist@andrew.cmu.edu].\n## Sample 1: General purpose academic integrity policy\nHonesty and transparency are important features of good scholarship. On the flip side, plagiarism and cheating are serious academic offenses with serious consequences. If you are discovered engaging in either behavior in this course, you will earn a failing grade on the assignment in question, and further disciplinary action may be taken.\nFor a clear description of what counts as plagiarism, cheating, and/or the use of unauthorized sources&#160;and tools, please see the University&#8217;s Policy on Academic Integrity (revised in April 2013):[https://www.cmu.edu/policies/student-and-student-life/academic-integrity.html] \nI encourage you to work together on homework assignments and to make use of campus resources likeStudent Academic Success Center (SASC)to assist you in your pursuit of academic excellence. However, please note that in accord with the university&#8217;s policy you must acknowledge any collaboration or assistance that you receive on work that is to be graded,either from a person, reference, or a tool (including AI-generation tools like ChatGPT). So, when you turn in a homework assignments, please include a sentence at the end that says either:\n1. &#8220;I worked alone on this assignment.&#8221;, or\n2. &#8220;&#8220;I worked with \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_&#160;[person or tool]on this assignment.&#8221; and/or\n3. &#8220;&#8220;I received assistance from \\_\\_\\_\\_\\_\\_\\_\\_\\_&#160;[person or tool]on this assignment.&#8221;\nNote that providing this information will only serve to help me understand you better: I strongly endorse the use of campus resources likeSASC, as well as collaborative learning, when it increases your ability to succeed in this class and when it enhances your education and learning.\nIf you have questions about my integration of the university&#8217;s policy into this course, please do not hesitate to ask: my aim is to foster an environment where you can learn and grow, while ensuring that the work we all do is honest and fair. For more information about Carnegie Mellon&#8217;s standards with respect to academic integrity, you can also check out the following link:[http://www.cmu.edu/academic-integrity/] \n[go to checklist] \n## Sample 2: Academic integrity policy from Modern Languages\nStudents who copy assignments, allow assignments to be copied, or cheat on tests will fail the assignment or test on the first offense, and fail the entire course on the second.\nMany students have questions as to what constitutes too much \"help\" on essays or homework. Of course, you may ask a friend (who may have studied \\_\\_\\_\\_\\_\\_\\_\\_ longer than you) if a certain phrase or sentence is correct. You may consult an online dictionary or translator for a word or phrase. BUT, the line between legitimate help and cheating is this: Are you able to reproduce the same information on a test or on your own? If the answer is yes - i.e., you learned something from getting the help and won't make the same mistake again - that's okay. If the answer is no &#8211;&#8211; i.e., you can't identify the parts of speech in the phrase or you can't tell me what the word(s) mean on the spot) then you shouldn't turn in the assignment as your own work. You should, at the very least, indicate those parts of the assignment that are not your own work.\nExperienced teachers like me can easily recognize essays that are written by native, near-native, or advanced speakers, are copied from other sources, or are completed using online translation services. I am obligated to uphold the university's policy on academic integrity and I take this responsibility very seriously. If you are unsure about your particular situation, please ask me for clarification BEFORE you turn in an assignment as your own work. Please take the time to read the University&#8217;s discussion guide for promoting academic integrity at:\n[http://www.cmu.edu/academic-integrity/] \nIn addition, you can find the University&#8217;s full Policy on Academic Integrity here:\n[https://www.cmu.edu/policies/student-and-student-life/academic-integrity.html] \n[go to checklist] \n## Sample 3: Acceptable/unacceptable collaboration statement from Computer Science\nHere are some examples of acceptable collaboration:\n* Clarifying ambiguities or vague points in class handouts, textbooks, or lectures.\n* Discussing or explaining the general class material.\n* Providing assistance with Java, in using the system facilities, or with editing, debugging, and Java tools.\n* Discussing the code that we give out on the assignment.\n* Discussing the assignments to better understand them.\n* Getting help from anyone concerning programming issues which are clearly more general than the specific assignment (e.g., what does a particular error message mean?).\nNow for the dark side. As a general rule, if you do not understand what you are handing in, you are probably cheating. If you have given somebody the answer, you are probably cheating. In order to help you draw the line, here are some examples of clear cases of cheating:\n* Copying (program or assignment) files from another person, source, or tool, including retyping their files, changing variable names, copying code without explicit citation from previously published works (except the textbook), etc.\n* Allowing someone else to copy your code or written assignment, either in draft or final form.\n* Getting help froma peer or AI toolwhich you do not acknowledge on your solution.\n* Copying from another student during an exam, quiz, or midterm. This includes receiving exam-related information from a student who has already taken the exam.\n* Writing, using, or submitting a program that attempts to alter or erase grading information or otherwise compromise security.\n* Inappropriately obtaining course information from instructors and TAs.\n* Looking at someone else&#8217;s files containing draft solutions, even if the file permissions are incorrectly set to allow it.\n* Receiving help from students who have taken the course in previous years.\n* Lying to course staff.\n* Copying on quizzes or exams.\n* Reviewing any course materials (or software) from previous years.\n* Reading the current solution (handed out) if you will be handing in the current assignment late.\n[go to checklist] \n**Eberly Center\n**4765 Forbes Avenue\nTepper Quad, Suite 1310\nPittsburgh, PA 15213\n(412) 268-2896\n[Contact Us] \n![]![]![]![] &#160;This work is licensed under a&#160;[Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License].\n&#160;\n&#160;",
    "length": 8711,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Rosé Among New SCS Endowed Faculty Chair Recipients - \n                Language Technologies Institute -     School of Computer Science - Carnegie Mellon University",
    "url": "https://lti.cmu.edu/news-and-events/news/2025-10-27-rose-professorship.html",
    "text": "Rosé Among New SCS Endowed Faculty Chair Recipients - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\n[Carnegie Mellon University] **—****—****—**SearchSearchSearch this site only\n[Language Technologies Institute] ## [School of Computer Science] \n[![LTI Logo]] \n[School of Computer Science] ›[Language Technologies Institute] ›[News and Events] ›  news\n › Rosé Among New SCS Endowed Faculty Chair Recipients\n![Candid shot of Carolyn Rose and Jun-Yan Zhu seated in an auditorium] \n*October 27, 2025*# Rosé Among New SCS Endowed Faculty Chair Recipients\n## LTI Faculty Member Carolyn Rosé has Received the Kavčić-Moura Professorship\nBy Marylee Williams\nMedia Inquiries\n**Aaron Aupperlee**\n* aaupperlee(through)cmu.edu\n* [412-268-9068] \nTwo School of Computer Science professors recently received endowed faculty chairs to recognize their research contributions and support future work.&#160;&#160;\n[Carolyn Ros&#233;], faculty in the&#160;[Language Technologies Institute] &#160;and the&#160;[Human-Computer Interaction Institute], received the Kav&#269;i&#263;-Moura Professorship. Ros&#233;'s work bridges deep theoretical insights from language and interaction, such as social psychology and cognitive psychology, sociolinguistics and discourse analysis, and computational modeling technology. She has made significant contributions to automated analysis of conversational processes &#8212; in particular, collaborative learning processes &#8212; and dynamic agent-based support for group processes.\n\"As a researcher who has dedicated her career to impact in education and who directs one of Carnegie Mellon's largest data science graduate programs, I am honored to receive a chair named after Aleksandar Kav&#269;i&#263;, in light of his current work in Serbia to provide free textbooks for schools through his foundation, and Jos&#233; Moura, who has partnered with him and others to invest in data science education at Carnegie Mellon,\" Ros&#233; said.\nThe chaired professorship will support Ros&#233;'s work in human-AI collaboration with applications in sense-making and problem-solving in areas such as cybersecurity and data science.\n[Jun-Yan Zhu], faculty in the&#160;[Robotics Institute], received the Michael B. Donohue Assistant Professorship of Computer Science and Robotics. Zhu's research focuses on computer vision, computer graphics and machine learning. He leads the&#160;[Generative Intelligence Lab], which studies the collaboration between human creators and generative models. This human-centered approach empowers creators with generative AI while retaining control over the creation process and data ownership.\n\"The chaired professorship will be instrumental in allowing us to pursue cutting-edge research into a human-centric generative AI framework,\" Zhu said. \"Our goal is to empower creators to benefit from large-scale generative models while retaining control over the creation process and receiving proper compensation. This support will also help us continue our work to bring generative AI from the digital world to the physical one, enabling the creation of tangible objects through AI and advanced manufacturing.\"\nIn addition to the chaired professorships awarded this year, SCS also recently recognized faculty members who received Raj Reddy Career Development chairs last year. Honorees and their professorships include&#160;[Zachary Lipton], the Raj Reddy Career Development Professorship in Artificial Intelligence;&#160;[Deepak Pathak], the Raj Reddy Career Development Professorship in Robotics;&#160;[Emma Strubell], the Raj Reddy Career Development Professorship in the Language Technologies Institute; and&#160;[Bogdan Vasilescu], the Raj Reddy Career Development Professorship in Software and Societal Systems.\nA reception recognizing the recipients was held last week.",
    "length": 3856,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Meet AI - Computing Services - Office of the CIO - Carnegie Mellon University",
    "url": "https://www.cmu.edu/computing/services/ai/meet-ai/index.html",
    "text": "Meet AI - Computing Services - Office of the CIO - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[Computing Services] ## [Office of the CIO] \n[Office of the CIO] &#160;&#8250;&#160;[Computing Services] &#160;&#8250;&#160;[Services] &#160;&#8250;&#160;[Generative Artificial Intelligence (AI)] &#160;&#8250;&#160; Meet AI\n# Meet&#160;![ai] \nWhen we&#8217;re first exposed to Artificial Intelligence (AI), it might seem like more Science Fiction than Science, but at its core, AI is simply a computer program. CMU boasts a[groundbreaking legacy in AI], with pioneering contributions that have continuously shaped the field since its inception in the 1960s. If you&#8217;ve used platforms like Amazon, Spotify, or YouTube, you&#8217;ve already interacted with AI through features like recommendations and personalized content.\n## What is Generative AI?\nGenerative AI, or GenAI, is a type of computer program that creates new content, such as text, images, audio, video, or code, by recognizing patterns in the data it was trained on. It responds to user prompts based on what it has learned, but its output depends on the quality of its training data and the prompt. Human feedback helps improve accuracy and reduce bias, especially when correcting errors or unrealistic results (also called hallucinations).\n## How does GenAI work?\nThough there's a lot more to it, GenAI works like this:\n1. **The AI model is trained on human-created data.**\nExamples include writing, images, code, and more. These inputs help the model learn how people express ideas.\n2. **The system looks for patterns.**\nIt analyzes the data to understand how words, visuals, or sounds typically appear together.\n3. **You interact with the model by giving it a prompt.**\nA prompt is a task or question&#8212;like &#8220;Summarize this article&#8221; or &#8220;Suggest a title.&#8221;\n4. **Generative AI creates a response.**\nIt uses what it learned during training, plus your prompt, to produce new content.\n5. **You evaluate the result.**\nThe response might be helpful&#8212;or it might miss the mark. If the training data was biased or your input unclear, the output could be wrong. This is called a*hallucination*.\n6. **Your feedback helps improve future results.**\nGiving a thumbs up or trying again helps fine-tune how the AI responds over time.\n## What is an AI Model?\nAI models learn by studying patterns, similar to how humans get better at recognizing things through examples and repetition. For instance, you might learn to identify different types of flowers by seeing them in pictures or at the store.\n* They're computer programs designed to find patterns in data.\n* They learn from examples instead of being explicitly programmed with rules.\n* Once they&#8217;ve been trained, they can make predictions or decisions when given new information.\nJust like humans improve with practice, AI models get better with data and training.\n# Learn more\n* [What can I use AI for?] \n* [How do I use AI?] \n* [Protected AI Tools You Can Use] \n* [Use AI Safely at CMU] \n## Frequently Asked Questions\n## Can Generative AI think for itself?\nGenerative AI tools are not sentient and rely on data provided by humans. Remember:\n* An AI is only as good as the data it&#8217;s being trained on.\n* It is dependent on humans to &#8220;train&#8221; it by:\n* Reviewing and providing feedback on its output.\n* Ensuring the data the AI has access to is up to date.\n## How do I start using AI?\nStart simple.\n1. Pick a task you do often (like summarizing notes).\n2. Choose a tool from[CMU&#8217;s approved list.] \n3. Ask it a clear question or assign it a task.\nIf you are ready to try it out, check out our[How to Use AI] page for instructions on getting started with prompting.\n## What if the AI gives me an odd or wrong answer?\nThat happens&#8212;it's called a hallucination! If one occurs, you can:\n* Rephrase your question.\n* Upload supporting sources of information to provide more context.\n* Enter a chain-of thought prompt where you ask the AI to explain its reasoning.&#160;\n*Explain your reasoning step by step, including complete links to sources. Outline how you reached your conclusion.*\n## Is it safe to use AI with my data?\nYes&#8212;if you're using[CMU-approved AI tools] while logged in with your Andrew userID.\nThese tools:\n* Meet CMU&#8217;s privacy and security standards\n* Are FERPA-compliant\n* Prevent unauthorized access to your personal or academic data\n## How do I tell if an AI response is good?\nHere are some questions to ask yourself:\n* Does the response answer your question or complete the task you gave it?\n* Does it back up claims with facts, examples, or relevant and trustworthy references when needed?\n* Can you tell how or why the AI came to that answer? Is the reasoning clear?\n* Does it go beyond the obvious and offer helpful ideas, summaries, or patterns?\nIf you answered &#8220;yes&#8221; to these questions, you&#8217;ve got a good response.\n## Where can I learn more or ask questions?\nConnect with peers and experts in our[Community Google Group] and[Community GenAI Builder] space.\n* [About] \n* [Computing Services Intranet] \n* [CSS Awards and Recognition] \n* [News] \n* [Service Status] \n[Log In to Services] \n* [Computing Services Help Center] \n* [412-268-4357 (HELP)] \n* [it-help@cmu.edu]",
    "length": 5360,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Niloofar Mireshghallah - College of Engineering at Carnegie Mellon University",
    "url": "https://engineering.cmu.edu/directory/bios/mireshghallah-niloofar.html",
    "text": "Niloofar Mireshghallah - College of Engineering at Carnegie Mellon University\n[Skip to Main Content] \n[Carnegie Mellon College of Engineering Home Page![] Carnegie Mellon College of Engineering Home Page] \n[Menu] \n[Carnegie Mellon College of Engineering Home Page![] Carnegie Mellon College of Engineering Home Page] \nSearchSearch\nPopular Searches\n* [Admitted students] \n* [Master’s of AI Engineering] \n* [Engineering Magazine] \n* [graduate programs] \n* [Manufacturing Futures Institute] \n* [Rethink the Rink] \nSocial Media\n* [CMUEngineering] \n* [College of Engineering] \n* [CMUEngineering] \n* [CMUEngineering] \n* [RSS Feed] \n* [@CMUEngineering] \n* [Home] \n* [Directory] \n# Niloofar Mireshghallah\nAssistant Professor (Beginning Fall 2026),[Engineering and Public Policy],[Language Technologies Institute] \n![Directory] \n![Directory] \nNiloofar Mireshghallah is an incoming assistant professor with a joint appointment between Engineering and Public Policy and the Language Technology Institute at Carnegie Mellon University. Her research interests lie at the intersection of privacy, natural language processing, and the societal implications of machine learning, exploring the interplay between data, its influence on models, and the expectations of the people who regulate and use these models. Her work has been covered by The Washington Post and WIRED. She is a recipient of the NCWIT Collegiate Award (2020)&#160;and the Rising Star in Adversarial ML Award (2022), and a finalist of the Qualcomm Innovation Fellowship (2021).\nPreviously, Mireshghallah was a research scientist at FAIR (Meta) and a postdoctoral scholar at the Paul G. Allen Center for Computer Science &amp; Engineering at University of Washington, advised by Yejin Choi and Yulia Tsvetkov. She received her Ph.D. from the Department of Computer Science and Engineering at University of California San Diego in 2023, advised by Taylor Berg-Kirkpatrick.\nEmail[&#110;iloo&#x66;ar&#64;&#99;&#109;u&#46;ed&#x75;] Websites[Niloofar Mireshghallah's website] \n## Research Interests\n* [machine learning] \n* [privacy] \n## Media mentions\n[\nCyLab Security and Privacy Institute\n### Applications open for CMU Ph.D. programs in cybersecurity and privacy\n] \nCarnegie Mellon University offers several Ph.D. programs that attract students interested in pursuing research careers in security and privacy.\n[Update your page]",
    "length": 2376,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Protected AI Tools You Can Use",
    "url": "https://www.cmu.edu/computing/services/ai/meet-ai/tools/zoom-companion-how-to.html",
    "text": "# Protected AI Tools You Can Use\n\nThe AI tools listed on this page are available at CMU. When you sign in with your Andrew ID and password, each tool is FERPA-compliant and will not use your data to train its AI models.\n\n## Interested in New Tools?\n\nAI tools that have not yet been reviewed or licensed by CMU might not offer the same data protections and approved services.\n\nSubmit a [software request] for review and approval.\n\n# Use AI Safely at CMU\n\nBefore using CMU's protected AI tools, please review our [policies and guidelines for safe and ethical use].\n\n# DAO Accessibility Tools\n\nExplore [tools endorsed by the Digital Accessibility Office] that have AI capabilities.\n\n# Approved AI Tools\n\n## [AI Gateway] \n\n## [ChatGPT Edu] \n\n## [Gemini Web App] \n\n## [Microsoft Copilot] \n\n## [NotebookLM] \n\n## [Zoom AI Companion] \n\n## Tool Comparison Table\n\n| Tool | Purpose | Best For | Available To | Cost |\n| --- | --- | --- | --- | --- |\n| [AI Gateway] | AI Developer tool makes AI models easier to access. | Accessing  management to models via API keys. | Faculty and Staff | No cost; however an Oracle String is required to pass on any costs incurred from using a model endpoint. |\n| [ChatGPT Edu] | Synthesizes info, summarizes, and generates content. | Research, writing, and problem-solving. | Faculty and Staff; Students sponsored by a faculty or staff member | $240 / per year |\n| [Gemini Web App] | Google's AI that handles text, voice, and files. | Meeting summaries, working with Google Apps, and searching across formats. | Students, Faculty, Staff, and Sponsored | Available with your Andrew account. |\n| [Microsoft Copilot Chat] | AI support for Office tasks, images, and code. | Microsoft files, documents, and coding help. | Students, Faculty, and Staff | Available with your Andrew account. |\n| [NotebookLM] | Creates AI-powered notebooks from uploads. | Organizing ideas, summarizing sources, and creating podcasts. | Students, Faculty, Staff, and Sponsored | Available with your Andrew account. |\n| [Zoom AI Companion] | Adds summaries and action items to meetings. | Real-time help during virtual meetings. | Students, Faculty, Staff, and Sponsored | Available with your Andrew account. |\n\n**Note:** Available add-ons for protected AI tools have been thoroughly reviewed and vetted for use at CMU. For example, ChatGPT Edu with [Agents] is already available to paid ChatGPT Edu subscribers.\n\n- [About] \n- [Computing Services InfoCenter] \n- [CSS Awards and Recognition] \n- [News] \n- [Service Status] \n\n[Log In to Services] \n\n- [Computing Services Help Center] \n- [412-268-4357 (HELP)] \n- [it-help@cmu.edu]",
    "length": 2623,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "CMU Researcher Uses ChatGPT To Execute Computer Tasks",
    "url": "https://www.cs.cmu.edu/news/2023/llms-execute-computer-tasks",
    "text": "CMU Researcher Uses ChatGPT To Execute Computer Tasks\n# [![] Carnegie Mellon University School of Computer Science] \n[Skip to Main Content] Search**\nSearch**\n# CMU Researcher Uses ChatGPT To Execute Computer TasksLarge Language Models Can Solve Computer Tasks Using Keyboard, Mouse Actions\nAaron AupperleeTuesday, May 23, 2023[**Print this page.] \n![] CMU-led research shows that large language models can perform tedious or repetitive tasks by completing keyboard and mouse actions.\nResearch spearheaded by Carnegie Mellon University shows that AI systems such as ChatGPT and Midjourney, known best for generating text, code or images, can also handle repetitive tasks.\nStephen McAleer, a postdoctoral fellow in the[Computer Science Department] at CMU's School of Computer Science, worked with his colleagues to demonstrate that large language models (LLMs) such as ChatGPT can be used to perform general computer tasks by completing keyboard and mouse actions. These tasks range from file management and internet searches to email handling and form completion. This work is part of a new line of research shifting from generative AI systems to AI that takes action on computers, expanding the potential for AI applications.\n\"This approach opens up the possibility of many new applications and products that can navigate the web and automate repetitive tasks,\" McAleer said. \"The ultimate goal is to enable the agent to do anything on a computer that a human can do.\"\nThe application improves its output through a[recursive process of criticism and improvement], a method McAleer and his colleagues have coined RCI. With RCI, a pretrained LLM like ChatGPT is assigned a task, formulates a plan, executes it, and then reviews its performance to identify and rectify issues.\n[McAleer], along with[Geunwoo Kim] and[Pierre Baldi] from the Department of Computer Science at the University of California, Irvine, recently[published a paper] detailing their work.\n\"Current AI provides transformative opportunities and at the same time raises formidable challenges,\" Baldi said. \"This work is on the side of the opportunities, showing how computer work can be greatly facilitated if not completely automated using large language models.\"\nTheir research demonstrated that RCI outperforms all existing methods on a popular computer task benchmark. Whereas existing methods could require tens of thousands of demonstrations to learn a task, RCI typically requires only two or three demonstrations and has a 94% success rate across 55 tasks.\nMcAleer's interest in automating basic computer tasks emerged during his junior year of college, when an internship at a bank found him continually repeating the same tasks. This experience led him to two realizations: a disinterest in banking and a desire to automate tedious tasks.\n\"I've been working toward that goal ever since,\" McAleer said.\nEnabling LLMs to perform tasks humans find dull or repetitive could improve work, enhance productivity and foster prosperity. Successful models could expedite economic growth, automate scientific processes and save people valuable time to do things they love.\nMcAleer does advise caution, however. AI tools could become increasingly powerful, and his research shows that LLMs can self-improve. Consequently, it's essential to start having discussions about rules, regulations and safeguards to protect society from potential AI harm and ensure its benefits are universally accessible.\n\"Progress in AI has been moving more rapidly than I expected and it's time to start thinking about what happens if we are successful. What if autonomous agents could start making money on their own just by using computers? I can imagine scenarios where this would quickly get out of control,\" McAleer said, \"and I'm thinking hard about how to advance this technology the right way.\"\nMore information about RCI can be found on the[project's website].\n**For More Information**\nAaron Aupperlee | 412-268-9068 | aaupperlee@cmu.edu",
    "length": 3989,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Frequently Asked Questions - Online Education - Carnegie Mellon University",
    "url": "https://www.cmu.edu/online/gai-llm/frequently-asked-questions/index.html",
    "text": "Frequently Asked Questions - Online Education - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[# Generative AI &amp; Large Language Models\nFrequently Asked Questions\n] \n**[Curriculum] **\n**[ONLINE EXPERIENCE] **\n**[Admissions] **\n**[TUITION] **\n[Home] &#160;&#8250; Frequently Asked Questions# **Frequently Asked Questions**\nExplore the frequently asked questions below to learn more about the Graduate Certificate in Generative AI &amp; Large Language Models, the admission requirements, and the funding options available.\n## Program Information\n## When is the next start date for this program?\nWe follow the semester schedule as outlined in the official CMU Online Calendar.&#160;The next semester of this program will begin in Fall 2026. Specific class times for this certificate will be announced shortly before the start date.\n## How long will it take me to complete this certificate?\nThe certificate can be completed in three semesters (Spring and Fall only) or approximately 12 months.\n## How many courses are included in the certificate?\nThis certificate includes three graduate-level and credit-bearing courses taught by faculty in CMU&#8217;s Language Technologies Institute, which is housed within the School of Computer Science.\n## Do I have to take all of the courses?\nYou only need to successfully complete all courses in the program if you want to earn the certificate. If you are only interested in one course, however, you may complete that course only and it will show on your transcript with the grade earned.&#160;&#160;\n## How is the content delivered?\nThe courses are delivered 100% online. Every week, you will take at least one live-online class with a CMU professor and complete complementary learning activities on your own to supplement the class discussions.\n## How many credits will I earn after completing this certificate?\nThe certificate includes three graduate-level courses at 12 units each for a total of 36 units. This is generally equivalent to approximately 12 academic credits at other institutions.\n# At a Glance\n**Next Start Date**\nFall 2026\nPriority Deadline\\*: January 28, 2026\n\\*All applicants who submit by the priority deadline will receive a partial scholarship award.\n**[Request Information] **\n**[Apply Now] **\nQuestions? There are two ways to contact us. Call412-501-2686&#160;or send an email to[apply@online.cmu.edu] &#160;with your inquiries.\n## Admission Requirements\n## What kind of academic background do I need?\nSuccessful applicants will have an undergraduate degree in computer science, machine learning, data science, software engineering or a related field. Applicants should also be proficient in applied math (like calculus and linear algebra), statistics, Python, machine learning and deep learning.&#160;\nIf applicants do not have formal training in Python, machine learning or deep learning, knowledge gained through self-study or work experience will be considered if the applicant can provide evidence of proficiency.\n## Do I need work experience?\nIdeally, applicants will have some relevant work experience in either computer science or a related field. Internships or other related work are also acceptable.\n## Application Requirements\n## What materials do I need to submit with my application?\nBesides the online application, applicants must submit a current resum&#233;, transcripts and a statement of purpose to be considered for enrollment.\n## Is there an application fee?\nNo, this program does not require an application fee.\n## When is the application deadline?\nAll applicants who submit by the priority deadline of January 28, 2026 will be considered for a partial scholarship award.\n## How do I check the status of my application?\nYou can view the status of your application at any time in the[application portal]. A decision letter from Carnegie Mellon will be sent through the application portal within a few weeks of submitting your online application.\n## Is a deposit required to secure my spot?\nNo, a deposit is not required to secure your spot in the program.\n## Tuition &amp; Financing Options\n## If I choose to complete the entire certificate, what is my total investment?\nThe total investment for the Generative AI &amp; Large Language Models certificate during the 2026-2027 academic year is $25,452. A breakdown of the tuition and fees can be found on the&#160;[Tuition page.] &#160;Partial scholarships are available. All applicants who apply by the priority deadline of January 28, 2026 will receive a partial scholarship award. Carnegie Mellon alumni are eligible for a scholarship to the Graduate Certificate in Generative AI &amp; Large Language Models worth up to 20% of tuition.&#160;[] \n## Are scholarships available?\nYes. CMU offers partial scholarships for admitted Generative AI and Large Language Models students. All applicants who apply by the priority deadline of January 28, 2026 will receive initial consideration for these awards. Carnegie Mellon alumni are eligible for a scholarship to the Graduate Certificate inGenerative AI and Large Language Models worth up to 20% of tuition.\n## Are payment plans available?\nYes. CMU provides a[monthly payment option], managed by Nelnet Campus Commerce, that is designed to help students spread out tuition payments into manageable monthly installments. This plan also offers the ease of online enrollment. If you are admitted into the program and choose to join us, we recommend registering for this plan early to fully benefit from the range of payment options available.\n## If I enroll in this certificate, am I eligible for financial aid?\nAt this time, students pursuing a graduate certificate are not eligible to receive federal financial aid. However,[private loans] are a viable alternative to consider with competitive interest rates and borrower benefits. See[FastChoice], a free loan comparison service to easily research options.\n## How should I approach my employer about the tuition reimbursement benefits they offer?\nMany companies offer tuition reimbursement programs to foster professional development among their employees. We encourage you to contact your HR department to find out if similar opportunities exist at your workplace.\nWhen you speak to your employer, be sure to tell them that our program:&#160;\n* Consists of three transcripted, credit-bearing courses (not just continuing education units) taught by expert Carnegie Mellon professors from the nationally-ranked School of Computer Science.\n* Prepares you to design and implement scalable systems for large language models and teaches you how to efficiently train them with huge data sets, which is critical for advancing AI.\n* Trains you to determine the best model for a given task by evaluating the pros and cons of different models.\n* Empowers you to solve sophisticated engineering problems with modern hardware and software stacks that can accommodate the scale of large language models.\n* Teaches you the latest advances in large language models systems, machine learning, natural language processing, and system research.\n* Is delivered completely online, which means you can take classes on your own time while maintaining your normal work schedule.\n## Is this program eligible for CMU tuition remission?\nYes, the Graduate Certificate in Generative AI &amp; Large Language Models is eligible for CMU tuition remission. See the&#160;[CMU tuition remission policy] &#160;to check your eligibility.\n## Does CMU accept the GI Bill?\nCarnegie Mellon University provides services to veterans and their dependents who are eligible for Veterans Education Benefits under the Montgomery G.I. Bill&#174;, Post-9/11 G.I. Bill, and Vocational Rehabilitation and Employment Program. Please note, our online graduate certificates are not currently eligible for the Yellow Ribbon program.&#160;\nThe process starts with an application directly to Veterans Affairs and once approved, you will provide your Certificate of Eligibility to the Carnegie Mellon Veterans Affairs Coordinator.&#160;[Contact Information and additional details about the process can be found here.] \nStudents eligible for GI Bill funding may receive scholarship awards prior to full GI Bill funding confirmation. Scholarship awards will be adjusted to reflect GI Bill funding and cannot exceed the cost of tuition/fees.\n# Artificial Intelligence at Carnegie Mellon\n[\n## GenAI Innovation Incubator\nLed by Dr. Carolyn Ros&#233; and other CMU experts, the Generative AI Innovation Incubator is shaping the future of GenAI.\n![abstract image of generative ai]] \n[\n## Faculty Lightning Talk\nLearn more about Dr. Ippolito's research on harnessing large language models and understanding their limitations.\n![Dr. Daphne Ippolito]] \n[\n## Faculty Lightning Talk\nDr. Li introduces his research on multilingual natural language processing, large language models, and trustworthy AI.\n![Dr. Lei Li]] \n[\n## Multimodal AI\nDr. Morency discusses multimodal machine learning and the applications of multimodal AI at the 2019 WeCNLP Summit.\n![Dr. Louis-Philippe Morency]] \n[\n## Faculty Meet &amp; Greet\nDr. Yonatan Bisk discusses his research in the area of connecting language to actions in the world, primarily through robotics.\n![Dr. Yonatan Bisk]] \n[\n## Faculty Lightning Talk\nDr. Fried explains his interest in helping people collaborate with computers to carry out real-world tasks mediated by language.\n![Dr. Daniel Fried]]",
    "length": 9480,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Protected AI Tools You Can Use",
    "url": "https://www.cmu.edu/computing/services/ai/meet-ai/tools/google-ai-tools/gemini-web-app-how-to.html",
    "text": "Protected AI Tools You Can Use - Computing Services - Office of the CIO - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[Computing Services] ## [Office of the CIO] \n[Office of the CIO] &#160;&#8250;&#160;[Computing Services] &#160;&#8250;&#160;[Services] &#160;&#8250;&#160;[Generative Artificial Intelligence (AI)] &#160;&#8250;&#160; Protected AI Tools You Can Use\n# ![] \nProtected AI Tools You Can Use\nThe AI tools listed on this page are available at CMU. When you sign in with your Andrew ID and password, each tool is FERPA-compliant and will not use your data to train its AI models.\n## Interested in New Tools?\nAI tools that have not yet been reviewed or licensed by CMU might not offer the same data protections and approved services.&#160;\nSubmit a[software request] for review and approval.\n# Use AI Safely at CMU\nBefore using CMU's protected AI tools, please review our[policies and guidelines for safe and ethical use].\n# DAO Accessibility Tools\nExplore[tools endorsed by the Digital Accessibility Office] that have AI capabilities.\n# Approved AI Tools\n## [AI Gateway] \n## [ChatGPT Edu] \n## [Gemini Web App] \n## [Microsoft Copilot] \n## [NotebookLM] \n## [Zoom AI Companion] \n## Tool Comparison Table\n|Tool|Purpose|Best For|Available To|Cost|\n[AI Gateway] |AI Developer tool makes AI models easier to access.|Accessing&#160; management to models via API keys.|Faculty and Staff|No cost; however an Oracle String is required to pass on any costs incurred from using a model endpoint.&#160;|\n[ChatGPT Edu] |Synthesizes info, summarizes, and generates content.|Research, writing, and problem-solving.|Faculty and Staff; Students sponsored by a faculty or staff member|$240 / per year|\n[Gemini Web App] |Google's AI that handles text, voice, and files.|Meeting summaries, working with Google Apps, and searching across formats.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n[Microsoft Copilot Chat] |AI support for Office tasks, images, and code.|Microsoft files, documents, and coding help.|Students, Faculty, and Staff|Available with your Andrew account.|\n[NotebookLM] |Creates AI-powered notebooks from uploads.|Organizing ideas, summarizing sources, and creating podcasts.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n[Zoom AI Companion] |Adds summaries and action items to meetings.|Real-time help during virtual meetings.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n**Note:**Available add-ons for protected AI tools have been thoroughly reviewed and vetted for use at CMU. For example, ChatGPT Edu with[Agents] is already available to paid ChatGPT Edu subscribers.\n* [About] \n* [Computing Services InfoCenter] \n* [CSS Awards and Recognition] \n* [News] \n* [Service Status] \n[Log In to Services] \n* [Computing Services Help Center] \n* [412-268-4357 (HELP)] \n* [it-help@cmu.edu]",
    "length": 2961,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Sponsor Student Projects - \n                Center for Intelligent Business -     Tepper School of Business - Carnegie Mellon University",
    "url": "https://www.cmu.edu/intelligentbusiness/industry-engagement/support-capstones.html",
    "text": "Sponsor Student Projects - Center for Intelligent Business - Tepper School of Business - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[Center for Intelligent Business] ## [Tepper School of Business] \n[Tepper School of Business] &#160;&#8250;&#160;[Center for Intelligent Business] &#160;&#8250;&#160;[Industry Engagement] &#160;&#8250;&#160; Sponsor Student Projects\n# Sponsor Student Projects\nStudent projects are immersive, experiential courses that often culminate a program experience. Industry partners are an integral part of making these courses impactful learning experiences. Your company provides the business challenge and we will help you shape it into an educational experience and connect with the right audience. Tepper students apply their deep analytical skills, business knowledge, and creative problem-solving expertise to transform data into better decision-making and a competitive advantage for your business.\n**What to expect:**\n* 15 week project time frame in the fall or spring semester\n* Faculty supervision of program + industry or academic project advisor\n* 2-5 students from world-ranked CMU tackling your business problem\n* &#126;10 hours per student invested in the project weekly\n* Graduate, undergraduate and interdisciplinary team formats\n**Sponsorship entails:**\n* Provide project idea + data/material if applicable\n* Participation at kickoff, mid-term and closing meetings; project liaison biweekly touch points.\n* Educational Project Agreement&#160;\n&#160;\n# Download the Tepper Capstone Brochure\n* [2024/2025 Tepper Capstone Brochure] \n# Recent Project Capstone Outcomes\n[\n## Business Analytics Students Aim to Help Increase Blood Donors\n![Person giving blood]] \n[\n## MBA and MSBA Students Combine Expertise to Help AI Platform Overcome a Scaling Obstacle\n![robot graphic logo]] \n[\n## MS Business Analytics Students Examine Long-Held Parcel Delivery Problem\n![people unloading boxes from delivery truck]] \n[\n## Glance: Improving Click-through Rate on Mobile Lock Screen Advertisements\n![colorful data analytics illustration]] \n[\n## Reducing Tier 2 Creator Churn on Roposo Through Targeted Intervention\n![inmobi logo]] \n[\n## 99PLabs Research - Dynamic Vehicle Services\n![city street with trailing vehicle headlights and taillights]] \n[\n## Increasing Transaction Size Through Data Analytics\n![colorful data analytics chart]] \n[\n## MBA Students Help Medical Air Travel Agency Through Capstone Project\n![airplane]] \n[\n## Business Analytics Student Team Explores PNC Clickstream Data\n![graph on computer tablet in coffee shop]] \n[\n## Student Project Applies Data Science in Health Care\n![person in hospital gown being helped by medical staff]] \n[\n## Energy Business Track Students Explore Green Hydrogen with Honda\n![fueling up hydrogen car]]",
    "length": 2853,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Generative AI & Large Language Models",
    "url": "https://www.cmu.edu/online/gai-llm/admissions/index.html",
    "text": "Apply to CMU's Online Graduate Certificate in Generative AI &amp; Large Language Models - Online Education - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[# Generative AI &amp; Large Language Models\nAdmissions\n] \n**[CURRICULUM] **\n**[Online Experience] **\n**[ADMISSIONS] **\n**[TUITION] **\n[Home] &#160;&#8250; Admissions# **Apply to Advance your Expertise**\nGenerative AI is revolutionizing the world&#8217;s technical capabilities and it will inevitably impact the way all organizations operate. Carnegie Mellon&#8217;s new online Graduate Certificate in Generative AI and Large Language Models will help you strengthen your skill set to capitalize on this technical revolution. When you complete the online certificate, you will be ready to pioneer new systems with the latest and most advanced expertise in Generative AI.\n## **Is this the right program for you?\n**\nAs a graduate-level program in the School of Computer Science, Generative AI is designed for highly technical, advanced computer science professionals.&#160; As such, the program requires a history of academic success in math, programming, and machine learning, coupled with a high level of proficiency in multiple programming languages.&#160; Before you begin your application, take a moment to review the program requirements below.&#160;&#160;\n**Successful applicants will have:**\n* **A Bachelor&#8217;s Degree in Computer Science or a Related Field**\nTo be successful, applicants should have an undergraduate degree in computer science, machine learning, data science, software engineering, or a related field.\n* **Academic History in Advanced Mathematics**\nStudents should have successfully completed a minimum of 3 courses in advanced mathematics. Relevant topics include:\n* *Calculus, Differential Equations, and Linear Algebra*\n* *Matrix Math, Nonlinear Programming, and Nonlinear Optimization*\n* *Probability Theory and Statistics, Probability and Stochastic Processes*\n* *Combinatorics, Set Theory, and Graph Theory*\n* **Academic History in Computer Science**\nStudents should have successfully completed a minimum of 3 courses in computer science. Relevant topics include:\n* *Programming in C, C++, Java, Python*\n* *Analysis of Algorithms, Data Structures, and Algorithms*\n* *Computational Complexity*\n* *Discrete Structures / Discrete Math / Logic***\n* *Formal Languages*\n* *Parallel and Distributed Computing*\n* &#160;*Programming Languages*\n* *Object-Oriented Programming*\n* *Operating Systems*\n* *Software Engineering*\n* **Academic History and/or Extensive Experience in Machine Learning**\nStudents should have successfully completed at least one Machine Learning course. If formal coursework has not been taken, specific evidence of experience with machine learning will be considered. Applicants without this experience may be required to take a Machine Learning course prior to enrollment in the Generative AI Certificate.\n* **Academic History and/or Experience with Multiple Programming Languages**\nStudents must have proficiency in Python. In addition, they should have experience in other languages such as C/C++/C#, Java, Swift, Go, Scala, or Rust. Applicants without experience in other languages may need to do some preparatory work prior to enrollment.\n* **Dynamic Link Libraries**\nSome experience with PyTorch or TensorFlow. Applicants without experience may need to do some preparatory work prior to enrollment.\nIf you have questions about the program or how it aligns with your background, please call412-501-2686or send an email to[apply@online.cmu.edu] with your inquiries.\n## Application Requirements\nReady to apply? Here&#8217;s what you&#8217;ll need to complete the admissions process:&#160;\n**&#10004; Complete the[online application] \n**Submit your application in the application portal.\n**&#10004; Submit your resume/CV\n**We&#8217;d like to learn more about your employment history, academic background, technical skills and professional achievements. Submit a 1 to 2 page resume or CV showcasing your experience.&#160;\n**&#10004; Submit your transcripts\n**Submit an unofficial copy of your transcript for each school you attended. Transcripts must include your name, the name of the college or university, the degree awarded (along with the conferral date), as well as the grade earned for each course. Email your transcripts directly to[apply@online.cmu.edu].&#160;*Please note: former Carnegie Mellon students and/or alumni can request a copy of their CMU transcript from&#160;[The Hub].*\n**&#10004;&#160; Upload a statement of purpose\n**Tell us your professional story. Where have you been and where do you hope to go? In 500 words or less, explain your objective for applying to this program and what you hope to gain from completing the coursework.\n**&#10004; Submit your TOEFL, IELTS, or Duolingo test scores (if applicable)\n**An official TOEFL, IELTS, or Duolingo test is required for non-native English speakers. Please note, Carnegie Mellon University has[minimum requirements for all language test scores].&#160;&#160;\nHowever, this requirement may be waived for applicants who meet one of the following:\n1. Completed an in-residence bachelor&#8217;s, master&#8217;s, or doctoral degree program in the United Kingdom, United States, or Canada (excluding Quebec)\n2. Have at least three years of professional work experience where English was the primary language of communication. In this case, you will be prompted to describe your work experience in your application and include a link to your company&#8217;s website for verification.\n## A Note for International Applicants\nAs part of a global university with locations and students from around the world, the School of Computer Science welcomes the diverse perspectives that international students bring to our programs.\nTo help ensure you are fully prepared for the admissions process and, if admitted, for success as a student, this section provides detailed information about requirements for international applicants.\nThe Graduate Certificate in Generative AI &amp; Large Language Models considers for admission international applicants who reside within, or outside of, the domestic United States. International applicants who reside within or outside of the domestic United States are advised of the following information and additional requirements for international applicants to the program.\n### Student Visas\nSince this program is fully online, enrollment in this program will not qualify students for any type of visa to enter or remain in the United States for any purpose.&#160;\n### U.S. Sanctions; U.S. Sanctioned Countries\nIndividuals who are the target of U.S. sanctions or who are ordinarily resident in a U.S. sanctioned country or who live or expect to live in a U.S. sanctioned country while participating in the program are not eligible for admission to this program due to legal restrictions/prohibitions and should not apply. U.S sanctioned countries are currently Cuba, Iran, North Korea, Russia, Syria and the following regions of Ukraine: Crimea, Donetsk and Luhansk. In addition, all or a portion of this program may not be available to individuals who are ordinarily resident of certain countries due to legal restrictions.&#160;\nApplications received from these individuals will not be accepted. As well, if an individual is admitted to the program and subsequently, the individual becomes the target of U.S. sanctions, ordinarily resident of a U.S. sanctioned country or lives in a U.S. sanctioned country while participating in the program (or otherwise becomes ordinarily resident of country in which the program is not available due to legal restrictions), the individual&#8217;s continued enrollment in the program may be terminated and/or restricted (due to U.S. legal restrictions/ prohibitions) and the individual may not be able to complete the program.&#160;&#160;\n### Time and Attendance Requirement\nClasses for the program will be taught in the U.S. Eastern Time Zone, and students must be available to attend all live classes, regardless of location.\n### **Licensure in Various Jurisdictions**\nFrom time to time Carnegie Mellon reviews the licensing requirements of various jurisdictions in order to assess whether Carnegie Mellon may be precluded from making the program available to applicants that are residents of one or more of these jurisdictions prior to Carnegie Mellon obtaining the relevant license(s). Affected applicants from these jurisdictions, if any, will be notified prior to enrollment if the Carnegie Mellon determines that it is unable to make the program available to them for this reason.\n### Value Added Tax (VAT) and Other Taxes\nThe tuition, required fees and other amounts quoted for this program do not include charges for applicable Taxes (hereinafter defined). The student is responsible for payment of all applicable Taxes (if any) relating to the tuition, required fees and other amounts required to be paid to Carnegie Mellon for the program, including any Taxes payable as a result of the student&#8217;s payment of such Taxes.&#160;\nFurther, the student must timely make all payments due to Carnegie Mellon without deduction for Taxes, unless the deduction is required by law. If the student is required under applicable law to withhold Taxes from any payment due to Carnegie Mellon, the student is responsible for timely (i) paying to Carnegie Mellon such additional amounts as are necessary so that Carnegie Mellon receives the full amount that it would have received absent such withholding, and (ii) providing to Carnegie Mellon all documentation, if any, necessary to permit the student and/or Carnegie Mellon to claim the application of available tax treaty benefits (for Carnegie Mellon review and completion, if warranted and acceptable).&#160;\nTaxes mean any taxes, governmental charges, duties, or similar additions or deductions of any kind, including all use, income, goods and services, value added, excise and withholding taxes assessed by or payable in the student&#8217;s country of residence and/or country of payment (but does not include any U.S. federal, state or local taxes).\n# At a Glance\n**Next Start Date**\nFall 2026\nPriority Deadline\\*: January 28, 2026\n\\*All applicants who submit by the priority deadline will receive a partial scholarship award.\n**[Request Information] **\n**[Apply Now] **\nQuestions? There are two ways to contact us. Call412-501-2686&#160;or send an email to[apply@online.cmu.edu] with your inquiries.\n# So, why CMU?\n## We strive for excellence\n![white icon on red background of arrow progressing upward] \n## We embrace iteration\n![white icon on red background of iteration process] \n## We collaborate across disciplines\n![white icon on red background of three hands holding puzzle pieces] \n## We pioneer new fields\n![white icon on red background of person holding light bulb]",
    "length": 10944,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Open Forum for AI (OFAI)",
    "url": "https://www.cmu.edu/engin/programs/ofai.html",
    "text": "OFAI - ENGIN - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[ENGIN] \n# Open Forum for AI (OFAI)\n[ENGIN] &#160;&#8250;&#160;[Programs] &#160;&#8250;&#160; OFAI\nCarnegie Mellon University (CMU) is launching the Open Forum for AI (OFAI) to provide holistic, objective expert advice regarding AI, particularly as it relates to research, technical prototypes, policy recommendations, community engagement, and inclusion. The overarching vision is that AI should augment human capability rather than replace it; that AI development needs to be human centered. Leveraging CMU&#8217;s AI expertise and capacity, OFAI will include partners that offer a range of complementary expertise necessary for collective action for AI strategy and associated policy development.\n## Founding Reason\nOFAI&#8217;s launch signals a powerful call for deeper technical understanding and more rigorous scrutiny in AI, including but also extending beyond open source software. OFAI will advocate in an objective manner for wider involvement in the AI ecosystem to shape policy-making and address issues such as AI safety, privacy, and equity, as underscored in memoranda like the White House AI Executive Order. There is growing consensus that an open AI ecosystem will mitigate risks while fostering innovation and inclusion, but little clarity about the characteristics of such an ecosystem. OFAI aims to address this gap in a comprehensive and inclusive manner.\nOne current narrative is that AI can be executed only with large-language models and massive amounts of data and computational power; that is, with technology infrastructure available only to a certain few. A corollary of this narrative is that AI is too complex to be examined transparently. Within this scenario, the default may become large technology companies self-regulating, with small and medium enterprises and underrepresented groups finding it difficult to participate in the AI ecosystem.\nOFAI will augment this narrative by conducting research, making policy recommendations, developing outputs including AI technical prototypes, and convening diverse groups such that AI becomes a multi-stakeholder effort with facets at different levels of granularity. At the crux of these efforts will be the technical framework that outlines and defines openness of AI based on both artifacts and orchestration of those artifacts.\n# Contact\n**Sayeed Choudhury**\n[sayeedc@cmu.edu] \n*Associate Dean for Digital Infrastructure, University Libraries\nDirector, Open Source Programs Office*\n# ENGIN in the News\n* **[CMU Launches New Initiative for Human-Centered AI] **[library.cmu.edu]\n* **[Can Artificial Intelligence be Open Sourced?] **[cacm.acm.org]\n* [**CMU OSAID Statement**] \n# Additional Resources\n* [OFAI Landscape] [github.io]\n* [OFAI Position Paper] [.pdf]\n# About OFAI\n[Key Activities] &#160;&#160;&#160;[Team] \n## [Key Activities] \n## [Team]",
    "length": 2966,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "S2 Episode 14: Guiding a Safe Future for AI — Part 1 | Where What If Becomes What's Next Podcast",
    "url": "https://www.cmu.edu/whats-next-podcast/all-episodes/s2-episode-14-guiding-safe-future-ai-part-1",
    "text": "S2 Episode 14: Guiding a Safe Future for AI —Part 1 | Where What If Becomes What's Next Podcast[Skip to main content] \n[] \n[Where What If Becomes What's Next Podcast] \nWhat can we help you find?\n![A brain with one half showing neural networks and the other half showing AI circuitry. AI-generated image.] \nGuiding a Safe Future for AI —Part 1\n# S2 Episode 14: Guiding a Safe Future for AI —Part 1\n## S2 Episode 14 | October 8, 2025\nWhat if AI is automating the one thing that's always made us human —intelligence itself? And how do we ensure that it's developed safely?\nIn this first of a two-part series, we speak with Dr. Zico Kolter, head of Carnegie Mellon University's Machine Learning Department and newly appointed OpenAI board member, where he chairs their Safety and Security Committee, to explore the critical challenge of developing artificial intelligence safely.\nDr. Kolter discusses CMU's pioneering machine learning department and outlines four essential categories of AI safety concerns: immediate security threats like data exfiltration and prompt injection; societal impacts on jobs, economy and mental health; catastrophic risks from malicious actors wielding AI-powered capabilities; and long-term scenarios of uncontrollable superintelligence.\nUnlike previous technological revolutions that automated physical labor or computation, AI represents something unprecedented —the automation of intelligence itself. Dr. Kolter argues this fundamental difference demands collaborative oversight from industry, academia and government to ensure AI serves humanity's best interests. The conversation emphasizes why getting AI safety right matters more than ever as we integrate thinking machines into our critical infrastructure.\n## S2 Episode 14 Transcript\n![Where What If Becomes What's Next block text next to a robot hand with two fingers up to indicate season 2] \nNever Miss an Episode! Subscribe to Where What If Becomes What's Next Podcast on[Spotify],[Apple Podcasts],[YouTube Music] or wherever you listen to podcasts.",
    "length": 2039,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "10 CMU Students Selected for Amazon AI Ph.D. Fellowship Program | Carnegie Mellon University Computer Science Department",
    "url": "https://www.csd.cs.cmu.edu/news/10-cmu-students-selected-for-amazon-ai-phd-fellowship-program",
    "text": "10 CMU Students Selected for Amazon AI Ph.D. Fellowship Program | Carnegie Mellon University Computer Science Department[Skip to main content] \n[![Home]] \n*\nExpand Menu\n*\n \n# 10 CMU Students Selected for Amazon AI Ph.D. Fellowship Program\n*Tuesday, October 21, 2025*\n![] \nTen Carnegie Mellon doctoral students pursuing artificial intelligence research will receive support from Amazon through the company's new AI Ph.D. Fellowship Program.\nThe students come from across CMU's School of Computer Science and[College of Engineering]. Their research tackles the foundational challenges, theoretical underpinnings and deep technological systems critical to AI innovation.\n\"Close collaboration between academia and industry is critical to producing groundbreaking work that will shape technologies for years to come,\" said[Martial Hebert], dean of the School of Computer Science. \"Amazon and Carnegie Mellon share a common vision that AI can transform how we work, play, shop, socialize and learn. We are grateful for Amazon's support of foundational research in pursuit of innovation.\"\nAmazon's AI Ph.D. Fellowship Program aims to help drive the innovations that will underwrite the next step in the evolution of practical AI. The program will provide two years of funding for more than 100 Ph.D. students at nine universities who are pursuing research on core AI disciplines such as machine learning, computer vision and natural language processing.\n\"Amazon's AI Ph.D. Fellowship Program reflects our ongoing commitment to the academic community. We're fortunate to collaborate with some of the nation's brightest Ph.D. students who are advancing critical areas in AI —from high-performance chips and hardware to networking, software, foundation models, applications and more,\"said Rohit Prasad, a senior vice president and head scientist for Amazon AGI. \"What makes this program special is how it brings together Amazon's real-world experience across diverse industries with the fresh perspectives of these top researchers to cultivate the next generation of AI leaders. We believe investing in future talent is essential to moving the field forward and creating truly useful AI that benefits everyone.\"\nAmazon selected students for the program from CMU; Johns Hopkins University; the Massachusetts Institute of Technology; Stanford University; the University of California, Berkeley; the University of California, Los Angeles; the University of Texas at Austin; the University of Illinois Urbana-Champaign; and the University of Washington.\nThe $68 million program provides $10 million in student funding each year and $24 million annually in Amazon Web Services (AWS) cloud-computing credits. Each fellow is also paired with an Amazon research liaison, a senior scientist working at Amazon on a topic related to the fellow's work. Mentors will meet regularly with their fellows to offer guidance and to discuss the real-world implications of the fellows’ research.\nAmazon's AI Ph.D. Fellowship Program builds on the company's long history of supporting academic research. Amazon and CMU recently announced the launch of the[CMU-Amazon AI Innovation Hub] to bolster research on generative AI, robotics, natural language processing and cloud computing technologies. Faculty and student research have received funding through the[Amazon Scholar] program and[Amazon Research Awards], and[AWS committed to supporting CMU CS Academy], allowing the free computer science curriculum for middle and high school classrooms to be hosted on its servers at no cost.\nIn addition to supporting foundational research, Amazon, with support from Governor Josh Shapiro and other government leaders, announced this summer plans to[invest at least $20 billion in Pennsylvania] to expand its data center infrastructure for AI and cloud computing.\nFor more information on the AI Ph.D. Fellowship Program, visit the[Amazon Science website].\nThe following students are part of the inaugural fellowship cohort.\n### Apurva Gandhi, Computer Science Department (CSD)\n![Portrait of Apurva Gandhi.] \nGandhi will focus on training generally capable AI agent systems to tackle increasingly complex real-world tasks through advances in reinforcement learning, adaptive environments and scalable multi-agent infrastructure.\n### Karish Grover, Machine Learning Department (MLD)\n![Portrait of Karish Grover.] \nGrover studies geometric foundational models for graph mining. Understanding the geometric structure can enhance representation learning for complex graphs and multimodal data systems at scale, improving recommendations, fraud detection, knowledge reasoning, infrastructure optimization and anomaly detection.\n### Aashiq Muhamed, MLD\n![Portrait of Aashiq Muhamed.] \nMuhamed will enhance the safety of AI agents by intentionally eliciting harmful behaviors to determine the effectiveness of detecting misuse. This work could help AI agents self-correct harmful actions in real time and transform agent security into a reproducible, empirical science.\n### Yuxiao Qu, MLD\n![Portrait of Yuxiao Qu.] \nQu wants to equip AI agents with the curiosity of humans. An AI system that seeks knowledge similarly to a scientist —formulating hypotheses, running experiments and drawing conclusions —could push the frontiers of discovery in scientific research, drug discovery and persistent digital assistance.\n### Danqing Wang, Language Technologies Institute (LTI)\n![Portrait of Danqing Wang.] \nWang is working to improve the reliability and safety of LLM-based agents in complex, real-world environments by establishing benchmarks and evaluation methods, integrating security and functionality into training, and ensuring agents share only essential information to improve efficiency and minimize risks. This research will lay a strong foundation for the development of smart, trustworthy and safe AI agents.\n### Mengdi Wu, CSD\n![Portrait of Mengdi Wu.] \nWu uses machine learning techniques to automatically learn and adapt compute kernel optimization strategies for both hardware and workload. The work aims to deliver high-performance kernels across different platforms, reducing developer effort while enabling faster and more scalable model training and inference.\n### Xinyu Yang, Electrical and Computer Engineering (ECE)\n![Portrait of Xinyu Yang.] \nYang hopes to enable AI agents to scale by streamlining end-to-end training systems. The work introduces a new generative model architecture that enables multi-agent workflow within a single model runtime.\n### Zeji Yi, ECE\n![Portrait of Zeji Yi.] \nYi seeks to apply generative models to general-purpose robotic platforms, such as humanoids and dexterous hands. This work could pave the way for next-generation foundation models for humanoid robotics with potential applications including warehouse automation and fulfillment centers.\n### Zichun Yu, LTI\n![Portrait of Zichun Yu.] \nYu tackles the critical data-centric LLM challenge of limited organic data and the bottleneck it places on model pretraining. Yu will design and optimize synthetic data-generation systems to complement scarce organic data, improving both data quality and quantity and, ultimately, delivering better, cleaner, richer pretraining data.\n### Xinran Zhao, LTI\n![Portrait of Xinran Zhao.] \nZhao aims to enhance retrieval-augmented generation (RAG), generative AI that relies on external sources, which struggle with uncertain sources, evolving user interpretations and prior actions. Zhao's new system improves awareness, attribution and effectiveness in complex RAG scenarios.\n \n",
    "length": 7569,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "CMU Supports NIST Guidelines on Red Teaming for Generative AI",
    "url": "https://www.cmu.edu/news/stories/archives/2024/april/cmu-supports-nist-guidelines-on-red-teaming-for-generative-ai",
    "text": "CMU Supports NIST Guidelines on Red Teaming for Generative AI - News - Carnegie Mellon University\n[Skip to main content] \n[Carnegie Mellon University homepage] \nSearch Carnegie Mellon UniversitySearch\nMenu\n[News] \n*April 11, 2024*# CMU Supports NIST Guidelines on Red Teaming for Generative AI\n## * [Share on Facebook (opens in new window)] \n* [Share on X (opens in new window)] \n* [Share on LinkedIn (opens in new window)] \n* Print this page\n* [Share by email] \n**By:**Caroline Sheedy[Email] \nMedia Inquiries\n**\nName\nPeter Kerwin**\nTitle\nUniversity Communications &amp; Marketing\n[Email] \nPhone\n[412-268-1151] \nCarnegie Mellon University’s[Block Center for Technology and Society(opens in new window)] and[K&amp;L Gates Initiative in Ethics and Computational Technologies(opens in new window)] released a[white paper(opens in new window)] that will support national efforts to ensure that AI systems are safe, secure and trustworthy. The white paper followed a workshop the groups hosted in late February on red teaming —strategic testing to identify flaws and vulnerabilities in AI systems. There, experts from academia and industry worked to gain a shared understanding of red teaming for generative AI.\nThe workshop was in response to an[executive order(opens in new window)] released by President Joe Biden that set his administration’s priorities related to artificial intelligence used by Americans. It called for the[National Institute of Standards and Technology (NIST)(opens in new window)] to develop tools and tests to help ensure that AI systems fit those standards.\nCMU frequently collaborates with NIST on AI issues, said[Theresa Mayer(opens in new window)], CMU’s vice president for research.\n“Carnegie Mellon is proud to continue supporting this important work in providing the foundation of our nation's AI strategy as this technology continues to be implemented in the public sector. We've been deeply engaged with NIST and their ongoing work providing guidelines for this technology that will be vital in moving forward responsibly integrating AI tools and software into the federal government's everyday operations,” she said.\n[![Embedded YouTube video]] \n[Hoda Heidari(opens in new window)], the K&amp;L Gates Career Development Assistant Professor in Ethics and Computational Technologies in CMU’s[School of Computer Science(opens in new window)], was a conference organizer. She said there are significant questions about how to best use red teaming.\n“In response to a rising concern surrounding the safety, security and trustworthiness of generative AI models, practitioners and regulators alike have pointed to AI red teaming as a key strategy for identifying and mitigating societal risks of these models,” Heidari said. “However, despite AI red teaming retaining a central role in recent policy discussions and corporate messaging, significant questions remain about what precisely it means, how it relates to conventional red teaming practices and cybersecurity ... how it should be conducted and what role it can play in the future evaluation and regulation of generative AI.”\nThe workshop included discussions on research, industry practices and the policy and legal implications of AI red teaming. In addition to the white paper summary, video recordings of the event are available on the[Block Center’s YouTube(opens in new window)] channel.\n![Hoda Heidari] \n*Hoda Heidari*\n## Key Points from the White Paper\n* A functional definition of red teaming, its components, scope and limitations, is necessary for effective red teaming.\n* Generative AI research and practice communities must move toward standards and best practices around red teaming.\n* The composition of the red team (in terms of diversity of backgrounds and expertise) is an important consideration.\n* Red teaming efforts should address the broader system —as opposed to individual components.\n* The broader political economy (e.g., market forces, regulations) will influence the practice of red teaming.\n[More Information(opens in new window)] \n## —Related Content —[\n![wray-block-center-900x600-min.jpg] \n## Steve Wray Named Executive Director for CMU's Block Center for Technology and Society\n] \n[\n![group of people standing in front of blue curtain] \n## CMU Joins $110M U.S.-Japan Partnership To Accelerate AI Innovation\n] \n[\n![3d Illustration Colored round curves on dark abstract background. Spiral, twist, swirl.] \n## CMU and Partners Lead Creativity, Empathy and AI National Summit\n] \n* [The Piper: Campus &amp; Community News(opens in new window)] \n* [Official Events Calendar(opens in new window)] \n▴scroll to top",
    "length": 4620,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Interactive, Educational Exhibits Powered by AI  - \n                Office of the Vice President for Research - Carnegie Mellon University",
    "url": "https://www.cmu.edu/research-office/research-impacts/educational-exhibits-ai.html",
    "text": "Interactive, Educational Exhibits Powered by AI - Office of the Vice President for Research - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[Office of the Vice President for Research] \n[Office of the Vice President for Research] &#160;&#8250;&#160;[Research Impacts] &#160;&#8250;&#160; Interactive, Educational Exhibits Powered by AI\n# Interactive, Educational Exhibits Powered by AI\n![12_mc_norilla] \n**The problem:**Traditional science education often fails to engage children because it focuses on reciting scientific facts, not on the engaging process of scientific inquiry.\n**The solution:**With support from the National Science Foundation, a team of Carnegie Mellon University researchers have created a series of interactive, hands-on exhibits and learning stations for museums and schools.&#160;\n* The AI system, known as NoRILLA and named after a virtual gorilla, guides children through the full cycle of scientific inquiry&#8212;from forming a hypothesis to testing it&#8212;ensuring play is purposeful.&#160;\n* By offering just-in-time feedback on children's real-world actions, the system shifts the focus from remembering facts to understanding how science works.&#160;\n**The impact:**Studies show NoRILLA improves children's learning by five times compared to equivalent tablet or computer games while also increasing their interest and enjoyment.&#160;\n* It also kept children engaged for up to four times longer than traditional exhibits, confirming the power of inquiry-based learning.&#160;\n* Additional NSF funding is helping to expand NoRILLA from museums and science centers to intelligent science stations in schools.\n* NoRILLA has been disseminated to more than 40 schools and museums around the US and Europe, reaching millions of children.&#160;\n**Go deeper:**[Researchers Receive $3M NSF Grant to Expand AI-Powered Intelligent Science Stations in Schools] \n# Read More Spotlights\n* [Customized Finger Braces for Faster Injury Recovery] \n* [AI Unlocks Rare Disease Research] \n* [Using Drones to Fight Wildfires]",
    "length": 2116,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Protected AI Tools You Can Use",
    "url": "https://www.cmu.edu/computing/services/ai/meet-ai/tools/ai-gateway/how-to/index.html",
    "text": "Protected AI Tools You Can Use - Computing Services - Office of the CIO - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[Computing Services] ## [Office of the CIO] \n[Office of the CIO] &#160;&#8250;&#160;[Computing Services] &#160;&#8250;&#160;[Services] &#160;&#8250;&#160;[Generative Artificial Intelligence (AI)] &#160;&#8250;&#160; Protected AI Tools You Can Use\n# ![] \nProtected AI Tools You Can Use\nThe AI tools listed on this page are available at CMU. When you sign in with your Andrew ID and password, each tool is FERPA-compliant and will not use your data to train its AI models.\n## Interested in New Tools?\nAI tools that have not yet been reviewed or licensed by CMU might not offer the same data protections and approved services.&#160;\nSubmit a[software request] for review and approval.\n# Use AI Safely at CMU\nBefore using CMU's protected AI tools, please review our[policies and guidelines for safe and ethical use].\n# DAO Accessibility Tools\nExplore[tools endorsed by the Digital Accessibility Office] that have AI capabilities.\n# Approved AI Tools\n## [AI Gateway] \n## [ChatGPT Edu] \n## [Gemini Web App] \n## [Microsoft Copilot] \n## [NotebookLM] \n## [Zoom AI Companion] \n## Tool Comparison Table\n|Tool|Purpose|Best For|Available To|Cost|\n[AI Gateway] |AI Developer tool makes AI models easier to access.|Accessing&#160; management to models via API keys.|Faculty and Staff|No cost; however an Oracle String is required to pass on any costs incurred from using a model endpoint.&#160;|\n[ChatGPT Edu] |Synthesizes info, summarizes, and generates content.|Research, writing, and problem-solving.|Faculty and Staff; Students sponsored by a faculty or staff member|$240 / per year|\n[Gemini Web App] |Google's AI that handles text, voice, and files.|Meeting summaries, working with Google Apps, and searching across formats.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n[Microsoft Copilot Chat] |AI support for Office tasks, images, and code.|Microsoft files, documents, and coding help.|Students, Faculty, and Staff|Available with your Andrew account.|\n[NotebookLM] |Creates AI-powered notebooks from uploads.|Organizing ideas, summarizing sources, and creating podcasts.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n[Zoom AI Companion] |Adds summaries and action items to meetings.|Real-time help during virtual meetings.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n**Note:**Available add-ons for protected AI tools have been thoroughly reviewed and vetted for use at CMU. For example, ChatGPT Edu with[Agents] is already available to paid ChatGPT Edu subscribers.\n* [About] \n* [Computing Services InfoCenter] \n* [CSS Awards and Recognition] \n* [News] \n* [Service Status] \n[Log In to Services] \n* [Computing Services Help Center] \n* [412-268-4357 (HELP)] \n* [it-help@cmu.edu]",
    "length": 2961,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "ChatGPT Edu - Computing Services - Office of the CIO - Carnegie Mellon University",
    "url": "https://www.cmu.edu/computing//services/ai/chatgpt/index.html",
    "text": "Protected AI Tools You Can Use - Computing Services - Office of the CIO - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[Computing Services] ## [Office of the CIO] \n[Office of the CIO] &#160;&#8250;&#160;[Computing Services] &#160;&#8250;&#160;[Services] &#160;&#8250;&#160;[Generative Artificial Intelligence (AI)] &#160;&#8250;&#160; Protected AI Tools You Can Use\n# ![] \nProtected AI Tools You Can Use\nThe AI tools listed on this page are available at CMU. When you sign in with your Andrew ID and password, each tool is FERPA-compliant and will not use your data to train its AI models.\n## Interested in New Tools?\nAI tools that have not yet been reviewed or licensed by CMU might not offer the same data protections and approved services.&#160;\nSubmit a[software request] for review and approval.\n# Use AI Safely at CMU\nBefore using CMU's protected AI tools, please review our[policies and guidelines for safe and ethical use].\n# DAO Accessibility Tools\nExplore[tools endorsed by the Digital Accessibility Office] that have AI capabilities.\n# Approved AI Tools\n## [AI Gateway] \n## [ChatGPT Edu] \n## [Gemini Web App] \n## [Microsoft Copilot] \n## [NotebookLM] \n## [Zoom AI Companion] \n## Tool Comparison Table\n|Tool|Purpose|Best For|Available To|Cost|\n[AI Gateway] |AI Developer tool makes AI models easier to access.|Accessing&#160; management to models via API keys.|Faculty and Staff|No cost; however an Oracle String is required to pass on any costs incurred from using a model endpoint.&#160;|\n[ChatGPT Edu] |Synthesizes info, summarizes, and generates content.|Research, writing, and problem-solving.|Faculty and Staff; Students sponsored by a faculty or staff member|$240 / per year|\n[Gemini Web App] |Google's AI that handles text, voice, and files.|Meeting summaries, working with Google Apps, and searching across formats.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n[Microsoft Copilot Chat] |AI support for Office tasks, images, and code.|Microsoft files, documents, and coding help.|Students, Faculty, and Staff|Available with your Andrew account.|\n[NotebookLM] |Creates AI-powered notebooks from uploads.|Organizing ideas, summarizing sources, and creating podcasts.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n[Zoom AI Companion] |Adds summaries and action items to meetings.|Real-time help during virtual meetings.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n**Note:**Available add-ons for protected AI tools have been thoroughly reviewed and vetted for use at CMU. For example, ChatGPT Edu with[Agents] is already available to paid ChatGPT Edu subscribers.\n* [About] \n* [Computing Services InfoCenter] \n* [CSS Awards and Recognition] \n* [News] \n* [Service Status] \n[Log In to Services] \n* [Computing Services Help Center] \n* [412-268-4357 (HELP)] \n* [it-help@cmu.edu]",
    "length": 2961,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "What is Responsible AI Use? | Tepperspectives",
    "url": "https://tepperspectives.cmu.edu/all-articles/what-is-responsible-ai-use/",
    "text": "What is Responsible AI Use? | Tepperspectives\n[Skip to main site navigation] [Skip to main content] \n[![Carnegie Mellon University logo]] [![Tepper School of Business logo]![Tepper School of Business logo]] Reveal the site navigation\nOpen the search panel\nSearch Site\n* [About] \n* [Contact Us] \nDiscover More\n* [Tepper School of Business] \n* [Carnegie Mellon University] \n# What is Responsible AI Use?\nIn the latest Tepperspectives Video, Tepper School researchers Taya Cohen and Sofía Rodríguez Chaves look at how ethics and moral character influence responsible AI use in the absence of policy or regulations.\n[![A conversation with Taya Cohen and Sofia Rodriguez-Chaves] View Image] \n* Author(s)\nEmily DeJeu\n* Published\nDecember 17, 2025\n* Read Time\n2 minutes\n* Topic\n* [Artificial Intelligence] \n* [Ethics] \nShare this\nFacebookTwitterLinkedInBlueskyThreadsRedditEmail\n\\ \\ \\ What is Responsible AI Use? | RSS.com\\ \n[![Embedded YouTube video]] \nWith regulations changing and AI policy in the United States in flux, it is more important than ever for individual employees and managers to reflect on how to use AI for business responsibly. Tepper School researchers Taya Cohen and Sofia Rodriguez Chaves are investigating what it means to take a human-driven approach to AI for business. The question is no longer about whether to use AI, but how, and with what level of automation. When rules are relaxed and policies unclear, workers rely on their moral character to shape decisions about AI use.\n### ![A portrait of Sofía Rodríguez ChavesPh.D. Student, Tepper School of Business] Sofía Rodríguez Chaves\nPh.D. Student, Tepper School of Business![A portrait of Taya Cohen, Professor of Organizational Behavior and Business Ethics] Taya Cohen, Professor of Organizational Behavior and Business Ethics\n## Related Articles\n[]![AI and Transactive Memory Systems] \n### [AI and Transactive Memory Systems] \nTepper School doctoral student Pim Assavabhokhin speaks with Professor Emily DeJeu about how AI can enhance short-term decision accuracy and transactive memory systems to improve team speed, but over-reliance on technology can create a dependency.\n[]![Illustration of arrows] \n### [Is Entropy the New Key to Accounting?] \nTepper School researchers introduce Accounting Classification Entropy, a novel measure derived from information theory that quantifies the structural information in corporate financial reports, which is proven to be significantly associated with stock returns, trading volumes, and financial analysts' resource allocation.\n[]![Is AI Taking Jobs or Making them Easier] \n### [Is AI Taking Jobs or Making Them Easier?] \nTepper School faculty members Emily DeJeu and Brandy Aven discuss the future of artificial intelligence in the world of work.\n[Explore all Articles]",
    "length": 2789,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Explore Generative Artificial Intelligence (AI) at CMU",
    "url": "https://www.cmu.edu/ai-daily/index.html",
    "text": "Generative Artificial Intelligence (AI) - Computing Services - Office of the CIO - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[Computing Services] ## [Office of the CIO] \n[Office of the CIO] &#160;&#8250;&#160;[Computing Services] &#160;&#8250;&#160;[Services] &#160;&#8250;&#160; Generative Artificial Intelligence (AI)\n# Explore Generative Artificial Intelligence (AI) at CMU\nGenerative AI (GenAI) helps you create text, images, music, and videos, just by describing what you need. These tools can support your learning, creativity, and work across many roles at CMU. Explore our resources below to learn the basics and get familiar with the tools available to you. Then, dive into building more advanced skills.\n## [Learn and Connect] \nDiscover campus AI events, topic-based communities, and other learning opportunities.\n## [Protected&#160;AI Tools] [] \nLearn about the AI tools that are safe to use within CMU&#8217;s environment.\n## [Use AI Safely at CMU] \nLearn how to use AI safely and ethically, following CMU&#8217;s policies and guidelines.\n* [About] \n* [Computing Services InfoCenter] \n* [CSS Awards and Recognition] \n* [News] \n* [Service Status] \n[Log In to Services] \n* [Computing Services Help Center] \n* [412-268-4357 (HELP)] \n* [it-help@cmu.edu]",
    "length": 1342,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Protected AI Tools You Can Use",
    "url": "https://www.cmu.edu/computing/services/ai/meet-ai/tools/chatgpt/chat-gpt-how-to.html",
    "text": "Protected AI Tools You Can Use - Computing Services - Office of the CIO - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[Computing Services] ## [Office of the CIO] \n[Office of the CIO] &#160;&#8250;&#160;[Computing Services] &#160;&#8250;&#160;[Services] &#160;&#8250;&#160;[Generative Artificial Intelligence (AI)] &#160;&#8250;&#160; Protected AI Tools You Can Use\n# ![] \nProtected AI Tools You Can Use\nThe AI tools listed on this page are available at CMU. When you sign in with your Andrew ID and password, each tool is FERPA-compliant and will not use your data to train its AI models.\n## Interested in New Tools?\nAI tools that have not yet been reviewed or licensed by CMU might not offer the same data protections and approved services.&#160;\nSubmit a[software request] for review and approval.\n# Use AI Safely at CMU\nBefore using CMU's protected AI tools, please review our[policies and guidelines for safe and ethical use].\n# DAO Accessibility Tools\nExplore[tools endorsed by the Digital Accessibility Office] that have AI capabilities.\n# Approved AI Tools\n## [AI Gateway] \n## [ChatGPT Edu] \n## [Gemini Web App] \n## [Microsoft Copilot] \n## [NotebookLM] \n## [Zoom AI Companion] \n## Tool Comparison Table\n|Tool|Purpose|Best For|Available To|Cost|\n[AI Gateway] |AI Developer tool makes AI models easier to access.|Accessing&#160; management to models via API keys.|Faculty and Staff|No cost; however an Oracle String is required to pass on any costs incurred from using a model endpoint.&#160;|\n[ChatGPT Edu] |Synthesizes info, summarizes, and generates content.|Research, writing, and problem-solving.|Faculty and Staff; Students sponsored by a faculty or staff member|$240 / per year|\n[Gemini Web App] |Google's AI that handles text, voice, and files.|Meeting summaries, working with Google Apps, and searching across formats.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n[Microsoft Copilot Chat] |AI support for Office tasks, images, and code.|Microsoft files, documents, and coding help.|Students, Faculty, and Staff|Available with your Andrew account.|\n[NotebookLM] |Creates AI-powered notebooks from uploads.|Organizing ideas, summarizing sources, and creating podcasts.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n[Zoom AI Companion] |Adds summaries and action items to meetings.|Real-time help during virtual meetings.|Students, Faculty, Staff, and Sponsored|Available with your Andrew account.|\n**Note:**Available add-ons for protected AI tools have been thoroughly reviewed and vetted for use at CMU. For example, ChatGPT Edu with[Agents] is already available to paid ChatGPT Edu subscribers.\n* [About] \n* [Computing Services InfoCenter] \n* [CSS Awards and Recognition] \n* [News] \n* [Service Status] \n[Log In to Services] \n* [Computing Services Help Center] \n* [412-268-4357 (HELP)] \n* [it-help@cmu.edu]",
    "length": 2961,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "CMU partners",
    "url": "https://engineering.cmu.edu/mfi/partnerships/cmu-partners.html",
    "text": "CMU partners\n[Skip to Content] \n[![Manufacturing Futures Initiative]] \nMenu\nSearch\nSearchSearch\n* [Home] \n* [Partnerships] \n# CMU partners\n* [Partnerships] \n* [Mill 19 partners] \nMFI&#8217;s mission to inspire, engineer, and lead technological and workforce advances for agile, intelligent, efficient, resilient, and sustainable manufacturing is shared by its many partners throughout Carnegie Mellon University.\n![Next Manufacturing logo] \n#### Next Manufacturing Center\n[The Next Manufacturing Center] &#160;is a leading research center for additive manufacturing (AM), commonly known as 3-D printing. The center leverages the engineering and data science expertise from across Carnegie Mellon University to develop new approaches for design optimization, materials development and characterization, process parameter selection, and parts qualification and certification.\n![Robotics Institute logo] \n#### The Robotics Institute\n[The Robotics Institute] &#160;was established in 1979 to conduct basic and applied research in robotics technologies relevant to industrial and societal tasks. The institute facilities include approximately 100,000 square feet at the main Pittsburgh campus and 100,000 square feet at the National Robotics Engineering Center in Lawrenceville. While much of their research work focuses on core robotics technologies like manipulation, locomotion, and control, they also focus on related research areas, including machine learning, computer vision, and graphics.\n![CyLab logo] \n#### CyLab\n[CyLab] is Carnegie Mellon University&#8217;s security and privacy research institute. Housed in the 25,000+ sq. ft. Collaborative Innovation Center, Cylab brings together experts from all schools across the University, encompassing the fields of engineering, computer science, public policy, information systems, business, humanities, and social sciences. CyLab researchers are often called upon by government leaders to provide expertise on security and privacy issues. Their work in helping shape public policy related to security and privacy spans several decades.\n![CISR logo] \n#### Center for Iron and Steelmaking Research\nThe[Center for Iron and Steelmaking Research] (CISR) is devoted to education and research related to ironmaking, steelmaking, and metals processing. It is housed within the[Department of Materials Science] at Carnegie Mellon University.\n![CMU Block Center logo] \n#### The Block Center for Technology and Society\nThe[Block Center] focuses on how emerging technologies, such as artificial intelligence, robotics, machine learning, and advanced manufacturing, will alter the future of work, including how they can be harnessed for social good and how innovation in these spaces can be more inclusive and generate targeted, relevant solutions that reduce inequality and improve quality of life for all.\n![CAPD logo] \n#### Center for Advanced Process for Decision-making\nThe[CAPD] is a Carnegie Mellon University research center engaged in process systems engineering research for the process industries. CAPD is developing advanced computer-based techniques for process synthesis, control, and optimization; planning and scheduling; energy systems; and molecular computing.\n![CONIX logo] \n#### CONIX Research Center\n[CONIX] aims to provide a new middle tier of distributed computing that tightly couples the cloud and edge by pushing increased levels of autonomy and intelligence into the network. Led by[Anthony Rowe], the Computing on Network Infrastructure for Pervasive Perception, Cognition, and Action Research Center&#8212;CONIX&#8212;works toward improving Internet of Things (IoT) networks.",
    "length": 3642,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Key Initiatives - Office of the Vice Provost for Teaching and Learning Innovation - Carnegie Mellon University",
    "url": "https://www.cmu.edu/tli-office/key-initiatives/index.html",
    "text": "Key Initiatives - Office of the Vice Provost for Teaching and Learning Innovation - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[Office of the Vice Provost for Teaching and Learning Innovation] \n[Office of the Vice Provost for Teaching and Learning Innovation] &#160;&#8250;&#160; Key Initiatives\n# Key Initiatives\n## [Core Competencies Initiative(CCI)] \nA CMU initiative that leverages faculty expertise, educational technology, the holistic student experience, and multi-faceted data integration to help our teaching and learning community provide opportunities for students to develop their skills in several core competencies.\n![] \n![] \n## [CMU Online] \nOnline, graduate-level certificate programs taught by world-class CMU faculty and featuring a rich, interactive online experience with weekly live-online classes. CMU Online graduate-level programs provide learners &#8211; many of them working professionals across the U.S. &#8211; the same quality and rigor you&#8217;d expect from CMU.\n## Generative AI + Education\nMulti-faceted set of programs, activities, and resources aimed at raising awareness about generative AI and supporting the responsible, judicious, and effective use of AI tools in education. This work includes[instructional modules] on generative AI (targeted to students in their role as learners), a[faculty seed grant program] for new tool research and development, and[support for studying generative AI&#8217;s impacts] on students&#8217; learning outcomes and experiences.\n![]",
    "length": 1586,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Commonwealth Project",
    "url": "https://www.cmu.edu/block-center/responsible-ai/commonwealth-project",
    "text": "[Skip to main content] \n\nThe Commonwealth Project\n\n# Commonwealth Project\n\n## Pennsylvania AI Governance Initiative\n\nThe Block Center for Technology and Society at Carnegie Mellon University is collaborating with the Commonwealth of Pennsylvania to support the responsible implementation of generative AI technologies in state government operations.\n\n### Background\n\nIn September 2023, Governor Josh Shapiro signed Executive Order 2023-19, establishing priorities for the use of generative AI in commonwealth agencies. This order created a GenAI Governance Board to oversee the adoption of these technologies. The Block Center was named as a key thought partner in this initiative.\n\n### Our Approach\n\nThe Block Center is providing expertise and guidance through three main channels:\n\n- **Educational Workshops:** Raising awareness and understanding of GenAI capabilities among Governance Board members.\n- **Strategic Consultation:** Regular engagement with the Director of Emerging Technologies to support implementation efforts.\n- **Research Support:** Facilitating graduate student research projects to inform the state's AI strategy.\n\n### Key Activities\n\n#### Educational Workshops\n\nWe have conducted workshops on fundamental AI concepts, privacy and security concerns, and AI governance through procurement processes. These sessions feature expert faculty and allow for in-depth Q&A with Governance Board members.\n\n#### Ongoing Consultation\n\nOur team meets monthly with the Director of Emerging Technologies to:\n\n- Plan activities and identify areas for faculty support\n- Discuss the OpenAI Pilot Program implementation\n- Connect key stakeholders with CMU expertise\n\n#### Graduate Research\n\nA team of Heinz School students completed a systems synthesis project for the Office of Administration, which included:\n\n- Benchmarking Pennsylvania's GenAI goals against neighboring states\n- Developing a tool to scope problems and identify appropriate AI solutions\n\n### Future Initiatives\n\nAs we move forward, we are proposing several new activities:\n\n- **AI Readiness Conference:** A 1.5-day event in Harrisburg covering key topics for government AI adoption\n- **CMU AI Readiness Toolkit:** Consolidating CMU-developed tools to support AI implementation\n- **Annual State Government AI Index:** Expanding our benchmarking research to all 50 states\n- **Policy Problem Use-Cases:** Piloting the AI Readiness Toolkit process on 2–3 state government challenges\n\n### Impact\n\nThis partnership aims to:\n\n- Enhance the efficiency and effectiveness of state government services\n- Ensure the responsible and ethical use of AI technologies\n- Position Pennsylvania as a leader in government AI adoption\n\nBy combining CMU's technical expertise with Pennsylvania's governance needs, we are working to create a model for responsible AI implementation in the public sector.",
    "length": 2853,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Generative AI & Large Language Models",
    "url": "https://www.cmu.edu/online/gai-llm/index.html",
    "text": "CMU's Online Graduate Certificate in Generative AI &amp; Large Language Models - Online Education - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n# Generative AI &amp; Large Language Models\nOnline Graduate Certificate\n**[Curriculum] **\n**[Online Experience] **\n**[Admissions] **\n**[TUITION] **\n# **GenAI is Transforming the World**\n## What will*you*create with it?\nGenerative AI has already revolutionized the world and it&#8217;s not slowing down. As a trained computer scientist, if you want to contribute to the revolution of Generative AI, and make an immediate impact in your organization,*now*is the time to enhance your expertise.&#160;&#160;\n### A training ground for Generative AI&#160;\nIn Carnegie Mellon&#8217;s new Generative AI and Large Language Models graduate certificate, offered by CMU&#8217;s nationally-ranked School of Computer Science, you will learn the latest and most advanced techniques in Generative AI, large language models and multimodal machine learning from expert faculty at the forefront of computer science research.\n*This is not your average online certificate program.*The coursework covers complex topics that build on expertise in applied mathematics, programming, machine learning and deep learning.\nBy the end of this certificate, you will be prepared to build customized applications of Generative AI. You will learn how to&#160;design and implement scalable systems for large language models, evaluate and choosebetween existing models, do customization via finetuning, and leverage multimodal machine learning through integrating and modeling multiple communicative modalities (e.g. audio, images, and video).\nMore than theory, this program takes a hard-core systems approach by giving you not only the technical skills but the ability to implement and scale solutions based on your unique organizational needs and resources. Here you will gain the depth, breadth and practical skills to apply this technology immediately.\nOur advanced program will teach you how to:\n* Implement state-of-the-art language models such as GPT and LLaMA from scratch.\n* Compare and contrast different models andapproachesin order to determine the best setup for tasks you care about.\n* Perform model training and inference using popular frameworks such as HuggingFace.\n* Design and run generative AI systems on high performance computer infrastructure using tools like SLURM.&#160;&#160;\n* Understand and be able to apply algorithms and system techniques to efficiently train LLMs with huge datasets, including efficient fine-tuning and reinforcement learning with human feedback, acceleration on GPU and other hardware, model compression for deployment, and online system maintenance.\n* Implement multimodal systems such as audio-visual speech recognition, image generation, and video captioning&#8212;addressing challenges in (1) multimodal representation learning, (2) translation and mapping between modalities, (3) modality alignment, (4) multimodal fusion and (5) co-learning.### A powerful certificate. Conveniently offered.\nThe Graduate Certificate in Generative AI and Large Language Models is offered[100% online] to accommodate your busy schedule as a working professional. Along with weekly, live-online interactive classes taught by expert CMU faculty, you will complete hands-on learning activities on your own time that complement the discussions you have in class. To earn the certificate, you will complete three rigorous CMU classes over a 12-month period.\n### For computer science pioneers\nThis certificate program is best suited for:\n* **Industry professionals****working in computer science, data science, software engineering or a similar field**who want to enhance their domain knowledge with expertise in Generative AI and large language models so they can build new and innovative solutions for the future.&#160;&#160;\n* **Recent college graduates****with a degree in computer science, data science, software engineering or a similar field**who want to gain in-depth, state-of-the-art knowledge about Generative AI and large language models to enhance their skills, make an immediate impact in their organization, and stay competitive in the job market.&#160;\n# At a Glance\n**Next Start Date**\nFall 2026\nPriority Deadline\\*: March 4, 2026\n\\*All applicants who submit by the priority deadline will receive a partial scholarship award.\n**Program Length**\n12 months\n**Program Format**\n100% online\n**Live-Online Schedule**\n1x per week for one hour in the evening with a second optional one-hour weekly recitation session.\n**Taught By**\nSchool of Computer Science\n**[Request Information] **\n**[Apply Now] **\nQuestions? There are two ways to contact us. Call412-501-2686&#160;or send an email to&#160;[apply@online.cmu.edu] &#160;with your inquiries.[] \n# CMU Online Graduate Certificates\n*Below, explore more online opportunities offered by Carnegie Mellon University.*\n**[Machine Learning &amp; Data Science] \n**With a STEM undergraduate degree and Python proficiency, you can learn how to harness the power of big data in this certificate offered by the School of Computer Science.\n**[Foundations of Data Science] **\nDesigned for individuals with non-technical backgrounds, this certificate from the Dietrich College of Humanities &amp; Social Sciences can help you make data-driven decisions in the workplace.\n[**AI Engineering Fundamentals**] \nHave a mechanical engineering degree, a familiarity with Python and an eagerness to design next-generation solutions? This program from the College of Engineering could be for you.\n[**AI Engineering for Digital Twins &amp; Analytics**] \nLearn how to lead the implementation of AI + Digital Twins for your organization from world-renowned experts in CMU's College of Engineering.\n[**Managing AI Systems**] \nIf you are interested in driving the adoption of AI in your organization, then this program from the Heinz School of Public Policy is for you. No technical expertise is required for admission.\n# On-Campus Degree\nInterested in the**on-campus**Master of Science degree in Computational Data Science offered by CMU's School of Computer Science? Visit the[program website] &#160;for more details.\n# 2026 U.S. News &amp; World Report Rankings\n## #1 in the Nation\nFor CMU's AI graduate programs\n![blue abstract background with neural networks] \n## #1 in the Nation\nFor CMU's programming languages courses\n![binary code background] \n## #2 in the Nation\nFor CMU's computer science graduate programs\n![building on cmu's campus with rainbow bridge in front]",
    "length": 6622,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Copilot Arena Helps Rank Real-World LLM Coding Abilities",
    "url": "https://www.cs.cmu.edu/news/2025/copilot-arena",
    "text": "Copilot Arena Helps Rank Real-World LLM Coding Abilities\n# [![] Carnegie Mellon University School of Computer Science] \n[Skip to Main Content] Search**\nSearch**\n# Copilot Arena Helps Rank Real-World LLM Coding Abilities\nCharlotte HuTuesday, April 22, 2025[**Print this page.] \n![] With so many AI coding assistants out there, it can be hard to keep track of ones that perform well on real-world tasks. CMU researchers developed Copilot Arena to do just that by crowdsourcing user ratings of LLM-written code.\nWith so many AI coding assistants out there, it can be hard to keep track of ones that perform well on real-world tasks. To help analyze which leading or emerging code-writing large language models (LLMs) the developer community prefers, researchers at Carnegie Mellon University developed[Copilot Arena], a platform that crowdsources user ratings of LLM-written code.\nAI coding assistants that can generate code on their own can make a difficult and time-consuming process easier and faster. However, even the slightest error &#8212; to which AI coding assistants can be prone &#8212; could derail an entire project.\nCopilot Arena has been downloaded more than 11,200 times since launching in September and has provided more than 4.5 million suggestions to users of 10 models. The tool has around 500 daily users and more than 3,000 unique users overall.\nValerie Chen and Wayne Chi, graduate students in CMU's School of Computer Science, co-led the development of Copilot Arena. They developed the tool in partnership with the creators of Chatbot Arena, a similar LLM-ranking platform that[predicted the rising popularity of DeepSeek] before it went mainstream. The team published the first set of findings from the platform in the[preprint journal arXiv], in a[blog post] on the Copilot Arena website, and on Carnegie Mellon's[Machine Learning Blog].\nThe team believes free, open-source tools like Copilot Arena are important for model developers trying to improve their AI coding assistants in a way that benefits actual users.\nThe setup is simple. Software developers using Visual Studio Code (VS Code) can download and access the Copilot Arena extension while they work. They can ask Copilot Arena to help them with a certain section of code, and Copilot Arena offers two options to choose from without telling the user which LLMs provided the responses. The LLMs are then ranked on the backend based on how frequently users chose their outputs.\n\"User votes help build this leaderboard of which models are best for coding applications and also give us insights into how people are interacting with these kinds of AI tools,\" said Chen, a Ph.D. student in the[Machine Learning Department].\nThe AI models they've tested include ones from Google's Gemini, DeepSeek, Anthropic's Claude, OpenAI's GPT models, Meta's Llama, Qwen from Alibaba Cloud, and Codestral from Mistral AI. New models are added into the platform as they're released.\n\"We've also got a lot of interest from people building these code-generation models. Recently, a startup named Inception Labs created a new model called Mercury Coder,\" said Chi, a Ph.D. student in the[Computer Science Department]. \"They reached out to us so they could test their model on our platform. This was an unreleased model at the time, and they wanted to demonstrate that their model was fast and of good quality.\"\nDeepSeek and Claude's Sonnet currently sit atop the leaderboard. Chi noted that this parallels what developers in online communities have said are their favorite models to use for coding.\nDuring their research, the CMU team found that Copilot Arena's top-performing models differed from existing evaluation approaches. The existing approaches are based on static benchmarks, like simple functional problems or tasks from Leetcode, an online platform with preset questions for coding practice, and not on the dynamics of user preference used by Copilot Arena.\nBeing able to evaluate the performance of AI coding models while users are working on real-world problems has allowed the Copilot Arena team to perform a more detailed analysis of the areas where specific models have an advantage and where they may fall short. For example, many existing benchmarks tend to test AI models on short problems, meaning there are only a few lines of existing code or no code at all. But that's not indicative of what happens in the real world.\n\"In practice, when people write code, they might keep everything in one big file. Models have to be able to handle that,\" Chen said. \"We see that models like DeepSeek tend to be better at that than smaller models like Qwen.\"\nAs another example, Chi said that Claude's Sonnet performs better than other models at front-end tasks like website development and back-end tasks like data and infrastructure management.\n\"Evaluation is probably the most important problem in all of machine learning right now,\" said[Ameet Talwalkar], a machine learning professor at CMU and an adviser on the project. \"You want to evaluate these models in the most realistic settings possible. You also want to be scalable.\"\nFor the better part of the last two decades, computer scientists worked mostly on classification problems, like whether a cat appeared in an image. These problems are hard for computers but easy to evaluate, Talwalkar said. People simply need to manually annotate whether there is a cat in the image and compare it to the model's prediction.\n\"Now we're asking models to do these incredibly complicated things and, for coding in particular, evaluation is hard,\" he said.\nCopilot Arena tries to capture rigorous, realistic interactions between AI models and human developers in a way that can also be scaled across multiple users and use cases, Talwalkar said. \"It has a lot of value.\"\nOn top of evaluating models, tools like Copilot Arena may help researchers study the changing nature of programming.\n\"We are in the middle of a dramatic pivot from developers writing code manually to AI assistance being ubiquitous,\" said Chris Donahue, an assistant professor in CSD and an adviser on the project. \"Not only does Copilot Arena help us better understand the implications of this shift for downstream aspects of code like reliability, security and maintainability, but it also allows us to study the fundamental shift in human and computer agency in programming.\"\nThe tool itself is a work in progress. Chen and Chi plan to expand the set of features available on the Copilot Arena platform to accommodate code editing and agentic systems.\n**For More Information**\nAaron Aupperlee | 412-268-9068 | aaupperlee@cmu.edu",
    "length": 6618,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Using AI to Create Alternative Formats and Compliant Content",
    "url": "https://www.cmu.edu/computing/news/2025/ai-compliant-content.html",
    "text": "_November 26, 2025_\n\n# Using AI to Create Alternative Formats and Compliant Content\n\n## AI as an Accessible Content Assistant\n\nAs highlighted in earlier articles, the [Digital Accessibility Office] supports the thoughtful use of AI to help lower barriers to digital access. When applied responsibly and paired with human judgment, AI can be a valuable tool for understanding accessibility principles, improving existing materials, and creating alternative formats that make information more accessible to everyone.Producing content in multiple formats—text, audio, simplified language, summaries, and structured outlines—supports a broader range of users and contexts.\n\n## Podcast and Video Overview Created by NotebookLM\n\nThe podcast and video below were generated with [NotebookLM] using the three articles in this series as the source. There is currently no editing functionality for NotebookLM videos and podcasts, which limits the output significantly, but these formats may still serve as valuable alternatives when an overview of the concepts is sufficient. _**Please note that these formats contain some inaccuracies in pronunciation and may not accurately express all intended information. They are intended only as imaginative ways to review and repurpose information.**_\n\n[Podcast] [Video] NotebookLM also offers interactive podcasts for invited audiences, so you can choose to interrupt the podcasters and ask a question about the content. It’s an engaging and interactive format that may work well for certain types of content with a limited audience. If you’d like to access the interactive version of this podcast, please email [digital-access@cmu.edu] for an invitation.\n\n## AI and Automation Tools for Alternative Format Generation\n\nCarnegie Mellon University provides access to [protected tools], including Google Gemini, NotebookLM, and ChatGPT Edu, all of which are capable of supporting access through the creation of digital content in multiple formats.\n\n| | | |\n| --- | --- | --- |\n| #### Tool | #### Best accessibility use case | #### Specific functions |\n| **ChatGPT Edu** | Reimagining existing content for diverse audiences | Rewriting complex academic texts into plain language versions, producing audio script generation, and suggesting alternative formats. |\n| **Google Gemini** | Supporting multimodal content creation | Converting written content for translations; generating visual summaries or infographic outlines; creating alternative reading levels (academic, intermediate, and plain language). |\n| **Grackle Extension** | Creating accessible downloads from Google Workspace | Auto-checking your Google Docs, Slides, and Sheets for accessibility errors and generate tagged PDF downloads. |\n| **Microsoft Office Integrated Accessibility Tool** | Integrated support across the Microsoft suite | Document reformatting (adding proper heading structure, alt text, and logical reading order); generating speaker notes or captioned scripts for presentation narration; creating readable summaries into screen-reader-friendly text. |\n| **NotebookLM** | Converting written materials into alternative learning formats | Generating podcasts and audio summaries from notes; creating video or script creation outlines; producing simplified study materials or outlines from complex readings. |\n| **SiteImprove AI** | Ensuring quality and compliance of content | AI Generate can rewrite text to improve readability and inclusiveness while maintaining accuracy and tone. This is the ideal tool for search engine-optimized content. |\n| **UDOIT** | Course content in the Canvas LMS | Converting content from document formats into Canvas pages and can help to review and optimize course content for accessibility. |\n\n## Best Practices and Cautions for Responsible AI\n\n- **Accuracy:** Users must always review AI output because errors and “hallucinations” can occur.\n- **Context:** AI may misinterpret the intended purpose or audience for a given article or image. Creators must refine and expand prompts for clarity.\n- **Bias:** Because models can reflect stereotypes or limited perspectives, users should request inclusive language and diverse representation when prompting them.\n- **Privacy:** Users must not upload sensitive or personally identifiable information. Please review CMU’s policies and guidelines for the safe and ethical use of AI.\n- **Oversight:** All AI-generated materials must align with CMU’s accessibility standards and policies.\n\n## Other Articles in this Series\n\n- [AI and the Future of Accessibility] \n- [AI for Accessibility Remediation] \n\n- [About] \n- [Computing Services Intranet] \n- [CSS Awards and Recognition] \n- [News] \n- [Service Status] \n\n[Log In to Services] \n\n- [Computing Services Help Center] \n- [412-268-4357 (HELP)] \n- [it-help@cmu.edu]",
    "length": 4793,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Signature Initiative: Collaborative AI - Tepper School of Business - Carnegie Mellon University",
    "url": "https://www.cmu.edu/tepper/the-intelligent-future/strategic-plan/signature-initiative.html",
    "text": "Signature Initiative: Collaborative AI | Tepper School of Business[Skip to main content] \n[] \n[Tepper School of Business] \nWhat can we help you find?\nPopular Searches\n* [What are options for individual programs?] \n* [What is an Online Hybrid MBA?] \n* [Who can I hire?] \n# Signature Initiative: Collaborative AI\nDrawing on its deep expertise at the intersection of technology, analytics, and business, the Tepper School will apply Collaborative AI —an integrated simulation of complex human and system behavior —to transform business education and research.\n![] \nTRANSFORMING BUSINESS EDUCATION\n* Using Collaborative AI, we will harness collaborative AI to**reshape business education away from the traditional case study model and toward true-to-life simulation and personalized learning.**\n* By**integrating collaborative AI across the curriculum**— with holistic projects spanning areas from accounting and finance to marketing and organizational behavior —our faculty will provide students with a strong foundation on which to build the tools of tomorrow and gain a competitive advantage.\n* We will help emerging and experienced leaders to**understand how to recast the role of the manager in an AI age**, by harnessing AI to amplify, not replace, human connections and ideas.\nTRANSFORMING RESEARCH\n* Our researchers will dive into the most difficult, complex problems facing businesses today by leveraging Collaborative AI to**generate and test new solutions and drive methodological advances across all business disciplines.**\n* We will**collaborate with world-class experts from across Carnegie Mellon University working alongside industry partners**to grapple with the economic, societal, and ethical implications of generative AI.\n* We will cultivate new hubs of innovation, such as the Center for Intelligent Business to enable**better decision-making, optimization, and innovation across all areas of business**through applications of collaborative AI.",
    "length": 1962,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Generative AI",
    "url": "https://guides.library.cmu.edu/generative-ai",
    "text": "Home - Generative AI - CMU LibGuides at Carnegie Mellon University[Skip to Main Content] [![Carnegie Mellon University Libraries]] \nSearch this GuideSearch\n# Generative AI\n* [Home] \n* [Introduction] \n* [Generative AI Glossary] \n* [What is Generative AI?] \n* [Prompt Engineering] \n* [Ethical Considerations] \n* [Citing Generative AI*This link opens in a new window*] \n* [Additional Resources] \n## Engineering Librarian\n[\n![] \nHaoyong Lan\n] \nhe/him/his\n[Email] \n**Contact:**\nSorrells 4409\n(412) 268-2443\n[Website] \n**Subjects:**[Biomedical],[CMU Campuses Outside of Pittsburgh],[Electrical & Computer],[Engineering] \n## Introduction\nThis guide introduces basic concepts of generative artificial intelligence (AI) and how it could be applied in teaching, learning, and research. It provides resources related to prompt engineering techniques which are key to effective human-generative AI interaction. The guide also offers guidance on using generative AI ethically and how to cite AI-generated content. Additional resources include CMU guidelines and learning materials related to generative AI.\n[![&quot;CMU mascot Scotty is reading a book with a computer in the library&quot; generated by Gemini]] \n## Generative AI Glossary\n**Auto-Regressive Model**: &quot;A model that infers a prediction based on its own previous predictions. For example, auto-regressive language models predict the next token based on the previously predicted tokens. All Transformer-based large language models are auto-regressive.&quot;\n**Chain-of-Thought Prompting:**&quot;A prompt engineering technique that encourages a large language model (LLM) to explain its reasoning, step by step.&quot;\n**Chat:**&quot;The contents of a back-and-forth dialogue with an ML system, typically a large language model. The previous interaction in a chat (what you typed and how the large language model responded) becomes the context for subsequent parts of the chat.&quot;\n**Contextualized Language Embedding:**&quot;An embedding that comes close to &quot;understanding&quot; words and phrases in ways that native human speakers can. Contextualized language embeddings can understand complex syntax, semantics, and context.&quot;\n**Context Window:**&quot;The number of tokens a model can process in a given prompt. The larger the context window, the more information the model can use to provide coherent and consistent responses to the prompt.&quot;\n**Distillation:**&quot;The process of reducing the size of one model (known as the teacher) into a smaller model (known as the student) that emulates the original model&#39;s predictions as faithfully as possible.&quot;\n**Few-Shot Prompting:**&quot;A prompt that contains more than one (a &quot;few&quot;) example demonstrating how the large language model should respond.&quot;\n**Fine Tuning:**&quot;A second, task-specific training pass performed on a pre-trained model to refine its parameters for a specific use case.&quot;\n**Instruction Tuning:**&quot;A form of fine-tuning that improves a generative AI model&#39;s ability to follow instructions. Instruction tuning involves training a model on a series of instruction prompts, typically covering a wide variety of tasks. The resulting instruction-tuned model then tends to generate useful responses to zero-shot prompts across a variety of tasks.&quot;\n**Low-Rank Adaptability:**&quot;An algorithm for performing parameter efficient tuning that fine-tunes only a subset of a large language model&#39;s parameters.&quot;\n**Model Cascading:**&quot;A system that picks the ideal model for a specific inference query.&quot;\n**Model Router:**&quot;The algorithm that determines the ideal model for inference in model cascading. A model router is itself typically a machine-learning model that gradually learns how to pick the best model for a given input. However, a model router could sometimes be a simpler, non-machine learning algorithm.&quot;\n**One-shot prompting:**&quot;A prompt that contains one example demonstrating how the large language model should respond.&quot;\n**Parameter-Efficient Tuning:**&quot;A set of techniques to fine-tune a large pre-trained language model (PLM) more efficiently than full fine-tuning. Parameter-efficient tuning typically fine-tunes far fewer parameters than full fine-tuning, yet generally produces a large language model that performs as well (or almost as well) as a large language model built from full fine-tuning.&quot;\n**Pre-Trained Model:**&quot;Models or model components (such as an embedding vector) that have already been trained.&quot;\n**Pre-Training:**&quot;The initial training of a model on a large dataset.&quot;\n**Prompt:**&quot;Any text entered as input to a large language model to condition the model to behave in a certain way.&quot;\n**Prompt-based Learning:**&quot;A capability of certain models that enables them to adapt their behavior in response to arbitrary text input (prompts).&quot;\n**Prompt Engineering:**&quot;The art of creating prompts that elicit the desired responses from a large language model.&quot;\n**Prompt Tuning:**&quot;A parameter efficient tuning mechanism that learns a &quot;prefix&quot; that the system prepends to the actual prompt.&quot;\n**Reinforcement Learning from Human Feedback:**&quot;Using feedback from human raters to improve the quality of a model&#39;s responses.&quot;\n**Role Prompting:**&quot;An optional part of a prompt that identifies a target audience for a generative AI model&#39;s response.&quot;\n**Soft Prompt Tuning:**&quot;A technique for tuning a large language model for a particular task, without resource-intensive fine-tuning. Instead of retraining all the weights in the model, soft prompt tuning automatically adjusts a prompt to achieve the same goal.&quot;\n**Temperature:**&quot;A hyperparameter that controls the degree of randomness of a model&#39;s output. Higher temperatures result in more random output, while lower temperatures result in less random output.&quot;\n**Zero-Shot Prompting:**&quot;A prompt that does not provide an example of how you want the large language model to respond.&quot;\nDefinitions from GoogleGenerative AI Glossary:\n*Machine Learning Glossary: Generative AI*.Google for Developers. Retrieved May 10, 2024, from[https://developers.google.com/machine-learning/glossary/generative] \n* * [**Next:**What is Generative AI? &gt;&gt;] \n* Last Updated:Mar 13, 2025 12:57 PM\n* URL:https://guides.library.cmu.edu/generative-ai\n* [**Print Page] \n[Login to LibApps] \n[Report a problem] \nSubjects:[Computer Science],[Digital Scholarship] \nTags:[artificial intelligence],[Generative AI],[prompt engineering] \n[****]",
    "length": 6624,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Generative AI & Large Language Models",
    "url": "https://www.cmu.edu/online/gai-llm/",
    "text": "CMU's Online Graduate Certificate in Generative AI &amp; Large Language Models - Online Education - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n# Generative AI &amp; Large Language Models\nOnline Graduate Certificate\n**[Curriculum] **\n**[Online Experience] **\n**[Admissions] **\n**[TUITION] **\n# **GenAI is Transforming the World**\n## What will*you*create with it?\nGenerative AI has already revolutionized the world and it&#8217;s not slowing down. As a trained computer scientist, if you want to contribute to the revolution of Generative AI, and make an immediate impact in your organization,*now*is the time to enhance your expertise.&#160;&#160;\n### A training ground for Generative AI&#160;\nIn Carnegie Mellon&#8217;s new Generative AI and Large Language Models graduate certificate, offered by CMU&#8217;s nationally-ranked School of Computer Science, you will learn the latest and most advanced techniques in Generative AI, large language models and multimodal machine learning from expert faculty at the forefront of computer science research.\n*This is not your average online certificate program.*The coursework covers complex topics that build on expertise in applied mathematics, programming, machine learning and deep learning.\nBy the end of this certificate, you will be prepared to build customized applications of Generative AI. You will learn how to&#160;design and implement scalable systems for large language models, evaluate and choosebetween existing models, do customization via finetuning, and leverage multimodal machine learning through integrating and modeling multiple communicative modalities (e.g. audio, images, and video).\nMore than theory, this program takes a hard-core systems approach by giving you not only the technical skills but the ability to implement and scale solutions based on your unique organizational needs and resources. Here you will gain the depth, breadth and practical skills to apply this technology immediately.\nOur advanced program will teach you how to:\n* Implement state-of-the-art language models such as GPT and LLaMA from scratch.\n* Compare and contrast different models andapproachesin order to determine the best setup for tasks you care about.\n* Perform model training and inference using popular frameworks such as HuggingFace.\n* Design and run generative AI systems on high performance computer infrastructure using tools like SLURM.&#160;&#160;\n* Understand and be able to apply algorithms and system techniques to efficiently train LLMs with huge datasets, including efficient fine-tuning and reinforcement learning with human feedback, acceleration on GPU and other hardware, model compression for deployment, and online system maintenance.\n* Implement multimodal systems such as audio-visual speech recognition, image generation, and video captioning&#8212;addressing challenges in (1) multimodal representation learning, (2) translation and mapping between modalities, (3) modality alignment, (4) multimodal fusion and (5) co-learning.### A powerful certificate. Conveniently offered.\nThe Graduate Certificate in Generative AI and Large Language Models is offered[100% online] to accommodate your busy schedule as a working professional. Along with weekly, live-online interactive classes taught by expert CMU faculty, you will complete hands-on learning activities on your own time that complement the discussions you have in class. To earn the certificate, you will complete three rigorous CMU classes over a 12-month period.\n### For computer science pioneers\nThis certificate program is best suited for:\n* **Industry professionals****working in computer science, data science, software engineering or a similar field**who want to enhance their domain knowledge with expertise in Generative AI and large language models so they can build new and innovative solutions for the future.&#160;&#160;\n* **Recent college graduates****with a degree in computer science, data science, software engineering or a similar field**who want to gain in-depth, state-of-the-art knowledge about Generative AI and large language models to enhance their skills, make an immediate impact in their organization, and stay competitive in the job market.&#160;\n# At a Glance\n**Next Start Date**\nFall 2026\nPriority Deadline\\*: March 4, 2026\n\\*All applicants who submit by the priority deadline will receive a partial scholarship award.\n**Program Length**\n12 months\n**Program Format**\n100% online\n**Live-Online Schedule**\n1x per week for one hour in the evening with a second optional one-hour weekly recitation session.\n**Taught By**\nSchool of Computer Science\n**[Request Information] **\n**[Apply Now] **\nQuestions? There are two ways to contact us. Call412-501-2686&#160;or send an email to&#160;[apply@online.cmu.edu] &#160;with your inquiries.[] \n# CMU Online Graduate Certificates\n*Below, explore more online opportunities offered by Carnegie Mellon University.*\n**[Machine Learning &amp; Data Science] \n**With a STEM undergraduate degree and Python proficiency, you can learn how to harness the power of big data in this certificate offered by the School of Computer Science.\n**[Foundations of Data Science] **\nDesigned for individuals with non-technical backgrounds, this certificate from the Dietrich College of Humanities &amp; Social Sciences can help you make data-driven decisions in the workplace.\n[**AI Engineering Fundamentals**] \nHave a mechanical engineering degree, a familiarity with Python and an eagerness to design next-generation solutions? This program from the College of Engineering could be for you.\n[**AI Engineering for Digital Twins &amp; Analytics**] \nLearn how to lead the implementation of AI + Digital Twins for your organization from world-renowned experts in CMU's College of Engineering.\n[**Managing AI Systems**] \nIf you are interested in driving the adoption of AI in your organization, then this program from the Heinz School of Public Policy is for you. No technical expertise is required for admission.\n# On-Campus Degree\nInterested in the**on-campus**Master of Science degree in Computational Data Science offered by CMU's School of Computer Science? Visit the[program website] &#160;for more details.\n# 2026 U.S. News &amp; World Report Rankings\n## #1 in the Nation\nFor CMU's AI graduate programs\n![blue abstract background with neural networks] \n## #1 in the Nation\nFor CMU's programming languages courses\n![binary code background] \n## #2 in the Nation\nFor CMU's computer science graduate programs\n![building on cmu's campus with rainbow bridge in front]",
    "length": 6622,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Explore Generative Artificial Intelligence (AI) at CMU",
    "url": "https://www.cmu.edu/ai-daily/news-and-events/index.html",
    "text": "# Explore Generative Artificial Intelligence (AI) at CMU\n\nGenerative AI (GenAI) helps you create text, images, music, and videos, just by describing what you need. These tools can support your learning, creativity, and work across many roles at CMU. Explore our resources below to learn the basics and get familiar with the tools available to you. Then, dive into building more advanced skills.\n\n## [Learn and Connect] \n\nDiscover campus AI events, topic-based communities, and other learning opportunities.\n\n## [Protected AI Tools] \n\nLearn about the AI tools that are safe to use within CMU’s environment.\n\n## [Use AI Safely at CMU] \n\nLearn how to use AI safely and ethically, following CMU’s policies and guidelines.\n\n- [About] \n- [Computing Services InfoCenter] \n- [CSS Awards and Recognition] \n- [News] \n- [Service Status] \n\n[Log In to Services] \n\n- [Computing Services Help Center] \n- [412-268-4357 (HELP)] \n- [it-help@cmu.edu]",
    "length": 931,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Academic Integrity",
    "url": "https://www.cmu.edu/policies/student-and-student-life/academic-integrity.html",
    "text": "Academic Integrity - University Policies - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[University Policies] \n[University Policies] &#160;&#8250;&#160;[Student and Student Life] &#160;&#8250;&#160; Academic Integrity\n# Academic Integrity\nPOLICY TITLE:|Carnegie Mellon University Policy on Academic Integrity|\nDATE OF ISSUANCE:|This Policy was approved by President&#8217;s Council on April 11, 2013 and eplaces the University&#8217;s Policy on Cheating and Plagiarism, which was originally issued to campus on June 16, 1980 as*Organization Announcement #297*, and then revised in 1990. Administrative updates were made on August 29, 2019; August 25, 2020; and August 15, 2024.|\nRESPONSIBLE DEPARTMENT/UNIT:|Office of the Vice President for Student Affairs. Questions on Policy content should be directed to the Office of Community Responsibility, 412-268-2140.|\nABSTRACT:|Academic credit awarded to an individual should represent the work of that individual. Therefore, students at Carnegie Mellon are expected to produce their own original academic work. Collaboration or assistance on academic work to be graded is not permitted unless explicitly authorized by the course instructor(s). The citation of all sources is required. When collaboration or assistance is permitted by the course instructor(s), the acknowledgement of any collaboration or source of assistance is likewise required. Failure to do so is dishonest and is the basis for a charge of cheating, plagiarism, or unauthorized assistance. Such charges are subject to disciplinary action.|\nRELATED INFORMATION:|For disciplinary action procedures that apply to charges of cheating, plagiarism, or unauthorized assistance, see[Academic Integrity Actions].|\nStudents at Carnegie Mellon are engaged in intellectual activity consistent with the highest standards of the academy. The relationship between students and instructors and their shared commitment to overarching standards of respect, honor and transparency determine the integrity of our community of scholars. The actions of our students, faculty and staff are a representation of our university community and of the professional and personal communities that we lead. Therefore, a deep and abiding commitment to academic integrity is fundamental to a Carnegie Mellon education. Honesty and good faith, clarity in the communication of core values, professional conduct of work, mutual trust and respect, and fairness and exemplary behavior represent the expectations for ethical behavior for all members of the Carnegie Mellon community.\n## Policy Statement\nIn any manner of presentation, it is the responsibility of each student to produce her/his own original academic work. Collaboration or assistance on academic work to be graded is not permitted unless explicitly authorized by the course instructor(s). Students may utilize the assistance provided by the Student Academic Success Center and the Academic Resource Center (CMU-Q) unless specifically prohibited by the course instructor(s). Any other sources of collaboration or assistance must be specifically authorized by the course instructor(s).\nIn all academic work to be graded, the citation of all sources is required. When collaboration or assistance is permitted by the course instructor(s) or when a student utilizes the services provided by the Student Academic Success Center and the Academic Resource Center (CMU-Q), the acknowledgement of any collaboration or assistance is likewise required. This citation and acknowledgement must be incorporated into the work submitted and not separately or at a later point in time. Failure to do so is dishonest and is subject to disciplinary action.\nInstructors have a duty to communicate their expectations including those specific to collaboration, assistance, citation and acknowledgement within each course. Students likewise have a duty to ensure that they understand and abide by the standards that apply in any course or academic activity. In the absence of such understanding, it is the student&#8217;s responsibility to seek additional information and clarification.\n## Policy Violations\n*Cheating*occurs when a student avails her/himself of an unfair or disallowed advantage which includes but is not limited to:\n1. Theft of or unauthorized access to an exam, answer key or other graded work from previous course offerings.\n2. Use of an alternate, stand-in or proxy during an examination.\n3. Copying from the examination or work of another person or source.\n4. Submission or use of falsified data.\n5. Using false statements to obtain additional time or other accommodation.\n6. Falsification of academic credentials.\n*Plagiarism*is defined as the use of work or concepts contributed by other individuals without proper attribution or citation. Unique ideas or materials taken from another source for either written or oral use must be fully acknowledged in academic work to be graded. Examples of sources expected to be referenced include but are not limited to:\n1. Text, either written or spoken, quoted directly or paraphrased.\n2. Graphic elements.\n3. Passages of music, existing either as sound or as notation.\n4. Mathematical proofs.\n5. Scientific data.\n6. Concepts or material derived from the work, published or unpublished, of another person.\n*Unauthorized assistance*refers to the use of sources of support that have not been specifically authorized in this policy statement or by the course instructor(s) in the completion of academic work to be graded. Such sources of support may include but are not limited to advice or help provided by another individual, published or unpublished written sources, and electronic sources. Examples of unauthorized assistance include but are not limited to:\n1. Collaboration on any assignment beyond the standards authorized by this policy statement and the course instructor(s).\n2. Submission of work completed or edited in whole or in part by another person.\n3. Supplying or communicating unauthorized information or materials, including graded work and answer keys from previous course offerings, in any way to another student.\n4. Use of unauthorized information or materials, including graded work and answer keys from previous course offerings.\n5. Use of unauthorized devices.\n6. Submission for credit of previously completed graded work in a second course without first obtaining permission from the instructor(s) of the second course. In the case of concurrent courses, permission to submit the same work for credit in two courses must be obtained from the instructors of both courses.\nProcedures for dealing with allegations of these policy violations are detailed in the university&#8217;s Academic Integrity Actions Procedures, which are published in The WORD student handbook. Periodic review of these procedures will be overseen by the Dean of Student Affairs or her/his designee in consultation with Faculty Senate and the relevant student governing bodies. Any amendments to these procedures are subject to the approval of Faculty Senate. Additional guidelines and procedures for graduate students may exist at the college/department/program level, in which case they are communicated in the college/department/program graduate student handbook.\n* [Articles of Incorporation] \n* [Bylaws of the University] \n* [Site Map]",
    "length": 7395,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Qatar Tribune: CMU-Q launches pioneering AI program to transform higher education in Qatar - Carnegie Mellon University in Qatar",
    "url": "https://www.qatar.cmu.edu/news/cmu-q-launches-ai-program/",
    "text": "Qatar Tribune: CMU-Q launches pioneering AI program to transform higher education in Qatar - Carnegie Mellon University in Qatar[Skip to content] \nSearch\nSearch\n* [People] \n* [News] \n* [Events] \n* [Academic Calendar] \n* [Pre-College Programs] \n* [Spend a Semester in Qatar] \n* [Cross Register in Education City] \n* [Carnegie Mellon University![arrow]] \n* [العربية] \n* [Accessibility] \n**صفحات جديدةباللغةالعربيةحصريًاقريبًا**\nيسرّناالإعلانأننانعكفحاليًاعلىإعدادصفحاتجديدةمُصمّمةلجمهورناالناطقباللغةالعربيةلتقديمتجربةاستخداممتميزةومحتوىمخصصوملائمأكثرلهم.\nسنطلقهذهالصفحاتالمرتقبةقريبًافيالأشهرالقليلة**Dedicated Arabic Pages Are Coming Soon**\nWe're excited to announce that we are actively developing new, dedicated pages specifically designed for our Arabic-speaking users. These will offer tailored content and an enhanced experience.\nExpected to launch in the next few months. Stay tuned!\n[![CMU-Q logo]![CMU-Q logo]] \nSample text 123\nSearchMenu\n[![CMU-Q logo]![CMU-Q logo]] \nMenu\n* [Latest News] \n* [News Archive] \n# Qatar Tribune: CMU-Q launches pioneering AI program to transform higher education in Qatar\n##### ![] \n## Summary\nThe Qatar Tribune covers the media briefing to announce CMU-Q’s pioneering Bachelor of Science in Artificial Intelligence program, the first of its kind in Qatar. Speakers at the event, including representatives from the Qatar Ministry of Education and Higher Education and Qatar Foundation, as well as CMU-Q leadership and faculty experts, share how the degree is ushering in a new era for higher education in Qatar.\n*Originally published September 30, 2025 in the*[*Qatar Tribune*] **\n*By Khaled Al Hameidi*\nDoha\nCarnegie Mellon University in Qatar (CMU-Q), a Qatar Foundation partner university, has marked a new milestone in higher education in the country with the official launch of its[Bachelor of Science in Artificial Intelligence] (BSAI) programme.\nThe announcement was made during a media briefing and panel discussion at Education City, which brought together senior officials, faculty members, government representatives, and media professionals to reflect on the significance of the occasion.\nThe programme, the first of its kind in Qatar, comes at a pivotal moment as artificial intelligence continues to reshape global economies and societies.\nFor Qatar, the programme represents both a bold academic initiative and a national investment in the future workforce, designed to align with the ambitions of Qatar National Vision 2030 to build a sustainable, knowledge-based economy.\nThe event opened with remarks from leaders at[Qatar Foundation] (QF), who underlined the central role of education in preparing young people for an era in which artificial intelligence is no longer a distant technological aspiration but an essential part of daily life.\nThey noted that the launch of the BSAI programme builds directly on QF’s mission to equip students with the skills, mindset, and adaptability required to succeed in a global economy increasingly defined by emerging technologies.\nFor QF, the degree represents more than an academic credential; it is a strategic pathway to cultivating innovators, researchers, and leaders who will help guide Qatar through the complex challenges and opportunities of the digital age.\nRepresentatives from the[Ministry of Education and Higher Education] (MOEHE) also addressed the gathering, reaffirming the government’s commitment to advancing innovation in higher education. They noted that the BSAI programme directly responds to the needs of the national workforce, where expertise in artificial intelligence, data science, and computational technologies is becoming increasingly vital.\nBy introducing a specialised AI curriculum in Qatar, the ministry is helping to shape a new generation of professionals who will ensure the nation not only keeps pace with global developments but also contributes original ideas and solutions to the wider region and beyond. Officials further highlighted the importance of collaboration between government, academic institutions, and the private sector, describing such partnerships as the cornerstone of an educational ecosystem capable of sustaining long-term progress.\nIn his keynote remarks, Dr Michael Trick, Dean of Carnegie Mellon University in Qatar, placed the programme within the context of[Carnegie Mellon’s long and distinguished history in artificial intelligence].\nSpeaking with both pride and anticipation, Dr Trick recalled that when he first joined the faculty in 1989, CMU was already recognised as a global leader in AI research. The university’s legacy in this field stretches back decades, with pioneers such as Alan Newell, Herb Simon, Allen Perlis, and Raj Reddy shaping the early contours of what has since become one of the most transformative forces in human progress.\nAt a time when the power of computing was barely understood, Carnegie Mellon was among the very first institutions to recognise its potential to change the world.\nDr Trick highlighted how the university has consistently expanded its role as a leader in computing and artificial intelligence, tracing a journey marked by milestones such as the creation of its Department of Computer Science in the mid-1960s, the establishment of the first US Robotics Institute in the 1970s, the launch of the Software Engineering Institute in the 1980s, and the founding of the world’s first dedicated School of Computer Science in 1988.\nWhen CMU brought its globally top-ranked computer science degree to Qatar in 2004, it marked another turning point, embedding world-class expertise in Education City. In 2018, the Pittsburgh campus introduced the first[Bachelor of Science in Artificial Intelligence] programme in the United States, and now, in 2025, that pioneering curriculum has been brought to Doha.\n“Today would not be possible without the unwavering support of the Ministry of Education and Higher Education and Qatar Foundation,” Dr Trick said.\nHe described the launch as the culmination of years of vision and collaboration, and at the same time a beginning filled with promise. Looking ahead, he expressed his enthusiasm for welcoming new faculty experts in artificial intelligence, for meeting the students who will embark on this academic journey, and for seeing how the graduates of the programme will ultimately contribute not only to Qatar’s development but also to the wider Middle East and the world.\nDuring the panel discussion that followed, senior faculty members elaborated on the programme’s design and objectives. They explained how the curriculum integrates foundational computer science courses with advanced subjects such as machine learning, robotics, natural language processing, and computer vision.\nRather than relying solely on classroom instruction, the programme places strong emphasis on hands-on, project-based learning, ensuring that students apply their knowledge in real-world contexts. Opportunities for internships, industry collaborations, and research projects are embedded within the academic pathway, preparing graduates to transition seamlessly into professional roles or advanced study.\nFaculty panellists also highlighted that the programme is deliberately structured to serve both local and global needs. By training students within Qatar, CMU-Q is helping to build capacity that will directly support national industries ranging from energy and transportation to healthcare and cybersecurity.\nFor Qatar Foundation and the Ministry of Education and Higher Education, the significance of the BSAI extends beyond academia. Both institutions view the programme as a long-term investment in human capital, one of the most vital pillars of Qatar National Vision 2030. By equipping students with advanced skills in one of the world’s most dynamic fields, Qatar is taking a decisive step towards diversifying its economy, reducing reliance on hydrocarbons, and positioning itself as a regional hub for technology and innovation.\nSeptember 30, 2025\n5 minute read\n## Tags\n[AI],[artificial intelligence],[Curriculum Innovation],[Education City],[Faculty Research],[Government Collaboration],[Qatar Foundation] \n## Categories\n[Academics],[Admission],[Artificial Intelligence],[Artificial Intelligence Research],[Business Administration],[Community Partners],[Computer Science],[Educational Innovation],[Faculty Research],[Featured],[In the Media],[Information Systems],[News],[Research] \n### Share this News\n[Share on Email] [Share on LinkedIn] [Share on Facebook] \n## Related News\n* ![Computer Science sophomores publish speech research at premier IEEE conference] \nFebruary 1, 2026### [Computer Science sophomores publish speech research at premier IEEE conference] \nA research paper titled &#8220;LLM-based post-ASR error correction for disordered speech&#8221; has been accepted by the IEEE International Conference on...\n* ![CMU-Q faculty awarded four Education City Multiversity Grants] \nJanuary 25, 2026### [CMU-Q faculty awarded four Education City Multiversity Grants] \nSummary Faculty members at Carnegie Mellon University in Qatar have been awarded four grants under Qatar Foundation’s inaugural Education City...\n* ![CMU-Q professor addresses Asian ambassadors on the future of AI] \nJanuary 22, 2026### [CMU-Q professor addresses Asian ambassadors on the future of AI] \nDOHA, QATAR –Nui Vatanasakdakul, teaching professor of Information Systems at Carnegie Mellon University in Qatar (CMU-Q), addressed a gathering...\n* [![] English]",
    "length": 9483,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "CMU's Cutting-Edge Curriculum - Generative AI & Large Language Models - Online Education - Carnegie Mellon University",
    "url": "https://www.cmu.edu/online/gai-llm/curriculum/index.html",
    "text": "CMU's Cutting-Edge Curriculum - Generative AI &amp; Large Language Models - Online Education - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[# Generative AI &amp; Large Language Models\nCutting-Edge Curriculum\n] \n**[CURRICULUM] **\n**[Online Experience] **\n**[Admissions] **\n**[TUITION] **\n[Home] &gt; Curriculum# Cutting-Edge Curriculum\n## *Training for future GenAI experts poised to transform the world*\nAs Generative AI continues to evolve, computer scientists will need the most sophisticated and cutting-edge skills to enhance the capabilities of AI for organizations.&#160;In the Generative AI and Large Language Models graduate certificate, courses cover three distinct areas of knowledge:\n* **Theory**- in our*Large Language Models: Methods and Applications*course, you will learn the practical applications of LLM's, what they are, what they can do, and how they work.\n* **Data Representation**- in our*Multimodal Machine Learning*course, you will learn how different language modalities are used in various prediction problems.\n* **Scalability**- in our*Large Language Model Systems*course, you will learn how to apply and scale LLM's for your organization.\nWith the ability to understand the use of large language models, train with massive multimodal data sets and implement scalable systems, you will be ready to maximize the potential of generative AI, all on your own. See more details about our coursework below.\n## Curriculum Overview\nThe online Graduate Certificate in Generative AI &amp; Large Language Models includes 3 graduate-level, credit-bearing courses taught by expert CMU faculty and features the following course progression:\n#### For Fall 2026 Start:\n|\n**Semester**\n|\n**Fall 2026**\n|\n**Spring 2027**\n|\n**Fall 2027**\n|\nCourse|\nLarge Language Models: Methods and Applications\n|Large Language Model Systems|Multimodal Machine Learning|\nEach course will appear on your Carnegie Mellon transcript with the grade earned.&#160;To earn the certificate, you must successfully complete all courses in the program. If you are only interested in one course, however, you may complete that course only and it will show on your transcript with the grade earned.&#160;\n### Course Descriptions:\n## Large Language Models: Methods and Applications\n**Course Number:**11-967\n**Number of Units:**12 units\nThis course provides a broad foundation for understanding, working with, and adapting existing tools and technologies in the area of Large Language Models like BERT, T5, GPT, and others.\nThroughout this course, you will learn:\n* A range of topics including systems, data, data filtering, training objectives, RLHF/instruction tuning, ethics, policy, evaluation, and other human facing issues.\n* How transformer architectures work and explore the reasons why they are better than LSTM-based seq2seq, decoding strategies, etc. Through readings and hands-on assignments, you will explore techniques for pretraining, attention, prompting, etc.&#160;\n* How to apply the skills you've learned in a semester-long course project, making use of locally sourced model instances that offer the opportunity to explore behind the curtain of commercial APIs.\n* How to compare and contrast different models in the LLM ecosystem in order to determine the best model for any task.\n* How to implement and train a neural language model from scratch in Pytorch.\n* How to utilize open source libraries to finetune and do inference with popular pre-trained language models.\n* How to apply LLM&#8217;s in downstream applications and how decisions made during pre-training affect suitability for tasks.&#160;&#160;\n* How to design new methodologies to leverage existing large scale language models in novel ways.\n*Please note: I*n order to complete homeworks and activities, students will need to sign up for Amazon Web Services (AWS) or an equivalent service that offers access to A10g or similar GPUs. The AWS cost to complete assignments will range from $150-300 and will vary based on your usage. In addition, students**&#160;will need to sign up for the OpenAI API. The cost to complete the assignments via OpenAI will be up to $25. Instructions&#160;for accessing both services will be provided when the class begins.**\n## Multimodal Machine Learning\n**Course Number:**11-977\n**Number of Units:**12 units\nIn this course, you will learn the fundamental mathematical concepts in machine learning and deep learning that are relevant to the five main challenges in multimodal machine learning:&#160;\n1. Multimodal representation learning\n2. Translation and mapping\n3. Modality alignment\n4. Multimodal fusion\n5. Co-learning&#160;\nThe mathematical concepts you will learn include, but are not limited to, multimodal auto-encoder, deep canonical correlation analysis, multi-kernel learning, attention models and multimodal recurrent neural networks.\nYou will also review recent papers describing state-of-the-art probabilistic models and computational algorithms for multimodal machine learning and discuss the current and upcoming challenges. Finally, you will study recent applications of multimodal machine learning including multimodal affect recognition, image and video captioning and cross-modal multimedia retrieval.\n*Please note: The Multimodal Machine Learning course may require Amazon Web Services (AWS) and/or OpenAI or other services to complete assignments with fees up to $300 (subject to change). More details will be available as you get closer to the course start date.*\n## Large Language Model Systems\n**Course Number:**&#160;11-968\n**Number of Units:**12 units\nLLM's are often very large and require increasingly larger data sets to train, which means developing scalable systems is critical for advancing AI. In this course, you will learn the essential skills for designing and implementing scalable LLM systems.&#160;&#160;\nThroughout the course, you will:\n* Learn the approaches for training, serving, fine-tuning, and evaluating LLM's from the systems perspective.\n* Gain familiarity with sophisticated engineering using modern hardware and software stacks needed to accommodate the scale.\n* Acquire essential skills for designing and implementing LLM systems, including:\n* Algorithms and system techniques to efficiently train LLM's with huge data\n* Efficient embedding storage and retrieval\n* Data efficient fine-tuning\n* Communication efficient algorithms\n* Efficient implementation of reinforcement learning with human feedback\n* Acceleration on GPU and other hardware\n* Model compression for deployment\n* Online maintenance\n* Learn about the latest advances in LLM systems regarding machine learning, natural language processing, and system research.\n***Students must complete&#160;Large Language Models: Methods and Applications prior to this course.&#160;***\n*Please note: The Large Language Models Systems course may require Amazon Web Services (AWS) and/or OpenAI or other services to complete assignments with fees up to $300 (subject to change).&#160;More details will be available as you get closer to the course start date.*\n# At a Glance\n**Next Start Date**\nFall 2026\nPriority Deadline\\*: January 28, 2026\n\\*All applicants who submit by the priority deadline will receive a partial scholarship award.\n**[Request Information] **\n**[Apply Now] **\nQuestions? There are two ways to contact us. Call412-501-2686&#160;or send an email to&#160;[apply@online.cmu.edu] &#160;with your inquiries.\n# Meet Our World-Class Faculty\n[![Dr. Carolyn Ros&#233;]] **\n[Dr. Carolyn Ros&#233;] **\n*Professor, Language Technologies &amp; Human-Computer Interaction*\n**Education:**Ph.D., Carnegie Mellon University\n**Research Focus:&#160;**Bridging deep, theoretical insights from theories of language and interaction and computational modeling paradigms such as deep learning and LLMs, Dr. Ros&#233; applies understanding of language and interaction in design and orchestration of ensembles of data representations with needed affordances and architectural elements that introduce inductive biases at the algorithmic level.\n[![Dr. Daphne Ippolito]] **\n[Dr. Daphne Ippolito] **\n*Assistant Professor, Language Technologies*\n**Education:**Ph.D., University of Pennsylvania\n**Research Focus:**&#160;Dr. Ippolito's research focuses on the tradeoffs and limitations of generating text with neural language models, as well as strategies for evaluating natural language generation systems. She also researchers how to incorporate AI-in-the-loop language generation into assistive tools for writers. Before starting her role at Carnegie Mellon, Dr. Ippolito worked as a Research Scientist at Google Brain.\n[![leili.png]] **\n[Dr. Lei Li] **\n*Assistant Professor, Language Technologies*\n**Education:&#160;**Ph.D., Carnegie Mellon University\n**Research Focus:&#160;**Through his research, Dr. Li explores topics associated with large language models (e.g. efficient large language model systems), multilingual natural language processing (e.g. speech translation), and AI for science. Before joining CMU, Dr. Li worked as a principal researcher at Baidu's Institute of Deep Learning in Silicon Valley and as the founding director of ByteDance's AI Lab.\n[![Dr. Louis-Philippe Morency]] \n**[Dr. Louis-Philippe Morency] **\n*Associate Professor, Language Technologies*\n**Education:&#160;**Ph.D.,Massachusetts Institute of Technology\n**Research Focus:&#160;**Dr.**&#160;**Morency leads the&#160;Multimodal Communication and Machine Learning Laboratory which&#160;focuses on**&#160;**building the computational foundations to help computers analyze, recognize and predict subtle human communicative behaviors during social interactions.This lab integrates expertise from fields like machine learning, computer vision, natural language processing, and social psychology.\n[![Dr. Yonatan Bisk]] \n**[Dr. Yonatan Bisk] **\n*Assistant Professor, Language Technologies*\n**Education:&#160;**Ph.D.,University of Illinois at Urbana-Champaign\n**Research Focus:&#160;**At CMU, Dr. Bisk leads the CLAW Lab, which includes members from the Language Technologies Institute, Machine Learning Department and Robotics Institute. The lab's research assumes that perception, embodiment, and language cannot exist without one another. Overall, they work to uncover&#160;the latent structures of natural language, modeling the semantics of the physical world, and connecting language to perception and control.\n[![Dr. Daniel Fried]] \n**[Dr. Daniel Fried] **\n*Assistant Professor, Language Technologies*\n**Education:&#160;**Ph.D., UC Berkeley\n**Research Focus:&#160;**Dr. Fried's lab focuses on building language interfaces that can help people with real-world tasks. They aim to make programming more commmunicative by creating models, methods, and datasets for producing code from language. Much of their work also takes a multi-agent system perspective on communication, showing that natural language processing agents can be improved by modeling the intents and interpretations people have when they use language.&#160;\n[![Dr. Graham Neubig]] \n**[Dr. Graham Neubig] **\n*Associate Professor, Language Technologies &amp; Machine Learning*\n**Education:&#160;**Ph.D., Kyoto University\n**Research Focus:**&#160;Dr. Neubig's research focuses on language and its role in human communication, with a long-term goal of breaking down barriers in human-human or human-machine communication through the development of natural language processing (NLP) technologies. This includes technology for machine translation, which helps break down barriers in communication for people who speak different languages, and natural language understanding, which helps computers understand and respond to human language.\n![CMU School of Computer Science logo] \nThe Graduate Certificate in Generative AI &amp; Large Language Models is offered by the Language Technologies Institute (LTI) at CMU, which is housed within the highly-ranked School of Computer Science (SCS). SCS faculty are esteemed in their field, and many of them have collaborated on critical projects that have paved the way for future discoveries in artificial intelligence. Check out some of their work below:\n[![autonomous driving]] \nResearchers from CMU&#8217;s Robotics Institute completed a long-distance autonomous driving test in 1995 called the[No Hands Across America mission].\n[![football field]] \nIn 2001, SCS Founders University Professor Takeo Kanade and his team created a[video replay system] called EyeVision&#160;for Super Bowl XXXV.\n[![Graphic of autonomous vehicle data]] \nIn 2007, Faculty Emeritus William &#8220;Red&#8221; Whittaker led CMU&#8217;s Tartan Racing team to victory in the[DARPA&#8217;s Grand Challenge].\n[![facial-recognition.png]] \nAssistant Research Professor L&#225;szl&#243; Jeni used computer vision technology to create a[facial recognition tool] &#160;that can help people with visual impairment.\n# The Building Blocks of Our Curriculum\n**![] **\n**Practical Problem Solving**\nAs a student in CMU&#8217;s Generative AI online graduate certificate, you will not only master the fundamentals of large language models but also learn how to practically apply this technology in the workplace. Understanding large language models, how they work, and how to build them are vital for success, but knowing how to leverage this knowledge while thinking critically about real-world problems is equally important.\n**![] **\n**Real-World, Industry-Focused Classes**\nIn this program, you will learn how to approach problems from experts who have been there, done that. You will learn to think strategically about challenges you encounter on the job by considering questions like, &#8216;What resources are available to me?&#8217; or &#8216;What limitations do I have?&#8217; Your critical thinking skills, combined with your technical prowess, will empower you to design the most cutting-edge solutions for your organization.\n**![] **\n**Thoughtfully Designed Coursework**\nThe coursework for this certificate is deliberately designed to highlight Generative AI and large language models from different angles. Each course focuses on one of three distinct concepts: theory, data representation and their affordances, and system scalability.By completing three complementary and complex courses, you will be ready to innovate new and exciting designs that will take your organization to the next level.",
    "length": 14412,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Signature Initiative: Collaborative AI",
    "url": "https://www.cmu.edu/tepper/about/strategic-plan/signature-initiative-collaborative-ai",
    "text": "[Skip to main content] \n\n# Signature Initiative: Collaborative AI\n\nDrawing on its deep expertise at the intersection of technology, analytics, and business, the Tepper School will apply Collaborative AI — an integrated simulation of complex human and system behavior — to transform business education and research.\n\nTRANSFORMING BUSINESS EDUCATION\n\n- Using Collaborative AI, we will harness collaborative AI to **reshape business education away from the traditional case study model and toward true-to-life simulation and personalized learning.**\n- By **integrating collaborative AI across the curriculum** — with holistic projects spanning areas from accounting and finance to marketing and organizational behavior — our faculty will provide students with a strong foundation on which to build the tools of tomorrow and gain a competitive advantage.\n- We will help emerging and experienced leaders to **understand how to recast the role of the manager in an AI age**, by harnessing AI to amplify, not replace, human connections and ideas.\n\nTRANSFORMING RESEARCH\n\n- Our researchers will dive into the most difficult, complex problems facing businesses today by leveraging Collaborative AI to **generate and test new solutions and drive methodological advances across all business disciplines.**\n- We will **collaborate with world-class experts from across Carnegie Mellon University working alongside industry partners** to grapple with the economic, societal, and ethical implications of generative AI.\n- We will cultivate new hubs of innovation, such as the Center for Intelligent Business to enable **better decision-making, optimization, and innovation across all areas of business** through applications of collaborative AI.",
    "length": 1729,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Advancing Student Learning at CMU Through Generative AI",
    "url": "https://www.cmu.edu/news/stories/archives/2023/october/advancing-student-learning-at-cmu-through-generative-ai",
    "text": "Advancing Student Learning at CMU Through Generative AI - News - Carnegie Mellon University\n[Skip to main content] \n[Carnegie Mellon University homepage] \nSearch Carnegie Mellon UniversitySearch\nMenu\n[News] \n*October 23, 2023*# Advancing Student Learning at CMU Through Generative AI\n## * [Share on Facebook (opens in new window)] \n* [Share on X (opens in new window)] \n* [Share on LinkedIn (opens in new window)] \n* Print this page\n* [Share by email] \n**By:**Michael Henninger[Email] \nMedia Inquiries\n**\nName\nPeter Kerwin**\nTitle\nUniversity Communications &amp; Marketing\n[Email] \nPhone\n[412-268-1151] \nCarnegie Mellon University’s[Eberly Center for Teaching Excellence and Educational Innovation(opens in new window)] is launching a Generative Artificial Intelligence Teaching as Research (GAITAR) Initiative, which will include several new efforts to bring generative AI to classrooms across CMU. The Center launched a series of GAITAR Institutes to promote instructor-led innovations and educational research designs across diverse contexts. Additionally, the Eberly Center is now seeking applicants for its GAITAR Fellowship 2023.\nNew to the Eberly Center’s portfolio of offerings, the GAITAR Fellowship provides $5,000 for a CMU instructor to design and implement a teaching innovation using a generative AI tool in a spring, summer or fall 2024 CMU course. They must then measure the impacts of the innovation on student learning and disseminate their findings at CMU and beyond. The[deadline for applications(opens in new window)] is Nov. 1.\nThe fellowship aims to incentivize and lower barriers to innovation, implementation and the dissemination of educational research findings.\n> &quot;We embrace this as an inflection point to take these tools and new ways of thinking to enhance our teaching and learning strategies.” —James H. Garrett Jr.\n![Jim Garrett] \n*James H. Garrett Jr.*\n“In many ways, CMU is the birthplace of both learning science and AI and machine learning, dating back to the[Newell and Simon days(opens in new window)],” said[James H. Garrett Jr.(opens in new window)], CMU’s provost and chief academic officer. “If anybody should be advancing the research and application of AI in education, it should be Carnegie Mellon. We embrace this as an inflection point to take these tools and new ways of thinking to enhance our teaching and learning strategies.”\nThe Eberly Center recently finished delivering a GAITAR Institute on campus, a four-session program that generated ideas for teaching innovations implementing generative AI in CMU courses, preparing instructors to study the results with tangible Eberly Center support from start to finish.\nSince 1996, the Eberly Center has brought pedagogical and technological issues together to support Carnegie Mellon faculty and graduate students in their roles as educators. The center, which fosters a culture of experimentation, innovation and iterative improvement through collaboration, approaches the use of AI with empirical questions —where do AI tools enhance student learning and experience? What do students consider as the benefits and tradeoffs of using AI? How can equitable access and outcomes be ensured when using AI?\nCMU’s University Education Council will be convening town hall sessions in early November to hear students' and educators' perspectives on the most pressing needs and opportunities related to AI and its potential for impact on education. The full spectrum of community input will inform broader university strategies to advance the applications of generative AI in education.\n![Amy Burkert] \n*Amy Burkert*\n“Many articles have shared that education is being upended by these new tools,” said[Amy Burkert(opens in new window)], vice provost for education. “There are, indeed, many changes taking place, but the question is, ‘How can we help our community leverage that potential into an asset rather than a cause for concern?’”\nThe theme of the Eberly Center’s 7th annual Teaching and Learning Summit, held on Sept. 21, was “[Adapting to Generative AI in Teaching(opens in new window)].” During the Summit,faculty members from the[Heinz College of Information Systems and Public Policy(opens in new window)], the[Dietrich College of Humanities and Social Sciences(opens in new window)], and the[Human-Computer Interaction Institute(opens in new window)] discussed their use of AI in the classroom.\n## Generative AI Tools FAQ\nThe recent evolution of AI tools, such as ChatGPT, DALL-E 2 and GitHub Copilot, is impressive, as is the associated volume of media coverage.\nIn response to inquiries from CMU colleagues, the Eberly Center compiled a list of[frequently asked questions(opens in new window)] informed by evidence-based and inclusive teaching strategies, CMU policies, and the current state of technology tools.\n[Read more(opens in new window)] \nThe Eberly Center supports teaching as research.\n[Read more about their research and findings(opens in new window)] \n[![Embedded YouTube video]] \n*Watch Haylee Massaro deliver a talk on embracing generative AI in the classroom during the Eberly Center's 2023 Teaching and Learning Summit.*\n“We want to make sure that our entire community’s voices are heard, especially those of our students so we can better understand their most pressing needs and the exciting opportunities they see related to generative AI,” Burkert said.\n![Marsha Lovett] \n*Marsha Lovett*\n“We are taking a very scientific approach to this —a learning science approach,” said[Marsha Lovett(opens in new window)], vice provost for teaching and learning innovation and co-coordinator of[The Simon Initiative(opens in new window)], CMU’s learning-engineering ecosystem that works to improve student learning outcomes. “We are actively supporting our faculty members to lean in, learn about generative AI, and incorporate it into their teaching where it can benefit students. On top of that, we are actively supporting faculty to study its impacts on student learning and the student experience. We must continue to be data-informed on this.”\nThe work to apply generative AI tools and techniques in the classroom is only one part of a broader university strategy to advance the next generation of artificial intelligence’s impact across education, research and society. The university has been increasingly called upon for its AI expertise by public and private sector partners. Most recently,[Gov. Josh Shapiro visited CMU(opens in new window)] to announce an executive order on the use of generative AI in Commonwealth agencies. CMU’s[Block Center for Technology and Society(opens in new window)] one of the nation’s leading research centers working to shape the impact of these technologies, will partner with the Shapiro administration on this effort.\n## —Related Content —[\n![Farnam Jahanian shakes hands with Gov. Josh Shapiro] \n## Gov. Shapiro Visits CMU —Birthplace of AI —To Sign Executive Order on Generative AI\n] \n[\n![William S. Dietrich II] \n## Celebrating 10 Years of Dietrich Foundation Support\n] \n[\n![Rayid Ghani testifying] \n## CMU Artificial Intelligence Experts Brief Policymakers\n] \n* [The Piper: Campus &amp; Community News(opens in new window)] \n* [Official Events Calendar(opens in new window)] \n▴scroll to top",
    "length": 7256,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Computing - University Policies - Carnegie Mellon University",
    "url": "https://www.cmu.edu/policies/information-technology/computing.html",
    "text": "Computing - University Policies - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[University Policies] \n[University Policies] &#160;&#8250;&#160;[Information Technology] &#160;&#8250;&#160; Computing\n# Computing\nPOLICY TITLE:|Carnegie Mellon University Computing Policy|\nACCOUNTABLE DEPARTMENTS/UNIT:|Office of the Chief Information Officer. Questions about this Policy should be directed to the Information Security Office, 412-268-8556.|\nDATE OF ISSUANCE:|Approved by the President's Council on May 16, 2003. Administrative changes were made July 2018.|\n&#160;ABSTRACT:|Sets forth university guidelines for use of computing resources.|\n&#160;RELATED POLICIES:|\n* [Academic Integrity] \n* [Appointment and Tenure Policy] \n* [Community Standards and Procedures] \n* [Conflict of Interest/Commitment] \n* [Fair Use Policy] \n* [Freedom of Expression] \n* [Information Security Policy] \n* [Intellectual Property Policy] \n* [Discriminatory and Sexual Misconduct Policy (Interim)] \n* [Privacy Rights of Students] [] \n* [Separation of Individual's and Institution's Interests] |\n## Statement\nThe purpose of this policy is to set forth guidelines so that members of our community may use the campus network and computing facilities in ways that are responsible and respectful of privacy. This policy sets forth the university&#8217;s expectations of acceptable behavior on the part of computer systems users at Carnegie Mellon by providing guidelines for appropriate use of computing and related communication systems and examples of inappropriate use. These standards of acceptable behavior also extend beyond the campus community into the Internet. Just as it is unacceptable to violate others&#8217; rights to privacy, property and resources within Carnegie Mellon, it is also unacceptable to violate those rights on systems that are not at Carnegie Mellon but are accessible through Carnegie Mellon&#8217;s connection to the Internet.\nThis policy applies to all users of Carnegie Mellon computing systems, including students, faculty and staff, and any others granted the use of university computing resources. It applies to the use of all computing facilities owned, leased, operated or contracted by Carnegie Mellon University. As used in this policy, terms such as &#8220;computing,&#8221; &#8220;computing/communications systems,&#8221; &#8220;computing resources,&#8221; etc., refer to all computers, communication systems, and peripherals, software, telephones and systems with similar functions, which are owned by Carnegie Mellon, or which utilize Carnegie Mellon infrastructure such as telephone lines or computer networks.\nAlthough this policy does not attempt to deal specifically with legal issues, university members are responsible to act in compliance with the law, including any federal, state and local laws governing computer and telecommunications use, as well as all other applicable university policies.\n## Privileges and Responsibilities\nEvery member of the Carnegie Mellon community who uses computing and related communications systems at Carnegie Mellon, or systems that belong to Carnegie Mellon or which rely on Carnegie Mellon&#8217;s infrastructure has the responsibilities described in this policy. This includes members of the Carnegie Mellon community who have restricted privileges, such as alumni who may have electronic mail access only. Individuals with personally-owned computers, but who rely upon the university network to connect those computers (either through an on-campus or remote network connection, such as ethernet or wireless) are expected to abide by the policies set forth in this document. Personally-owned computers operating in stand-alone mode or networked through a non-university connection are not covered under this policy, but those users are encouraged to consult the usage policies set forth by their Internet Service Provider.\nA fundamental premise of this policy is that anyone sharing computing resources with other individuals should behave as a reasonable, mature and ethical person. The user must recognize that computer systems and networks do not exist in a special environment; on the contrary, use of computers is a form of communication, and every component of a computing environment and every piece of information it contains belong to the university, the university community as a whole, or some individual or group within that community.\nAccess to Carnegie Mellon&#8217;s computing resources is contingent upon being a member of the university community and adhering to university and Computing Services policies, guidelines and procedures, including this policy. Misuse may result in the loss of access and/or university disciplinary action. For some users and certain systems, access may be authorized by specific departments, research centers or other organizations affiliated with Carnegie Mellon. In such cases, any department- or group-specific policies and guidelines must be adhered to when using resources provided by the department or group. This is in addition to university policies and Computing Services guidelines and procedures.\nAny user who suspects a violation of the university&#8217;s computer use policies, or who has knowledge of potential vulnerabilities or security loopholes in a system or network at Carnegie Mellon, should immediately notify the Information Security Office at[iso-ir@andrew.cmu.edu].\n### Maintain the Security and Confidentiality of your Account\nUsers assume personal responsibility for the use made of their computer accounts. This responsibility begins with selecting a secure password, and involves maintaining the confidentiality of that password and changing the password regularly in order to assure the continued security of your account. For guidance in selecting a secure password, see[Guidelines for Password Management]. If you believe that someone has made unauthorized use of your account, you should change your password immediately and report the incident to&#160;the[Information Security Office].\n### Respect for Others&#8217; Property and Privacy Rights\nUsers are responsible to respect copyright agreements and intellectual property ownership. Any material that is the work of another, whether explicitly copyrighted or not, should not be distributed by any user without appropriate acknowledgement and/or permission of the creator. Unless permission has been granted by the owner of copyright protected materials, distribution of copyright protected material via the university network or computer systems is prohibited. While the university has been granted permission by software vendors to distribute certain software packages via the network, it is not generally permissible for individual users to distribute that same software to others via the university network or computer systems. See the sections in this policy on[Misuse and Inappropriate Behavior]. While there may be cases in which property rights to particular programs, data, etc., are ambiguous or in dispute, the user must assume that any information not created by himself or herself belongs to someone else and must respect that person&#8217;s privacy and property rights to that information. (In certain situations, even information created by the user may not belong to that user but rather to the university or others.) This policy is not intended to limit &#8220;fair use&#8221; as permitted under the Copyright Act and users having questions about whether a particular use constitutes a &#8220;fair use&#8221; may consult the Office of the General Counsel for advice.\n### Improper/Illegal Communications&#160;\nAny communications that would be improper or illegal on any other medium are equally so on the computer: libelous material, obscene messages, harassment, forgery, threats, etc. However, this is not intended to restrict the free expression of ideas. Communication conducted in accordance with the university policy on[Freedom of Expression] and with the statement on Academic Freedom and Responsibility enunciated in the[Appointment and Tenure Policy] of Carnegie Mellon University will not be considered a violation of this policy. For further guidelines, see also the university policy on[Separation of Individual&#8217;s and Institution&#8217;s Interests].\n### Responsible Sharing of Resources&#160;\nWhere a resource such as memory, CPU time or access to network resources belongs to the whole community collectively, it must be shared.\nIt is unacceptable to make such excessive use of system or network resources that other users cannot obtain access. Examples include excessive use of CPU time during a period of heavy use on a timesharing system, excessive use of disk space on a system that does not limit such utilization, the use of an excessive amount of network bandwidth in an environment of networked computers, and any activity that makes a system unusable or significantly degrades performance for others. A novice user might be unaware that a particular action constitutes &#8220;excessive use&#8221; but, without doubt, once a system administrator makes him or her aware of the fact that such an action is unreasonable, that user will be held responsible for any further such infractions. If you are unsure whether your needs constitute excessive use, contact the system administrator. Similarly, if you need an unusual amount of disk space, CPU time or other resources, check with the system administrator to find out whether this use can be accommodated, rather than risk interfering with the work of others on the system.\n### Risks of Data Loss and Data Persistence&#160;\nAlthough the university will make efforts to secure the network and university controlled servers from abuse and damage, it cannot guarantee against data loss by a student, faculty, member or staff, either on a university-operated or an individually-owned computer.\nUsers should know that even those files that they have &#8220;deleted&#8221; using the appropriate procedures in the application or operating system, may indeed be recoverable if they exist in a system backup file or other persistent form. If the university is asked to recover such data by subpoena, it must cooperate, and data that the user believes to have been destroyed may be recovered in the process.\n### Personal Use&#160;\nWhile the university makes computer resources available primarily to achieve its goals of education and research, and for administrative activities, it realizes the need to encourage the personal use of computing for the convenience of the campus community. Thus, it is reasonable to allow the use of computing resources for computer mail, document preparation, personal or course Web page publication, or other activity that can facilitate convenience or enhance productivity, to the extent that the activity is within the limits described by[Responsible Sharing of Resources]. Any personal use of computing resources related to operating a personal business or commercial enterprise is prohibited unless permission to do so has been specifically granted by the provost or the provost&#8217;s designee.\nWe do recognize the difficulty of distinguishing whether certain cases of &#8220;personal use&#8221; are allowable, such as activities that result in personal financial gain (e.g. checking stock prices online), relate to a commercial business (e.g. university-sponsored technology transfer efforts), or support (but do not constitute operating) a personal business (e.g. a student developing a business plan or a faculty member writing a report for a consulting engagement outside the university). In such cases, we rely on individuals to be responsible and judicious in the use of university&#8217;s shared computing resources. In particular ensuring:\n* appropriate use of resources (e.g. any such work is completed outside of university time and does not utilize shared resources such as CPU cycles or network bandwidth to a degree that adversely impacts academic or research activities);\n* appropriate use of licenses (e.g. do not use software procured with academic use licenses for commercial applications or development, unless the license explicitly permits such use);\n* appropriate marketing (e.g. no creation of &#8220;.com&#8221; domains within Carnegie Mellon&#8217;s &#8220;edu&#8221; domain, no advertising services and products using Carnegie Mellon email accounts, and no advertising using web pages on Carnegie Mellon servers (any server with a .CMU.EDU host name).\nIn cases of questionable personal use of resources, you may contact[it-help@andrew.cmu.edu] to determine whether a particular activity is permissible.\nWe reserve the right to restrict personal use of university systems and networks by an individual or by the community at large, if the use of resources for such activities becomes excessive.&#160; If you need unlimited access to computer networks for private or business purposes, you can subscribe to a commercial service.\nFor information regarding the use of resources to produce intellectual property and profit from the development of such property see Carnegie Mellon University&#8217;s[Intellectual Property Policy] and the[Policy on Conflict of Interest/Commitment].\n## Privacy\nThe user must presume that the contents of any other users&#8217; directory are private unless expressly designated otherwise, just as one would presume that the contents of someone&#8217;s apartment or office are private. The only exceptions to this rule are: that in some environments, files such as &#8220;plan files&#8221; may be considered public even if the user has not expressly designated them as such; and that some services such as web pages and anonymous or &#8220;guest access&#8221; ftp services may be considered to be public, but only for those areas not protected by password and which are &#8220;obviously&#8221; public. An unprotected account or shared device (such as a shared disk on a networked computer) are not considered to be public unless the name or service expressly indicates that it is. In such cases, any files or other data which would appear to be private in nature, by virtue of the file name or data stored, even if &#8220;publicly accessible&#8221; should be considered to be private. The user accessing such files has a responsibility to ask the owner of the files or service if the files are intended to be publicly accessible before the user does more than a &#8220;cursory glance&#8221; sufficient to cause the question.\nA user can explicitly grant access to his or her directories, files or to services run from his or her systems. However, users who issue general or vague invitations to browse through their files incur a special obligation to protect any material that they do not wish others to see. Indeed, all users are urged to maintain protection levels on their files consistent with the access they are actually willing to give to other users.\n### Access to Faculty Data\nElectronic data on a faculty member&#8217;s account, whether stored on a computer in the faculty member&#8217;s office or elsewhere under the proprietary control of that faculty member, may not be examined, i.e., the contents of the data read by a person, without the faculty member&#8217;s consent, except in cases of emergency or in response to a valid subpoena, search warrant, or order of a court. Posting of data by a faculty member on servers available to the public or to students shall be understood to imply consent, and electronic access given to specific parties by the faculty member will likewise imply consent for those parties to access permitted data. Emergencies may include, for example, but are not limited to, the death, incapacity or disappearance of the faculty member, or the search for and examination of files used for apparently malicious activity in an account which endangers the integrity of shared computers, the network, or other aspects of the university&#8217;s computing infrastructure.\nOnly specifically designated individuals are permitted to determine what passes for an &#8220;emergency.&#8221; Such individuals may be specifically designated, or may be designated by job position/description. All assignments for individuals or positions will be done by Provost or by a designate of the Provost.\nWhenever possible and legally permissible, notification must be given to the faculty member whose data are subject to subpoena, search warrant, or order of court prior to compliance therewith, and, whenever possible and legally permissible, sufficient time must be allowed, before intrusion, to allow the faculty member to file a motion to quash. Information obtained from an examination warranted by an emergency cannot be used as evidence in university sanctions of any faculty member, and cannot be released to the public, or to the university community or to public officials, except as such releases are essential to resolution of the emergency, or constitute evidence of a crime concealment of which would obstruct justice, and in the latter case release may only be to appropriate law enforcement officials. Any intrusion by an employee of the university into a faculty member&#8217;s electronic data must be reported to the faculty member as soon as possible, and within five days of the event in writing both to the faculty member, if possible, and unless prohibited by order of court, and to an Ombudsman, who shall be a member of the regular faculty selected annually by the Nominating Committee of the Faculty Senate and who has been endorsed by majority vote of the Faculty Senate. The Ombudsman shall be a current or retired regular faculty member who holds no administrative appointment and is not a member of the Faculty Review Committee. The Ombudsman shall have authority to investigate whether an intrusion was warranted by the policy and, (i) shall inform the President and the affected faculty member of the Ombudsman&#8217;s findings; (ii) where a violation of the policy is found, shall inform the Faculty Review Committee of the policy violation; and (iii) where appropriate, in the absence of the affected faculty member, to bring a grievance before the Faculty Review Committee. Violation of any aspect of this policy is a sanctionable offense.\nFor purposes of this section, the term &#8220;faculty&#8221; shall mean any person who is a member of the Faculty Organization as defined in Article III of the Constitution of the Faculty Organization.\n### Access to Staff Data\nElectronic data on a staff member&#8217;s account, whether stored on a computer in the staff member&#8217;s office or elsewhere under the proprietary control of that staff member, may not be examined, i.e., the contents of the data read by a person, without the staff member&#8217;s consent, except in cases of emergency, in response to a valid subpoena, search warrant, order of a court, or by specific request by the staff members&#8217; supervisor for the purpose of accessing work-related electronic data. Posting of data by a staff member on servers available to the public or to members of the university shall be understood to imply consent, and electronic access given to specific parties by the staff member will likewise imply consent for those parties to access permitted data. Emergencies may include, for example, but are not limited to, the death, incapacity or disappearance of the staff member, or the search for and examination of files used for apparently malicious activity in an account which endangers the integrity of shared computers, the network, or other aspects of the university&#8217;s computing infrastructure.\nOnly specifically designated individuals are permitted to determine what passes for an &#8220;emergency.&#8221;&#160; Such individuals may be specifically designated, or may be designated by job position/description. All assignments for individuals or positions will be done by Provost or by a designate of the Provost.\nWhenever possible and legally permissible, notification must be given to the staff member whose data are subject to subpoena, search warrant, or order of court prior to compliance therewith. Information obtained from an examination warranted by an emergency will not be released to the public, or to the university community or to public officials, except as such releases are essential to resolution of the emergency, or constitute evidence of a crime concealment of which would obstruct justice, and in the latter case release may only be to appropriate law enforcement officials. Any such findings may be reported to the staff member&#8217;s supervisor, department head, or to Human Resources for appropriate investigation and action. Any intrusion by an employee of the university into a staff member&#8217;s electronic data must be reported to the staff member as soon as possible, and within five days of the event via electronic mail unless prohibited by order of court, or due to a continuance of an ongoing investigation by the University. Violation of any aspect of this policy is a sanctionable offense.\nWhen possible, staff members will be informed about the issuance of court orders, or other intrusions into their electronic data. In cases where a staff member believes that electronic data in their account has been inappropriately accessed by another staff member, the incident should be reported to Human Resources.\n### Access to Student Data\nElectronic data stored in a student account, whether stored on a computer in the student&#8217;s residence or elsewhere under the proprietary control of that student, may not be examined, i.e., the contents of the data read by a person, without the student&#8217;s consent, except in cases of emergency or in response to a valid subpoena, search warrant, order of a court, or by order of the Office of the Dean of Student Affairs. Posting of data by a student on servers available to the public shall be understood to imply consent, and electronic access given to specific parties by the student will likewise imply consent for those parties to access permitted data. Emergencies may include, for example, but are not limited to, the death, incapacity or disappearance of the student, or the search for and examination of files used for apparently malicious activity in an account which endangers the integrity of shared computers, the network, or other aspects of the university&#8217;s computing infrastructure.\nOnly specifically designated individuals are permitted to determine what passes for an &#8220;emergency&#8221;. Such individuals may be specifically designated, or may be designated by job position/description. All assignments for individuals or positions will be done by Provost or by a designate of the Provost.\nWhenever possible and legally permissible, notification must be given to the student whose data are subject to subpoena, search warrant, or order of court prior to compliance therewith. Information obtained from an examination warranted by an emergency will not be released to the public, or to the university community or to public officials, except as such releases are essential to resolution of the emergency, or constitute evidence of a crime of concealment which would obstruct justice, and in the latter case release may only be to appropriate law enforcement officials. Any findings of potential wrongdoing unrelated to the original intent of the search, must be reported to the Office of the Dean of Student Affairs for appropriate investigation and action. Any intrusion by an employee of the university into a student&#8217;s electronic data must be reported to the student as soon as possible, and within five days of the event via electronic mail to the student, if possible, unless prohibited by an order of the court or because of an ongoing investigation conducted by the university. Violation of any aspect of this policy is a sanctionable offense.\nWhen possible, students will be informed about the issuance of court orders, or other intrusions into their electronic data, including the purpose of the search. In cases where a student believes that electronic data in their account has been inappropriately accessed by a staff member, the incident should be reported to Office of the Dean of Student Affairs.\n**Note:**Removable media such as floppy disks, zip drives, tapes, or CDs in a faculty or staff office, or in a residence hall are not subject to search by Computing Services, though Computing Services will assist authorized law enforcement agencies or authorities to read data after they are obtained, at the agencies&#8217; or authorities&#8217; request.\n### Protecting Confidential Information\nUsers who maintain confidential information, such as records relating to employees or students, are responsible for following privacy-related policies, laws, and data use agreements.\n### Protecting Personal Information\nAs is described throughout this policy, data transmitted across the university network or stored on university systems may be accessed by others as a result of misuse by an individual, as an incidental result of the routine operation of the network and systems, or in response to a court subpoena or university investigation into suspected or alleged misuse. While complete privacy of personal data may not be possible, users who wish to ensure a higher degree of privacy for their data are encouraged to use encryption, PGP security, or other techniques to reduce the risk that others may access their data.\n## Misuse and Inappropriate Behavior\nThe following activities are expressly prohibited at Carnegie Mellon:\n* Using a computer system without proper authorization granted through the university, college, or department management structure. Some activities such as &#8220;port scanning&#8221; are not expressly prohibited. However, if the target of such scanning requests that an individual or system stop performing such actions, the person or system performing the scans must stop scanning the target machine unless the scans are being carried out by a system administrator who has the authority and responsibility over the machine(s) being scanned or for the network being used.\n* Concealing your identity, or assuming the identity of another (e.g., by sending forged electronic mail). Note that some forms of electronic communication, such as browsing Web pages, passively &#8220;identify&#8221; users. Keeping your identity private either by not setting an identity in your browser or by using a Web-anonymizer in order to protect yourself from being put onto mailing lists is not a violation of this policy.\n* Sharing your password or account with the specific exception of staff or faculty members allowing their administrative support personnel to access their accounts in order to provide services appropriate to their job functions. Note that some policies for the accessing of specific systems or data (see PCI-DSS Guidelines) explicitly forbid the sharing of passwords used to access them, and that such restrictions for those specific systems override this policy.\n* Using another person&#8217;s computer account, userID, files, or data without appropriate permission, as described in the previous bullet (e.g. using an account found &#8220;logged in&#8221; on a cluster machine).\n* Deleting or tampering with another user&#8217;s files or with information stored by another user on any information-bearing medium (disk, tape, memory, etc.). Even if the user&#8217;s files are unprotected, with the exception of files obviously intended for public reading, such as Web pages, it is improper for another user to read them unless the owner has given permission (e.g. in an announcement in class or on a computer bulletin board).\n* Attempting to &#8220;crack&#8221; or guess other users&#8217; passwords. System administrators or those specifically designated by the administrator or owner of a system may attempt to crack passwords in order to test and enhance the security of the system. In cases where an individual or department &#8220;owns&#8221; machines which use password files controlled by another organization (e.g. Andrew machines or their like), the owner may not attempt to crack passwords without explicit permission by the owners of the password database.\n* Obtaining passwords by other means, such as password capturing and key logging programs.\n* Attempting to circumvent system security (e.g. breaking into a system or using programs to obtain &#8220;root&#8221; access), without the explicit permission of the owner of that system.\n* Denying appropriate access to resources to other users (e.g. &#8220;ping flooding&#8221; another system, sending &#8220;mail bombs,&#8221; or modifying a login file in order to cause a user to not be able to log in).\n* Releasing programs such as viruses, Trojan horses, worms, etc., that disrupt other users, damage software or hardware, disrupt network performance, or replicate themselves for malicious purpose.\n* Sending commercial solicitations via electronic mail (i.e. spamming) to individuals, or to newsgroups or mailing lists where such advertising is not part of the purpose of the group or list. (It is permissible to send a commercial solicitation to a &#8220;for sale&#8221; newsgroup, provided that the advertisement conforms to other policies and guidelines at Carnegie Mellon.)\n* Any &#8220;mass mailing&#8221; which is solicitous in nature, unless the mailing is in the conduct of university business.\n* Reselling of services based on the university network, such as web hosting, mailing services or the selling of shell accounts.\n* Running a proxy server which results in inappropriate or unauthorized access to university materials to non-university members.\n* Advertising commercial businesses or ventures on Web pages hosted by Carnegie Mellon, unless prior authorization has been granted.\n* Using mail messages to harass or intimidate another person (such as by repeatedly sending unwanted mail or broadcasting unsolicited mail).\n* Violations of any local, state or federal laws, such as the distribution of copyright-protected materials (e.g. the distribution of commercial software, music or films in electronic format without appropriate permissions by the owner, even if the user distributing the materials notifies others of their copyright status).\n* Tampering with, willful destruction of or theft of any computer equipment, whether it belongs to the university or to an individual. Tampering includes any deliberate effort to degrade or halt a system, to tie up a system or to compromise the system/network performance. Willful destruction includes any deliberate disabling or damaging of computer systems, peripheral equipment such as scanners or printers, or other facilities or equipment including the network, and any deliberate destruction or impairment of software or other users&#8217; files or data.\n* The unauthorized removal of university or another's computing equipment, which constitutes theft.\nThis list should not be considered to be complete or exhaustive. It should, however, serve as a set of examples of obviously inappropriate behaviors. If you are in doubt about the appropriateness of something that you want to do, contact the Computing Services Help Center at 412-268-HELP, or send mail to[it-help@andrew.cmu.edu] and ask first.\n## Enforcement\nInappropriate behavior in the use of computers is punishable under the general university policies and regulations regarding faculty, students and staff. The offenses mentioned in this policy range from relatively minor to extremely serious, though even a minor offense may be treated severely if it is repeated or malicious.Certain offenses may also be subject to prosecution under federal, state or local laws.\nAppropriate disciplinary action depends not only on the nature of the offense, but also on the intent and previous history of the offender. The range of possible penalties includes reprimands, loss of computing privileges, course failures for students, disciplinary probation, suspension or dismissal from the university and/or criminal prosecution.\nOffenses that are minor or appear to be accidental in nature are often handled in a very informal manner such as through electronic mail. More serious offenses involve formal procedures pursued through the Division of Student Affairs for students, Human Resources and/or the hiring university department or administrative unit for staff, or the Faculty Review Committee for faculty.\n### Restrictions of Privileges During Investigations\nDuring the course of an investigation of alleged inappropriate or unauthorized use, it may be necessary to temporarily suspend a user&#8217;s network or computing privileges, but only after determining there is at least a prima facie case against the individual, as well as a risk to the university or its computing resources if privileges are not revoked. In these cases, it is important to recognize that the restriction of network or computing privileges is intended to protect the system rather than to punish the individual. For example, if a computer account has been used to launch an attack on another system, that account will be rendered inactive until the investigation is complete. This is a necessary action taken to prevent further misuse and does not presume that the account holder initiated the misuse. Unsubstantiated reports of abuse will not result in the suspension of accounts or network access unless sufficient evidence is provided to show that inappropriate activity occurred. For example, if someone reports that their computer was &#8220;attacked&#8221; by a Carnegie Mellon system, the burden will be upon the complainant to provide sufficient data logs or other evidence to show that the incident did, indeed at least appear to be an attack.\n### Adverse Impact on Shared Systems\nThe university reserves the right to discontinue communication with external systems that are known to harbor spammers, account crackers, or phishing sites, despite the fact that this may restrict certain acceptable communications. When deemed necessary, this action will be taken to protect the security and safety of our systems. Similarly, there may be cases where a particular service or activity on a given university system will, by the very nature of its legitimate operation, tend to generate attacks from other Internet sites. If these attacks are frequent and severe enough to cause service interruptions for larger parts of the campus community, it may be necessary to temporarily or permanently remove these systems from the campus network. In cases where such an action is deemed necessary, network administrators will work with the maintainers of the system to identify alternative methods of network access. In cases where the university restricts access to external sites or removes network access for internal sites, the purpose of the action is to maintain the security and reliability of the computer systems and networks rather than to punish an individual or a site, or to restrict the free expression of ideas.\n* [Articles of Incorporation] \n* [Bylaws of the University] \n* [Site Map]",
    "length": 35231,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "AI for Accessibility Remediation - Computing Services - Office of the CIO - Carnegie Mellon University",
    "url": "https://www.cmu.edu/computing/news/2025/ai-remediation.html",
    "text": "_November 20, 2025_\n\n# AI for Accessibility Remediation\n\n## **AI as a Remediation Assistant**\n\n[The Digital Accessibility Office] encourages the responsible use of AI to reduce barriers, expand participation, and align with [CMU’s Digital Accessibility Policy] and the [Web Content Accessibility Guidelines (WCAG)]. With human oversight, AI can be useful for learning about accessibility standards and best practices, remediating content, and developing alternative formats to expand access. Because we can ask questions about the intended audience and how they will interact with our content, accessibility is always easier to incorporate during the creation phase. Still, in cases of existing content, AI can help speed up the remediation process or create additional formats that may improve usability.Carnegie Mellon University provides access to [protected tools] like Microsoft Copilot, Google Gemini, ChatGPT Edu, and Siteimprove AI, which are useful for accessibility remediation. Contact the Digital Accessibility Office at [digital-access@cmu.edu] with questions about remediation or accessing tools.\n\n## Common Accessibility Errors\n\n[WebAIM] produces a 1 Million report each year that is packed with valuable data about the state of accessibility on the web. According to their 2025 report:\n\n- There are 5.4% more images used on homepages in 2025 than in 2024–our websites are becoming more graphic-heavy. However, 18.5% of all homepage images **lacked alternative text**.\n- 94.8% of homepages had detected WCAG 2 failures. The most common issues were **low-contrast text, missing form input labels, empty links, and empty buttons**.\n\n## Remediation Areas\n\n### Alt Text and Image Descriptions\n\nAI tools can now draft alt text or image descriptions. However, because results vary, and alt text should be contextual, it is necessary to review and edit outputs to ensure accuracy and relevance. Here are three examples of images of an apple. The three images are very different from one another and require varying descriptions. All of these text equivalents could be appropriate, depending on the use case and level of detail needed. Getting suggestions from AI and then combining or altering the descriptions to fit your context is recommended.\n\n#### **Example 1**\n\n- **ChatGPT:** A single red apple with a short stem standing upright on a smooth white surface against a plain white background.\n- **Microsoft Office:** A red apple with water drops on it\n- **Gemini:** A single, vibrant red apple with a short stem, slightly damp with water droplets, centered against a clean white background.\n\n#### Example 2\n\n- **ChatGPT:** A black apple-shaped logo with a bite taken out of one side, centered on a smooth silver-gray background.\n- **Microsoft Office:** A black apple logo on a white surface.\n- **Gemini:** A close-up of the iconic Apple logo, a bitten apple silhouette, centered on a brushed metal or gray surface, likely the lid of a MacBook or other Apple device.\n\n#### Example 3\n\n- **ChatGPT:** A surreal image of a green apple with its middle section sliced away to reveal bright yellow liquid inside, resembling juice. A snail is climbing on the top right side of the apple against a dark green background.\n- **Microsoft Office:** A snail on a green apple.\n- **Gemini:** A surreal composite image of a large green apple that appears partially filled with bright yellow-green liquid, as if the bottom half is a clear glass container. A small snail with a spiral shell is perched on the upper-right edge of the apple, looking toward the viewer. The background is a dark, moody green.\n\n### HTML Remediation (Forms, Links, and Buttons)\n\n- [Siteimprove AI] can generate suggested HTML fixes for flagged accessibility issues, such as missing ARIA roles or incorrectly built form fields.\n- [ChatGPT Edu] and other tools can produce accessible code snippets, but human knowledge is likely necessary to integrate the code into existing systems. As a learning tool, try querying ChatGPT Edu about WCAG-compliant code and the elements that make the HTML accessible. It has a surprisingly deep understanding of best practices and standards.\n- Review and manually test suggestions to ensure compliance before implementing changes.\n\n### Transcript and Caption Support\n\n- [Zoom AI Companion] offers live transcriptions and automated captioning for meetings and webinars held on Zoom. Individual users can adjust their captioning settings to allow for a comfortable font size.\n\n### Simplifying Text\n\n- Summarizing and outlining dense materials increases comprehension.\n- [NotebookLM] and [ChatGPT Edu] can simplify language and generate clear study materials.\n\n### Remediating Documents\n\n- Microsoft Office includes a built-in accessibility checker that can help make Word and PowerPoint files more accessible. This accessibility checker can suggest more readable text color combinations and slide layouts.\n- [Grackle Workspace] is an extension for Google Workspace that can help to remediate Google Docs, Slides, and Sheets and export more accessible PDFs. You already have access to this extension with your Andrew userID.\n\n## Limitations in Automated Remediation\n\n- **PDF Remediation:** Autotagging and automated PDF remediation still struggle with applying tags retroactively. While AI tools can expedite remediation by adding tags, many PDFs still require manual editing for elements such as reading order, alt text, and other aspects.\n- **Accessibility Overlays:** Automated systems known as accessibility overlays claim to resolve website issues by running as a plugin on top of existing code. They are notoriously unhelpful as they do not produce standards-compliant code, and often conflict with existing website technology. These tools often make websites harder to use with assistive technology. It is recommended to focus resources on building content correctly from the code and content creation levels, rather than relying on overlay solutions.\n\n## Alternative Formats\n\nOne way to ensure content is accessible to everyone is to produce it in multiple formats. For example, a lecture video should also include captions, an accompanying transcript, and a download of the slides shown in the video. In the next article, we will discuss tools available at CMU for generating accessible content and creating additional formats.\n\n## Other Articles in this Series\n\n- [AI and the Future of Accessibility] \n- [Using AI to Create Alternative Formats and Compliant Content] \n\n- [About] \n- [Computing Services Intranet] \n- [CSS Awards and Recognition] \n- [News] \n- [Service Status] \n\n[Log In to Services] \n\n- [Computing Services Help Center] \n- [412-268-4357 (HELP)] \n- [it-help@cmu.edu]",
    "length": 6690,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Which AI Tool Should I Choose? - Computing Services - Office of the CIO - Carnegie Mellon University",
    "url": "https://www.cmu.edu/computing/news/2024/ai-tools/which-tool-to-use.html",
    "text": "Which AI Tool Should I Choose? - Computing Services - Office of the CIO - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[Computing Services] ## [Office of the CIO] \n[Office of the CIO] &#160;&#8250;&#160;[Computing Services] &#160;&#8250;&#160;[Featured News] &#160;&#8250;&#160; 2024\n&#160;&#8250;&#160; ai-tools\n&#160;&#8250;&#160; Which AI Tool Should I Choose?\n![Photo of a woman shrugging, surrounded by question marks.] \n*October 31, 2024*# Which AI Tool Should I Choose?\n***A Quick Guide for CMU Community Members***\nAs generative AI becomes more common in academic and administrative life, you may wonder which tools you should use and for what purpose.&#160;\nHere&#8217;s a quick guide to help you learn the difference between common tools, which ones are currently available with your CMU account, and why you may use one over another.\n## Available with Your CMU Account\n### Microsoft Copilot\nCopilot is a generative AI chatbot that can help you summarize meeting notes, brainstorm new ideas, generate images and code samples, and more. Copilot is powered by OpenAI&#8217;s GPT-4 and DALL-E 3 models.\nWith Copilot, you can input your own prompts,**upload files**to interact with or use it in the Edge sidebar to**interact with webpages**. You can even**generate Microsoft Office files**, like documents, spreadsheets, and powerpoints, directly from Copilot.\nFor faculty, staff, and students over 18 years old,**Copilot protects your data**when you access it using your CMU account. Microsoft will not retain your prompts or responses to train its AI models. Just check for the white shield icon after you log in.\n[Try Microsoft Copilot] \n### ChatGPT Edu\nChatGPT, developed by OpenAI, is an advanced AI-powered chatbot that can help you synthesize information, summarize complex topics, conduct research, and generate new content, including text, code, and images. Use it to enhance your writing, brainstorming, studying, problem-solving, and more.\n**Faculty and staff can purchase ChatGPT Edu licenses through the university's software catalog.**\nChatGPT Edu offers:\n* FERPA-compliance &#8211; ChatGPT Edu is the only licensing option that meets FERPA requirements.\n* Simplified billing &#8211; CMU community members will pay for licenses using an Oracle string.\n[Try ChatGPT] \n### gemini.google.com\ngemini.google.com is another chatbot option similar to Copilot but powered by Google&#8217;s own large language models. With gemini.google.com, you can input prompts via text or**using your voice**and**upload files**to interact with.\n**gemini.google.com also provides data protection**for faculty, staff, sponsored accounts, and students over 18 years old when you log in with your CMU account. Google will not retain your prompts or responses to train its AI models.\n[Try gemini.google.com&#160;] \n### NotebookLM\nNotebookLM is a research and writing assistant and note-taking tool that allows you to**upload sources and create custom notebooks**to interact with using Google&#8217;s Gemini AI models. Upload PDFs, websites, videos, audio files, Google Docs, and more, and NotebookLM will help you summarize, make connections between sources, and generate new ideas.\nNotebookLM can even condense information from your sources into a**conversational podcast or FAQ**format!&#160;\nLike gemini.google.com,**NotebookLM provides data protection**for faculty, staff, sponsored accounts, and students over 18 years old when you log in with your CMU account. Google will never use your sources, prompts, or responses to train their AI models.\n[Try NotebookLM] \n### Zoom AI Companion\nAI Companion is an embedded tool accessible within Zoom. AI companion allows you to:\n* Create AI-generated meeting recaps, next steps, and in-depth summaries\n* Allow attendees to ask the AI questions if they miss something during a meeting\n* Create smart recordings with chapters and key highlights\n**AI Companion also provides data protection for faculty, staff, and students**when logged in with your CMU account. Zoom will not use your audio, video, chat, screen sharing, attachments, or any other data to train its artificial intelligence models.\n[Try Zoom AI Companion] \n## Available with a Personal Account\n### ChatGPT Free, Plus, Pro, and Teams\nIf you choose to use a ChatGPT Free, Plus, Pro, or Teams account, only enter information that you would share publicly online. OpenAI may retain your prompts and responses to train its AI models.\n[Try ChatGPT] \n# Explore the Software Catalog\nYou can see a complete list of software titles available to the CMU community, including these generative AI tools, in the[university software catalog]. And if you don&#8217;t see a tool you&#8217;re interested in using, you can[submit a software request].\n# Resources\n* [CMU Guidance for Using Generative AI] \n* [University Software Catalog] \n* [About] \n* [Computing Services Intranet] \n* [CSS Awards and Recognition] \n* [News] \n* [Service Status] \n[Log In to Services] \n* [Computing Services Help Center] \n* [412-268-4357 (HELP)] \n* [it-help@cmu.edu]",
    "length": 5108,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Leaves of Absence - \n                Office of the Vice Provost for Faculty - Carnegie Mellon University",
    "url": "https://www.cmu.edu/faculty-office/policies/leaves.html",
    "text": "Leaves of Absence - Office of the Vice Provost for Faculty - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[Office of the Vice Provost for Faculty] \n[Office of the Vice Provost for Faculty] &#160;&#8250;&#160;[Policies and Procedures] &#160;&#8250;&#160; Leaves of Absence\n# **Leaves of Absence**\nThe university offers various leave of absence options for faculty members to best accommodate those who require time away from campus.\n* [Family and Parental Leaves of Absence] \n* [Personal Leaves of Absence] \n* [Professional Leaves of Absence] \n* [Tenure Decision Deadline (TDD) Extension] \n# Resources\n* [Appointment and Tenure Policy] \n* [Family and Medical Leave] \n* [Faculty Time Away from Work] \n# Contact\n[facultyleaves@andrew.cmu.edu] \n## Family and Parental Leaves of Absence\nA regular faculty member (tenure-track, teaching-track, librarian and archivist-track and research-track) who is the parent of a newborn child, or who has adopted a child of preschool age, and who is the primary caregiver of the child, is entitled to a one-semester paid leave of absence. Teaching or other duties that would otherwise be carried out during the period of leave may not be shifted to other semesters against the wishes of the person taking such paid leave. Tenure-track faculty members without tenure who take a one-semester paid parental leave may, at their discretion, exclude one year from current service for the purpose of determining the tenure decision deadline. Reappointment and promotion clocks may be similarly delayed by one year for all regular faculty members taking one semester of paid parental leave.\nFamily and parental leave requests can be submitted at any time and will be reviewed on a regular basis.\nFor more information, please refer to the[Faculty Leaves Policy] and the[Faculty Parental Leave Policy].&#160;\n[To apply, complete the Faculty Parental Leave of Absence Application.] \n## Personal Leaves of Absence\nLeaves for personal circumstances are granted on either a half-time or a full-time basis. For example, a faculty member might request such leave to care for an ill, elderly parent. Additionally, such leave can be granted to support childcare.\nPersonal leave requests can be submitted at any time and will be reviewed on a regular basis.\nFor more information, please refer to the[Faculty Leaves Policy].&#160;\n[To apply, submit a completed Faculty Personal Leave Application to facultyleaves@andrew.cmu.edu.] \n## Professional Leaves of Absence\nThe university offers professional leaves to enable faculty members to develop professionally, whether the leave is supported in part by the university or wholly by external funds.\nFor more information, including eligibility requirements, please refer to the[Faculty Leaves Policy].&#160;\n[To apply, complete theFaculty Professional Leave of Absence Application.] \n## Tenure Decision Deadline (TDD) Extension&#160;\nTenure-Track Faculty requesting Parental Leave may also request an extension to their tenure decision deadline.&#160;Faculty members should work with their department head to discuss their options and complete the required Tenure Decision Deadline Extension form.\nFor more information on when leaves can be accompanied by extensions to the tenure decision deadline,&#160;view the[Faculty Leaves Policy],&#160;[Faculty Parental Leave Policy], and the[Appointment and Tenure Policy].&#160;\n[To apply, complete the Tenure Decision Deadline Extension Form.] \n* [COVID-19 TDD Extension Implementation Details]",
    "length": 3574,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "AI in Research Program",
    "url": "https://www.library.cmu.edu/service/ai-research",
    "text": "[Skip to main content] \n\n# AI in Research Program\n\n**Empowering the CMU community to use AI tools in research responsibly.** The AI in Research (AIR) Program is a new initiative from CMU Libraries that provides expertise, training, and a community of practice around the effective and responsible use of generative AI (GenAI) and other AI-powered tools to facilitate academic research. The program helps researchers explore AI tools, adopt best practices, and connect with peers using similar tools in scholarly work.\n\n### Program Scope\n\nThe program is designed for researchers interested in applying out-of-the-box AI tools – such as research assistants, data summarizers, or coding assistants – within the research process. Our services focus on helping researchers use these tools responsibly, rather than developing the AI models behind them.\n\n### Tool Assessment & Guidance\n\nWith new tools emerging constantly, it can be difficult to know which ones are effective or appropriate for your research. We are developing a **Tool Assessment Framework** to help CMU researchers understand whether a given AI-powered tool is suitable for their research needs. This framework helps to guide researchers as they explore AI-powered tools by considering factors such as:\n\n- Functionality and mechanism\n- Data sources and documentation\n- Output quality and reproducibility\n- Transparency, ethics, and privacy\n\nThis evolving framework aims to help students and researchers better understand a tool’s strengths, limitations, and potential risks before integrating it into your workflows.\n\n### Training & Capacity Building\n\nOur growing suite of **training workshops and resources** is designed to help researchers across all disciplines understand the foundations of using GenAI and other AI-powered tools effectively and responsibly:\n\n- What LLMs are good and bad at\n- Prompt design strategies\n- Avoiding common pitfalls (e.g., hallucinations, citations errors)\n- Improving reproducibility and transparency\n\nWorkshops are open to students, faculty and staff from all disciplines. Individuals with all skill levels and backgrounds are welcome, whether you’re just getting started or looking to deepen your AI literacy.\n\n###### Resources:\n\n- [**Artificial Intelligence Research LibGuide**] **:** Provides essential definitions of key artificial intelligence concepts and connects researchers to CMU Libraries' specialized resources, including research tools, datasets, and scholarly articles.\n- [**Generative AI LibGuide**] **:** Provides essential resources for understanding and effectively using AI tools in academic settings, covering prompt engineering techniques, ethical considerations, citation practices, and CMU-specific guidelines to support teaching, learning, and research applications.\n- [**TDM Guide**] **:** Libraries resources for Text and Data Mining **.**\n- [**Best Practices for Large Language Models**] **:** A curated selection of examples to get the best out of AI chatbots.\n- [**POEM**] **:** Metaliteracies.\n- [**CLEAR**] **:** A framework for prompt engineering.\n- [**Anthropic's Prompt Engineering Tutorial**] **:** An interactive tutorial that helps you understand how to engineer optimal prompts within Claude.\n\n[View all upcoming workshops].\n\n### Community & Peer Learning\n\nTo foster campus-wide collaboration and knowledge sharing, we’re hosting an **AI In Research Community of Practice**, a meetup event where students, faculty and staff can:\n\n- Ask questions about AI tools and best practices\n- Use and test tools collaboratively using a Tool Assessment Framework\n- Explore and share use cases specific to their field\n- Exchange learnings with other users\n\nEach session features a theme to guide discussion and interaction. These informal sessions are designed to create a low-barrier, peer-supported environment that encourages experimentation, insight sharing, and hand-on learning.\n\n- Time: **Noon - 2:00 pm, Every first Wednesday**\n- Location: **The Den, Sorrells Library**\n\n[Learn more & Register] \n\n### Our Team\n\n- [**Huajin Wang**], STEM Librarian\n- [**Sayeed Choudhury**], Associate Dean for Digital Infrastructure\n- [**Alfredo Gonzalez Espinoza**], Research Data Services Librarian\n- [**Thomas Hughes**], OSPO Community Manager\n- [**Haoyong Lan**], STEM Librarian\n- [**Kristen Scotti**], STEM Librarian\n- [**Emma Slayton**], Data Education Librarian\n\n### Primary Contact(s)\n\n### [Huajin Wang] \n\n##### STEM Librarian\n\n[**Manage**] \n\n### Manage Information & Data\n\nWork with our specialists to evaluate, select, and implement the tools to organize your data and keep your project on track.",
    "length": 4619,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Generative AI & Large Language Models",
    "url": "https://www.cmu.edu/online/gai-llm/tuition/index.html",
    "text": "Tuition Info for CMU's Online Graduate Certificate in Generative AI - Online Education - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[# Generative AI &amp; Large Language Models\nTuition\n] \n**[Curriculum] **\n**[ONLINE EXPERIENCE] **\n**[Admissions] **\n**[TUITION] **\n[Home] &#160;&#8250; Tuition# **Invest in Your Future**\nBy enrolling in our graduate-level program, you'll be investing in your professional growth to prepare for the next wave of Generative AI solutions. We know this is a significant investment. Not just for you, but for your family as well.&#160;\n### Scholarship Opportunities\nAll students who submit their application by the priority deadline will be considered for a partial scholarship&#160;to help offset the cost of tuition. If admitted to the program, the amount of your award will be communicated with your admissions letter.&#160;&#160;\nStudents who submit after the priority deadline may be eligible for any remaining scholarships that are still available. But we highly encourage you to apply by the priority deadline if you are interested in a scholarship award. &#160;\nIn addition, Carnegie Mellon alumni are eligible for a scholarship to the Graduate Certificate in Generative AI &amp; Large Language Models worth up to 20% of tuition. Indicate your alumni status within the application to be eligible.\n### **So, what is the investment per course?**\nBelow is a tuition breakdown for the 2025/2026 academic year:\n|Semester|Course|Units|Investment|\n**Spring 2026**\n|\nMultiomodal Machine Learning\n|\n12 units\n|\n$8,484\n|\n**Fall 2026**\n|\nLarge Language Models: Methods and Applications\n|\n12 units\n|\n$8,484\n|\n**Spring 2027**\n|\nLarge Language Model Systems\n|\n12 units\n|\n$8,484\n|\nTotal Investment\n|\n**$25,452**\n|\n**Additional Course-Related Expenses**\n* Large Language Models: Methods and Applications - in order to complete homeworks and activities, students will need to sign up for Amazon Web Services (AWS) or an equivalent service that offers access to A10g or similar GPUs. The AWS cost to complete assignments will range from $150-300 and will vary based on your usage. In addition, students&#160;will need to sign up for the OpenAI API. The cost to complete the assignments via OpenAI will be up to $25. Instructions&#160;for accessing both services will be provided when the class begins.\n* Multimodal Machine Learning and Large Language Model Systems - AWS and/or OpenAI or other services may be required for these courses with fees up to $300 per course. More details will be available as you get closer to the course start date.\n**University Fees**\n* A technology fee of approximately $240 will be assessed each semester (subject to change).\n**Additional Notes**\n* CMU measures coursework in units. Three units are equivalent to one credit hour.\n* The rates above are subject to change and are for the 2025/2026 academic year only. If the program is not completed within that time frame, tuition may increase slightly for the following academic year.## Monthly Payment Plan\nCMU provides a[monthly payment option], managed by Nelnet Campus Commerce, designed to help students spread out tuition payments into manageable monthly installments. This plan also offers the ease of online enrollment. Should you be admitted and choose to join us, we recommend registering for this plan early to fully benefit from the range of payment options available.\n### **Payment Plan in Action**\nMeet Jesse - he plans to start the program in the Fall and was awarded a $1,000 scholarship per course. Here's an example of what his tuition breakdown might look like with a payment plan:\n**FALL**|\n**Description**\n|\n**Tuition or Fee**\n|\nCourse: Large Language Model Systems\n|\n$8,484\n|\n&#160; &#160; &#160;Less Scholarship\n|\n-$500\n|\nTechnology Fee\n|\n$240\n|\nCloud Computing &amp; AI Tools Fee\n|\n$300\n|\nPayment Plan Enrollment Fee\n|\n$45\n|\n**Remaining Tuition &amp; Fees Due**\n|\n**$8,569**\n|\n20% Down Payment - Due Aug. 20\n|\n$1,713.80\n|\nPayment #1 - Due Sept. 1\n|\n$1,713.80\n|\nPayment #2 - Due Oct. 1\n|\n$1,713.80\n|\nPayment #3 - Due Nov. 1\n|\n$1,713.80\n|\nPayment #4 - Due Dec. 1\n|\n$1,713.80\n|\nBy taking advantage of the monthly payment plan option, Jesse can break tuition into smaller installments that he can pay throughout the semester.&#160;\n*Please note:&#160;[Nelnet payment plans] do not carry over from one semester to the next. Therefore, students must re-enroll and establish a new payment plan at the beginning of each semester.&#160;*\n## Financial Aid &amp; Private Loans\nStudents pursuing a graduate certificate are not eligible to receive federal financial aid. However,[private loans] are a viable alternative to consider with competitive interest rates and borrower benefits. See[FastChoice], a free loan comparison service to easily research options.\n## Employer Tuition Reimbursement\nUsing your company's tuition reimbursement benefits can help significantly offset the cost of tuition, especially if you start in the Fall and your tuition benefits restart every calendar year.&#160;&#160;&#160;\n### **Tuition Benefits in Action**\nMeet Casey - she plans to start the program in the Fall and was awarded a $1,000 scholarship per course. Her company provides $5,000 in tuition reimbursement per calendar year. Here&#8217;s an example of what her tuition breakdown could look like with tuition reimbursement benefits:\n**FALL**|\n**Description**\n|\n**Tuition or Fee**\n|\nCourse: Large Language Model Systems\n|\n$8,484\n|\n&#160; &#160; &#160;Less Scholarship\n|\n-$500\n|\nTechnology Fee\n|\n$240\n|\nCloud Computing &amp; AI Tools Fee\n|\n$300\n|\nTuition Reimbursement\n|\n-$5,000\n|\n**Remaining Tuition &amp; Fees Due**\n|\n**$3,524**\n|\n**SPRING**|\n**Description**\n|\n**Tuition or Fee**\n|\nCourse: Multimodal Machine Learning\n|\n$8,484\n|\n&#160; &#160; &#160;Less Scholarship\n|\n-$500\n|\nTechnology Fee\n|\n$240\n|\nCloud Computing &amp; AI Tools Fee\n|\n$300\n|\nTuition Reimbursement\n|\n-$5,000\n|\n**Remaining Tuition &amp; Fees Due**\n|\n**$3,524**\n|\n**FALL**|\n**Description**\n|\n**Tuition or Fee**\n|\nCourse: Large Language Models - Methods &amp; Applications\n|\n$8,484\n|\n&#160; &#160; &#160;Less Scholarship\n|\n-$500\n|\nTechnology Fee\n|\n$240\n|\nCloud Computing &amp; AI Tools Fee\n|\n$325\n|\n**Remaining Tuition &amp; Fees Due**\n|\n**$8,549**\n|\nAs you can see, Casey is maximizing her tuition reimbursement benefits across two calendar years, resulting in a personal contribution of $15,597.&#160;She can also use the payment plan to spread the cost out even further.\n### **Make a Case To Your Employer**\nIf your employer is hesitant about supporting the program, be sure to highlight the value and benefits of completing an online certificate at Carnegie Mellon. You can share that our program:&#160;\n* Consists of three&#160;[transcripted, credit-bearing courses] &#160;(not just continuing education units) taught by expert Carnegie Mellon professors from the nationally-ranked School of Computer Science.\n* Teaches you the latest advances in large language model systems, machine learning, natural language processing, and system research.\n* Prepares you to design and implement scalable systems for large language models and teaches you how to efficiently train them with huge data sets, which is critical for advancing AI.\n* Trains you to determine the best model for a given task by evaluating the pros and cons of different models.\n* Empowers you to solve sophisticated engineering problems with modern hardware and software stacks that can accommodate the scale of large language models.\n* Is delivered&#160;[completely online], which means you can take classes on your own time while maintaining your normal work schedule.\nNot sure how to approach your employer? Need specific documents to proceed with enrollment?&#160;[Contact a Program Specialist] &#160;for assistance. If you&#8217;re ready to make more data-informed decisions, we&#8217;re here to help you make that a reality.\n## CMU Employee Tuition Reimbursement\nThe Graduate Certificate in Generative AI &amp; Large Language Models is eligible for CMU tuition remission. Review the&#160;[CMU tuition remission policy] &#160;to check your eligibility.\n## G.I. Bill Funding\nCarnegie Mellon University provides services to veterans and their dependents who are eligible for Veterans Education Benefits under the Montgomery G.I. Bill&#174;, Post-9/11 G.I. Bill, and Vocational Rehabilitation and Employment Program. Please note, our online graduate certificates are not currently eligible for the Yellow Ribbon program.&#160;\nThe process starts with an application directly to Veterans Affairs and once approved, you will provide your Certificate of Eligibility to the Carnegie Mellon Veterans Affairs Coordinator.&#160;[Contact Information and additional details about the process can be found here.] \nStudents eligible for GI Bill funding may receive scholarship awards prior to full GI Bill funding confirmation. Scholarship awards will be adjusted to reflect GI Bill funding and cannot exceed the cost of tuition/fees.\n# At a Glance\n**Next Start Date**\nFall 2026\nPriority Deadline\\*: January 28, 2026\n\\*All applicants who submit by the priority deadline will receive a partial scholarship award.\n**[Request Information] **\n**[Apply Now] **\nQuestions? There are two ways to contact us. Call412-501-2686&#160;or send an email to[apply@online.cmu.edu] &#160;with your inquiries.\n### **[FREQUENTLY ASKED QUESTIONS] **",
    "length": 9438,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Advancing Student Learning at CMU Through Generative AI - Dietrich College of Humanities and Social Sciences - Carnegie Mellon University",
    "url": "https://www.cmu.edu/dietrich/news/news-stories/2023/october/ed-ai.html",
    "text": "Advancing Student Learning at CMU Through Generative AI - Dietrich College of Humanities and Social Sciences - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[Dietrich College of Humanities and Social Sciences] \n[Dietrich College of Humanities and Social Sciences] &#160;&#8250;&#160;[News] &#160;&#8250;&#160;[News Stories] &#160;&#8250;&#160;[2023] &#160;&#8250;&#160;[October] &#160;&#8250;&#160; Advancing Student Learning at CMU Through Generative AI\n*October 25, 2023*# Advancing Student Learning at CMU Through Generative AI\nBy Michael Henninger\nCarnegie Mellon University&#8217;s Eberly Center for Teaching Excellence and Educational Innovation is launching a Generative Artificial Intelligence Teaching as Research (GAITAR) Initiative, which will include several new efforts to bring generative AI to classrooms across CMU. The Center launched a series of GAITAR Institutes to promote instructor-led innovations and educational research designs across diverse contexts. Additionally, the Eberly Center is now seeking applicants for its GAITAR Fellowship 2023.\nNew to the Eberly Center&#8217;s portfolio of offerings, the GAITAR Fellowship provides $5,000 for a CMU instructor to design and implement a teaching innovation using a generative AI tool in a spring, summer or fall 2024 CMU course. They must then measure the impacts of the innovation on student learning and disseminate their findings at CMU and beyond. The deadline for applications is Nov. 1.\nThe fellowship aims to incentivize and lower barriers to innovation, implementation and the dissemination of educational research findings.\n&#8220;In many ways, CMU is the birthplace of both learning science and AI and machine learning, dating back to the Newell and Simon days,&#8221; said James H. Garrett Jr., CMU&#8217;s provost and chief academic officer. &#8220;If anybody should be advancing the research and application of AI in education, it should be Carnegie Mellon. We embrace this as an inflection point to take these tools and new ways of thinking to enhance our teaching and learning strategies.&#8221;\nThe Eberly Center recently finished delivering a GAITAR Institute on campus, a four-session program that generated ideas for teaching innovations implementing generative AI in CMU courses, preparing instructors to study the results with tangible Eberly Center support from start to finish.\nSince 1996, the Eberly Center has brought pedagogical and technological issues together to support Carnegie Mellon faculty and graduate students in their roles as educators. The center, which fosters a culture of experimentation, innovation and iterative improvement through collaboration, approaches the use of AI with empirical questions &#8212; where do AI tools enhance student learning and experience? What do students consider as the benefits and tradeoffs of using AI? How can equitable access and outcomes be ensured when using AI?\nCMU&#8217;s University Education Council will be convening town hall sessions in early November to hear students' and educators' perspectives on the most pressing needs and opportunities related to AI and its potential for impact on education. The full spectrum of community input will inform broader university strategies to advance the applications of generative AI in education.&#160;\n&#8220;Many articles have shared that education is being upended by these new tools,&#8221; said Amy Burkert, vice provost for education. &#8220;There are, indeed, many changes taking place, but the question is, &#8216;How can we help our community leverage that potential into an asset rather than a cause for concern?&#8217;&#8221;\nThe theme of the Eberly Center&#8217;s 7th annual Teaching and Learning Summit, held on Sept. 21, was &#8220;Adapting to Generative AI in Teaching.&#8221; During the Summit,&#160;faculty members from the Heinz College of Information Systems and Public Policy, the Dietrich College of Humanities and Social Sciences, and the Human-Computer Interaction Institute discussed their use of AI in the classroom.\n[![Embedded YouTube video]] \nWe want to make sure that our entire community&#8217;s voices are heard, especially those of our students so we can better understand their most pressing needs and the exciting opportunities they see related to generative AI,&#8221; Burkert said.\n&#8220;We are taking a very scientific approach to this &#8212; a learning science approach,&#8221; said Marsha Lovett, vice provost for teaching and learning innovation and co-coordinator of The Simon Initiative, CMU&#8217;s learning-engineering ecosystem that works to improve student learning outcomes. &#8220;We are actively supporting our faculty members to lean in, learn about generative AI, and incorporate it into their teaching where it can benefit students. On top of that, we are actively supporting faculty to study its impacts on student learning and the student experience. We must continue to be data-informed on this.&#8221;\nThe work to apply generative AI tools and techniques in the classroom is only one part of a broader university strategy to advance the next generation of artificial intelligence&#8217;s impact across education, research and society. The university has been increasingly called upon for its AI expertise by public and private sector partners. Most recently, Gov. Josh Shapiro visited CMU to announce an executive order on the use of generative AI in Commonwealth agencies. CMU&#8217;s Block Center for Technology and Society one of the nation&#8217;s leading research centers working to shape the impact of these technologies, will partner with the Shapiro administration on this effort.&#160;\n![James H. Garrett, Jr. headshot] \n*James H. Garrett, Jr.*\n*![Amy Burkert headshot] \nAmy Burkert\n*\n*![Marsha Lovett headshot] \nMarsha Lovett*\n* [CMU Directory] \n* [Contact] \n* [Dietrich College Calendar] \n* [Site Map]",
    "length": 5946,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Motional puts AI at center of robotaxi reboot as it targets 2026 for driverless service - Safety21",
    "url": "https://safety21.cmu.edu/2026/01/19/motional-puts-ai-at-center-of-robotaxi-reboot-as-it-targets-2026-for-driverless-service/",
    "text": "Motional puts AI at center of robotaxi reboot as it targets 2026 for driverless service - Safety21[Skip to content] \n[![]] \n* [Contact] \n* [Support Our Work] \n* [Impacts] \n* [Accomplishments] \n* [US DOT Reports] \n* [About Us] \n* [Executive Leadership] \n* [Student Leadership] \n* [Faculty] \n* [Academic Partners] \n* [Advisory Council] \n* [Deployment Partners] \n* [Carnegie Mellon University Affiliates] \n* [What We Do] \n* [Policy Papers] \n* [Research] \n* [Education &#038; Workforce Development] \n* [Technology Transfer] \n* [Spin-Off Companies] \n* [Collaboration] \n* [What’s Happening] \n* [Featured] \n* [Seminars] \n* [Stories] \n* [Projects] \n* [Safety21 Projects—2025 –2026] \n* [Research Recaps] \n* [Project Archive] \n* [For Students] \n* * * [Carnegie Mellon University] \n* [Get Involved] \n* [Opportunities for Student Involvement] \n* [Transportation Club] \n* [Other Transportation Groups] \n* [Coursework at CMU] \n* [Project Courses for Potential Safety21 Projects] \n* [Internships &#038; Job Opportunities] \n* [Student Alumni] \n* * [The Ohio State University] \n* [Campus Transit Lab] \n* [Center for Automotive Research] \n* [EcoCAR] \n* [Smart Campus Student Organization] \n* * [University of Pennsylvania] \n* [Penn Transportation Club] \n* * * [Morgan State University] \n* [Transportation &#038; Urban Infrastructure Studies (TUIS)] \n* [Community College of Philadelphia] \n* [Community College of Allegheny County] \n* [University of Texas –Rio Grande Valley] \n* [Events] \n* [2026 National Safety Summit of US DOT University Transportation Centers] \n* [2025 Safety21 Deployment Partner Consortium Symposium] \n* [2025 National Summit on AV Leadership] \n* [Smart Safety Connection Seminar Series] \n* [U.S. DOT Future of Transportation Summit] \n* [Future of Transportation Summit Networking Event] \n* [News] \n* [Industry News] \n* [Safety21 News] \n* [Impacts] \n* [Accomplishments] \n* [US DOT Reports] \n* [Support Our Work] \n* [Contact] \n# Motional puts AI at center of robotaxi reboot as it targets 2026 for driverless service\n[Home] »[Industry News] »Motional puts AI at center of robotaxi reboot as it targets 2026 for driverless service\nNearly two years ago, Motional was at an autonomous vehicle crossroads. The company, born from a $4 billion joint venture between Hyundai Motor Group and Aptiv, had already missed a deadline to launch a driverless robotaxi service with partner Lyft. It had lost Aptiv as one of its financial backers… Several layoffs…had whittled the company from its peak of about 1,400 employees to less than 600.\n…Motional was going to have to evolve or die. It paused everything and picked option No. 1. Motional told TechCrunch it has rebooted its robotaxi plans with an AI-first approach to its self-driving system and a promise to launch a commercial driverless service in Las Vegas by the end of 2026. The company has already opened up a robotaxi service —with a human safety operator behind the wheel —to its employees. …By the end of the year, the human safety operator will be pulled from the robotaxis and a true commercial driverless service will begin, the company said.\n[Read More &gt;] \n## Receive Our Newsletter\nGet the latest Safety21 news sent to your inbox.\nFirst Name\nEmail Address\\*\nSubscribe",
    "length": 3230,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "CMU Examines How AI Tools Are Reshaping Learning for Both Teachers and Students",
    "url": "https://www.cmu.edu/news/stories/archives/2025/april/cmu-examines-how-ai-tools-are-reshaping-learning-for-both-teachers-and-students",
    "text": "CMU Examines How AI Tools Are Reshaping Learning for Both Teachers and Students - News - Carnegie Mellon University\n[Skip to main content] \n[Carnegie Mellon University homepage] \nSearch Carnegie Mellon UniversitySearch\nMenu\n[News] \n![Students take part in their class on mobile apps design and development] \n*April 3, 2025*# CMU Examines How AI Tools Are Reshaping Learning for Both Teachers and Students\n## * [Share on Facebook (opens in new window)] \n* [Share on X (opens in new window)] \n* [Share on LinkedIn (opens in new window)] \n* Print this page\n* [Share by email] \n**By:**Caroline Sheedy[Email] \nMedia Inquiries\n**\nName\nCassia Crogan**\nTitle\nUniversity Communications &amp; Marketing\n[Email] \nPhone\n[412-268-9295] \nGenerative AI is becoming an integral part of college life, whether through formal coursework or self-guided learning. As students and instructors learn the evolving technology together, they must navigate big questions, like whether the artificial intelligence tools students use are actually helping them learn or if access to the tools is equitable. At Carnegie Mellon University, an initiative to research the impacts of generative AI tools on teaching and learning is helping the university take an empirical approach to studying whether, when and how generative AI can have a positive effect on student outcomes.\n“Before we can productively govern AI tools in education, we need to understand their impacts,” said[Marsha Lovett(opens in new window)], CMU’s vice provost for teaching and learning innovation.\nLovett’s colleagues at the[Eberly Center for Teaching Excellence and Educational Innovation(opens in new window)] started the[Generative Artificial Intelligence Teaching as Research (GAITAR)(opens in new window)] initiative to lower the barriers to innovating with AI and systematically collect data on those innovations. GAITAR forms a community of practice around the technology by providing education, consultation and support for research comparing what happens when AI is incorporated in a course to when it is not.\n“It is important to collect rich data on the key student behaviors and outcomes we care about during these innovations in order to promote exploration and refinement of more promising directions,” Lovett said.\nAs faculty formally incorporated AI into their courses, the results showed there is a lot to learn about how to use AI tools effectively.\n## Taking a second look at art\n[Scott Andrew(opens in new window)], an adjunct professor of art, teaches an AI based generative animation course for CMU’s[School of Art.(opens in new window)] Andrew uses AI tools in his own animation work and was curious to see how students could pull from past experience and gain control over the aesthetics and technical aspects of animations created through AI tools.\nThrough the GAITAR initiative, Andrew’s class did a comparative project where students brought in previous animations they had created without the use of AI. He asked them to rethink and recreate those projects utilizing a suite of programs including Runway, Deforum Stable Diffusion, ChatGPT, ElevenLabs, Midjourney and Dall-E.\nAndrew saw a range of uses —some students tried to use AI to make animations identical to their original art, some did a “style transfer,” using AI to shift the aesthetics of their originals, and pulled conceptually from their originals to create something that looked very different.\nThrough repeated practice, students gained confidence and self-efficacy in the ability to work with AI tools to make an animation.\n**Work by I Lok U, a student in Andrew’s class.**\nAndrew acknowledged that using AI for art is complicated.\n“Lots of artists are really nervous about that, or very angered by it, because there's a lot of blurry areas when it comes to things like intellectual property,” he said. “I'm of multiple minds about it, but I do think that students today need to learn what it is and how to work with it, because it's going to be expected within the industry.”\n![Marsha Lovett] \n*Marsha Lovett*\n>  >  >  >  [> (opens in new window)\n] \n[> View this post on Instagram\n> (opens in new window)\n] \n>  >  >  >  >  >  >  >  >  >  >  [> A post shared by Carnegie Mellon’s Heinz College (@heinzcollege)\n> (opens in new window)\n] \n*Heinz College Professor and GAITAR fellow*[*Jordan Usdan*(opens in new window)] *created a clone of himself for his Generative AI course, allowing students to interact with an AI model that was trained on the course's curriculum.*\n## Making decisions about when to use AI\n[Fethiye Ozis(opens in new window)], an associate teaching professor of[civil and environmental engineering(opens in new window)], wanted to see if AI tools like Perplexity or ChatGPT could help her students improve their data science skills.\n![Fethiye Ozis] \nFethiye Ozis\nAs part of a project in one of Ozis’ undergraduate courses, students analyzed air quality data from sensors they placed on campus. They were asked to use the data to identify patterns for the best week and time of day to host an outdoor activity, compare the air quality of newer and older buildings on campus, and answer other research questions. The sensors collected information every two minutes, leaving the students with massive amounts of data to interpret.\n“The first two times I taught the course, AI tools were not available,” Ozis said. “My first impression was that students were not necessarily prepared to deal with the amount of data the sensors collected.”\nOzis wanted to know how using AI tools would impact students’ skills for data processing, cleaning and visualization, and better understand students’ attitudes about using AI tools for these tasks.\nThough the number of students who participated was small, performance data showed no difference between students who chose to use AI tools compared to those (from the same class and a prior cohort) who did not. Interestingly, when students had the option to use AI, 44% chose not to, citing reasons related to critical evaluation of the tools’ utility and confidence in their own data skills. This result opens further questions about what factors influence students’ decisions to use AI tools or not, and how we can prepare students to make well-informed decisions.\n## Optimizing classroom time for AI education\nWhether students need to be instructed on how to use AI tools is another question.[​​Emily DeJeu(opens in new window)], an assistant teaching professor at CMU’s[Tepper School of Business(opens in new window)], spent a significant amount of time developing materials to teach her business communication undergraduates to effectively use tools like Microsoft CoPilot. She wanted to figure out productive use cases that would improve both their work and learning outcomes. After about a year, she wasn’t sure if it was making a difference.\n![Emily DeJeu] \nEmily DeJeu\nDeJeu collaborated with the Eberly Center team to design a research project to assess how AI instruction about the utility of LLMs for assisting students’ growth and development as communicators influenced their writing ability and perceptions of these tools' usefulness in workplace communication.\nShe found that writing quality improved when students were permitted to use generative AI. However, this does not necessarily indicate that students’ underlying writing skills improved. In this particular course, adding targeted instruction about AI itself did not increase students’ writing quality or impact students’ perceptions about how helpful genAI is for their growth or efficiency as communicators.\n“I think my big takeaway is that I didn’t have to spend a ton of time teaching students how to use AI tools, but I did need to spend some time thinking about how to design assignments that don't privilege AI use,” DeJeu said.\nDeJeu noted that she thinks it’s important for teachers to teach their students how to use AI ethically.\n“Even though students don't seem to need instruction in use cases, they probably need guidance on things like ethical authorship. That is not something that an 18-20 year old would have. I very much advocate for carving out time to talk about that,” she said.\n## Using AI for giving and receiving feedback\n[Alan Thomas Kohler(opens in new window)], a senior lecturer in the[Writing and Communication Program(opens in new window)] in CMU’s[Dietrich College of Humanities and Social Sciences(opens in new window)], wanted to experiment with how AI tools could be engaged in the writing process. Kohler teaches a professional and technical communication course for computer science majors. Giving and receiving feedback is a core component of the course.\n![Alan Thomas Kohler] \nAlan Thomas Kohler\n“We reinforce the idea that peer review is good for both the giver and the receiver of feedback equally,” he said. “There is value in centering your reader by getting an understanding of the reader's experience of your text, but there is also value in thinking about the choices that other people make for a given assignment, how those choices differ from your own, and what you might learn from those differences.”\nKohler wanted to know if there was potential for AI tools to support peer review. Over two semesters, he incorporated a standardized prompt that students could use with Copilot to get feedback on their projects, which included cover letters, persuasive emails and communication plans. While the results of Kohler’s research so far do not show benefits to students' learning or performance, he plans to continue to use and study AI tools.\n“I'm very interested in this field and all the different ways that generative AI can be used. We can engage with it and embrace it in ways that are beneficial to our students and don't replace their learning,” he said.\n## **Shaping future learning outcomes**\nThese projects are four of many ongoing at CMU. Lovett said she thinks the GAITAR projects will have a long-term impact at the university.\n“I really hope that, with such studies becoming part of our standard practice in higher education, we can be more informed as we explore novel applications of AI and even consider changes at the systems level in terms of the degree programs we're offering, our approaches to assessment and offering greater opportunity for student access and equitable outcomes,” she said.\n![GAITAR cycle] \nGAITAR fellows investigate whether generative AI tools increase, decrease or do not change student learning and equity.\n[Learn more about their work(opens in new window)] \n## —Related Content —[\n![Jim Garrett] \n## Advancing Student Learning at CMU Through Generative AI\n] \n[\n![Farnam Jahanian and Josh Shapiro] \n## Shapiro Unveils AI Pilot Program Results at Carnegie Mellon\n] \n[\n![CMU's Gates-Hillman Complex] \n## Carnegie Mellon University and Google Public Sector Partner To Accelerate AI Research with Extensive GPU Cloud Deployment\n] \n* [The Piper: Campus &amp; Community News(opens in new window)] \n* [Official Events Calendar(opens in new window)] \n▴scroll to top",
    "length": 11010,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Propose A Capstone Project -     Engaging with Dietrich College -     Dietrich College of Humanities and Social Sciences - Carnegie Mellon University",
    "url": "https://www.cmu.edu/dietrich/partners/projects.html",
    "text": "Propose A Capstone Project - Engaging with Dietrich College - Dietrich College of Humanities and Social Sciences - Carnegie Mellon University\n[Carnegie Mellon University] [**&#8212;****&#8212;****&#8212;**] SearchSearchSearch this site only\n# [Engaging with Dietrich College] \n## [Dietrich College of Humanities and Social Sciences] \n# Capstone Projects\nReceive both recruitment and research benefits for your organization by sponsoring a semester-long capstone project.\n[Dietrich College of Humanities and Social Sciences] &#160;&#8250;&#160;[Engaging with Dietrich College] &#160;&#8250;&#160; Propose A Capstone Project\n# A Hotbed for Experiential Learning\nWe at Dietrich College believe the application of coursework to real-world scenarios is essential to our students' education. Capstone projects do just that. Sponsoring a capstone project not only helps our students gain valuable experience, but it allows you to learn from the fresh knowledge of advanced Dietrich College students and introduces your company to full-time job seekers who will be entering the market.\nAll Dietrich College capstone projects are...\n* Led by a faculty member with domain expertise.\n* Teams of 3-5 talented students from Dietrich College's diverse student body.\n* One semester in length.\n# Examples of Excellence\n### Principal Financial Group partners with CMU students to revolutionize retirement, insurance and asset management spaces.\nStudents in the Department of Statistics and Data Science built a statistical model that combines real estate returns with accurate predictions in diverse markets across different property types using real-world data from Principal Financial Group.\nThis partnership was the first to support concurrent student projects in one semester across three of Carnegie Mellon's colleges &#8212;&#160;the Dietrich College of Humanities and Social Sciences, Tepper School of Business and Heinz College of Information Systems and Public Policy.\n\"When it comes to cross-campus collaboration, Carnegie Mellon University puts it to practice, and it's immensely powerful,\" said Joseph Byrum, Principal's chief data scientist.&#160;\n[REad more about OUR partnership WITH PRINCIPAL FINANCIAL GROUP] \n### Graduates partner with SESCO Enterprises, LLC to tackle the energy market.\nStudents completing their Master of Statistical Practice at Carnegie Mellon University selected a project aiming to improve forecasting in the power system. Sabrina Zhu and two of her colleagues joined SESCO Enterprises, LLC, a FERC-registered power marketer, on this project. To examine this process, Zhu and her colleagues built a regression model using historical data to simulate market conditions.\n\"We did not expect [the team] to solve the problem completely, instead, we hoped they can be creative and thoughtful on designing their approach. They have exceeded all expectations,\" said Jian Shu, manager of quantitative trading at SESCO Enterprises, LLC.\n\"Students can truly understand what it means to work in data science on actual industry problems, with real data, with a real industry client, while industry partners can tap into the fresh perspectives provided by these highly capable and expertly trained modern data scientists,\" said Jamie McGovern, Special Faculty, director of the Master of Statistical Practice Program.\n[Read more about OUR PARTNERSHIP WITH SESCO ENTERPRISES, LLC] \n# Propose a Capstone Project\nFirst Name\nLast Name\nEmail\nCompany\nTitle\nReferred By\n--None--Business Engagement CenterCPDCDietrich Sta&#64256;/FacultyGoogleLinkedInOther\nComments:\n# Also Consider...\nOpportunities to recruit. Once students learn more about your organization through a capstone project, they often have a growing interest in the type of work you do.\n[Learn More about Recruitment at Dietrich College] \nNot sure where to begin? Reach out and we'll provide more personalized assistance on how to engage with Dietrich College.\n**Adam Causgrove**\nAssociate Director of Corporate Relations\n814-397-6388\n[causgrove@cmu.edu]",
    "length": 4019,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "CMU Collaborates on Project To Develop Future Robotic Wheelchair",
    "url": "https://www.cs.cmu.edu/news/2025/arpah_wheelchair",
    "text": "CMU Collaborates on Project To Develop Future Robotic Wheelchair\n# [![] Carnegie Mellon University School of Computer Science] \n[Skip to Main Content] Search**\nSearch**\n# CMU Collaborates on Project To Develop Future Robotic WheelchairCarnegie Mellon Robotics Institute Team Will Integrate Robotic Arm Into Design\nAaron AupperleeTuesday, November 4, 2025[**Print this page.] \n![] The Robotic Caregiving and Human Interaction Lab inside the School of Computer Science’s Robotics Institute will spearhead the software integration of a robotic arm into the wheelchair design as part of an Advanced Research Projects Agency for Health project.\nCarnegie Mellon researchers will collaborate on a federally funded project to wholly rethink and redesign wheelchairs to incorporate new technologies and offer greater mobility.&#160;\nThe[Robotic Caregiving and Human Interaction Lab] inside the School of Computer Science's[Robotics Institute] (RI) will spearhead the software integration of a robotic arm into the wheelchair design to assist people with grasping objects, opening doors and other chores and tasks both in and outside the home.\n\"The central idea is to make the future of wheelchairs,\" said[Zackory Erickson], an assistant professor in the RI and head of the Robotic Caregiving and Human Interaction Lab. \"The wheelchair will be built around the robotic arm. If people are going shopping, they can use the arm to pick items off the shelf. If they are in their homes, they can clean their dishes, do laundry, water plants and more with their robotic wheelchair.\"\nThe[University of Pittsburgh will lead the project], which is funded up to $41.5 million by the[Advanced Research Projects Agency for Health] (ARPA-H) project, to develop the Robotic Assisted Mobility and Manipulation Platform (RAMMP) system. The platform will use next-generation robotics and new assistive technology to reimagine a wheelchair and assistive robotic arm that will improve the independence, safety and quality of life for people with disabilities, including veterans. In addition to Pitt and CMU, the project also includes Northeastern University, Cornell University, Purdue University and companies ATDev, Kinova Robotics and LUCI Mobility.&#160;\nThe new wheelchair will integrate advanced robotics, artificial intelligence, a novel operating system and digital twin technology. The RAMMP system will advance the design of powered mobility and manipulation devices by improving their function, obstacle detection and negotiation abilities. It will also seamlessly integrate with robotic arms for more effective object interaction. Its real-time, 360&#176; environmental awareness and adaptive control features will allow users to navigate complex environments with enhanced capabilities, confidence and safety.\n\"Most powered wheelchairs aren't designed to overcome many of the common challenges in the real world &#8212; and changing the environment to accommodate them is nearly impossible,\" said[Rory Cooper], founding and current director of Pitt's[Human Engineering Research Laboratories], and a co-lead of the project. \"We need smarter technology that prevents tipping and falling, improves mobility, and adds more function such as coordinated mobility and robotic arm manipulation of objects so people with disabilities can fully participate in everyday life.\"&#160;\nCMU researchers will focus on the robotic arm. While some wheelchairs already have robotic arms, they are often bolted on after the fact and not integrated into the overall design. This robotic arm will be part of the wheelchair design from the beginning, and the CMU team will apply advances in robot learning, simulation, autonomy and advanced sensing to make it easier to use.\nThe CMU team will develop and refine algorithms to control the robotic arm mounted on the wheelchair. They'll also create a digital twin of the wheelchair to test its functionality and train it in a simulated environment.&#160;\nRobotic arms and grippers can be tricky and tedious to control manually. Using a robotic arm with a joystick to grab an item off a shelf in a grocery store or turn a doorknob in the home could take as long as three minutes, and being even a centimeter off could mean pushing objects around or having an unsteady grip. The automated assistance developed by CMU researchers could help align the gripper or perform other precise movements.&#160;\n\"Precision is really important for a lot of these tasks,\" Erickson said. \"We want to enable some underlying intelligence in the system with shared control between the arm and the user. If we can automate some level of manipulation assistance using robot learning methods and shared control techniques, we can make it easier to operate &#8212; not tedious or slow.\"\nThe CMU researchers will also develop and integrate new sensors into the arm to further enhance the capabilities of the robotic arm. While cameras will be essential for allowing the arm to locate and align with objects, other tactile and haptic sensors could be used to perceive force, temperature and vibration or to use a touchscreen and other interfaces.&#160;\nFinally, the CMU team will test the new wheelchairs with individuals who have disabilities. The studies will test the new technologies, specifically the robotic arm, sensors and control algorithms, in scenarios such as shopping and performing household chores. The CMU team will meet regularly with users and stakeholders and gather critical feedback to better understand their needs and provide data to the broader project team.&#160;\nThe Robotic Caregiving and Human Interaction Lab is no stranger to developing assistive technologies. Past projects in the lab have sought to create robotic systems to assist with getting dressed, hanging up laundry and eating. The lab even designed a head-worn assistive teleoperation (HAT) device &#8212; an experimental interface to control a mobile robot &#8212; and spent a week[testing it in the home of a person with quadriplegia].\n[![Embedded YouTube video]] \nThis research was funded, in part, by ARPA-H. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the U.S. government.\n**For More Information**\nAaron Aupperlee | 412-268-9068 | aaupperlee@cmu.edu",
    "length": 6363,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Carnegie Mellon Announces Online Graduate Certificate To Master Generative AI, LLMs",
    "url": "https://www.cs.cmu.edu/news/2024/generative-AI-certificate",
    "text": "Carnegie Mellon Announces Online Graduate Certificate To Master Generative AI, LLMs\n# [![] Carnegie Mellon University School of Computer Science] \n[Skip to Main Content] Search**\nSearch**\n# Carnegie Mellon Announces Online Graduate Certificate To Master Generative AI, LLMs\nAaron AupperleeTuesday, July 23, 2024[**Print this page.] \n![] SCS faculty will teach the latest and most advanced techniques in generative AI, large language models and multimodal machine learning as part of CMU's new online Graduate Certificate in Generative AI and Large Language Models.\nGenerative artificial intelligence didn't write this, but would anyone be surprised if it did?\nIn just a few years, the development and applications of generative AI and large language models (LLMs) have exploded, finding their way into how people work, create, and interact with technology and each other. It's everywhere, and it's growing.\nTo master this emerging and game-changing technology, Carnegie Mellon University has launched a new, online[Graduate Certificate in Generative AI and Large Language Models]. Faculty from CMU's School of Computer Science will teach the latest and most advanced techniques in generative AI, large language models and multimodal machine learning.\n\"Generative AI is reshaping the technology landscape,\" said[Carolyn Rose], the certificate's faculty program director and a professor in both the[Human-Computer Interaction Institute] and the[Language Technologies Institute]. \"If you want to contribute to its evolution and make an immediate impact in your organization, now is the time to enhance your expertise.\"\nGenerative AI and LLMs went mainstream in late 2022, when the first chatbot powered by these tools was released. More models, chatbots, and image and video creators quickly followed. But SCS had been working with generative AI and LLMs for years. They pioneered their development; discovered early applications; and continue to push for safety, security, ethics and responsible use as the tools progress.\nThe 12-month program includes three credit-bearing, graduate-level courses. In the online courses taught live by world-renowned faculty, program participants will develop foundational skills for understanding, working with, and adapting existing tools and technologies; explore the fundamental mathematical concepts in machine learning and deep learning; and learn how to design and implement scalable LLM systems. Applicants should have a degree in computer science or a related field, proficiency in applied math and statistics, Python programming expertise, and machine learning and deep learning experience.\nApplications are open. For more information, visit the[Graduate Certificate in Generative AI and Large Language Models website].\n**For More Information**\nAaron Aupperlee | 412-268-9068 | aaupperlee@cmu.edu",
    "length": 2838,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Learn More - Online Education - Carnegie Mellon University",
    "url": "https://www.cmu.edu/online/gai-llm/learn-more/",
    "text": "Learn More - Generative AI Online Graduate Certificate - Online Education - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n# CMU Online Graduate Certificate\nGenerative AI and Large Language Models\nThis is not your average AI online certificate.\nRigorous coursework**at CMU's School of Computer Science**&#160;equips you to implement and scale generative AI solutions - guided by the same experts advancing the field.&#160;\nWe are #1 in AI for a reason. Are you ready?\n**Download the Program Tech Sheet**\n*Get details about the curriculum, course format, and tuition by submitting the form below.*\nLoading...\n## **![] **\n## **Key Program Features**\n![] **Taught Live-Online by CMU Faculty&#160;**in CMU&#8217;s School of Computer Science, ranked #1 in the nation for AI and computer science graduate programs and programming languages courses.\n&#160;\n![] **Designed for Working Professionals&#160;**with weekly, live-online sessions&#160;in the evening (ET) and asynchronous coursework you can finish on your own time, at your own pace.&#160;\n&#160;\n![] **Engaging Educational Experiences&#160;**that go beyond recorded lectures. Active learning sessions will help you master key concepts so you can immediately apply them at work.\n&#160;\n![] **Consistently ranked among top AI programs.&#160;**CMU is ranked #1 in the Nation for AI graduate programs, programming languages courses, and computer science graduate programs.&#160;\n&#160;\n&#160;\n# Program Highlights\nDelivered 100% online\nTaught by expert CMU faculty\n3 graduate-level courses\n12 months to complete\n36 units total (&#126;12 credits)\nStart in Fall or Spring\nMonthly payment plans\nG.I. Bill eligible program\n# World Class Faculty from CMU's School of Computer Science\n![Dr. Carolyn Rose] \n[] **[Dr. Carolyn Ros&#233;] **\n*Professor of Language Technologies and Human-Computer Interaction*\n**Education:**Ph.D., Carnegie Mellon University&#160;\n![Dr. Daphne Ippolito] \n[] **[Dr. Daphne Ippolito] **\n*Assistant Professor of Language Technologies*\n**Education:**Ph.D., University of Pennsylvania&#160;\n![Dr. Lei Li] \n[] **[Dr. Lei Li] **\n*Assistant Professor of Language Technologies*\n**Education:**Ph.D., Carnegie Mellon University&#160;\n![louis-philippe-morency.jpg] \n[] **[Dr. Louis-Philippe Morency] **\n*Associate Professor of Computer Science*\n**Education:**Ph.D., Massachusetts Institute of Technology&#160;\n![Dr. Yonatan Bisk] \n[] **[Dr. Yonatan Bisk] **\n*Assistant Professor of Language Technologies*\n**Education:**Ph.D., University of Illinois at Urbana-Champaign&#160;\n![Dr. Daniel Fried] \n[] **[Dr. Daniel Fried] **\n*Assistant Professor of Language Technologies*\n**Education:**Ph.D., UC Berkeley&#160;\n![Dr. Graham Neubig] \n[] **[Dr. Graham Neubig] **\n*Associate Professor of Language Technologies and Machine Learning*\n**Education:**Ph.D., Kyoto University&#160;\n## Built for Your Busy Life. Designed to Make an Impact.\nCMU&#8217;s Generative AI &amp; Large Language Models certificate, taught by world-renowned faculty in the School of Computer Science, equips professionals to master the tools and techniques transforming today's AI landscape. This program combines CMU's academic rigor with the flexibility working professionals need to develop cutting-edge skills that are in demand across industries.\n**When you enroll in our certificate, you can expect:**\n* Evening, live-online sessions taught by expert faculty in CMU's School of Computer Science who are advancing the field of generative AI\n* Self-paced assignments that deepen your understanding of LLMs and their real-world applications&#160;\n* Real-time collaboration with peers tackling similar challenges in tech, business, and research\n* Personalized support to keep you on track throughout your learning journey\nAt Carnegie Mellon, we don't just teach generative AI - we help professionals shape its future. Hear more about how we bring**CMU's signature content in generative AI****&#160;to working professionals around the country.**Learn how we make this happen from CMU's Vice Provost for Teaching and Learning Innovation, Dr. Marsha Lovett.\n[![Embedded YouTube video]] \nWant more info about the program? Download our Program Tech Sheet.\nOr, if you're ready to apply, start your application today!\n[Download Program\nTech Sheet] [Apply Now] [Contact Us]",
    "length": 4365,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "CFA Working Group on Artificial Intelligence",
    "url": "https://www.cmu.edu/cfa/faculty-and-staff/faculty/ai-working-group.html",
    "text": "# CFA Working Group on Artificial Intelligence\n\nThe College of Fine Arts shares with all schools and colleges at Carnegie Mellon University in advancing efforts related to artificial intelligence research, practice and development so that our world will benefit from these improvements. CFA faculty, students and staff are dedicated to AI research and creative practice within our five schools and three associated programs.\n\nThe arts, architecture and design influence AI in different and striking ways, and our ongoing research will continue to change our region, our nation and our planet. Through our work, we seek to discover the next level of visual perception, face and speech recognition, and cybersecurity — among other developing technologies — working with colleagues inside CFA and across disciplines at CMU.\n\n## CFA Generative AI Working Group Members\n\n- [CFA Generative AI Working Group Members] \n- [CFA Funds for AI] \n- [University Resources] \n\nDaragh Byrne\n\nAssociate Teaching Professor, Architecture; Working Group Lead\n\n[daragh@cmu.edu] \n\nDick Block\n\nTeaching Professor; Associate Head, Drama\n\n[rblock@andrew.cmu.edu] \n\nDana Cupkova\n\nAssociate Professor, Architecture\n\n[cupkova@cmu.edu] \n\nJohannes DeYoung\n\nAssociate Professor, Art\n\n[jsdeyoung@cmu.edu] \n\nJocelyn Dueck\n\nAssociate Professor, Music\n\n[jdueck@andrew.cmu.edu] \n\nDina El Zanfaly\n\nAssistant Professor, Design\n\n[delzanfa@andrew.cmu.edu] \n\nAnnie Hui-Hsin Hsieh\n\nAssistant Teaching Professor, Music\n\n[anniehuihsinhsieh@cmu.edu] \n\nGolan Levin\n\nProfessor, Art\n\n[golan@andrew.cmu.edu] \n\nVernelle Noel\n\nAssistant Professor, Architecture\n\n[vnoel@andrew.cmu.edu] \n\nSusan Raponi\n\nAssistant Professor, Music\n\n[sraponi@andrew.cmu.edu] \n\nLawrence Shea\n\nAssociate Professor, Drama\n\n[lshea@cmu.edu] \n\nTuliza Sindi\n\nVisiting Assistant Professor; Anna Kalla Professorship, Architecture\n\n[tsindi@andrew.cmu.edu] \n\nAndrew Twigg\n\nAssociate Teaching Professor, Design\n\n[atwigg@cmu.edu] \n\nJenn Joy Wilson\n\nAssociate Dean for Research, CFA\n\n[jjwilson@andrew.cmu.edu] \n\n## AIxArts Incubator Fund\n\nThe AI and the Arts Incubator Fund seeds new collaborative partnerships that strengthen, broaden and diversify innovation and experimentation at the intersection of artificial intelligence and the arts.\n\n[Learn about the process and timeline] \n\n## AI Up-skilling Fund\n\nArtificial intelligence has rapidly changed the landscape of teaching, creative practice and research. In recognition of the impact of these new technologies, Dean Poole has created the College of Fine Arts Up-skilling Fund for AI.\n\n[Learn more about eligibility & timeline] \n\n## University Resources\n\nIn addition to coordinating the creation of the CFA Up-skilling Fund for AI, the AI Working Group has identified university resources that may help faculty and staff as they continue to explore the growing capabilities of AI.\n\n- [Technology for Education \\| Eberly Center] \n- [Responsible AI \\| Block Center for Technology and Society] \n- [AI Guidelines \\| Computing Services] \n\n- [Generative AI \\| Computing Services] \n- [Generative AI Tools FAQ \\| Eberly Center] \n- [Generative AI Teaching as Research (GAITAR) \\| Eberly Center] \n\n- [Faculty & Staff Resources] \n\n- [Contact] \n\n[![CFA Magazine logo mark.]]",
    "length": 3229,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "NIST Awards $6M to Carnegie Mellon University To Establish AI Cooperative Research Center",
    "url": "https://www.heinz.cmu.edu/media/2024/September/nist-awards-6m-to-carnegie-mellon-university-to-establish-ai-cooperative-research-center",
    "text": "NIST Awards $6M to Carnegie Mellon University To Establish AI Cooperative Research Center | Carnegie Mellon University's Heinz Collegestartwitterblueskylinkedinfacebookenvelopelinkedininstagramyoutubelogoalert-redalerthomeleft-quotechevronhamburgerminusplussearchtrianglex\nSearch CMU HeinzSearch\n[] \n# NIST Awards $6M to Carnegie Mellon University To Establish AI Cooperative Research Center\nU.S. Secretary of Commerce&#160;[Gina Raimondo] &#160;announced Sept. 24 that the Department of Commerce&#8217;s&#160;[National Institute of Standards and Technology] &#160;(NIST) has awarded $6 million to Carnegie Mellon University to establish a joint center to support cooperative research and experimentation for the test and evaluation of modern AI capabilities and tools.&#160;\nThe CMU/NIST AI Measurement Science &amp; Engineering Cooperative Research Center (AIMSEC) will seek to advance measurement science for modern AI systems, using stakeholder partnerships in a wide range of application domains &#8212; including human services, education, finance, transportation, energy and more &#8212;&#160; to test approaches and translate assessment capabilities and methodologies into practice.&#160;\n&#8220;Artificial intelligence is the defining technology of our generation, and at the Commerce Department we are committed to working with America&#8217;s world-class higher education institutions, like Carnegie Mellon University, to advance safe, secure and trustworthy development of AI,&#8221; Raimondo said. &#8220;I am excited to announce this NIST award of $6 million for Carnegie Mellon to boost research of AI systems and support a new generation of scientists and engineers that will help advance American innovation globally.&#8221;\n&#8220;Carnegie Mellon University is looking forward to partnering with NIST on research and development that will enable the trustworthy deployment of AI-driven decisions and systems,\" said CMU president&#160;[Farnam Jahanian]. &#8220;The work of the center will lead to the development of standards and tools and by filling in this critical missing piece in the nation&#8217;s emerging technologies landscape, we will be equipping American businesses, researchers, leaders and consumers to better understand and trust emerging technologies and better utilize AI tools to their full, transformative potential.&#8221;\n&#8220;AI is revolutionizing industries across the board, and it&#8217;s critical that we ensure these advancements are safe, reliable, and equitable,&#8221; said Congresswoman Summer Lee (PA-12), whose district includes CMU.&#160; &#8220;This $6 million grant will help Carnegie Mellon University and its partners lead the charge in developing AI technologies that protect privacy, enhance accountability, and ensure fairness in how these tools are deployed. Pittsburgh has always been at the forefront of technological innovation, and this new center will help ensure that the next generation of AI development is secure, ethical, and beneficial for all.&#8221;\nCarnegie Mellon University is a pioneer in AI technology development, in the study and analysis of AI deployments as socio-technical systems, and a leader in AI ethics and policy with several hundred faculty already focused on ensuring the safe and responsible development and use of AI. Several research centers and initiatives are expected to coordinate with the AIMSEC, including:\n* The[&#160;Block Center for Technology and Society], which&#160;[has worked closely with NIST] &#160;to operationalize the&#160;[NIST AI Risk Management Framework] &#160;to better manage the potential risks of AI systems and to&#160;[support guidelines on red teaming&#160;] for generative AI.\n* The&#160;[CMU Foundation and Language Model (FLAME) Center],[] &#160;which convenes faculty with deep expertise in the evaluation and safety assessments of generative AI and foundation models.&#160;\n* The&#160;[National Center for Calibrated Trust, Measurement and Evaluation] &#160;(CaTE) at the Software Engineering Institute (SEI), funded by the Department of Defense, which helps the U.S. military assess the trustworthiness of AI systems.\n* The&#160;[Artificial Intelligence Security Incident Response Team] &#160;[] (AISIRT), also led by SEI, which monitors and studies vulnerabilities that emerge from advances in AI and machine learning.&#160;\nAIMSEC will focus on foundational research and developing AI system-level tooling, metrics, evaluation procedures, development processes and best practices to help AI builders consistently engineer safe AI systems. Its efforts will align with NIST AI priorities including better methods for measuring validity, reliability, safety, privacy and security; accountability, transparency, fairness and explainability; and generative AI evaluation at any stage of development or deployment.\n&#8220;This new cooperative research center will expand NIST&#8217;s knowledge base and fundamental research capacity in AI,&#8221; said Under Secretary of Commerce for Standards and Technology and NIST Director&#160;[Laurie E. Locascio]. &#8220;Through this partnership, we will strengthen our understanding of foundation models and support new research &#8212; and new researchers &#8212; in this rapidly evolving field.&#8221;\nThe grant to CMU was awarded through NIST&#8217;s Measurement Science and Engineering Research Grant Program, which supports collaborative research that is aligned with NIST&#8217;s research objectives. The program seeks to develop a diverse, world-class pool of scientists and engineers to engage in NIST&#8217;s measurement science and standards research and to promote understanding of measurement science and standards.&#160;\nThe new university-wide center will be housed at CMU&#8217;s&#160;[Heinz College of Information Systems and Public Policy] and will draw on strengths to support the NIST AI Innovation Lab (NAIIL), a component of NIST&#8217;s larger efforts on fundamental AI measurement research and guideline development.\nShare\n* [] \n* [] \n* [] \n* [] \n## In This Story\n![Ramayya Krishnan] \n**[Prof. Ramayya Krishnan] **\nDean of Heinz College\nExpert in AI and public policy\n---\n*Ramayya Krishnan, dean of the Heinz College of Information Systems and Public Policy and William W. and Ruth F. Cooper Professor of Management Science and Information Systems, will be the lead research coordinator for AIMSEC.&#160;*\n## Contact Us\nPeter KerwinUniversity Communications &amp; Marketing[412-268-1151] [pkerwin@andrew.cmu.edu] \n## Related Articles\n&#32;\n## Students develop machine learning tool to mitigate side effects from cancer treatment\n[Read More] \n&#32;\n## Invisible, Essential, Everywhere: Information Systems Explained\n[Read More] \n&#32;\n## Carnegie Mellon University Launches the Center for Collaboration Science\n[Read More] \nAll News Link\ntiktok",
    "length": 6834,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Restricted Research - University Policies - Carnegie Mellon University",
    "url": "https://www.cmu.edu/policies/research/restricted-research.html",
    "text": "Restricted Research - University Policies - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[University Policies] \n[University Policies] &#160;&#8250;&#160;[Research] &#160;&#8250;&#160; Restricted Research\n# Restricted Research\nPOLICY TITLE:|Carnegie Mellon University Policy on Restricted Research|\nDATE OF ISSUANCE:|This policy was originally issued to campus on September 14, 1988, as Organizational Announcement #317,*Policy on Restricted Research.*|\nACCOUNTABLE DEPARTMENT/UNIT:|Office of the Vice President for Research. Questions on policy content should be directed to&#160;the Office of Sponsored Programs, 412-268-2812|\nABSTRACT:|Restricted research is inappropriate at Carnegie Mellon University except when confined to the semi-autonomous units, which are not associated with any academic departments.|\n## Statement\nUniversities have two primary purposes: to create knowledge and to disseminate knowledge. Carnegie Mellon University recognizes the importance of open intellectual communication within a research group, within the university, and within the larger community outside. Ideally, all units of the university would disseminate the results of research as quickly and as widely as possible. Some members or units of the university, however, desire to do research that may be difficult or impossible without restrictions or without access to classified or proprietary materials.\nThere exists, therefore, a tension between the university's goal of disseminating knowledge freely and the desire on the part of some of its members to conduct restricted research on important problems. The university intends to guarantee the academic freedom of all faculty members to do research in their own manner on topics of their own choosing, provided that such research is consistent with the overall purposes of the university.\nThis policy seeks to resolve the tension between the desire to participate in restricted research and the desire to maintain the open atmosphere of the university by confining restricted research to semi-autonomous units, which are not associated with any academic departments. It thereby establishes the principle that restricted research is inappropriate at Carnegie Mellon University except in the semi-autonomous units.\nThis policy does not attempt to anticipate all possible concerns about restricted research. In some cases, decisions will need to be made about particular research projects to which the application of particular policy guidelines are not clear. In choosing to accept or decline such projects, the university will weigh the potential of a project for generating and disseminating new knowledge, for the benefit of society, against the project's potential for adversely affecting the climate for research conducted in a free and open environment. While this policy sets no explicit limits on the extent of classified research permitted in the semi-autonomous units, it is not the intent of the policy to encourage any unit of the university to engage in classified research as a primary ongoing activity. Indeed, it is expected that classified projects will never represent more than a small fraction of the total research effort in any unit.\n## Definitions\n**Research:**all projects and investigations involving the creation of new knowledge of a theoretical or practical nature. The term \"research\" as used here encompasses both \"research\" and \"development\" as they are commonly defined.\n**Classified research:**research, the free dissemination of the results of which is deemed to jeopardize national security. The federal government controls access to the environment in which such research is performed, restricts discussions about the work in progress to individuals with clearance and a \"need to know,\" and limits publication of research, results or access to data needed to verify results, for a specified period of time.\n**Proprietary research:**research that results in intellectual property that is owned by entities other than Carnegie Mellon University. Such entities may wish to market products derived from inventions or ideas that are developed at the university. They might, therefore, desire to fund projects which restrict access to data and to discussions about work in progress to individuals with a \"need to know,\" and to seek, for a specified period of time, a delay in publication of research results or data needed to verify results. Such entities may also provide access to proprietary material, which researchers must agree not to include in publications.\n**Publication:**oral or written dissemination.\n**Restricted research:**includes all classified research, and any proprietary or other research that requires more than a six month delay in publication of the research results.\n**Semi-autonomous units:**units of the university specifically so designated by the president, after consultation with the URC and the Faculty Senate, currently the Mellon Institute and the Software Engineering Institute.\n**Non-autonomous units:**all university entities other than semi-autonomous units.\n## Restricted Research in Non-Autonomous Units\nIt is the policy of Carnegie Mellon that restricted research is inappropriate and, therefore, not permitted within its non-autonomous units.\nIt is also the policy of Carnegie Mellon not to permit involvement of students in projects which carry restrictions that may impede their progress toward a degree. Therefore, students should not be involved in contracts that require the delay of a student's publication of research results when such results are intended for use in obtaining academic credit, except that a sponsor may require a delay of thirty days for review of publications for removal of proprietary information that was provided by the sponsor for the conduct of the research.\nProprietary research is allowed within non-autonomous units provided it is subject to limitations (excluding students' publications as noted above) no more stringent than the following:\n* A sponsor may request a delay of up to six months in publication so that steps may be taken to secure intellectual property rights to inventions or ideas developed under the contract.\n* A sponsor may require a delay of thirty days for review of publications for removal of proprietary information which was provided for the conduct of the research.\n**Considerations for Faculty/Researchers**\nThe university recognizes that problems arise in both restricted research and research that is not itself restricted but that involves access to classified or propriety information or materials (hereinafter, restricted materials). Researchers may also have access to restricted materials when serving as consultants. Access to restricted materials gives rise to concerns about limitations on researchers' freedom to communicate. In such instances, researchers must exercise considerable judgment to conduct their research in an open environment while protecting the restricted materials to which they have access. Researchers must also be aware that the university will judge their performance as researchers through their publications or through other scholarly products that arise from their research. Research that is restricted in dissemination, or not available for public review, cannot be considered in promotion or reappointment decisions or in evaluations of academic performance of any kind.\n**Considerations for Students**\nThere are important concerns about the involvement of students in restricted research. It is necessary for students to publish their work in order to obtain degrees, course credit and professional recognition. Students rely to a large degree on their faculty advisor's judgment for guidance and advice. Research that is restricted in dissemination, or not available for public review, cannot be used for academic credit. Thus, before working on such research, a student must be notified in writing that work on this research may not be used for academic credit.\n## Restricted Research in Semi-Autonomous Units\nThe semi-autonomous units associated with Carnegie Mellon may conduct restricted research.\nFaculty members may conduct restricted research in or in cooperation with semi-autonomous units only on a consulting basis or by means of a formal, internal leave of absence from their non-autonomous units.\nWork that is restricted in any way may not be used for academic evaluations until it is released for publication, and then only with respect to future academic actions.\nStudents may occasionally be employed by the semi-autonomous units, provided that such employment does not interfere substantially with progress toward a degree. However, they must be made aware that work that is restricted cannot be used for academic credit. Work that was restricted and is later released for dissemination and review can be applied toward future academic credit. Students should be discouraged from working on restricted research in which dissemination may be delayed indefinitely.\n## Guidelines for all Units\nWork by students on restricted research projects shall not be made a condition for admission or financial aid.\nThe principal investigator is responsible for informing all members of a project (faculty, staff and students) of any restrictions imposed on the dissemination of information related to the research. This must be done prior to the start of the project or prior to an individual joining an existing project.\nRestrictions on access to university facilities due to the conduct of restricted research must be kept to a minimum. Access to and movement through the facilities in which restricted research is conducted must be consistent with standard university procedures.\nThe Provost's Office is responsible for obtaining signed documents from principal investigators on restricted research projects attesting that they are aware of all restrictions imposed on the research and that they have informed all participants of these restrictions.\nThe Office of Sponsored Research shall review all proposals and contracts prior to approval for conformity with these guidelines. Any that do not meet these guidelines will be referred to the University Research Council (URC) for review and recommendation of appropriate action to the provost.\nTo maintain a balance with the university's goals of broad dissemination of knowledge, the URC will conduct an annual review of all restricted research being conducted at the university. This review will be made based on a listing of all contracts that involve restricted research. This listing shall include the title and sponsor(s) of the research, name(s) of principal investigator(s), and the amount of funding of each contract.\nThe university community will be informed annually, through the URC's written report to the Faculty Senate and Student Senate, of the nature and overall impact of restricted research at Carnegie Mellon.\nExisting sponsored research projects shall be allowed to continue under the terms of their present contract. However, renewal contracts must conform with this policy.\n* [Articles of Incorporation] \n* [Bylaws of the University] \n* [Site Map]",
    "length": 11223,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "AI Red-Teaming Workshop Will Explore Best Practices",
    "url": "https://www.sei.cmu.edu/news/ai-red-teaming-workshop-will-explore-best-practices/",
    "text": "AI Red-Teaming Workshop Will Explore Best Practices\nicon-carat-rightmenusearchcmu-wordmark\n[Carnegie Mellon Universitycmu-wordmark] \n# AI Red-Teaming Workshop Will Explore Best Practices\n![Blue-team and red-team collage] \n###### December 16, 2024•Article\n**December 16, 2024—**Red-teaming is a common cybersecurity practice in which testers emulate cyber attacks on networked systems to find weak points before adversaries do. The technique is becoming more common for evaluating the safety risks of generative artificial intelligence (AI) systems, but the practice is poorly defined. To help the AI community mature AI red-teaming, the Software Engineering Institute (SEI) will hold[Probing the Limits: A Workshop on Red-Teaming AI Systems], a free, hybrid event on January 28, 2025, in Pittsburgh and online.\nRed-teaming is a flexible method that appeals to AI practitioners facing the broad risk surface of modern AI systems, especially generative AI. While the practice borrows useful approaches from cybersecurity, penetration testing in particular, the AI community lacks clear guidance on how to conduct red-teaming effectively. Without defined protocols and expectations for red-teaming, confidence in AI safety diminishes among AI developers, consumers, and policy makers.\nSEI machine learning research scientist[Anusha Sinha] decided to organize January’s workshop after characterizing the current state of the practice in an award-winning 2024[paper]. Sinha and her coauthors, SEI intern Michael Feffer and researchers from Carnegie Mellon University (CMU), found that red-teaming for generative AI has no standardized protocols and there is little consensus among researchers and industry practitioners on its best practices.\nThe paper proposed essential criteria to guide AI red-teaming. However, Sinha believes that another way to mature the practice is to foster direct conversations among practitioners, as CMU did at a February 2024 event to inform National Institute of Standards and Technology (NIST) guidance on AI red-teaming. Sinha and her SEI colleagues are hosting Probing the Limits to further collaboration among the cybersecurity and generative AI communities.\nCybersecurity practitioners, AI policy makers and researchers, and AI safety testers, evaluators, and auditors are invited to attend the workshop. The program includes interactive panels on best practices for red-teaming and penetration testing, red-teaming for generative AI systems in practice, and policy considerations for AI red-teaming.\n“The goal is for practitioners to learn from each other,” said Sinha. “They might take away new techniques, connect with others who can inform their practice, and get an idea of what policy around AI red-teaming might look like. They can also engage with researchers from academia who are putting out the cutting-edge research.”\nCybersecurity and AI experts do not often have the opportunity to trade their techniques. Operating at the intersection of government, academia, and industry, the SEI convenes experts from each domain to advance the practices of software engineering, cybersecurity, and AI engineering.\n[Register online] to attend Probing the Limits: A Workshop on Red-Teaming AI Systems virtually or in person.\n##### SHARE\n* [**] \n* [**] \n* [**] \n* [**] \n* [**] \n[**Previous![Carleton Named SEI Fellow] #### Carleton Named SEI Fellow\n] \n[Next**![SEI Releases Security Engineering Framework] #### SEI Releases Security Engineering Framework\n] \n### Press Inquiries\n**SEI Public Relations**\nMedia Line:[412-268-4793] \nEmail:[public-relations@sei.cmu.edu] \n### News Archive\nLooking for older news stories? Check the archives:\n[2026],[2025],[2024],[2023],[2022],[2021],[2020],[2019]",
    "length": 3721,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Advancing Student Learning at CMU Through Generative AI",
    "url": "https://news.pantheon.cmu.edu/stories/archives/2023/october/advancing-student-learning-at-cmu-through-generative-ai",
    "text": "[Skip to main content] \n\n_October 23, 2023_\n\n# Advancing Student Learning at CMU Through Generative AI\n\n- [Share on Facebook (opens in new window)] \n- [Share on X (opens in new window)] \n- [Share on LinkedIn (opens in new window)] \n- Print this page\n\n- [Share by email] \n\n**By:**\nMichael Henninger\n[Email] \n\nMedia Inquiries\n\n**Name**\n**Peter Kerwin**\n\nTitle\n\nUniversity Communications & Marketing\n\n[Email] \n\nPhone\n\n[412-268-1151] \n\nCarnegie Mellon University’s [Eberly Center for Teaching Excellence and Educational Innovation(opens in new window)] is launching a Generative Artificial Intelligence Teaching as Research (GAITAR) Initiative, which will include several new efforts to bring generative AI to classrooms across CMU. The Center launched a series of GAITAR Institutes to promote instructor-led innovations and educational research designs across diverse contexts. Additionally, the Eberly Center is now seeking applicants for its GAITAR Fellowship 2023.\n\nNew to the Eberly Center’s portfolio of offerings, the GAITAR Fellowship provides $5,000 for a CMU instructor to design and implement a teaching innovation using a generative AI tool in a spring, summer or fall 2024 CMU course. They must then measure the impacts of the innovation on student learning and disseminate their findings at CMU and beyond. The [deadline for applications(opens in new window)] is Nov. 1.\n\nThe fellowship aims to incentivize and lower barriers to innovation, implementation and the dissemination of educational research findings.\n\n> \"We embrace this as an inflection point to take these tools and new ways of thinking to enhance our teaching and learning strategies.” — James H. Garrett Jr.\n\n![Jim Garrett] \n\n_James H. Garrett Jr._\n\n“In many ways, CMU is the birthplace of both learning science and AI and machine learning, dating back to the [Newell and Simon days(opens in new window)],” said [James H. Garrett Jr.(opens in new window)], CMU’s provost and chief academic officer. “If anybody should be advancing the research and application of AI in education, it should be Carnegie Mellon. We embrace this as an inflection point to take these tools and new ways of thinking to enhance our teaching and learning strategies.”\n\nThe Eberly Center recently finished delivering a GAITAR Institute on campus, a four-session program that generated ideas for teaching innovations implementing generative AI in CMU courses, preparing instructors to study the results with tangible Eberly Center support from start to finish.\n\nSince 1996, the Eberly Center has brought pedagogical and technological issues together to support Carnegie Mellon faculty and graduate students in their roles as educators. The center, which fosters a culture of experimentation, innovation and iterative improvement through collaboration, approaches the use of AI with empirical questions — where do AI tools enhance student learning and experience? What do students consider as the benefits and tradeoffs of using AI? How can equitable access and outcomes be ensured when using AI?\n\nCMU’s University Education Council will be convening town hall sessions in early November to hear students' and educators' perspectives on the most pressing needs and opportunities related to AI and its potential for impact on education. The full spectrum of community input will inform broader university strategies to advance the applications of generative AI in education.\n\n![Amy Burkert] \n\n_Amy Burkert_\n\n“Many articles have shared that education is being upended by these new tools,” said [Amy Burkert(opens in new window)], vice provost for education. “There are, indeed, many changes taking place, but the question is, ‘How can we help our community leverage that potential into an asset rather than a cause for concern?’”\n\nThe theme of the Eberly Center’s 7th annual Teaching and Learning Summit, held on Sept. 21, was “ [Adapting to Generative AI in Teaching(opens in new window)].” During the Summit,faculty members from the [Heinz College of Information Systems and Public Policy(opens in new window)], the [Dietrich College of Humanities and Social Sciences(opens in new window)], and the [Human-Computer Interaction Institute(opens in new window)] discussed their use of AI in the classroom.\n\n## Generative AI Tools FAQ\n\nThe recent evolution of AI tools, such as ChatGPT, DALL-E 2 and GitHub Copilot, is impressive, as is the associated volume of media coverage.\n\nIn response to inquiries from CMU colleagues, the Eberly Center compiled a list of [frequently asked questions(opens in new window)] informed by evidence-based and inclusive teaching strategies, CMU policies, and the current state of technology tools.\n\n[Read more(opens in new window)] \n\nThe Eberly Center supports teaching as research.\n\n[Read more about their research and findings(opens in new window)] \n\n[iframe] \n\n_Watch Haylee Massaro deliver a talk on embracing generative AI in the classroom during the Eberly Center's 2023 Teaching and Learning Summit._\n\n“We want to make sure that our entire community’s voices are heard, especially those of our students so we can better understand their most pressing needs and the exciting opportunities they see related to generative AI,” Burkert said.\n\n![Marsha Lovett] \n\n_Marsha Lovett_\n\n“We are taking a very scientific approach to this — a learning science approach,” said [Marsha Lovett(opens in new window)], vice provost for teaching and learning innovation and co-coordinator of [The Simon Initiative(opens in new window)], CMU’s learning-engineering ecosystem that works to improve student learning outcomes. “We are actively supporting our faculty members to lean in, learn about generative AI, and incorporate it into their teaching where it can benefit students. On top of that, we are actively supporting faculty to study its impacts on student learning and the student experience. We must continue to be data-informed on this.”\n\nThe work to apply generative AI tools and techniques in the classroom is only one part of a broader university strategy to advance the next generation of artificial intelligence’s impact across education, research and society. The university has been increasingly called upon for its AI expertise by public and private sector partners. Most recently, [Gov. Josh Shapiro visited CMU(opens in new window)] to announce an executive order on the use of generative AI in Commonwealth agencies. CMU’s [Block Center for Technology and Society(opens in new window)] one of the nation’s leading research centers working to shape the impact of these technologies, will partner with the Shapiro administration on this effort.\n\n## — Related Content —\n\n[![Farnam Jahanian shakes hands with Gov. Josh Shapiro] \\\n\\\n**Gov. Shapiro Visits CMU — Birthplace of AI — To Sign Executive Order on Generative AI**] \n\n[![William S. Dietrich II] \\\n\\\n**Celebrating 10 Years of Dietrich Foundation Support**] \n\n[![Rayid Ghani testifying] \\\n\\\n**CMU Artificial Intelligence Experts Brief Policymakers**] \n\n- [The Piper: Campus & Community News(opens in new window)] \n\n- [Official Events Calendar(opens in new window)] \n\n▴scroll to top",
    "length": 7116,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "CMU Researches Explore Using AI in the Classroom - AI Daily - Computing Services - Carnegie Mellon University",
    "url": "https://www.cmu.edu/ai-daily/news-and-events/august/ai-classroom.html",
    "text": "Generative Artificial Intelligence (AI) - Computing Services - Office of the CIO - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[Computing Services] ## [Office of the CIO] \n[Office of the CIO] &#160;&#8250;&#160;[Computing Services] &#160;&#8250;&#160;[Services] &#160;&#8250;&#160; Generative Artificial Intelligence (AI)\n# Explore Generative Artificial Intelligence (AI) at CMU\nGenerative AI (GenAI) helps you create text, images, music, and videos, just by describing what you need. These tools can support your learning, creativity, and work across many roles at CMU. Explore our resources below to learn the basics and get familiar with the tools available to you. Then, dive into building more advanced skills.\n## [Learn and Connect] \nDiscover campus AI events, topic-based communities, and other learning opportunities.\n## [Protected&#160;AI Tools] [] \nLearn about the AI tools that are safe to use within CMU&#8217;s environment.\n## [Use AI Safely at CMU] \nLearn how to use AI safely and ethically, following CMU&#8217;s policies and guidelines.\n* [About] \n* [Computing Services InfoCenter] \n* [CSS Awards and Recognition] \n* [News] \n* [Service Status] \n[Log In to Services] \n* [Computing Services Help Center] \n* [412-268-4357 (HELP)] \n* [it-help@cmu.edu]",
    "length": 1342,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "CMU LibGuides: CMU-Qatar Library: GenAI Guide: Generative AI in the Academic Realm",
    "url": "https://guides.library.cmu.edu/GenAI",
    "text": "Generative AI in the Academic Realm - CMU-Qatar Library: GenAI Guide - CMU LibGuides at Carnegie Mellon University[Skip to Main Content] [![Carnegie Mellon University Libraries]] \n[![Banner]] \nSearch this GuideSearch\n# CMU-Qatar Library: GenAI Guide\n* [Generative AI in the Academic Realm] \n* [Prompting as an Art and Skill] \n* [AI Tools for Research] \n* [Documenting AI Use & Citing Sources] \n## Instruction & Outreach Librarian\n[\n![] \nReya Saliba\n] \n[Email] \n**Contact:**\nOffice 1154\n+974 4454 8403\n## Disclaimer\nThis guide is intended solely to inform. We donot generally endorsethe use of GenAI in an academic setting. Students should refer to their course syllabi and consult with their instructors for specific policies and guidelines regarding the permissible use of AI in their coursework.\nAs GenAI models continue to be improved and repurposed, the content of this guide may become outdated and we will do our best toensure the information provided is updated regularly and remains accurate.\n## Teaching with GenAI\n![] \nCMU&#39;s*Eberly Center for Teaching Excellence &amp; Educational Innovation*has compiled a list of FAQs on AI&#39;s impact on teaching, drawing from evidence-based strategies and university policies. This resource aims to help faculty thoughtfully consider evolving technologies in education, with an open invitation for further discussion and input from the teaching community. Check[Eberly Centerwebsite] for more information.\n* [Eberly Center] \n## CMU Libraries' Role in AI Research\n![] \nCarnegie Mellon University Libraries have long been involved with AI, playing a crucial role in bridging AI&#39;s past and future, maintaining archives while also integrating modern tools into research processes and guiding the CMU community through the evolving AI landscape. Check[CMU Libraries website] and[CMU Libraries Generative AI Guide] for more information.\n* [CMU Libraries' Role in AI Research] \n* [CMU Libraries Generative AI Guide] \n#### &quot;Previous AI helped curate our world [...], but GPT AI will allow you to create your world&quot; (Bowen &amp; Watson, 2024, p. 26).\n### ![] \nCreated using GPT-4o\n## An introduction to Generative AI: The example of ChatGPT\n## The Development of GenAI Models\nChatGPT is an AI model that falls under the category of***deep learning***, a subfield of machine learning and artificial intelligence. It is designed to generate text in a conversational style by learning complex patterns from input data, without being explicitly programmed for each task. ChatGPT&#39;s***neural network***consists of billions of parameters and mathematical operations that determine the probabilities of which words come next, rather than being a database of pre-written sentences.\nThis video by the University of Arizona Libraries provides a quick summary of the technology behind ChatGPT, and explains basic terms such as narrowAI, deep learning, and neural networks.\n## Training GenAI Models\nEarlier language processing techniques had significant drawbacks that limited their effectiveness. The***transformers architecture***, introduced in 2017, overcame these challenges by introducing an*attention mechanism*, enabling AI to focus on the most important elements of text. This led to the development of***large language models (LLMs)***, like ChatGPT, which are trained on vast amounts of data and can generalize to new domains. ChatGPT&#39;s training process involves***reinforcement learning from human feedback***(RLHF), allowing it to generate more conversational and human-like responses.\nThe next video by the University of Arizona Libraries provides an overview ofhow GenAI models are being trained and explains some of the terminologyused when talking about GenAI such as transformers, large language models (LLMs), andreinforcement learning from human feedback (RLHF).\n## AI Tools for Specific Tasks\n## What AI Tools are Available?\nWhether you need to generate some text, images, music, videos, or work on a research project, or transcribe and analyze some data,here are few examples of tools that you can try.\nExercisecaution when AI tools. Always review your prompts and outputs carefully to ensure you do not share any private, sensitive, or copyrighted information.\n**Content Generator**|**Images &amp;&amp; Art**|**Video Maker**|**Programming &amp; Coding**|**Music &amp; Sound**|**Research**|**Transcribing**|\n**[Gemini] \\***(Available through CMU)\n|**[DALLE-E2] **|**[Record Once] **|**[GitHub Copilot] **|**[SoundDraw] **|\n**[Scite] \\*\\*** (Available through CMU Libraries)\n|**[Fathom] **|\n**[Copilot] \\***(Available through CMU)\n|**[Midjourney] **|**[Lumen5] **|**[CodeWhisperer] **|**[Audiobox] **|\n[**SciSpace**] (also known as typeset.io)\n|**[Ecoute] **|\n**[Perplexity] [.ai] **|**[Stable Diffusion] **|**[Pictory] **|**[Codex] **|**[Beatoven] **|**[Elicit.com] **|**[Veed.io] **|\n**[Claude.ai] **|**[Ideogram] **|**[Synthesia] **|**[AI Code Generation] **|**[Udio] **|**[ResearchRabbit] **|**[Otter.ai] **|\n**[ChatGPT] **|**[NightCaf&eacute;] **|**[DeepBrain] **|**[Codeium] **|**[Soundverse] **|[**Consensus**] |**[Notta] **|\n*\\*Gemini and Copilot subscriptions are available through CMU. Log in using your Andrew ID and password.*\n*\\*\\*Scite is a database available to you through CMU Libraries. You can access it through our[Databases, eResources, &amp; Tools] page.*\n## Using GenAI in Academia\n## To What Extent Can you Use GenAI in your College Work?\nWhen considering the use of GenAI in academic assignments, several factors come into play, including the assignment type, topic, required resources, and your professor&#39;s guidelines. Professors may have varying policies:\n* Some may restrict GenAI use, requiring original work.\n* Others might allow limited use, provided you acknowledge it.\n* Some may design assignments that extensively incorporate GenAI.\nAlways refer to your course&#39;&#39;s academic integrity policy and consult your professor for clarity before starting your work. GenAI is a rapidly evolving tool that will likely be valuable in your future workplace, making AI literacy essential. However, it is crucial to continue to develophuman cognitive, social, and emotional skills by engaging with diverse academic opportunities that still require human insight and interaction.\n* * [**Next:**Prompting as an Art and Skill &gt;&gt;] \n* Last Updated:Aug 14, 2025 7:47 AM\n* URL:https://guides.library.cmu.edu/GenAI\n* [**Print Page] \n[Login to LibApps] \n[Report a problem] \n[****]",
    "length": 6481,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Responsible AI",
    "url": "https://www.cmu.edu/block-center/responsible-ai",
    "text": "Responsible AI | Block Center for Technology and Society - Carnegie Mellon University[Skip to main content] \n[] \n[Block Center for Technology and Society] \nWhat can we help you find?\n![Pennsylvania Governor Josh Shapiro signed an Executive Order on Commonwealth use of generative artificial intelligence during a visit on Wednesday, September 20, 2023, to the Tepper Building.] \n# Responsible AI\nArtificial intelligence (AI) is reshaping industries, decision-making, and daily life, making it essential to develop AI systems that are fair, transparent, and accountable. At The Block Center, our Responsible AI focus area is dedicated to ensuring AI technologies serve society equitably. We examine how AI impacts individuals and communities, develop frameworks for ethical AI deployment, and collaborate with policymakers, researchers, and industry leaders to promote responsible innovation.\nCarnegie Mellon’s interdisciplinary expertise—spanning computer science, public policy, ethics, and business—positions us as a leader in AI research. Through funded projects, we support initiatives that address bias in AI, improve system accountability, and create tools for AI governance. Our team of experts works at the intersection of technology and society, shaping policies and best practices that ensure AI benefits all.\nBy fostering responsible AI development, we aim to build a future where technology is not only powerful but also principled.\nResponsible AI is a university-wide initiative housed at The Block Center, with support from the School of Computer Science, that draws on expertise from across Carnegie Mellon.\n## Projects\nThe Block Center supports various projects aimed at promoting responsible AI practices. These projects include developing frameworks for ethical AI deployment, creating tools for AI evaluation, and conducting studies on the societal impacts of AI technologies.\n[\n![Pennsylvania Governor Josh Shapiro signed an Executive Order on Commonwealth use of generative artificial intelligence during a visit on Wednesday, September 20, 2023, to the Tepper Building.] ### PA AI Governance Initiative\n] \n![Ramayya Krishnan at the AI Diffusion Conference] \n## AI Policy Impact\nThe Responsible AI (RAI) initiative at Carnegie Mellon's Block Center for Technology and Society significantly influences policy by translating AI research into actionable insights that promote fairness, accountability, and transparency. By engaging with policymakers, the initiative ensures that AI technologies are developed and implemented in ways that are socially responsible and equitable.\nAdditionally, the initiative fosters community engagement through programs like &quot;AI 101,&quot; which educates various stakeholders—including labor unions, media professionals, and government representatives—on the societal implications of AI. These efforts demystify AI technologies and encourage inclusive dialogue, ensuring that diverse perspectives inform AI policy development. ​## Recent AI News\n### CMU Experts Lent Expertise to New U.S. Artificial Intelligence 'Roadmap'\n![Ramayya Krishnan] \n“This bipartisan roadmap recognizes that innovation in robotics is vital to realize AI’s ability to enhance the future of our economy and improve the quality of life in America,” said Theresa Mayer, CMU’s vice president for research.\n[Read the Article Here] \n### CMU Convenes Experts in Evaluating Generative AI\n![Hoda on Generatice AI] \nCarnegie Mellon University’s K&amp;L Gates Initiative in Ethics and Computational Technologies sponsored and co-organized an expert convening in Washington, D.C., on “Evaluating Generative AI Systems: the Good, the Bad and the Hype.” Organized in partnership with The GenLaw Center, the Center for Democracy and Technology, and Georgetown Law, the conference took place at Georgetown University Law Center on April 15.\n[Read the Article Here] \n### Forlizzi Briefs Senators on AI in the Workforce\n![Senate floor] \nCarnegie Mellon University School of Computer Science Professor Jodi Forlizzi shared four recommendations with U.S. senators to ensure that innovations in artificial intelligence are sustainable, responsible and work for workers.\n[Read the Article Here] \n## Stay informed. Fuel the Good. Connect with us.\n## Subscribe\n\\*indicates required\nEmail Address\\*\nFirst Name\\*\nLast Name\\*",
    "length": 4330,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Artificial Intelligence Guidance for Students",
    "url": "https://www.cmu.edu/career/students-and-alumni/resource-library/ai-guidance/index.html",
    "text": "Artificial Intelligence Guidance for Students - Career &amp; Professional Development Center - Student Affairs - Carnegie Mellon University\n[Carnegie Mellon University] **&#8212;****&#8212;****&#8212;**SearchSearchSearch this site only\n[Career &amp; Professional Development Center] ## [Student Affairs] \n[Student Affairs] &#160;&#8250;&#160;[Career &amp; Professional Development Center] &#160;&#8250;&#160;[Students &amp; Alumni] &#160;&#8250;&#160;[Resource Library] &#160;&#8250;&#160; Artificial Intelligence Guidance for Students\n# Artificial Intelligence Guidance for Students\nArtificial Intelligence (AI) tools can be powerful resources in your job or internship search. In fact, there are a number of career resources utilizing AI that Carnegie Mellon recommends and encourages students to use. In addition to CMU provided resources, CMU student job seekers may consider using other AI tools and resources available in the public domain (such as[ChatGPT]).\nPlatforms and*resources*available from CMU include the following:\n* [**Big Interview**] **:**AI feedback based upon video interview response submissions.When students save a video of their interview practice responses, Big Interview&#8217;s AI will process the recording and provide immediate feedback and coaching. Feedback includes eye contact, use of \"ums\" and other filler words, vocabulary, tone, rate of speech, and more.\n* [**Vmock**] **:**Provides instant personalized resume feedback via an online platform that uses sophisticated algorithms and data science along with machine learning and artificial intelligence to assist students in optimizing their resumes. Students receive anaggregate resume score to assess the strength of their resume, as well as detailed feedback on resume content and presentation.\n* [**Handshake**]:&#160; Students receive[job recommendations] tailored to their profiles, interests and past search history.&#160;[Recommendations get better] the more the student engages with the platform.&#160;It is important for all students to have a complete Handshake profile to ensure strong recommendations from Handshake.\n* **[CMU Guidance] **: Tools and direction provided by the university.*Note*:&#160;Google Gemini and Microsoft Copilot are available with a CMU Andrew ID and password.*Note:*&#160;[Copilot] is Microsoft&#8217;s generative AI platform. It uses multiple data models, including GPT-4 and DALL-E3, to generate written and visual content based on a prompt.&#160;Unlike open commercial tools, like Chat GPT, Copilot provides additional&#160;[data protection] &#160;when you access it using your Andrew userID. Microsoft will not retain your prompts or responses to train its AI models.\n[![Embedded YouTube video]] ### **VIDEO:\nArtificial Intelligence Platforms for\nYour Career Journey**\n## Generative AI Tools\nWhen considering the utilization of these tools we strongly encourage you to consider the following:\n## How can I use Generative AI for my cover letter or resume writing?\nResumes need to accurately reflect past experience, skill set, contributions to projects, etc. and be tailored to the job/industry for which the resume will be used.&#160; When using generative AI tools, it is important to ensure that content and information remains accurate and can be verified and expanded upon in the interview process.\nAdditionally, cover letters are less frequently needed in the job search process; however, for some applications applicants may be required to to submit a cover letter or they may choose to do so for positions of particular interest.&#160; When using an AI tool to assist in developing and writing a cover letter it is important to remember that suggested language provided by AI tools draws upon source material, including publicly available content on the Internet. This carries a risk of plagiarism.\nGenerative AI platforms can be used for idea generation of these documents, helping to suggest keywords or relevant skills that are found in job descriptions. Examples of prompt topics that may assist with this include:&#160;\n* Asking about how to highlight a specific skill on a resume based on prior experiences&#160;\n* Asking what skills or qualifications to highlight on a cover letter for a specific position\n* Asking to revise specific bullet points for clarity and/or to tailor to specific job postings&#160;\n*Note:*After prompting your generative AI platform to create or edit content on a resume or cover letter, it is critical for student job seekers to tailor this information and make edits to ensure that the final product reflects their unique &#8216;voice&#8217; and shares details and experiences specific to them.&#160;&#160;\nWhen using AI resources to develop application materials it is still important to reference guidelines provided by Carnegie Mellon and/or any specific guidelines provided by an individual company.&#160; We recommend following up with a CPDC Career Consultant to have a final resume and/or cover letter review before submitting documents as part of an application.\n## How can Generative AI help with my job/internship search?\nGenerative AI tools, such as ChatGPT or Copilot, can be helpful in discovering and assessing personal skill sets, as well as uncovering job/internship profiles that may align with specific backgrounds/experiences and preparing for/navigating an interview process.\n*Job/Internship Search:*Provide information about your degree program, previous experience, or skill sets and ask the generative AI platform to identify target industries, companies or types of job positions that you are qualified for or align well with your background.&#160;\n*Career Exploration:*Utilize generative AI platform to assess your own skill sets for the roles you&#8217;re pursuing. This is helpful in identifying gaps in your skills and the system may even offer tips on how to develop those skills.&#160;\n*Interview Preparation:*Share in an AI prompt a job/internship description from an online posting and ask for sample interview questions. These questions can then be used for practice to prepare for an upcoming interview and AI can also provide sample responses to specific questions. Please remember that AI tools cannot and should not replace your own specific, unique answers in an interview setting.\nAdditionally, students may find it helpful to use generative AI tools as part of their research process to prepare for interviews and learn more about a company, position, location, etc. AI tools for this purpose should be used in combination with other resources, like the company&#8217;s website, Handshake, etc., to ensure up-to-date information is referenced.&#160;&#160;\n## How do I ethically use AI and avoid plagiarism?\nRemember, generative AI tools are just that, tools.&#160; They do not, and should not, replace original thinking and writing.&#160; With that in mind, to ensure ethical use and to avoid plagiarism, keep the below in mind:\n* AI tools should serve as a starting point or a tool to aid in revisions and editing and not in place of original words, thinking, information and writing.\n* Always modify and rephrase any text or suggestions gained from an AI tool to be written in original words, style and voice.\n* Use a variety of resources and gain professional guidance from CPDC career consultants, faculty advisors, etc.&#160;\n* Review, revise and edit content to ensure nothing is plagiarized and everything presented accurately represents past/current experience(s), skills and overall abilities.&#160;\n* Site original sources when and where appropriate.\n* If an employer asks for a writing sample, they are seeking a sample that is representative of an applicant's authentic writing ability.&#160; It is imperative that samples be an original work.\n## Limitations of AI Tools\nGenerative AI tools, such as ChatGPT and Copilot, are only as good as the source material for which it is trained on. For example, as of summer 2023, ChatGPT&#8217;s source material only dates through September 2021, which means it will not draw on the most recent changes in the job market and can not provide responses based upon real time/up-to-date information.\n## A Final Word\nWhile both generative AI tools and other career resources are valuable for overall career exploration and job/internship search, they should be used in conjunction with professional guidance from the Career Consultant team here at CMU.&#160; We encourage all students to incorporate appointments with their CPDC Career Consultant into a comprehensive search to ensure that they get advice and guidance tailored to them as an individual.&#160;\n# Division of Student Affairs\n* [Athletics, Physical Education &amp; Recreation] \n* [Career &amp; Professional Development Center] \n* [Center for Student Diversity &amp; Inclusion] \n* [Civility Initiatives] \n* [Cohon University Center] \n* [Community Engagement &amp; Leadership Development] \n* [Community Health &amp; Well-Being] \n* [Community Responsibility] \n* [Conference &amp; Event Services] \n* [Counseling &amp; Psychological Services] \n* [Dean of Students] \n* [Dining Services] \n* [Family Engagement] \n* [First-Year Orientation] \n* [Fraternity &amp; Sorority Life] \n* [Housing Services] \n* [Pre-College Programs] \n* [Residential Education] \n* [Student Involvement &amp; Traditions] \n* [Student Support Resources] \n* [University Health Services] \n* [Wellness &amp; Meaning Making Programs]",
    "length": 9414,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  },
  {
    "query": "site:cmu.edu Carnegie Mellon University generative AI policy",
    "title": "Generative AI & Large Language Models",
    "url": "https://online.pantheon.cmu.edu/online/generative-ai-llms",
    "text": "[Skip to main content] \n\n# Generative AI & Large Language Models\n\n## Next Start Date\n\nJanuary 2026\n\n## Application Deadlines\n\nPriority\\*: November 12, 2025Final: December 3, 2025\n\n## Program Length\n\n12 Months\n\n## Taught By\n\nSchool of Computer Science\n\n## GenAI is Transforming the World\n\n**What will you create with it?**\n\nGenerative AI has already revolutionized the world and it’s not slowing down. As a trained computer scientist, if you want to contribute to the revolution of Generative AI, and make an immediate impact in your organization, now is the time to enhance your expertise.\n\n### A training ground for Generative AI\n\nIn Carnegie Mellon’s new **Generative AI and Large Language Models graduate certificate**, offered by CMU’s nationally-ranked School of Computer Science, you will learn the latest and most advanced techniques in Generative AI, large language models and multimodal machine learning from expert faculty at the forefront of computer science research.\n\nThis is not your average online certificate program. The coursework covers complex topics that build on expertise in applied mathematics, programming, machine learning and deep learning.\n\nBy the end of this certificate, you will be prepared to build customized applications of Generative AI. You will learn how to design and implement scalable systems for large language models, evaluate and choose between existing models, do customization via finetuning, and leverage multimodal machine learning through integrating and modeling multiple communicative modalities (e.g. audio, images, and video).\n\nMore than theory, this program takes a hard-core systems approach by giving you not only the technical skills but the ability to implement and scale solutions based on your unique organizational needs and resources. Here you will gain the depth, breadth and practical skills to apply this technology immediately.\n\n### Our advanced program will teach you how to:\n\n- Implement state-of-the-art language models such as GPT and LLaMA from scratch.\n- Compare and contrast different models and approaches in order to determine the best setup for tasks you care about.\n- Perform model training and inference using popular frameworks such as HuggingFace.\n- Design and run generative AI systems on high performance computer infrastructure using tools like SLURM.\n- Understand and be able to apply algorithms and system techniques to efficiently train LLMs with huge datasets, including efficient fine-tuning and reinforcement learning with human feedback, acceleration on GPU and other hardware, model compression for deployment, and online system maintenance.\n- Implement multimodal systems such as audio-visual speech recognition, image generation, and video captioning—addressing challenges in (1) multimodal representation learning, (2) translation and mapping between modalities, (3) modality alignment, (4) multimodal fusion and (5) co-learning.\n\n### A powerful certificate. Conveniently offered.\n\nThe Graduate Certificate in Generative AI and Large Language Models is offered 100% online to accommodate your busy schedule as a working professional. Along with weekly, live-online interactive classes taught by expert CMU faculty, you will complete hands-on learning activities on your own time that complement the discussions you have in class. To earn the certificate, you will complete three rigorous CMU classes over a 12-month period.\n\n### For computer science pioneers\n\nThis certificate program is best suited for:\n\n- Industry professionals working in computer science, data science, software engineering or a similar field who want to enhance their domain knowledge with expertise in Generative AI and large language models so they can build new and innovative solutions for the future.\n- Recent college graduates with a degree in computer science, data science, software engineering or a similar field who want to gain in-depth, state-of-the-art knowledge about Generative AI and large language models to enhance their skills, make an immediate impact in their organization, and stay competitive in the job market.\n\n## 2024 U.S. News & World Report Rankings\n\n### \\#1\n\n#### For CMU's AI graduate programs\n\n### \\#1\n\n#### For CMU's programming languages courses\n\n### \\#1\n\n#### For CMU's computer science graduate programs\n\n## Curriculum and Course Schedule\n\nThe online Graduate Certificate in Generative AI & Large Language Models includes 3 graduate-level, credit-bearing courses taught by expert CMU faculty and features the following course progression:\n\n**Training for future GenAI experts poised to transform the world**\n\nAs Generative AI continues to evolve, computer scientists will need the most sophisticated and cutting-edge skills to enhance the capabilities of AI for organizations. In the Generative AI and Large Language Models graduate certificate, courses cover three distinct areas of knowledge:\n\n- **Theory** – In our _Large Language Models: Methods and Applications_ course, you will learn the practical applications of LLMs, what they are, what they can do, and how they work.\n- **Data Representation** – In our _Multimodal Machine Learning_ course, you will learn how different language modalities are used in various prediction problems.\n- **Scalability** – In our _Large Language Model Systems_ course, you will learn how to apply and scale LLMs for your organization.\n\nWith the ability to understand the use of large language models, train with massive multimodal data sets and implement scalable systems, you will be ready to maximize the potential of generative AI, all on your own. See more details about our coursework below.\n\n| Semester | Course |\n| --- | --- |\n| Fall 2025 | Large Language Model Systems |\n| Spring 2026 | Multimodal Machine Learning |\n| Fall 2026 | Large Language Models: Methods and Applications |\n\n**For Fall 2025 Start**\n\nEach course will appear on your Carnegie Mellon transcript with the grade earned. To earn the certificate, you must successfully complete all courses in the program. If you are only interested in one course, however, you may complete that course only and it will show on your transcript with the grade earned.\n\n## Course Descriptions\n\n### Large Language Models: Methods and Applications\n\n**Course Number:** 11-967\n\n**Number of Units:** 12 units\n\nThis course provides a broad foundation for understanding, working with, and adapting existing tools and technologies in the area of Large Language Models like BERT, T5, GPT, and others.\n\n**Throughout this course, you will learn:**\n\n- A range of topics including systems, data, data filtering, training objectives, RLHF/instruction tuning, ethics, policy, evaluation, and other human-facing issues.\n- How transformer architectures work and why they are better than LSTM-based seq2seq models. You’ll explore decoding strategies and techniques for pretraining, attention, prompting, and more through readings and hands-on assignments.\n- How to apply the skills you’ve learned in a semester-long course project, using locally sourced model instances that allow you to go beyond commercial APIs.\n- How to compare and contrast different models in the LLM ecosystem to determine the best model for a given task.\n- How to implement and train a neural language model from scratch using PyTorch.\n- How to utilize open source libraries to fine-tune and perform inference with popular pre-trained language models.\n- How to apply LLMs in downstream applications and understand how pre-training decisions affect task suitability.\n- How to design new methodologies that leverage existing large-scale language models in novel ways.\n\n**Please note:** In order to complete homework and activities, students will need to sign up for Amazon Web Services (AWS) or an equivalent service that offers access to A10g or similar GPUs. The AWS cost to complete assignments will range from $150–$300, depending on usage. Additionally, students will need to sign up for the OpenAI API. The cost to complete the assignments via OpenAI will be up to $25. Instructions for accessing both services will be provided at the start of the course.\n\n### Multimodal Machine Learning\n\n**Course Number:** 11-977\n\n**Number of Units:** 12 units\n\nIn this course, you will learn the fundamental mathematical concepts in machine learning and deep learning that are relevant to the five main challenges in multimodal machine learning:\n\n- Multimodal representation learning\n- Translation and mapping\n- Modality alignment\n- Multimodal fusion\n- Co-learning\n\nThe mathematical concepts you will learn include, but are not limited to, multimodal auto-encoders, deep canonical correlation analysis, multi-kernel learning, attention models, and multimodal recurrent neural networks.\n\nYou will also review recent papers describing state-of-the-art probabilistic models and computational algorithms for multimodal machine learning and discuss current and emerging challenges. Finally, you will study recent applications of multimodal machine learning including multimodal affect recognition, image and video captioning, and cross-modal multimedia retrieval.\n\n**Please note:** The Multimodal Machine Learning course may require Amazon Web Services (AWS) and/or OpenAI or other services to complete assignments, with fees up to $300 (subject to change). More details will be available as you get closer to the course start date.\n\n### Large Language Model Systems\n\n**Course Number:** 11-968\n\n**Number of Units:** 12 units\n\nLLMs are often very large and require increasingly larger datasets to train, which means developing scalable systems is critical for advancing AI. In this course, you will learn the essential skills for designing and implementing scalable LLM systems.\n\n**Throughout the course, you will:**\n\n- Learn the approaches for training, serving, fine-tuning, and evaluating LLMs from the systems perspective.\n- Gain familiarity with sophisticated engineering using modern hardware and software stacks needed to accommodate the scale.\n- Acquire essential skills for designing and implementing LLM systems, including:\n - Algorithms and system techniques to efficiently train LLMs with huge data\n - Efficient embedding storage and retrieval\n - Data-efficient fine-tuning\n - Communication-efficient algorithms\n - Efficient implementation of reinforcement learning with human feedback\n - Acceleration on GPU and other hardware\n - Model compression for deployment\n - Online maintenance\n- Learn about the latest advances in LLM systems regarding machine learning, natural language processing, and systems research.\n\n**Please note:** The Large Language Model Systems course may require Amazon Web Services (AWS) and/or OpenAI or other services to complete assignments, with fees up to $300 (subject to change). More details will be available as you get closer to the course start date.\n\n## Meet Our World-Class Faculty\n\n### [Dr. Carolyn Rosé] \n\n_Professor, Language Technologies & Human-Computer Interaction_\n\n**Education:** Ph.D., Carnegie Mellon University\n\n**Research Focus:** Bridging deep, theoretical insights from theories of language and interaction and computational modeling paradigms such as deep learning and LLMs, Dr. Rosé applies understanding of language and interaction in design and orchestration of ensembles of data representations with needed affordances and architectural elements that introduce inductive biases at the algorithmic level.\n\n### [Dr. Daphne Ippolito] \n\n_Assistant Professor, Language Technologies_\n\n**Education:** Ph.D., University of Pennsylvania\n\n**Research Focus:** Dr. Ippolito's research focuses on the tradeoffs and limitations of generating text with neural language models, as well as strategies for evaluating natural language generation systems. She also researchers how to incorporate AI-in-the-loop language generation into assistive tools for writers. Before starting her role at Carnegie Mellon, Dr. Ippolito worked as a Research Scientist at Google Brain.\n\n### [Dr. Lei Li] \n\n_Assistant Professor, Language Technologies_\n\n**Education:** Ph.D., Carnegie Mellon University\n\n**Research Focus:** Through his research, Dr. Li explores topics associated with large language models (e.g. efficient large language model systems), multilingual natural language processing (e.g. speech translation), and AI for science. Before joining CMU, Dr. Li worked as a principal researcher at Baidu's Institute of Deep Learning in Silicon Valley and as the founding director of ByteDance's AI Lab.\n\n### [Dr. Louis-Philippe Morency] \n\n_Associate Professor, Language Technologies_\n\n**Education:** Ph.D., Massachusetts Institute of Technology\n\n**Research Focus:** Dr. Morency leads the Multimodal Communication and Machine Learning Laboratory which focuses on building the computational foundations to help computers analyze, recognize and predict subtle human communicative behaviors during social interactions. This lab integrates expertise from fields like machine learning, computer vision, natural language processing, and social psychology.\n\n### [Dr. Yonatan Bisk] \n\n_Assistant Professor, Language Technologies_\n\n**Education:** Ph.D., University of Illinois at Urbana-Champaign\n\n**Research Focus:** At CMU, Dr. Bisk leads the CLAW Lab, which includes members from the Language Technologies Institute, Machine Learning Department and Robotics Institute. The lab's research assumes that perception, embodiment, and language cannot exist without one another. Overall, they work to uncover the latent structures of natural language, modeling the semantics of the physical world, and connecting language to perception and control.\n\n### [Dr. Daniel Fried] \n\n_Assistant Professor, Language Technologies_\n\n**Education:** Ph.D., UC Berkeley\n\n**Research Focus:** Dr. Fried's lab focuses on building language interfaces that can help people with real-world tasks. They aim to make programming more commmunicative by creating models, methods, and datasets for producing code from language. Much of their work also takes a multi-agent system perspective on communication, showing that natural language processing agents can be improved by modeling the intents and interpretations people have when they use language.\n\n### [Dr. Graham Neubig] \n\n_Associate Professor, Language Technologies & Machine Learning_\n\n**Education:** Ph.D., Kyoto University\n\n**Research Focus:** Dr. Neubig's research focuses on language and its role in human communication, with a long-term goal of breaking down barriers in human-human or human-machine communication through the development of natural language processing (NLP) technologies. This includes technology for machine translation, which helps break down barriers in communication for people who speak different languages, and natural language understanding, which helps computers understand and respond to human language.\n\n## Is CMU the right fit?\n\nLet’s face it, pursuing any kind of advanced training is an investment of your time, energy and resources. Before you begin your application, take a moment to review the program requirements below.\n\nSuccessful applicants will have:\n\n- **A bachelor’s degree in computer science or a related field:** To successfully complete the coursework in this program, applicants should have an undergraduate degree in computer science, machine learning, data science, software engineering, or a related field.\n- **Proficiency in applied mathematics and statistics:** Students should have successfully completed coursework in applied mathematics (such as calculus and linear algebra) and statistics.\n- **Proficiency in Python:** Students should have a foundation in algorithms and data structures and be proficient in Python. If students do not have formal training in Python, knowledge gained through self-study or work experience will be considered if the student can provide evidence of proficiency.\n\n- **Proficiency in machine learning and deep learning concepts:** Students should have familiarity with machine learning and deep learning. If students do not have formal training in these topics, knowledge gained through self-study or work experience will be considered if the students can provide evidence of proficiency.\n- **A passion for learning and innovation:** The coursework in this program provides in-depth explorations of complicated topics related to machine learning and large language models. To master these concepts, students will need a hunger to learn and an unwavering drive to build imaginative solutions for their organization.\n\n## Admissions Information\n\nReady to apply? Here’s what you’ll need to complete the admissions process:\n\n### Complete the Online Application\n\n### Complete the Online Application\n\n[**Submit your application**] online in less than 30 minutes.\n\n### Submit your resume/CV\n\n### Submit your resume/CV\n\nWe’d like to learn more about your employment history, academic background, technical skills and professional achievements. Submit a 1 to 2 page resume or CV showcasing your experience.\n\n### Submit your transcripts\n\n### Submit your transcripts\n\nSubmit an unofficial copy of your transcript for each school you attended. Transcripts must include your name, the name of the college or university, the degree awarded (along with the conferral date), as well as the grade earned for each course. Email your transcripts directly to [apply@online.cmu.edu]. Former Carnegie Mellon students and alumni can request a copy of their CMU transcript from The Hub.\n\n### Upload a statement of purpose\n\n### Upload a statement of purpose\n\nTell us your professional story. Where have you been and where do you hope to go? In 500 words or less, explain your objective for applying to this program and what you hope to gain from completing the coursework.\n\n### Submit your TOEFL, IELTS, or DuoLingo test scores (if applicable)\n\n### Submit your TOEFL, IELTS, or DuoLingo test scores (if applicable)\n\nAn official TOEFL, IELTS or DuoLingo test is required for non-native English speakers. We prefer scores from the past two years but will consider older results if a copy is available. This requirement is waived for applicants with at least two years of professional work experience using English as their primary language.\n\n## Tuition\n\nBy enrolling in our graduate-level program, you'll be investing in your professional growth to prepare for the next wave of Generative AI solutions. We know this is a significant investment — not just for you, but for your family as well.\n\n**Carnegie Mellon alumni** are eligible for a scholarship to the Graduate Certificate in Generative AI & Large Language Models worth up to **20% of tuition**. Indicate your alumni status within the application to be eligible.\n\n#### So, what is the investment per course?\n\nBelow is a tuition breakdown for the 2025/2026 academic year:\n\n| Semester | Course | Units | Investment |\n| --- | --- | --- | --- |\n| Fall 2025 | Large Language Model Systems | 12 | $8,484 |\n| Spring 2026 | Multimodal Machine Learning | 12 | $8,484 |\n| Fall 2026 | Large Language Models: Methods and Applications | 12 | $8,484 |\n| **Total Investment** | **$25,452** |\n\n**2025/2026 Tuition Breakdown**\n\n#### Additional Course-Related Expenses\n\n- **Large Language Models: Methods and Applications** – To complete homework and activities, students will need to sign up for Amazon Web Services (AWS) or a similar service offering access to A10g (or equivalent) GPUs. Estimated cost: $150–$300 depending on usage. Additionally, students must sign up for the OpenAI API, with assignment costs up to $25. Access instructions will be provided at course start.\n- **Multimodal Machine Learning and Large Language Model Systems** – AWS and/or OpenAI or similar services may be required, with estimated fees up to $300 per course. More details will be shared closer to the course start dates.\n\n#### University Fees\n\nA technology fee of approximately **$245 per semester** will be assessed (subject to change).\n\n_Note:_ The rates listed above apply to the 2025/2026 academic year only. If the program is not completed within this timeframe, tuition may increase slightly for the following academic year.\n\n## About the School of Computer Science\n\nThe Graduate Certificate in Generative AI & Large Language Models is offered by the Language Technologies Institute (LTI) at CMU, which is housed within the highly-ranked School of Computer Science (SCS). SCS faculty are esteemed in their field, and many of them have collaborated on critical projects that have paved the way for future discoveries in artificial intelligence. Check out some of their work:\n\n- Researchers from CMU’s Robotics Institute completed a long-distance autonomous driving test in 1995 called the [No Hands Across America mission].\n- In 2001, SCS Founders University Professor Takeo Kanade and his team created a [video replay system called EyeVision] for Super Bowl XXXV.\n- In 2007, Faculty Emeritus William “Red” Whittaker led CMU’s Tartan Racing team to victory in the [DARPA’s Grand Challenge].\n- Assistant Research Professor László Jeni used computer vision technology to [create a facial recognition tool] that can help people with visual impairment.\n\n## Ready? Start Your Application Here\n\nLoading...",
    "length": 21179,
    "domain_restricted": true,
    "university": "Carnegie Mellon University",
    "domain": "cmu.edu"
  }
]